{"cells":[{"cell_type":"markdown","metadata":{"id":"XVaAULW6qhh1"},"source":["### Connect Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20471,"status":"ok","timestamp":1654703641458,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"_DdiqzlkZMhe","outputId":"316c4261-f812-4a24-a75d-9cd671f5de52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"markdown","metadata":{"id":"ttpluWU4tHLq"},"source":["### Package Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_3NHgGwZIsI"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.signal import savgol_filter\n","from collections import Counter\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from scipy.spatial import distance\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import seaborn as sns\n","from scipy.optimize import curve_fit\n","from scipy.signal import filtfilt\n","from collections import defaultdict"]},{"cell_type":"markdown","metadata":{"id":"6cosBM9Jd74f"},"source":["### GPU Device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":492,"status":"ok","timestamp":1654247471517,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"DbMtBMv4Rxa5","outputId":"d13feec4-38b6-4ea9-aa83-7c8a2d306ff1"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-f6cf7e79-58b3-b073-d5cd-5e82850ce4d2)\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1654247475337,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"bLu_lZGKu9dp","outputId":"4ad75c75-01fa-4c6c-db0a-2de1abd1bbfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["gpu = tf.test.gpu_device_name()\n","print(gpu)"]},{"cell_type":"markdown","metadata":{"id":"ihJkU1v2STVo"},"source":["### Pre-Processing Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1nRYshEtGy2"},"outputs":[],"source":["def decaying_exp(x, a, b):\n","    \"\"\" Returns exponential function\n","\n","    Parameters\n","    ----------\n","    x : ndarray\n","        times\n","    a : double\n","        t(inf) value\n","    b : double\n","        slope to t=0\n","        \n","    Returns\n","    -------\n","    ndarray\n","        y-axis values of the function\n","    \"\"\"\n","    return a*(1-np.exp(-b * x))\n","\n","\n","def fit_pixels_interpolate(time, X, interpolate_idx):\n","    \"\"\" Interpolates the curves for each pixel\n","\n","    Parameters\n","    ----------\n","    time : ndarray\n","        times\n","    X : ndarray\n","        TxNM array to be interpolated\n","    idx_active : ndarray\n","        NM array specifying pixels that are active\n","    interpolate_idx : int\n","        interpolation is performed until this index\n","\n","    Returns\n","    -------\n","    popt : ndarray\n","        optimal parameters for interpolation of each pixel, with shape 2xNM\n","    \"\"\"\n","    popt = np.zeros((2, X.shape[1]))\n","\n","    # for every pixel\n","    for i in range(X.shape[1]):\n","\n","      data = filtfilt(b=np.ones(10) / 10, a=[1], x=X[:, i])\n","\n","      # Fit the curve (interpolate) to the decaying exponential\n","      try:\n","        popt[:, i], pcov = curve_fit(decaying_exp, time[:interpolate_idx], data[:interpolate_idx], p0=[-10, 0.1])\n","      except:\n","        \n","        popt[:, i] = None\n","\n","    return popt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R9gzaEl7wE7H"},"outputs":[],"source":["def filter_by_drift(df, interpolate_idx):\n","\n","  \"\"\" Filters pixels by their fitting to the drift model\n","  \n","  Parameters\n","  ----------\n","  df : pandas.DataFrame \n","    DataFrame with pixel data that the fitting is applied to\n","  interpolate_idx : int\n","    Interpolation is perfromed until this index\n","\n","  Returns\n","  -------\n","  df : pandas.DataFrame\n","    DataFrame with only the data from the active pixels\n","  drfit_avg : numpy.array\n","    Array containing the average drift value at each time stamp\n","\n","  \"\"\"\n","\n","  popt = fit_pixels_interpolate(np.array(df.index), df.values, interpolate_idx)\n","\n","  drift_avg = np.zeros(df.shape[0])\n","  pix_count = 0\n","  active = np.array(np.zeros(df.shape[1]), dtype=bool)\n","\n","  for idx in range(df.shape[1]):\n","\n","  # check if any of the drift params for the pixel are nan\n","    if(np.isnan(popt[0, idx]) and np.isnan(popt[1, idx])):\n","      active[idx] = False\n","    else:\n","      # if drift params exist then iterate over the values of the index and use these as x values for the drift curve\n","      y_vals = []\n","      for i in df.index:\n","        val = decaying_exp(i, popt[0,idx], popt[1,idx])\n","        y_vals.append(val)\n","      \n","      # subtract the extrapolated drift from the signal\n","      drift_error = np.abs(np.array(df.values[:, idx] - y_vals))\n","      \n","      # only keep pixels with drift error of less than 30mV\n","      if((drift_error < 30).all()):\n","        drift_avg = np.add(drift_avg, np.array(y_vals))\n","        pix_count += 1\n","        active[idx] = True\n","      else:\n","        active[idx] = False\n","\n","  drift_avg/=pix_count\n","\n","  df = df.loc[:, active]\n","\n","  return df, drift_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W1YMbu9bSW5m"},"outputs":[],"source":["def filter_by_vref(X, v_thresh=70):\n","    '''\n","    Identifies active pixels by checking if one of the first 10 derivatives d(i) is > v_thresh\n","\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_thresh : int, optional\n","        Minimum value of the derivative d(i)=X(i+1)-X(i) in mV. Default is 70\n","        \n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if, during the first 10 samples,\n","        one of the derivatives is > v_thresh. The derivatives are calculated as d(i) = X(i+1)-X(i)\n","    '''\n","    return (np.diff(X[:10, :], axis=0) > v_thresh).any(axis=0)  # check if one of the first 10 derivatives is >v_thresh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XjXkAhKwSgFB"},"outputs":[],"source":["def filter_by_vrange(X, v_range=(100, 900)):\n","    '''\n","    Identifies active pixels by checking that all the values are in v_range\n","\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_range : (int, int), optional\n","        tuple containing the minimum and maximum allowable voltage in mV. Default is (100, 900)\n","        \n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if the value is always in v_range\n","    '''\n","    return (X < v_range[1]).all(axis=0) & (X > v_range[0]).all(axis=0)  # for each pixel, check if all the values are\n","    # within the given range\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5a7Uqi9Skg_"},"outputs":[],"source":["def filter_by_derivative(X, vthresh=5):\n","    \"\"\" Identifies active pixels by checking that the absolute value of the derivative is always below vthresh\n","\n","    Parameters\n","    ----------\n","    X : ndarray\n","        input 2D array of shape TxNM\n","    vthresh : int\n","        threshold for active pixels. Default is 5\n","        \n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if all the derivatives are below vthresh\n","    \"\"\"\n","    x_diff = np.abs(np.diff(X, axis=0))\n","    return (x_diff < vthresh).all(axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DhuoGbbPutKZ"},"outputs":[],"source":["def filter_active_pixels(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): \n","  \"\"\" Filters pixels by reference electrode voltage, derivative and voltage range \n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","    Dataframe containing pixel data which will be filtered \n","  v_thresh_ref : int, optional\n","    Threshold for active pixels for filtering by reference electrode volatge . Default is 50\n","  v_range : (int, int), optional\n","    Tuple containing the minimum and maximum allowable voltage in mV for the voltage range filteration. Default is (100, 900)\n","  v_thresh_deriv : int, optional\n","    Threshold for filtering pixels by derivative. Default is 5\n","\n","  Returns\n","  -------\n","  df : pandas.DataFrame\n","    DataFrame after data from inactive pixels is removed\n","  \"\"\"\n","  \n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZJkYzPiVvd6"},"outputs":[],"source":["def filter_active_pixels_deriv(df, v_thresh_deriv=5): \n","  \"\"\" Filters pixels by derivative  \n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","    Dataframe containing pixel data which will be filtered \n","  v_thresh_deriv : int, optional\n","    Threshold for filtering pixels by derivative. Default is 5\n","\n","  Returns\n","  -------\n","  df : pandas.DataFrame\n","    DataFrame after data from inactive pixels is removed\n","  \"\"\"\n","  \n","  active = filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imVXR8eVUrby"},"outputs":[],"source":["def filter_active_pixels_range(df, v_range=(100, 900)):\n","  \"\"\" Filters pixels by voltage range \n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","    Dataframe containing pixel data which will be filtered \n","  v_range : (int, int), optional\n","    Tuple containing the minimum and maximum allowable voltage in mV for the voltage range filteration. Default is (100, 900)\n","\n","  Returns\n","  -------\n","  df : pandas.DataFrame\n","    DataFrame after data from inactive pixels is removed\n","  \"\"\"\n","  \n","  active = filter_by_vrange(df.values, v_range)\n","\n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RTF9Vh78MZSB"},"outputs":[],"source":["def reshape_data(df, rows, cols):\n","  \"\"\" Reshapes TxNM data into TxNxM where (T = Number of time samples, N = Number of Rows, M = Number of Columns)\n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","    Dataframe containing pixel data which will be reshaped\n","  rows : int\n","    Number of rows \n","  cols : int\n","    Number of columns\n","\n","  Returns\n","  -------\n","  X : numpy.ndarray\n","    3D array containing the reshaped data \n","  \"\"\"\n","  X = df.values #pandas.DataFrame.values: Return a Numpy representation of the DataFrame.\n","  X = X.reshape(-1, rows, cols, order='F') #or C. different reshaping row by row or column by column but this works\n","  return X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9Xt8X4zL7hc"},"outputs":[],"source":["def filter_chemical_pixels(df, arr_rows, arr_cols):\n","  \"\"\" Removes all the temperature pixels from the data \n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","    Dataframe containing pixel data which will filtered\n","  rows : int\n","    Number of rows \n","  cols : int\n","    Number of columns\n","\n","  Returns\n","  -------\n","  df : pandas.DataFrame\n","    DataFrame after temperature pixels are removed\n","  \"\"\"\n","  X = reshape_data(df, arr_rows, arr_cols) # reshape data to T x 78 x 56\n","  X_mean = np.mean(X, axis=0) # get mean to have 78 x 56 shape\n","  X_mean[1::3, 1::3] = np.nan # set temperature pixels to nan\n","  X_mean = X_mean.flatten('F') # restore shape to 4068 \n","\n","  active_chemical = ~(np.isnan(X_mean)) # get bool array of all chemical pixels\n","\n","  # drop pixels \n","  df = df.loc[: , active_chemical]\n","  return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o82EQTYe9euH"},"outputs":[],"source":["def time_to_index(times, time_vect):\n","    '''\n","    Returns index of the times closest to the desired ones time_vect\n","\n","    Parameters\n","    ---------\n","    times : list\n","        list of integers containing the desired times\n","    time_vect : nparray\n","        array of the times at which the values are sampled\n","\n","    Returns\n","    -------\n","    list\n","        for each element in the input list times, return an element in the output list\n","        with the index of the sample closest to the desired time\n","    '''\n","    indices = []\n","    for time in times:  # for each time in the input list\n","        indices.append( np.argmin(np.abs(time_vect - time)) )\n","        # find index of the sampled time (in time_vect) closest to the desired one (time)\n","    return indices\n","\n","\n","def find_loading_time(time_vect, X, bounds=(600, 900)):  # for v2\n","    ''' Finds loading and settling time for the data of v2 chip\n","\n","    Parameters\n","    ----------\n","    time_vect : ndarray\n","        1D array with dimension T containing the sampling times\n","    X : ndarray\n","        2D array with dimension TxNM containing the sampled data\n","    bounds : list, optional\n","        tuple containing the minimum and maximum times (in ms) where the loading time has to be searched.\n","        Default is (600, 900)\n","        \n","    Returns\n","    -------\n","    tuple\n","        - settled_index : index at which the settling occurs\n","        - settled_time : time at which the settling occurs\n","    '''\n","\n","    search_start, search_end = time_to_index(bounds, time_vect)  # for each time in bounds, find the index\n","    # of the sample (in time_vect) that is closest to the desired one (in bounds)\n","    X_mean = np.mean(X, axis=1)  # for each sample, calculate the mean of all pixels\n","    X_mean_diff = np.diff(X_mean)  # find the derivative\n","\n","    loading_index = np.argmax(X_mean_diff[search_start:search_end]) + search_start + 1  # find the index\n","    # where the derivative is max in the specified interval\n","    loading_index = loading_index  # add settling time\n","    settled_index = loading_index + 10  # add settling time\n","    settled_time = time_vect[settled_index]  # find the time that index corresponds to\n","\n","    return settled_index, settled_time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9m8OqTUtQVb0"},"outputs":[],"source":["def preprocess_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","  \"\"\"Applies all pre-processing steps to single well experimental data\n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","    Dataframe containing pixel data which will pre-processed\n","  deriv_thresh : int\n","    Threshold for filtering by derivative\n","  deriv_thresh_bgsub : int, optional\n","    Threshold for filtering by derivative after background subtraction step\n","\n","  Returns\n","  -------\n","  df : pandas.DataFrame\n","    Transpose of the DataFrame with only data from active pixels after pre-processing\n","  \"\"\"\n","\n","  df = filter_chemical_pixels(df, 78, 56) # filter all chemical pixels\n","\n","  df = filter_active_pixels_drop(df=df, v_thresh_deriv=deriv_thresh, v_range=(100,900)) # filter pixels by range, vref and deriv\n","\n","  settle_idx, settle_time = find_loading_time(df.index, df, bounds=(600, 900)) # find settling point\n","  df = df.iloc[settle_idx + 10:, :] # use only the data after the settling time + 30s to allow reaction to have settled\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise don't\n","\n","  df = df.iloc[0:150+250, :] # take only 400 samples after settling point (approx 19-20mins) \n","\n","  df.index = df.index - df.index[0] # set the first time value to 0\n","  \n","  X, drift = filter_by_drift(df, 40) # filter by fitting of pixel to drift model\n","\n","  if(len(X.columns) != 0): \n","    df = X\n","    \n","  for col in df.columns:\n","    df[col] = savgol_filter(df[col],101, 3) # apply smoothing to each pixel \n","\n","  return df.T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9Er5B2BxpUK"},"outputs":[],"source":["def preprocess_partial_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","  \n","  \"\"\"Applies all pre-processing steps to double well experimental data\n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","    Dataframe containing pixel data which will pre-processed\n","  deriv_thresh : int\n","    Threshold for filtering by derivative\n","  deriv_thresh_bgsub : int, optional\n","    Threshold for filtering by derivative after background subtraction step\n","\n","  Returns\n","  -------\n","  df : pandas.DataFrame\n","    DataFrame with only data from active pixels after pre-processing\n","  \"\"\"\n","\n","  df = filter_active_pixels_range(df=df, v_range=(100,900)) # filter by range incase of any saturation\n","  \n","  df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh) # filter pixels by deriv\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise dont\n","\n","  df = df.iloc[:150+250, :] # take only 400 samples after settling point (approx 19-20mins) \n","\n","  df.index = df.index - df.index[0] # set the first time value to 0\n","  \n","  X, drift = filter_by_drift(df, 40) # filter by fitting of pixel to drift model\n","\n","  if(len(X.columns) != 0): \n","    df = X\n","\n","  for col in df.columns:\n","    df[col] = savgol_filter(df[col],101, 3) # apply smoothing to each pixel\n","    \n","  return df.T"]},{"cell_type":"markdown","metadata":{"id":"PaNIFO5iSa9C"},"source":["### Evaluation Metric Helper Functions"]},{"cell_type":"code","source":["def accuracy(classifications):\n","  \"\"\" Returns the value of the accuracy from predicted outputs and true outputs\n","\n","  Parameters\n","  ----------\n","  classifications : dictionary(tuple(int,int))\n","    Dictionary containing a tuple which holds the true output and prediction output from classification\n","\n","  Returns\n","  -------\n","  accuracy : double\n","    Classification Accuracy \n","  \"\"\"\n","  total = len(classifications)\n","  total_correct = 0\n","  for i in classifications.values():\n","    \n","    if(i[0] == None or i[1] == None): ## if any predictions are inconclusive \n","      continue\n","\n","    if(i[0] == i[1]):\n","      total_correct +=1\n","\n","  accuracy = (total_correct/total)\n","\n","  return accuracy"],"metadata":{"id":"U2zoSqPJLatm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sensitivity(classifications):\n","  \"\"\" Returns the value of the sensitivity from predicted outputs and true outputs\n","\n","  Parameters\n","  ----------\n","  classifications : dictionary(tuple(int,int))\n","    Dictionary containing a tuple which holds the true output and prediction output from classification\n","\n","  Returns\n","  -------\n","  sensitivity : double\n","    Classification sensitivity \n","  \"\"\"\n","  true_pos = 0\n","  false_neg = 0\n","\n","  for i in classifications.values():\n","\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","\n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 1 and predicted == 0):\n","      false_neg += 1\n","\n","  sensitivity = (true_pos/(true_pos + false_neg))\n","\n","  return sensitivity"],"metadata":{"id":"lzSAF5WsTIuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def specificity(classifications):\n","  \"\"\" Returns the value of the specificity from predicted outputs and true outputs\n","\n","  Parameters\n","  ----------\n","  classifications : dictionary(tuple(int,int))\n","    Dictionary containing a tuple which holds the true output and prediction output from classification\n","\n","  Returns\n","  -------\n","  specificity : double\n","    Classification specificity \n","  \"\"\"\n","\n","  true_neg = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 0 and predicted == 0):\n","      true_neg += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  specificity = (true_neg/(true_neg + false_pos))\n","\n","  return specificity"],"metadata":{"id":"WP_kdiXMYeU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def precision(classifications):\n","  \"\"\" Returns the value of the precision from predicted outputs and true outputs\n","\n","  Parameters\n","  ----------\n","  classifications : dictionary(tuple(int,int))\n","    Dictionary containing a tuple which holds the true output and prediction output from classification\n","\n","  Returns\n","  -------\n","  precision : double\n","    Classification precision \n","  \"\"\"\n","  true_pos = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  precision = (true_pos/(true_pos + false_pos))\n","\n","  return precision"],"metadata":{"id":"w7-_ZPDDaxRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def f1(classifications):\n","  \"\"\" Returns the value of the F1 score from predicted outputs and true outputs\n","\n","  Parameters\n","  ----------\n","  classifications : dictionary(tuple(int,int))\n","    Dictionary containing a tuple which holds the true output and prediction output from classification\n","\n","  Returns\n","  -------\n","  double\n","    Classification F1 score \n","  \"\"\"\n","  numerator = 2*precision(classifications)*sensitivity(classifications)\n","  denominator = precision(classifications) + sensitivity(classifications)\n","  return numerator/denominator"],"metadata":{"id":"qkFpU-UJbV1R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mp6t9KbXUtag"},"source":["### Data Loading Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72Rhya-GUxAS"},"outputs":[],"source":["def load_partial_covid_exp(filepath):\n","  \"\"\" Loading in double well experimental data from csv file\n","\n","  Parameters\n","  ----------\n","  filepath : string\n","    Path to the csv file that loads the double well data\n","  \n","  Returns\n","  -------\n","  df_pos : pandas.DataFrame\n","    DataFrame with pixel data from the positive well \n","  df_neg : panads.DataFrame\n","    DataFrame with pixel data from the negative well\n","  \"\"\"\n","  \n","  bot_filepath = filepath[:-4] + \"_bot.csv\"\n","  top_filepath = filepath[:-4] + \"_top.csv\"\n","\n","  ## load in 2 sheets\n","  df_neg = pd.read_csv(top_filepath, header=0, index_col=0)\n","  df_pos = pd.read_csv(bot_filepath, header=0, index_col=0)\n","\n","  return df_pos, df_neg"]},{"cell_type":"markdown","metadata":{"id":"W9kgS_-Cx1nm"},"source":["### Array Dims"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whsJZh4Zx0xs"},"outputs":[],"source":["arr_rows = 78\n","arr_cols = 56"]},{"cell_type":"markdown","metadata":{"id":"KCr7gvB_tf5-"},"source":["### Load Data"]},{"cell_type":"markdown","metadata":{"id":"AvJiLnQ8tiKx"},"source":["#### Positive Samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ekqd_pB0tuTS"},"outputs":[],"source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  avg_data_g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_data_export.csv\"\n","  avg_g1 = pd.read_csv(avg_data_g1_file, header=0)\n","\n","  ## Gamma 2\n","  avg_data_g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_data_export.csv\"\n","  avg_g2 = pd.read_csv(avg_data_g2_file, header=0)\n","\n","  ## Gamma 3\n","  avg_data_g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_data_export.csv\"\n","  avg_g3 = pd.read_csv(avg_data_g3_file, header=0)\n","  \n","  ## Gamma 5 \n","  avg_data_g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_data_export.csv\"\n","  avg_g5 = pd.read_csv(avg_data_g5_file, header=0)\n","\n","  ## 22RV1.ap1\n","  avg_data_22rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_data_export.csv\"\n","  avg_22rv1_ap1 = pd.read_csv(avg_data_22rv1_ap1_file, header=0)\n","\n","  ## 22RV1.ap2\n","  avg_data_22rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_data_export.csv\"\n","  avg_22rv1_ap2 = pd.read_csv(avg_data_22rv1_ap2_file, header=0)\n","\n","  ## 22RV1y.p3\n","  avg_data_22rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_data_export.csv\"\n","  avg_22rv1y_p3 = pd.read_csv(avg_data_22rv1y_p3_file, header=0)\n","\n","  ## 22RV1y.p4\n","  avg_data_22rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_data_export.csv\"\n","  avg_22rv1y_p4 = pd.read_csv(avg_data_22rv1y_p4_file, header=0)\n","\n","  ## ARV7.p1\n","  avg_data_arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_data_export.csv\"\n","  avg_arv7_p1 = pd.read_csv(avg_data_arv7_p1_file, header=0).iloc[1:, :].reset_index(drop=True) # row 0 was NAN\n","\n","  ## ARV7.p3\n","  avg_data_arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_data_export.csv\"\n","  avg_arv7_p3 = pd.read_csv(avg_data_arv7_p3_file, header=0)\n","\n","  ## ARV7.p4\n","  avg_data_arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_data_export.csv\"\n","  avg_arv7_p4 = pd.read_csv(avg_data_arv7_p4_file, header=0)\n","\n","  ## Beta 1\n","  avg_data_b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_data_export.csv\"\n","  avg_b1 = pd.read_csv(avg_data_b1_file, header=0)\n","\n","  ## Beta 2\n","  avg_data_b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_data_export.csv\"\n","  avg_b2 = pd.read_csv(avg_data_b2_file, header=0)\n","\n","  ## Beta 5\n","  avg_data_b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_data_export.csv\"\n","  avg_b5 = pd.read_csv(avg_data_b5_file, header=0)\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZRah5zpxXp6"},"outputs":[],"source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_vsChem_export.csv\"\n","  g1 = pd.read_csv(g1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g1.index = avg_g1[\"Time Elapsed\"]\n","\n","  ## Gamma 2\n","  g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_vsChem_export.csv\"\n","  g2 = pd.read_csv(g2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g2.index = avg_g2[\"Time Elapsed\"]\n","\n","  ## Gamma 3\n","  g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_vsChem_export.csv\"\n","  g3 = pd.read_csv(g3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g3.index = avg_g3[\"Time Elapsed\"]\n","\n","  ## Gamma 5\n","  g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_vsChem_export.csv\"\n","  g5 = pd.read_csv(g5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g5.index = avg_g5[\"Time Elapsed\"]\n","\n","  ## 22RV1.ap1\n","  rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_vsChem_export.csv\"\n","  rv1_ap1 = pd.read_csv(rv1_ap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap1.index = avg_22rv1_ap1['Time Elapsed']\n","\n","  ## 22RV1.ap2\n","  rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_vsChem_export.csv\"\n","  rv1_ap2 = pd.read_csv(rv1_ap2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap2.index = avg_22rv1_ap2['Time Elapsed']\n","\n","  ## 22RV1y.p3\n","  rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_vsChem_export.csv\"\n","  rv1y_p3 = pd.read_csv(rv1y_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p3.index = avg_22rv1y_p3['Time Elapsed']\n","\n","  ## 22RV1y.p4\n","  rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_vsChem_export.csv\"\n","  rv1y_p4 = pd.read_csv(rv1y_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p4.index = avg_22rv1y_p4['Time Elapsed']\n","\n","  ## ARV7.p1 \n","  arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_vsChem_export.csv\"\n","  arv7_p1 = pd.read_csv(arv7_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)] \n","  arv7_p1.index = avg_arv7_p1[\"Time Elapsed\"]\n","\n","  ## ARV7.p3 \n","  arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_vsChem_export.csv\"\n","  arv7_p3 = pd.read_csv(arv7_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p3.index = avg_arv7_p3[\"Time Elapsed\"]\n","\n","  ## ARV7.p4 \n","  arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_vsChem_export.csv\"\n","  arv7_p4 = pd.read_csv(arv7_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p4.index = avg_arv7_p4[\"Time Elapsed\"]\n","\n","  ## Beta 1\n","  b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_vsChem_export.csv\"\n","  b1 = pd.read_csv(b1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b1.index = avg_b1[\"Time Elapsed\"]\n","\n","  ## Beta 2\n","  b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_vsChem_export.csv\"\n","  b2 = pd.read_csv(b2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b2.index = avg_b2[\"Time Elapsed\"]\n","\n","  ## Beta 5\n","  b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_vsChem_export.csv\"\n","  b5 = pd.read_csv(b5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b5.index = avg_b5[\"Time Elapsed\"]"]},{"cell_type":"markdown","metadata":{"id":"7qOF9VBstkbe"},"source":["#### Negative Samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mlU83yKsuSHV"},"outputs":[],"source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):  \n","  ## ARV7.n1\n","  avg_data_arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_data_export.csv\"\n","  avg_arv7 = pd.read_csv(avg_data_arv7_file, header=0)\n","\n","  ## Yap.n2\n","  avg_data_yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_data_export.csv\"\n","  avg_yap = pd.read_csv(avg_data_yap_file, header=0)\n","\n","  ## Yap1.n2\n","  avg_data_yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_data_export.csv\"\n","  avg_yap1 = pd.read_csv(avg_data_yap1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## Yap1.n1.1 \n","  avg_data_yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_data_export.csv\"\n","  avg_yap1n1 = pd.read_csv(avg_data_yap1n1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## ARV7.n2\n","  avg_data_arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_data_export.csv\"\n","  avg_arv72 = pd.read_csv(avg_data_arv72_file, header=0)\n","\n","  ## ARV7.n3\n","  avg_data_arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_data_export.csv\"\n","  avg_arv73 = pd.read_csv(avg_data_arv73_file, header=0)\n","\n","  ## DU145y.n1\n","  avg_data_du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_data_export.csv\"\n","  avg_du145y_n1 = pd.read_csv(avg_data_du145y_n1_file, header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W3_XExOjypwI"},"outputs":[],"source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):  \n","  ## ARV7.n1 \n","  arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_vsChem_export.csv\"\n","  arv7 = pd.read_csv(arv7_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7.index = avg_arv7[\"Time Elapsed\"]\n","\n","  ## Yap.n2\n","  yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_vsChem_export.csv\"\n","  yap = pd.read_csv(yap_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap.index = avg_yap[\"Time Elapsed\"]\n","\n","  ## Yap1.n2\n","  yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_vsChem_export.csv\"\n","  yap1 = pd.read_csv(yap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1.index = avg_yap1[\"Time Elapsed\"]\n","\n","  ## Yap1.n1.1\n","  yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_vsChem_export.csv\"\n","  yap1n1 = pd.read_csv(yap1n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1n1.index = avg_yap1n1[\"Time Elapsed\"]\n","\n","  ## ARV7.n2\n","  arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_vsChem_export.csv\"\n","  arv72 = pd.read_csv(arv72_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv72.index = avg_arv72[\"Time Elapsed\"]\n","\n","  ## ARV7.n3\n","  arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_vsChem_export.csv\"\n","  arv73 = pd.read_csv(arv73_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv73.index = avg_arv73[\"Time Elapsed\"]\n","\n","  ## DU145y.n1\n","  du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_vsChem_export.csv\"\n","  du145y_n1 = pd.read_csv(du145y_n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145y_n1.index = avg_du145y_n1[\"Time Elapsed\"]"]},{"cell_type":"markdown","metadata":{"id":"AXQUM6RDTajp"},"source":["#### Covid Partial Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xoTwuHUETf5a"},"outputs":[],"source":["## 150520_2_118\n","avg_118_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_2_118/exp_summary_118.csv\"\n","exp_118_pos, exp_118_neg = load_partial_covid_exp(avg_118_file)\n","\n","## 150520_4_2_86\n","avg_86_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_4_2_86/exp_summary_86.csv\"\n","exp_86_pos, exp_86_neg = load_partial_covid_exp(avg_86_file)\n","\n","## 150520_5_129\n","avg_129_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_5_129/exp_summary_129.csv\"\n","exp_129_pos, exp_129_neg = load_partial_covid_exp(avg_129_file)\n","\n","## 180520_4_165\n","avg_165_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_4_165/exp_summary_165.csv\"\n","exp_165_pos, exp_165_neg = load_partial_covid_exp(avg_165_file)\n","\n","## 180520_6_35\n","avg_35_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_6_35/exp_summary_35.csv\"\n","exp_35_pos, exp_35_neg = load_partial_covid_exp(avg_35_file)\n","\n","## 190520_1_28\n","avg_28_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_1_28/exp_summary_28.csv\"\n","exp_28_pos, exp_28_neg = load_partial_covid_exp(avg_28_file) \n","\n","## 190520_2_14\n","avg_14_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_2_14/exp_summary_14.csv\"\n","exp_14_pos, exp_14_neg = load_partial_covid_exp(avg_14_file)\n","\n","## 210520_2_40\n","avg_40_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_2_40/exp_summary_40.csv\"\n","exp_40_pos, exp_40_neg = load_partial_covid_exp(avg_40_file)\n","\n","## 210520_3_88\n","avg_88_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_3_88/exp_summary_88.csv\"\n","exp_88_pos, exp_88_neg = load_partial_covid_exp(avg_88_file)\n","\n","## 210520_6_27\n","avg_27_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_6_27/exp_summary_27.csv\"\n","exp_27_pos, exp_27_neg = load_partial_covid_exp(avg_27_file)\n","\n","## 250520_1_134\n","avg_134_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_1_134/exp_summary_134.csv\"\n","exp_134_pos, exp_134_neg = load_partial_covid_exp(avg_134_file)\n","\n","## 250520_2_97\n","avg_97_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_2_97/exp_summary_97.csv\"\n","exp_97_pos, exp_97_neg = load_partial_covid_exp(avg_97_file)\n","\n","## 250520_6_2D1\n","avg_2d1_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_6_2D1/exp_summary_2D1.csv\"\n","exp_2d1_pos, exp_2d1_neg = load_partial_covid_exp(avg_2d1_file)\n","\n","## 250520_7_64\n","avg_64_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_7_64/exp_summary_64.csv\"\n","exp_64_pos, exp_64_neg = load_partial_covid_exp(avg_64_file)"]},{"cell_type":"markdown","metadata":{"id":"7XgnkewwwPki"},"source":["### Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"CTcUwvRiwUmJ"},"source":["#### Positive Samples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77380,"status":"ok","timestamp":1654247641361,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"1-WlDoK49D2Y","outputId":"87442d4a-415f-4ef8-dd5a-fd67ce44ea4e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n"]}],"source":["g1 = preprocess_data(g1, 500)\n","g2 = preprocess_data(g2, 500) #-- 5.2865965366363525\n","g3 = preprocess_data(g3, 500) #-- 8.670833349227905\n","g5 = preprocess_data(g5, 500) #-- 5.734365940093994\n","rv1_ap1 = preprocess_data(rv1_ap1, 500)\n","rv1_ap2 = preprocess_data(rv1_ap2, 500) #-- 6.83215594291687\n","rv1y_p3 = preprocess_data(rv1y_p3, 500) \n","rv1y_p4 = preprocess_data(rv1y_p4, 500)\n","arv7_p1 = preprocess_data(arv7_p1, 500)\n","arv7_p3 = preprocess_data(arv7_p3, 500)\n","arv7_p4 = preprocess_data(arv7_p4, 500)\n","b1 = preprocess_data(b1, 500) #-- 7.712360858917236\n","b2 = preprocess_data(b2, 500) #-- 7.934495210647583\n","b5 = preprocess_data(b5, 500)"]},{"cell_type":"markdown","metadata":{"id":"1WaPBFGuwYN4"},"source":["#### Negative Samples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38794,"status":"ok","timestamp":1654247680144,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"gazhgzLT9HLV","outputId":"d44a6b2f-47c6-4d3c-e9f8-9e7e6eae8924"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n","/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n"]}],"source":["arv7 = preprocess_data(arv7, 500)\n","yap = preprocess_data(yap, 500) #--8.715267419815063\n","yap1 = preprocess_data(yap1, 500)\n","yap1n1 = preprocess_data(yap1n1, 500)\n","arv72 = preprocess_data(arv72, 500)\n","arv73 = preprocess_data(arv73, 500)\n","du145y_n1 = preprocess_data(du145y_n1, 500)"]},{"cell_type":"markdown","metadata":{"id":"nUwBPNQNjQ7w"},"source":["#### Covid Partial Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31455,"status":"ok","timestamp":1654247711586,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"HQBQ_1YF9Oqj","outputId":"1e5f14d3-5d67-4071-a477-7847f5f6b9b1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"]}],"source":["exp_118_pos = preprocess_partial_data(exp_118_pos, 500)\n","exp_86_pos = preprocess_partial_data(exp_86_pos, 500)\n","exp_129_pos = preprocess_partial_data(exp_129_pos, 500)\n","exp_165_pos = preprocess_partial_data(exp_165_pos, 500)\n","exp_35_pos = preprocess_partial_data(exp_35_pos, 500)\n","exp_28_pos = preprocess_partial_data(exp_28_pos, 500)\n","exp_14_pos = preprocess_partial_data(exp_14_pos, 500)\n","exp_40_pos = preprocess_partial_data(exp_40_pos, 500)\n","exp_88_pos = preprocess_partial_data(exp_88_pos, 500)\n","exp_27_pos = preprocess_partial_data(exp_27_pos, 500)\n","exp_134_pos = preprocess_partial_data(exp_134_pos, 500)\n","exp_97_pos = preprocess_partial_data(exp_97_pos, 500)\n","exp_2d1_pos = preprocess_partial_data(exp_2d1_pos, 500)\n","exp_64_pos = preprocess_partial_data(exp_64_pos, 500)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYsOnsAW9Rob"},"outputs":[],"source":["exp_118_neg = preprocess_partial_data(exp_118_neg, 500)\n","exp_86_neg = preprocess_partial_data(exp_86_neg, 500)\n","exp_129_neg = preprocess_partial_data(exp_129_neg, 500)\n","exp_165_neg = preprocess_partial_data(exp_165_neg, 500)\n","exp_35_neg = preprocess_partial_data(exp_35_neg, 500)\n","exp_28_neg = preprocess_partial_data(exp_28_neg, 500)\n","exp_14_neg = preprocess_partial_data(exp_14_neg, 500)\n","exp_40_neg = preprocess_partial_data(exp_40_neg, 500)\n","exp_88_neg = preprocess_partial_data(exp_88_neg, 500)\n","exp_27_neg = preprocess_partial_data(exp_27_neg, 500)\n","exp_134_neg = preprocess_partial_data(exp_134_neg, 500)\n","exp_97_neg = preprocess_partial_data(exp_97_neg, 500)\n","exp_2d1_neg = preprocess_partial_data(exp_2d1_neg, 500)\n","exp_64_neg = preprocess_partial_data(exp_64_neg, 500)"]},{"cell_type":"markdown","metadata":{"id":"cco-BOwij9af"},"source":["### Machine Learning - Neural Network Ensemble"]},{"cell_type":"markdown","metadata":{"id":"j5qgb5mx3rOW"},"source":["#### Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OIYXEisg2WX_"},"outputs":[],"source":["def get_training_data_nn(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \"\"\" Gets the training data for the neural network classifier at a given timestamp\n","\n","  Parameters\n","  ----------\n","  positive_samples : dict(pandas.DataFrame)\n","    Dictionary of DataFrames with data from all the positive experiements\n","  negative_samples : dict(pandas.DataFrame)\n","    Dictionary of DataFrames with data from all the negative experiements\n","  timestamp : int\n","    Number of data-points which the data for each experiement must be truncated to\n","  test_samples : array, optional\n","    Array containing the name (key used in the dictionary) of the test samples, Default is []\n","\n","  Returns\n","  -------\n","  numpy.ndarray\n","    Contains the training data for the classifier at the given time stamp\n","  training_labels : numpy.array\n","    1D array with the true labels for each of the training experiements\n","  \"\"\"\n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","    \n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp (keep all rows and turncate columns)\n","    pos_subsample = sample.to_numpy()[:, 0:timestamp]\n","\n","    ## pos_count = 0 means this is first sample to set training data = sample ortherwise update training data \n","    if(pos_count == 0):\n","      training_data = pos_subsample\n","    else:\n","      training_data = np.concatenate((training_data,pos_subsample))\n","\n","    ## increment count of number of positive samples\n","    pos_count += len(sample)\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","    \n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp (keep all rows and turncate columns)\n","    neg_subsample = sample.to_numpy()[:, 0:timestamp]\n","\n","    ## update training data\n","    training_data = np.concatenate((training_data,neg_subsample))\n","\n","    ## increment count of number of negative samples\n","    neg_count += len(sample)\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xH5J1l0cgIHI"},"outputs":[],"source":["def get_test_data_nn(sample, timestamp):\n","  \"\"\" Gets the test data for the neural network classifier at a given timestamp for a test sample\n","\n","  Parameters\n","  ----------\n","  sample : pandas.DataFrame\n","    The test sample to be used \n","  timestamp : int\n","    Number of data-points which the data for each experiement must be truncated to\n","\n","  Returns\n","  -------\n","  numpy.ndarray\n","    Contains the test data for the classifier at the given time stamp\n","  \"\"\"\n","  subsample = sample.to_numpy()[:, 0:timestamp]\n","\n","  return np.asarray(subsample)"]},{"cell_type":"markdown","metadata":{"id":"d6Qyl80Wzy-r"},"source":["#### Training Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-bA8RfjcM35"},"outputs":[],"source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7}"]},{"cell_type":"markdown","metadata":{"id":"rxkmk6GHqC7g"},"source":["#### Model Specs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eztwFZUaloVP"},"outputs":[],"source":["number_of_samples = len(g1.columns)\n","number_of_classifiers = 50\n","\n","timestep = int(number_of_samples/number_of_classifiers)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]\n","\n","batch_size = 250\n","epochs = 15\n","loss_function = 'binary_crossentropy'\n","optimiser = 'adam'"]},{"cell_type":"markdown","metadata":{"id":"qG3eDbNkqG9A"},"source":["#### Creating Ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVVPVw4-ndtu"},"outputs":[],"source":["def create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples, positives, negatives):\n","  \"\"\" Makes and trains an ensemble of neural networks\n","\n","  Parameters\n","  ----------\n","  number_of_classifiers : int\n","    Number of classifers in the ensemble \n","  batch_size : int\n","    Number of experiements per batch during training\n","  epochs : int\n","    Number of epochs trained for\n","  loss_function : string\n","    Function used to calculate model loss\n","  optimiser : string\n","    Optimiser used during training\n","  timestamps : array(int)\n","    Array of timestamps at which the predictions are made\n","  test_samples : string\n","    The name of the experiements to used as the test samples\n","\n","  Returns\n","  -------\n","  neural_nets : array\n","    Array of trained neural networks\n","  \"\"\"\n","  neural_nets = [0]*number_of_classifiers\n","\n","  for i in range(number_of_classifiers):\n","\n","    ## make model \n","    neural_nets[i] = Sequential()\n","    neural_nets[i].add(Dense(32, activation='relu', input_dim = timestamps[i]))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(128, activation='relu'))\n","    neural_nets[i].add(Dense(512, activation='relu'))\n","    neural_nets[i].add(Dense(1024, activation='relu'))\n","    neural_nets[i].add(Dense(2048, activation='relu'))\n","    neural_nets[i].add(Dense(1, activation='sigmoid'))\n","\n","    ## compile model \n","    neural_nets[i].compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])\n","\n","    ## training data\n","    training_data, training_label = get_training_data_nn(positive_samples=positives, negative_samples=negatives, timestamp=timestamps[i], test_samples=[test_samples])\n","\n","    ## train model\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n","    neural_nets[i].fit(training_data, training_label,  batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[callback], verbose=0)\n","\n","    # print(\"\\n\\n\")\n","\n","  return neural_nets"]},{"cell_type":"markdown","metadata":{"id":"fGH97jNBfzdu"},"source":["#### Evaluating Ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7K7KpmnZU0s"},"outputs":[],"source":["def get_time_index(timestamps, predictions):\n","  \"\"\" Get the timestamp (in terms of number of data points) where the majority vote has been achived for an ensmeble of classifiers\n","\n","  Parameters\n","  ----------\n","  timestamps : array\n","    Array of ints with timestamps when each classification is made\n","  predictions : array\n","    Array containing the prediction made by the classifiers at each of the timestamps\n","\n","  Returns\n","  -------\n","    int\n","      The number of data-points after which the majority vote is determined for an ensemble of classifiers \n","  \"\"\"\n","\n","  ## create dict to hold count of predictions\n","  label_counters = defaultdict(int)\n","\n","  ## add entries to dict\n","  for index, pred in enumerate(predictions):\n","    label_counters[pred] += 1\n","\n","    ## if label count == half of total possible predictions then majority is achieved\n","    if(label_counters[pred] == int(len(predictions)/2)+1):\n","      return timestamps[index]\n","  \n","  return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_T5qTYuPFVA"},"outputs":[],"source":["def get_predictions(number_of_classifiers, ensemble, test_sample, timestamps):\n","  \"\"\" Get final prediction and time to result from neural network ensemble\n","\n","  Parameters\n","  ----------\n","  ensemble : array\n","    Array of trained neural network models\n","  timestamps : array(int)\n","    Array of timestamps at which the predictions are made\n","  test_sample : array\n","    The time series data for the experiement used as the test sample\n","\n","  Returns\n","  -------\n","  final_prediction : double \n","    Final output prediction from the ensmble\n","  time_to_result : int\n","    Time in seconds when the final classification was determined\n","  \"\"\"\n","\n","  pred = []\n","  final_preds = []\n","  \n","  for i in range(number_of_classifiers):\n","    ## create test data that will be predicted by each neural net (will be for every pixel)\n","    test_data = get_test_data_nn(test_sample, timestamps[i])\n","  \n","    ## make prediction for every pixel \n","    en_pred = en[i].predict(test_data)\n","\n","    ## make array of predictions for each pixel (each row is the predictions for one pixel)\n","    if(i==0):\n","      pred = en_pred\n","    else:\n","      pred = np.concatenate((pred, en_pred), axis = 1)\n","    \n","  ## round any value > 0.5 to 1 and < 0.5 to 0 \n","  pred = pred.round()\n","\n","\n","  ## for each classifier count the number of predictions as 1 or 0 and use the max to make final classifier pred as 0 or 1 \n","  for i in range(number_of_classifiers):\n","    classifier_preds = pred[:, i] ## get the predictions made for each pixel by the classifier\n","    final_classifier_pred = Counter(classifier_preds).most_common(1)[0][0] ## get majority pixel vote\n","    final_preds.append(final_classifier_pred) \n","\n","  ## make final prediction for the sample based on majority classifier prediction\n","  final_prediction = Counter(final_preds).most_common(1)[0][0]\n","\n","  ## get ttp from the list of preds made by each classifier\n","  time_index = get_time_index(timestamps, final_preds)\n","  time_to_result = test_sample.T.index[time_index-1] - test_sample.T.index[0]\n","  \n","  return final_prediction, time_to_result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPk5gIj2OrNp"},"outputs":[],"source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(negatives)\n","all_samples.update(positives)\n","\n","## create dict of samples with true labels\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.zeros(len(negatives)),np.ones(len(positives)))))\n","true_label_dict = dict(zip(keys, true_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FvT0rQlGBCB"},"outputs":[],"source":["final_classifications = {}\n","final_predictions = []\n","final_TTP = []\n","prediction_correctness = []\n","\n","with tf.device(gpu):\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","    print(f\"Testing sample: {test_sample_name}...\")\n","\n","    # make ensemble\n","    en = create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_sample_name, positives, negatives)\n","\n","    # get prediction and time to result\n","    sample_classification, time_to_result = get_predictions(number_of_classifiers, en, test_sample, timestamps)\n","\n","    # update arrays with final outcome and time to result\n","    final_predictions.append(sample_classification)\n","    prediction_correctness.append(\"Yes\" if sample_classification == true_label_dict[key] else \"No\")\n","\n","    final_classifications[key] = (sample_classification, true_label_dict[key])\n","    print(f\"Predicted Label: {sample_classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {sample_classification ==true_label_dict[key]} \\n\")\n","\n","    # if final prediction is positive get ttp \n","    if(sample_classification == 1.0):\n","      final_TTP.append(round((time_to_result+30)/60, 2)) # 30s added on because of pre-processing which takes start as 30s after actual start point\n","      print(f\"TTP: {time_to_result + 30}s \\t {round((time_to_result+30)/60, 2)} mins\")\n","    else:\n","      final_TTP.append(np.nan)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhkc8Lnr9-c2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654051117316,"user_tz":-60,"elapsed":32,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"46d62df5-d293-44ac-89b4-d114f1561ea7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 51.02040816326531\n","Sensitivity/Recall: 57.14285714285714\n","Specificity: 42.857142857142854\n","Precision: 57.14285714285714\n","F1 Score: 57.14285714285714\n"]}],"source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"]},{"cell_type":"markdown","source":["#### Confusion Matrix"],"metadata":{"id":"Qgj65jfXBQqS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qf85cGzE6M15","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"ok","timestamp":1654051117672,"user_tz":-60,"elapsed":372,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"281ed2f4-a686-449a-aa11-cea24802ed40"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 24.0, 'Predicted Output')"]},"metadata":{},"execution_count":54},{"output_type":"display_data","data":{"text/plain":["<Figure size 504x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["cm = confusion_matrix(true_labels, final_predictions, labels=[0, 1])\n","fig, ax = plt.subplots(1,1,figsize=(7,5))\n","heatmap = sns.heatmap(cm, annot=True, annot_kws={\"size\": 15}, linewidth=0.75, \n","            xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"], cbar=False, cmap='RdPu')\n","\n","heatmap.set_xticklabels(heatmap.get_xmajorticklabels(), fontsize = 15)\n","heatmap.set_yticklabels(heatmap.get_ymajorticklabels(), fontsize = 15)\n","\n","ax.set_ylabel('True Output', fontsize=15, labelpad=15)\n","ax.set_xlabel('Predicted Output', fontsize=15, labelpad=15)"]},{"cell_type":"markdown","metadata":{"id":"simepEdKIiL0"},"source":["### Github Commands"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1654703641459,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"YdlGDV3AzZ1L","outputId":"2d61b90d-c1d2-4b24-bbc9-36b5598b5c5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77268,"status":"ok","timestamp":1654703718714,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"itbAqo9qGukN","outputId":"b6dd324d-e812-4c70-ede8-c3e38a6c12b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add/rm <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mdeleted:    Best Performances.docx\u001b[m\n","\t\u001b[31mmodified:   Early Time Series Classification - Average Ouput KNN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Early Time Series Classification - Average Ouput NN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Early Time Series Classification - Pixel Data NN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Initial Data Analysis.ipynb\u001b[m\n","\t\u001b[31mmodified:   Visualisations.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}],"source":["username = \"adityag16\"\n","git_token = \"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\"\n","repository = \"/content/drive/MyDrive/Final-Year-Project\"\n","%cd {repository}\n","!git status"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1156,"status":"ok","timestamp":1654703719851,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"pNInxPqdG7nx","outputId":"5a21b2d8-f64b-4f4a-8dd4-462bfada106f"},"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git reset HEAD <file>...\" to unstage)\n","\n","\t\u001b[32mmodified:   Early Time Series Classification - Pixel Data NN.ipynb\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add/rm <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mdeleted:    Best Performances.docx\u001b[m\n","\t\u001b[31mmodified:   Early Time Series Classification - Average Ouput KNN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Early Time Series Classification - Average Ouput NN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Initial Data Analysis.ipynb\u001b[m\n","\t\u001b[31mmodified:   Visualisations.ipynb\u001b[m\n","\n"]}],"source":["!git add \"Early Time Series Classification - Pixel Data NN.ipynb\"\n","!git status"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25347,"status":"ok","timestamp":1654703745192,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"K1tS6nonHF9u","outputId":"d7f6ab8e-5a68-4a08-d47a-fa283a25819e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[main 64ec4a4] Added Documentaion -- need to fix filepaths\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite Early Time Series Classification - Pixel Data NN.ipynb (97%)\n","Counting objects: 3, done.\n","Delta compression using up to 4 threads.\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 16.75 KiB | 3.35 MiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/adityag16/Final-Year-Project\n","   24ba096..64ec4a4  main -> main\n"]}],"source":["!git config --global user.email \"aditya.gupta18@imperial.ac.uk\"\n","!git config --global user.name \"adityag16\"\n","\n","!git commit -m \"Added Documentaion -- need to fix filepaths\"\n","!git push origin main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8KO_iVTj0cIP"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["XVaAULW6qhh1","ttpluWU4tHLq","6cosBM9Jd74f","ihJkU1v2STVo","PaNIFO5iSa9C","Mp6t9KbXUtag","W9kgS_-Cx1nm","KCr7gvB_tf5-","7XgnkewwwPki","j5qgb5mx3rOW"],"machine_shape":"hm","name":"Early Time Series Classification - Pixel Data NN.ipynb","toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyPZ9lCMnuMTHihgzWO69EuO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
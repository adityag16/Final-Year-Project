{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Early Time Series Classification - Pixel Data NN.ipynb","provenance":[],"toc_visible":true,"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPBjRxEkU17XrHDlD3GnCCt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Connect Drive"],"metadata":{"id":"XVaAULW6qhh1"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21509,"status":"ok","timestamp":1653067727361,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"_DdiqzlkZMhe","outputId":"9406734d-282d-4ec7-d035-018e987816d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"markdown","metadata":{"id":"ttpluWU4tHLq"},"source":["### Package Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_3NHgGwZIsI"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.signal import savgol_filter\n","from collections import Counter"]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from scipy.spatial import distance\n","from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances"],"metadata":{"id":"5vMvjgqYCd2d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GPU Device"],"metadata":{"id":"6cosBM9Jd74f"}},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DbMtBMv4Rxa5","executionInfo":{"status":"ok","timestamp":1650488796356,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8be33a7e-69c2-401d-9164-887755456b12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-0a827671-bfd2-c73a-d984-1813501eb611)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1650488796662,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"bLu_lZGKu9dp","outputId":"f4aed792-8ae3-44a5-d949-46a2517cfa0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["gpu = tf.test.gpu_device_name()\n","print(gpu)"]},{"cell_type":"markdown","metadata":{"id":"ihJkU1v2STVo"},"source":["### Pre-Processing Helper Functions"]},{"cell_type":"code","source":["def decaying_exp(x, a, b):\n","    \"\"\" Returns exponential function\n","    Parameters\n","    ----------\n","    x : ndarray\n","        times\n","    a : double\n","        t(inf) value\n","    b : double\n","        slope to t=0\n","    Returns\n","    -------\n","    ndarray\n","        y-axis values of the function\n","    \"\"\"\n","    return a*(1-np.exp(-b * x))\n","\n","\n","def fit_pixels_interpolate(time, X, interpolate_idx):\n","    \"\"\" Interpolates the curves for each pixel\n","    Parameters\n","    ----------\n","    time : ndarray\n","        times\n","    X : ndarray\n","        TxNM array to be interpolated\n","    idx_active : ndarray\n","        NM array specifying pixels that are active\n","    interpolate_idx : int\n","        interpolation is performed until this index\n","    Returns\n","    -------\n","    popt : ndarray\n","        optimal parameters for interpolation of each pixel, with shape 2xNM\n","    \"\"\"\n","    popt = np.zeros((2, X.shape[1]))\n","\n","    # for every pixel\n","    for i in range(X.shape[1]):\n","\n","      data = filtfilt(b=np.ones(10) / 10, a=[1], x=X[:, i])\n","\n","      # Fit the curve (interpolate)\n","      try:\n","        popt[:, i], pcov = curve_fit(decaying_exp, time[:interpolate_idx], data[:interpolate_idx], p0=[-10, 0.1])\n","      except:\n","        # print('EXCEPT: could not fit this pixel', i)\n","        popt[:, i] = None\n","\n","    return popt"],"metadata":{"id":"g1nRYshEtGy2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filter_by_drift(df, interpolate_idx):\n","\n","  popt = fit_pixels_interpolate(np.array(df.index), df.values, interpolate_idx)\n","\n","  drift_avg = np.zeros(df.shape[0])\n","  pix_count = 0\n","  active = np.array(np.zeros(df.shape[1]), dtype=bool)\n","\n","  for idx in range(df.shape[1]):\n","\n","  # check if any of the drift params for the pixel are nan\n","    if(np.isnan(popt[0, idx]) and np.isnan(popt[1, idx])):\n","      active[idx] = False\n","    else:\n","      # if drift params exist then iterate over the values of the index and use these as x values for the drift curve\n","      y_vals = []\n","      for i in df.index:\n","        val = decaying_exp(i, popt[0,idx], popt[1,idx])\n","        y_vals.append(val)\n","      \n","      # subtract the extrapolated drift from the signal\n","      drift_error = np.abs(np.array(df.values[:, idx] - y_vals))\n","      \n","      # only keep pixels with drift error of less than 10mV\n","      if((drift_error < 12).all()):\n","        drift_avg = np.add(drift_avg, np.array(y_vals))\n","        pix_count += 1\n","        active[idx] = True\n","      else:\n","        active[idx] = False\n","\n","  drift_avg/=pix_count\n","\n","  df = df.loc[:, active]\n","\n","  return df, drift_avg"],"metadata":{"id":"R9gzaEl7wE7H"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W1YMbu9bSW5m"},"outputs":[],"source":["def filter_by_vref(X, v_thresh=70):\n","    '''\n","    Identifies active pixels by checking if one of the first 10 derivatives d(i) is > v_thresh\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_thresh : int, optional\n","        Minimum value of the derivative d(i)=X(i+1)-X(i) in mV. Default is 70\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if, during the first 10 samples,\n","        one of the derivatives is > v_thresh. The derivatives are calculated as d(i) = X(i+1)-X(i)\n","    '''\n","    return (np.diff(X[:10, :], axis=0) > v_thresh).any(axis=0)  # check if one of the first 10 derivatives is >v_thresh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XjXkAhKwSgFB"},"outputs":[],"source":["def filter_by_vrange(X, v_range=(100, 900)):\n","    '''\n","    Identifies active pixels by checking that all the values are in v_range\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_range : (int, int), optional\n","        tuple containing the minimum and maximum allowable voltage in mV. Default is (100, 900)\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if the value is always in v_range\n","    '''\n","    return (X < v_range[1]).all(axis=0) & (X > v_range[0]).all(axis=0)  # for each pixel, check if all the values are\n","    # within the given range\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5a7Uqi9Skg_"},"outputs":[],"source":["def filter_by_derivative(X, vthresh=5):\n","    \"\"\" Identifies active pixels by checking that the absolute value of the derivative is always below vthresh\n","    Parameters\n","    ----------\n","    X : ndarray\n","        input 2D array of shape TxNM\n","    vthresh : int\n","        threshold for active pixels. Default is 5\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if all the derivatives are below vthresh\n","    \"\"\"\n","    x_diff = np.abs(np.diff(X, axis=0))\n","    return (x_diff < vthresh).all(axis=0)"]},{"cell_type":"code","source":["def filter_active_pixels_drop(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"DhuoGbbPutKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZJkYzPiVvd6"},"outputs":[],"source":["def filter_active_pixels_deriv(df, v_thresh_deriv=5): \n","  active = filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_range(df, v_range=(100, 900)):\n","  active = filter_by_vrange(df.values, v_range)\n","\n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"imVXR8eVUrby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def reshape_data(df, rows, cols):\n","  X = df.values #pandas.DataFrame.values: Return a Numpy representation of the DataFrame.\n","  X = X.reshape(-1, rows, cols, order='F') #or C. different reshaping row by row or column by column but this works\n","  return X"],"metadata":{"id":"RTF9Vh78MZSB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filter_chemical_pixels(df, arr_rows, arr_cols):\n","  X = reshape_data(df, arr_rows, arr_cols) # reshape data to T x 78 x 56\n","  X_mean = np.mean(X, axis=0) # get mean to have 78 x 56 shape\n","  X_mean[1::3, 1::3] = np.nan # set temperature pixels to nan\n","  X_mean = X_mean.flatten('F') # restore shape to 4068 \n","\n","  active_chemical = ~(np.isnan(X_mean)) # get bool array of all chemical pixels\n","\n","  # drop pixels \n","  df = df.loc[: , active_chemical]\n","  return df\n"],"metadata":{"id":"D9Xt8X4zL7hc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o82EQTYe9euH"},"outputs":[],"source":["def time_to_index(times, time_vect):\n","    '''\n","    Returns index of the times closest to the desired ones time_vect\n","    Arguments\n","    ---------\n","    times : list\n","        list of integers containing the desired times\n","    time_vect : nparray\n","        array of the times at which the values are sampled\n","    Returns\n","    -------\n","    list\n","        for each element in the input list times, return an element in the output list\n","        with the index of the sample closest to the desired time\n","    '''\n","    indices = []\n","    for time in times:  # for each time in the input list\n","        indices.append( np.argmin(np.abs(time_vect - time)) )\n","        # find index of the sampled time (in time_vect) closest to the desired one (time)\n","    return indices\n","\n","\n","def find_loading_time(time_vect, X, bounds=(600, 900)):  # for v2\n","    ''' Finds loading and settling time for the data of v2 chip\n","    Parameters\n","    ----------\n","    time_vect : ndarray\n","        1D array with dimension T containing the sampling times\n","    X : ndarray\n","        2D array with dimension TxNM containing the sampled data\n","    bounds : list, optional\n","        tuple containing the minimum and maximum times (in ms) where the loading time has to be searched.\n","        Default is (600, 900)\n","    Returns\n","    -------\n","    tuple\n","        - settled_index : index at which the settling occurs\n","        - settled_time : time at which the settling occurs\n","    '''\n","\n","    search_start, search_end = time_to_index(bounds, time_vect)  # for each time in bounds, find the index\n","    # of the sample (in time_vect) that is closest to the desired one (in bounds)\n","    X_mean = np.mean(X, axis=1)  # for each sample, calculate the mean of all pixels\n","    X_mean_diff = np.diff(X_mean)  # find the derivative\n","\n","    loading_index = np.argmax(X_mean_diff[search_start:search_end]) + search_start + 1  # find the index\n","    # where the derivative is max in the specified interval\n","    loading_index = loading_index  # add settling time\n","    settled_index = loading_index + 10  # add settling time\n","    settled_time = time_vect[settled_index]  # find the time that index corresponds to\n","\n","    return settled_index, settled_time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9m8OqTUtQVb0"},"outputs":[],"source":["def preprocess_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","\n","  df = filter_chemical_pixels(df, 78, 56) # filter all chemical pixels\n","\n","  df = filter_active_pixels_drop(df=df, v_thresh_deriv=deriv_thresh, v_range=(100,900)) # filter pixels by range, vref and deriv\n","\n","  settle_idx, settle_time = find_loading_time(df.index, df, bounds=(600, 900)) # find settling point\n","  df = df.iloc[settle_idx + 10:, :] # use only the data after the settling time + 30s to allow reaction to have settled\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise don't\n","\n","  df = df.iloc[0:150+250, :] # take only 400 samples after settling point (approx 19-20mins) \n","\n","  df.index = df.index - df.index[0] # set the first time value to 0\n","  \n","  X, drift = filter_by_drift(df, 40) # filter by fitting of pixel to drift model\n","\n","  if(len(X.columns) != 0): \n","    df = X\n","    \n","  for col in df.columns:\n","    df[col] = savgol_filter(df[col],101, 3) # apply smoothing to each pixel \n","\n","  return df.T"]},{"cell_type":"code","source":["def preprocess_partial_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","\n","  df = filter_active_pixels_range(df=df, v_range=(100,900)) # filter by range incase of any saturation\n","  \n","  df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh) # filter pixels by deriv\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise dont\n","\n","  df = df.iloc[:150+250, :] # take only 400 samples after settling point (approx 19-20mins) \n","\n","  df.index = df.index - df.index[0] # set the first time value to 0\n","  \n","  X, drift = filter_by_drift(df, 40) # filter by fitting of pixel to drift model\n","\n","  if(len(X.columns) != 0): \n","    df = X\n","\n","  for col in df.columns:\n","    df[col] = savgol_filter(df[col],101, 3) # apply smoothing to each pixel\n","    \n","  return df.T"],"metadata":{"id":"o9Er5B2BxpUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalise_data(series):\n","  return (series - series.min()) / (series.max() - series.min())"],"metadata":{"id":"M6wMMfHZEADc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation Metric Helper Functions"],"metadata":{"id":"PaNIFO5iSa9C"}},{"cell_type":"code","source":["def accuracy(classification):\n","  total = len(classification)\n","  total_correct = 0\n","  for i in classification.values():\n","    if(i[0] == i[1]):\n","      total_correct +=1\n","\n","  accuracy = (total_correct/total)*100\n","\n","  return accuracy"],"metadata":{"id":"U2zoSqPJLatm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sensitivity(classification):\n","  true_pos = 0\n","  false_neg = 0\n","\n","  for i in classification.values():\n","\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","\n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 1 and predicted == 0):\n","      false_neg += 1\n","\n","  sensitivity = 100*(true_pos/(true_pos + false_neg))\n","\n","  return sensitivity"],"metadata":{"id":"lzSAF5WsTIuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def specificity(classification):\n","  true_neg = 0\n","  false_pos = 0\n","\n","  for i in classification.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 0 and predicted == 0):\n","      true_neg += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  specificity = 100*(true_neg/(true_neg + false_pos))\n","\n","  return specificity"],"metadata":{"id":"WP_kdiXMYeU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def precision(classification):\n","  true_pos = 0\n","  false_pos = 0\n","\n","  for i in classification.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  precision = 100*(true_pos/(true_pos + false_pos))\n","\n","  return precision"],"metadata":{"id":"w7-_ZPDDaxRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def f1(classification):\n","  numerator = 2*precision(classification)*sensitivity(classification)\n","  denominator = precision(classification) + sensitivity(classification)\n","  return numerator/denominator"],"metadata":{"id":"qkFpU-UJbV1R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Loading Helper Functions"],"metadata":{"id":"Mp6t9KbXUtag"}},{"cell_type":"code","source":["def load_partial_covid_exp(filepath):\n","\n","  bot_filepath = filepath[:-4] + \"_bot.csv\"\n","  top_filepath = filepath[:-4] + \"_top.csv\"\n","\n","  ## load in 2 sheets\n","  df_neg = pd.read_csv(top_filepath, header=0, index_col=0)\n","  df_pos = pd.read_csv(bot_filepath, header=0, index_col=0)\n","\n","  return df_pos, df_neg"],"metadata":{"id":"72Rhya-GUxAS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Array Dims"],"metadata":{"id":"W9kgS_-Cx1nm"}},{"cell_type":"code","source":["arr_rows = 78\n","arr_cols = 56"],"metadata":{"id":"whsJZh4Zx0xs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load Data"],"metadata":{"id":"KCr7gvB_tf5-"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"AvJiLnQ8tiKx"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  avg_data_g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_data_export.csv\"\n","  avg_g1 = pd.read_csv(avg_data_g1_file, header=0)\n","\n","  ## Gamma 2\n","  avg_data_g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_data_export.csv\"\n","  avg_g2 = pd.read_csv(avg_data_g2_file, header=0)\n","\n","  ## Gamma 3\n","  avg_data_g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_data_export.csv\"\n","  avg_g3 = pd.read_csv(avg_data_g3_file, header=0)\n","  \n","  ## Gamma 5 \n","  avg_data_g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_data_export.csv\"\n","  avg_g5 = pd.read_csv(avg_data_g5_file, header=0)\n","\n","  ## 22RV1.ap1\n","  avg_data_22rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_data_export.csv\"\n","  avg_22rv1_ap1 = pd.read_csv(avg_data_22rv1_ap1_file, header=0)\n","\n","  ## 22RV1.ap2\n","  avg_data_22rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_data_export.csv\"\n","  avg_22rv1_ap2 = pd.read_csv(avg_data_22rv1_ap2_file, header=0)\n","\n","  ## 22RV1y.p3\n","  avg_data_22rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_data_export.csv\"\n","  avg_22rv1y_p3 = pd.read_csv(avg_data_22rv1y_p3_file, header=0)\n","\n","  ## 22RV1y.p4\n","  avg_data_22rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_data_export.csv\"\n","  avg_22rv1y_p4 = pd.read_csv(avg_data_22rv1y_p4_file, header=0)\n","\n","  ## ARV7.p1\n","  avg_data_arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_data_export.csv\"\n","  avg_arv7_p1 = pd.read_csv(avg_data_arv7_p1_file, header=0).iloc[1:, :].reset_index(drop=True) # row 0 was NAN\n","\n","  ## ARV7.p3\n","  avg_data_arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_data_export.csv\"\n","  avg_arv7_p3 = pd.read_csv(avg_data_arv7_p3_file, header=0)\n","\n","  ## ARV7.p4\n","  avg_data_arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_data_export.csv\"\n","  avg_arv7_p4 = pd.read_csv(avg_data_arv7_p4_file, header=0)\n","\n","  ## Beta 1\n","  avg_data_b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_data_export.csv\"\n","  avg_b1 = pd.read_csv(avg_data_b1_file, header=0)\n","\n","  ## Beta 2\n","  avg_data_b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_data_export.csv\"\n","  avg_b2 = pd.read_csv(avg_data_b2_file, header=0)\n","\n","  ## Beta 5\n","  avg_data_b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_data_export.csv\"\n","  avg_b5 = pd.read_csv(avg_data_b5_file, header=0)\n","  "],"metadata":{"id":"Ekqd_pB0tuTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_vsChem_export.csv\"\n","  g1 = pd.read_csv(g1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g1.index = avg_g1[\"Time Elapsed\"]\n","\n","  ## Gamma 2\n","  g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_vsChem_export.csv\"\n","  g2 = pd.read_csv(g2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g2.index = avg_g2[\"Time Elapsed\"]\n","\n","  ## Gamma 3\n","  g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_vsChem_export.csv\"\n","  g3 = pd.read_csv(g3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g3.index = avg_g3[\"Time Elapsed\"]\n","\n","  ## Gamma 5\n","  g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_vsChem_export.csv\"\n","  g5 = pd.read_csv(g5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g5.index = avg_g5[\"Time Elapsed\"]\n","\n","  ## 22RV1.ap1\n","  rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_vsChem_export.csv\"\n","  rv1_ap1 = pd.read_csv(rv1_ap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap1.index = avg_22rv1_ap1['Time Elapsed']\n","\n","  ## 22RV1.ap2\n","  rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_vsChem_export.csv\"\n","  rv1_ap2 = pd.read_csv(rv1_ap2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap2.index = avg_22rv1_ap2['Time Elapsed']\n","\n","  ## 22RV1y.p3\n","  rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_vsChem_export.csv\"\n","  rv1y_p3 = pd.read_csv(rv1y_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p3.index = avg_22rv1y_p3['Time Elapsed']\n","\n","  ## 22RV1y.p4\n","  rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_vsChem_export.csv\"\n","  rv1y_p4 = pd.read_csv(rv1y_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p4.index = avg_22rv1y_p4['Time Elapsed']\n","\n","  ## ARV7.p1 \n","  arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_vsChem_export.csv\"\n","  arv7_p1 = pd.read_csv(arv7_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)] \n","  arv7_p1.index = avg_arv7_p1[\"Time Elapsed\"]\n","\n","  ## ARV7.p3 \n","  arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_vsChem_export.csv\"\n","  arv7_p3 = pd.read_csv(arv7_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p3.index = avg_arv7_p3[\"Time Elapsed\"]\n","\n","  ## ARV7.p4 \n","  arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_vsChem_export.csv\"\n","  arv7_p4 = pd.read_csv(arv7_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p4.index = avg_arv7_p4[\"Time Elapsed\"]\n","\n","  ## Beta 1\n","  b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_vsChem_export.csv\"\n","  b1 = pd.read_csv(b1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b1.index = avg_b1[\"Time Elapsed\"]\n","\n","  ## Beta 2\n","  b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_vsChem_export.csv\"\n","  b2 = pd.read_csv(b2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b2.index = avg_b2[\"Time Elapsed\"]\n","\n","  ## Beta 5\n","  b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_vsChem_export.csv\"\n","  b5 = pd.read_csv(b5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b5.index = avg_b5[\"Time Elapsed\"]\n","\n"],"metadata":{"id":"vZRah5zpxXp6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"7qOF9VBstkbe"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):  \n","  ## ARV7.n1\n","  avg_data_arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_data_export.csv\"\n","  avg_arv7 = pd.read_csv(avg_data_arv7_file, header=0)\n","\n","  ## Yap.n2\n","  avg_data_yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_data_export.csv\"\n","  avg_yap = pd.read_csv(avg_data_yap_file, header=0)\n","\n","  ## Yap1.n2\n","  avg_data_yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_data_export.csv\"\n","  avg_yap1 = pd.read_csv(avg_data_yap1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## Yap1.n1.1 \n","  avg_data_yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_data_export.csv\"\n","  avg_yap1n1 = pd.read_csv(avg_data_yap1n1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## ARV7.n2\n","  avg_data_arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_data_export.csv\"\n","  avg_arv72 = pd.read_csv(avg_data_arv72_file, header=0)\n","\n","  ## ARV7.n3\n","  avg_data_arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_data_export.csv\"\n","  avg_arv73 = pd.read_csv(avg_data_arv73_file, header=0)\n","\n","  ## DU145y.n1\n","  avg_data_du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_data_export.csv\"\n","  avg_du145y_n1 = pd.read_csv(avg_data_du145y_n1_file, header=0)"],"metadata":{"id":"mlU83yKsuSHV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):   \n","  ## ARV7.n1 \n","  arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_vsChem_export.csv\"\n","  arv7 = pd.read_csv(arv7_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7.index = avg_arv7[\"Time Elapsed\"]\n","\n","  ## Yap.n2\n","  yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_vsChem_export.csv\"\n","  yap = pd.read_csv(yap_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap.index = avg_yap[\"Time Elapsed\"]\n","\n","  ## Yap1.n2\n","  yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_vsChem_export.csv\"\n","  yap1 = pd.read_csv(yap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1.index = avg_yap1[\"Time Elapsed\"]\n","\n","  ## Yap1.n1.1\n","  yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_vsChem_export.csv\"\n","  yap1n1 = pd.read_csv(yap1n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1n1.index = avg_yap1n1[\"Time Elapsed\"]\n","\n","  ## ARV7.n2\n","  arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_vsChem_export.csv\"\n","  arv72 = pd.read_csv(arv72_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv72.index = avg_arv72[\"Time Elapsed\"]\n","\n","  ## ARV7.n3\n","  arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_vsChem_export.csv\"\n","  arv73 = pd.read_csv(arv73_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv73.index = avg_arv73[\"Time Elapsed\"]\n","\n","  ## DU145y.n1\n","  du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_vsChem_export.csv\"\n","  du145y_n1 = pd.read_csv(du145y_n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145y_n1.index = avg_du145y_n1[\"Time Elapsed\"]"],"metadata":{"id":"W3_XExOjypwI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Covid Partial Data"],"metadata":{"id":"AXQUM6RDTajp"}},{"cell_type":"code","source":["## 150520_2_118\n","avg_118_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_2_118/exp_summary_118.csv\"\n","exp_118_pos, exp_118_neg = load_partial_covid_exp(avg_118_file)\n","\n","## 150520_4_2_86\n","avg_86_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_4_2_86/exp_summary_86.csv\"\n","exp_86_pos, exp_86_neg = load_partial_covid_exp(avg_86_file)\n","\n","## 150520_5_129\n","avg_129_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_5_129/exp_summary_129.csv\"\n","exp_129_pos, exp_129_neg = load_partial_covid_exp(avg_129_file)\n","\n","## 180520_4_165\n","avg_165_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_4_165/exp_summary_165.csv\"\n","exp_165_pos, exp_165_neg = load_partial_covid_exp(avg_165_file)\n","\n","## 180520_6_35\n","avg_35_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_6_35/exp_summary_35.csv\"\n","exp_35_pos, exp_35_neg = load_partial_covid_exp(avg_35_file)\n","\n","## 190520_1_28\n","avg_28_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_1_28/exp_summary_28.csv\"\n","exp_28_pos, exp_28_neg = load_partial_covid_exp(avg_28_file) \n","\n","## 190520_2_14\n","avg_14_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_2_14/exp_summary_14.csv\"\n","exp_14_pos, exp_14_neg = load_partial_covid_exp(avg_14_file)\n","\n","## 210520_2_40\n","avg_40_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_2_40/exp_summary_40.csv\"\n","exp_40_pos, exp_40_neg = load_partial_covid_exp(avg_40_file)\n","\n","## 210520_3_88\n","avg_88_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_3_88/exp_summary_88.csv\"\n","exp_88_pos, exp_88_neg = load_partial_covid_exp(avg_88_file)\n","\n","## 210520_6_27\n","avg_27_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_6_27/exp_summary_27.csv\"\n","exp_27_pos, exp_27_neg = load_partial_covid_exp(avg_27_file)\n","\n","## 250520_1_134\n","avg_134_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_1_134/exp_summary_134.csv\"\n","exp_134_pos, exp_134_neg = load_partial_covid_exp(avg_134_file)\n","\n","## 250520_2_97\n","avg_97_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_2_97/exp_summary_97.csv\"\n","exp_97_pos, exp_97_neg = load_partial_covid_exp(avg_97_file)\n","\n","## 250520_6_2D1\n","avg_2d1_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_6_2D1/exp_summary_2D1.csv\"\n","exp_2d1_pos, exp_2d1_neg = load_partial_covid_exp(avg_2d1_file)\n","\n","## 250520_7_64\n","avg_64_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_7_64/exp_summary_64.csv\"\n","exp_64_pos, exp_64_neg = load_partial_covid_exp(avg_64_file)"],"metadata":{"id":"xoTwuHUETf5a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"7XgnkewwwPki"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"CTcUwvRiwUmJ"}},{"cell_type":"code","source":["g1 = preprocess_data(g1, 500)\n","g2 = preprocess_data(g2, 500)\n","g3 = preprocess_data(g3, 500)\n","g5 = preprocess_data(g5, 500)\n","rv1_ap1 = preprocess_data(rv1_ap1, 500)\n","rv1_ap2 = preprocess_data(rv1_ap2, 500)\n","rv1y_p3 = preprocess_data(rv1y_p3, 500)\n","rv1y_p4 = preprocess_data(rv1y_p4, 500)\n","arv7_p1 = preprocess_data(arv7_p1, 500)\n","arv7_p3 = preprocess_data(arv7_p3, 500)\n","arv7_p4 = preprocess_data(arv7_p4, 500)\n","b1 = preprocess_data(b1, 500)\n","b2 = preprocess_data(b2, 500)\n","b5 = preprocess_data(b5, 500)"],"metadata":{"id":"1-WlDoK49D2Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"1WaPBFGuwYN4"}},{"cell_type":"code","source":["arv7 = preprocess_data(arv7, 500)\n","yap = preprocess_data(yap, 500)\n","yap1 = preprocess_data(yap1, 500)\n","yap1n1 = preprocess_data(yap1n1, 500)\n","arv72 = preprocess_data(arv72, 500)\n","arv73 = preprocess_data(arv73, 500)\n","du145y_n1 = preprocess_data(du145y_n1, 500)"],"metadata":{"id":"gazhgzLT9HLV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Covid Partial Data"],"metadata":{"id":"nUwBPNQNjQ7w"}},{"cell_type":"code","source":["exp_118_pos = preprocess_partial_data(exp_118_pos, 500)\n","exp_86_pos = preprocess_partial_data(exp_86_pos, 500)\n","exp_129_pos = preprocess_partial_data(exp_129_pos, 500)\n","exp_165_pos = preprocess_partial_data(exp_165_pos, 500)\n","exp_35_pos = preprocess_partial_data(exp_35_pos, 500)\n","exp_28_pos = preprocess_partial_data(exp_28_pos, 500)\n","exp_14_pos = preprocess_partial_data(exp_14_pos, 500)\n","exp_40_pos = preprocess_partial_data(exp_40_pos, 500)\n","exp_88_pos = preprocess_partial_data(exp_88_pos, 500)\n","exp_27_pos = preprocess_partial_data(exp_27_pos, 500)\n","exp_134_pos = preprocess_partial_data(exp_134_pos, 500)\n","exp_97_pos = preprocess_partial_data(exp_97_pos, 500)\n","exp_2d1_pos = preprocess_partial_data(exp_2d1_pos, 500)\n","exp_64_pos = preprocess_partial_data(exp_64_pos, 500)"],"metadata":{"id":"HQBQ_1YF9Oqj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exp_118_neg = preprocess_partial_data(exp_118_neg, 500)\n","exp_86_neg = preprocess_partial_data(exp_86_neg, 500)\n","exp_129_neg = preprocess_partial_data(exp_129_neg, 500)\n","exp_165_neg = preprocess_partial_data(exp_165_neg, 500)\n","exp_35_neg = preprocess_partial_data(exp_35_neg, 500)\n","exp_28_neg = preprocess_partial_data(exp_28_neg, 500)\n","exp_14_neg = preprocess_partial_data(exp_14_neg, 500)\n","exp_40_neg = preprocess_partial_data(exp_40_neg, 500)\n","exp_88_neg = preprocess_partial_data(exp_88_neg, 500)\n","exp_27_neg = preprocess_partial_data(exp_27_neg, 500)\n","exp_134_neg = preprocess_partial_data(exp_134_neg, 500)\n","exp_97_neg = preprocess_partial_data(exp_97_neg, 500)\n","exp_2d1_neg = preprocess_partial_data(exp_2d1_neg, 500)\n","exp_64_neg = preprocess_partial_data(exp_64_neg, 500)"],"metadata":{"id":"sYsOnsAW9Rob"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - Neural Network Ensemble"],"metadata":{"id":"cco-BOwij9af"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"j5qgb5mx3rOW"}},{"cell_type":"code","source":["def get_training_data(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","    \n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp (keep all rows and turncate columns)\n","    pos_subsample = sample.to_numpy()[:, 0:timestamp]\n","\n","    ## pos_count = 0 means this is first sample to set training data = sample ortherwise update training data \n","    if(pos_count == 0):\n","      training_data = pos_subsample\n","    else:\n","      training_data = np.concatenate((training_data,pos_subsample))\n","\n","    ## increment count of number of positive samples\n","    pos_count += len(sample)\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","    \n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp (keep all rows and turncate columns)\n","    neg_subsample = sample.to_numpy()[:, 0:timestamp]\n","\n","    ## update training data\n","    training_data = np.concatenate((training_data,neg_subsample))\n","\n","    ## increment count of number of negative samples\n","    neg_count += len(sample)\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"OIYXEisg2WX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_test_data(sample, timestamp):\n","  subsample = sample.to_numpy()[:, 0:timestamp]\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"xH5J1l0cgIHI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"d6Qyl80Wzy-r"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7}"],"metadata":{"id":"d-bA8RfjcM35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Model Specs"],"metadata":{"id":"rxkmk6GHqC7g"}},{"cell_type":"code","source":["number_of_samples = len(g1.columns)\n","number_of_classifiers = 20\n","\n","timestep = int(number_of_samples/number_of_classifiers)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]\n","\n","batch_size = 100\n","epochs = 15\n","loss_function = 'binary_crossentropy'\n","optimiser = 'adam'"],"metadata":{"id":"eztwFZUaloVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBcYHOw_BU4E","executionInfo":{"status":"ok","timestamp":1650492851558,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"b4029ae7-5410-4b16-93af-89b1da92237f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, 260, 280, 300, 320, 340, 360, 380, 400]\n"]}]},{"cell_type":"markdown","source":["#### Creating Ensemble"],"metadata":{"id":"qG3eDbNkqG9A"}},{"cell_type":"code","source":["def create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples, positives, negatives):\n","\n","  neural_nets = [0]*number_of_classifiers\n","\n","  for i in range(number_of_classifiers):\n","\n","    # print(f\"============================================== Neural Network {i} ============================================\")\n","\n","    ## make model \n","    neural_nets[i] = Sequential()\n","    # neural_nets[i].add(Dense(16, activation='relu', input_dim = timestamps[i]))\n","    # neural_nets[i].add(Dense(32, activation='relu'))\n","    # neural_nets[i].add(Dense(32, activation='relu'))\n","    # neural_nets[i].add(Dense(64, activation='relu'))\n","    # neural_nets[i].add(Dense(64, activation='relu'))\n","    # neural_nets[i].add(Dense(128, activation='relu'))\n","    # neural_nets[i].add(Dense(128, activation='relu'))\n","    neural_nets[i].add(Dense(32, activation='relu', input_dim = timestamps[i]))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(128, activation='relu'))\n","    neural_nets[i].add(Dense(512, activation='relu'))\n","    neural_nets[i].add(Dense(1024, activation='relu'))\n","    neural_nets[i].add(Dense(2048, activation='relu'))\n","    neural_nets[i].add(Dense(1, activation='sigmoid'))\n","\n","    ## compile model \n","    neural_nets[i].compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])\n","\n","    ## model summary\n","    # neural_nets[i].summary()\n","\n","    ## training data\n","    training_data, training_label = get_training_data(positive_samples=positives, negative_samples=negatives, timestamp=timestamps[i], test_samples=[test_samples])\n","\n","    ## train model\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n","    neural_nets[i].fit(training_data, training_label,  batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[callback], verbose=0)\n","\n","    # print(\"\\n\\n\")\n","\n","  return neural_nets"],"metadata":{"id":"GVVPVw4-ndtu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Evaluating Ensemble"],"metadata":{"id":"fGH97jNBfzdu"}},{"cell_type":"code","source":["def get_predictions(number_of_classifiers, ensemble, test_sample, timestamps):\n","  pred = []\n","  final_preds = []\n","\n","  for i in range(number_of_classifiers):\n","    ## create test data that will be predicted by each neural net (will be for every pixel)\n","    test_data = get_test_data(test_sample, timestamps[i])\n","\n","    ## make prediction for every pixel \n","    en_pred = en[i].predict(test_data)\n","\n","    ## make array of predictions for each pixel (x axis is the ith neural net, y axis is pixel)\n","    if(i==0):\n","      pred = en_pred\n","    else:\n","      pred = np.concatenate((pred, en_pred), axis = 1)\n","    \n","  ## round any value > 0.5 to 1 and < 0.5 to 0 \n","  pred = pred.round()\n","\n","  ## for each pixel count the number of predictions as 1 or 0 and use the max to make final pixel pred as 0 or 1 \n","  for pixel_pred in pred:\n","    final_pixel_pred = Counter(pixel_pred).most_common(1)[0][0]\n","    final_preds.append(final_pixel_pred)\n","\n","  ## make final prediction for the sample based on majority pixel prediction\n","  final_prediction = Counter(final_preds).most_common(1)[0][0]\n","  \n","  return final_prediction"],"metadata":{"id":"P_T5qTYuPFVA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(negatives)\n","all_samples.update(positives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.zeros(len(negatives)),np.ones(len(positives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"ZPk5gIj2OrNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_classifications = {}\n","\n","with tf.device(gpu):\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","    print(f\"Testing sample: {test_sample_name}...\")\n","\n","    en = create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_sample_name, positives, negatives)\n","    sample_classification = get_predictions(number_of_classifiers, en, test_sample, timestamps)\n","\n","    final_classifications[key] = (sample_classification, true_label_dict[key])\n","    print(f\"Predicted Label: {sample_classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {sample_classification ==true_label_dict[key]} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FvT0rQlGBCB","outputId":"b2d512c1-6976-4959-c393-a11ac7219137","executionInfo":{"status":"ok","timestamp":1650509642486,"user_tz":-60,"elapsed":16785342,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample: exp_118_neg...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: exp_86_neg...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: exp_129_neg...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: exp_165_neg...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: exp_35_neg...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: exp_28_neg...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: exp_14_neg...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: exp_40_neg...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: exp_88_neg...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: exp_27_neg...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: exp_134_neg...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: exp_97_neg...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: exp_2d1_neg...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: exp_64_neg...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: yap...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: yap1...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: yap1n1...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: arv72...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: arv73...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: du145y_n1...\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False \n","\n","Testing sample: arv7...\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True \n","\n","Testing sample: exp_118_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_86_pos...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: exp_129_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_165_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_35_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_28_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_14_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_40_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_88_pos...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: exp_27_pos...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: exp_134_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_97_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_2d1_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: exp_64_pos...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: g1...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: g2...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: g3...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: g5...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: rv1_ap1...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: rv1_ap2...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: du145a_p1...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: du145a_p2...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: arv7_p3...\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False \n","\n","Testing sample: arv7_p1...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: arv7_p4...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n","Testing sample: du145a_p3...\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True \n","\n"]}]},{"cell_type":"code","source":["final_classifications"],"metadata":{"id":"4AuD_rrC2yYY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650509642486,"user_tz":-60,"elapsed":25,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"f58762e7-d0ad-44fd-90e1-373a8022ae57"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'arv7': (0.0, 0.0),\n"," 'arv72': (1.0, 0.0),\n"," 'arv73': (0.0, 0.0),\n"," 'arv7_p1': (1.0, 1.0),\n"," 'arv7_p3': (0.0, 1.0),\n"," 'arv7_p4': (1.0, 1.0),\n"," 'du145a_p1': (1.0, 1.0),\n"," 'du145a_p2': (1.0, 1.0),\n"," 'du145a_p3': (1.0, 1.0),\n"," 'du145y_n1': (1.0, 0.0),\n"," 'exp_118_neg': (1.0, 0.0),\n"," 'exp_118_pos': (0.0, 1.0),\n"," 'exp_129_neg': (0.0, 0.0),\n"," 'exp_129_pos': (0.0, 1.0),\n"," 'exp_134_neg': (0.0, 0.0),\n"," 'exp_134_pos': (0.0, 1.0),\n"," 'exp_14_neg': (1.0, 0.0),\n"," 'exp_14_pos': (0.0, 1.0),\n"," 'exp_165_neg': (0.0, 0.0),\n"," 'exp_165_pos': (0.0, 1.0),\n"," 'exp_27_neg': (1.0, 0.0),\n"," 'exp_27_pos': (1.0, 1.0),\n"," 'exp_28_neg': (0.0, 0.0),\n"," 'exp_28_pos': (0.0, 1.0),\n"," 'exp_2d1_neg': (1.0, 0.0),\n"," 'exp_2d1_pos': (0.0, 1.0),\n"," 'exp_35_neg': (1.0, 0.0),\n"," 'exp_35_pos': (0.0, 1.0),\n"," 'exp_40_neg': (1.0, 0.0),\n"," 'exp_40_pos': (0.0, 1.0),\n"," 'exp_64_neg': (1.0, 0.0),\n"," 'exp_64_pos': (0.0, 1.0),\n"," 'exp_86_neg': (0.0, 0.0),\n"," 'exp_86_pos': (1.0, 1.0),\n"," 'exp_88_neg': (0.0, 0.0),\n"," 'exp_88_pos': (1.0, 1.0),\n"," 'exp_97_neg': (0.0, 0.0),\n"," 'exp_97_pos': (0.0, 1.0),\n"," 'g1': (1.0, 1.0),\n"," 'g2': (1.0, 1.0),\n"," 'g3': (0.0, 1.0),\n"," 'g5': (1.0, 1.0),\n"," 'rv1_ap1': (1.0, 1.0),\n"," 'rv1_ap2': (1.0, 1.0),\n"," 'yap': (0.0, 0.0),\n"," 'yap1': (0.0, 0.0),\n"," 'yap1n1': (1.0, 0.0)}"]},"metadata":{},"execution_count":164}]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"mhkc8Lnr9-c2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650509642487,"user_tz":-60,"elapsed":15,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"1e6d0544-8a94-4f48-eb0b-2d5e2ef685f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 51.06382978723404\n","Sensitivity/Recall: 50.0\n","Specificity: 52.38095238095239\n","Precision: 56.52173913043478\n","F1 Score: 53.06122448979592\n"]}]},{"cell_type":"markdown","metadata":{"id":"simepEdKIiL0"},"source":["### Github Commands"]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"YdlGDV3AzZ1L","executionInfo":{"status":"ok","timestamp":1653067692296,"user_tz":-60,"elapsed":13,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"a6df622f-c758-4581-cc10-60dfa71e8606","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itbAqo9qGukN","outputId":"19bc365a-b56b-4592-d852-bf0cea8442b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project\n"]}],"source":["username = \"adityag16\"\n","git_token = \"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\"\n","repository = \"/content/drive/MyDrive/Final-Year-Project\"\n","%cd {repository}\n","!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNInxPqdG7nx"},"outputs":[],"source":["!git add \"Early Time Series Classification - Pixel Data NN.ipynb\"\n","!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1tS6nonHF9u"},"outputs":[],"source":["!git config --global user.email \"aditya.gupta18@imperial.ac.uk\"\n","!git config --global user.name \"adityag16\"\n","\n","!git commit -m \"removed some data samples\"\n","!git push origin main"]},{"cell_type":"code","source":[""],"metadata":{"id":"8KO_iVTj0cIP"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Early Time Series Classification - Average Ouput.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1WYaF_HRa3IGG6auTN3SvWNlJMYRlk-43","authorship_tag":"ABX9TyM64JPC5NrZ+YFQR4SSY/FI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Connect Drive"],"metadata":{"id":"XVaAULW6qhh1"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15568,"status":"ok","timestamp":1651222988336,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"_DdiqzlkZMhe","outputId":"173d86fb-c436-48ed-9bee-e9da3cd6e650"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"markdown","metadata":{"id":"ttpluWU4tHLq"},"source":["### Package Imports"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"Z_3NHgGwZIsI","executionInfo":{"status":"ok","timestamp":1651223164006,"user_tz":-60,"elapsed":343,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.signal import savgol_filter\n","from collections import Counter\n","import copy\n","from collections import defaultdict\n","from scipy.optimize import curve_fit\n","from scipy.signal import filtfilt"]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from scipy.spatial import distance\n","from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances"],"metadata":{"id":"5vMvjgqYCd2d","executionInfo":{"status":"ok","timestamp":1651222993537,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### GPU Device"],"metadata":{"id":"6cosBM9Jd74f"}},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kElpooT1fLzz","executionInfo":{"status":"ok","timestamp":1651223000192,"user_tz":-60,"elapsed":407,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"49e9288f-c227-4169-cf69-f48641dae443"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-670de5ef-3f12-9bce-204a-30bb253f0b26)\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1651223004699,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"bLu_lZGKu9dp","outputId":"3d1801c0-5b6b-4320-c488-7b03e536b558"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["gpu = tf.test.gpu_device_name()\n","print(gpu)"]},{"cell_type":"markdown","metadata":{"id":"ihJkU1v2STVo"},"source":["### Pre-Processing Helper Functions"]},{"cell_type":"code","source":["def decaying_exp(x, a, b):\n","    \"\"\" Returns exponential function\n","    Parameters\n","    ----------\n","    x : ndarray\n","        times\n","    a : double\n","        t(inf) value\n","    b : double\n","        slope to t=0\n","    Returns\n","    -------\n","    ndarray\n","        y-axis values of the function\n","    \"\"\"\n","    return a*(1-np.exp(-b * x))\n","\n","\n","def fit_pixels_interpolate(time, X, interpolate_idx):\n","    \"\"\" Interpolates the curves for each pixel\n","    Parameters\n","    ----------\n","    time : ndarray\n","        times\n","    X : ndarray\n","        TxNM array to be interpolated\n","    idx_active : ndarray\n","        NM array specifying pixels that are active\n","    interpolate_idx : int\n","        interpolation is performed until this index\n","    Returns\n","    -------\n","    popt : ndarray\n","        optimal parameters for interpolation of each pixel, with shape 2xNM\n","    \"\"\"\n","    popt = np.zeros((2, X.shape[1]))\n","\n","    # for every pixel\n","    for i in range(X.shape[1]):\n","\n","      data = filtfilt(b=np.ones(10) / 10, a=[1], x=X[:, i])\n","\n","      # Fit the curve (interpolate)\n","      try:\n","        popt[:, i], pcov = curve_fit(decaying_exp, time[:interpolate_idx], data[:interpolate_idx], p0=[-10, 0.1])\n","      except:\n","        # print('EXCEPT: could not fit this pixel', i)\n","        popt[:, i] = None\n","\n","    return popt"],"metadata":{"id":"g1nRYshEtGy2","executionInfo":{"status":"ok","timestamp":1651223036942,"user_tz":-60,"elapsed":368,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def filter_by_drift(df, interpolate_idx):\n","\n","  popt = fit_pixels_interpolate(np.array(df.index), df.values, interpolate_idx)\n","\n","  drift_avg = np.zeros(df.shape[0])\n","  pix_count = 0\n","  active = np.array(np.zeros(df.shape[1]), dtype=bool)\n","\n","  for idx in range(df.shape[1]):\n","\n","  # check if any of the drift params for the pixel are nan\n","    if(np.isnan(popt[0, idx]) and np.isnan(popt[1, idx])):\n","      active[idx] = False\n","    else:\n","      # if drift params exist then iterate over the values of the index and use these as x values for the drift curve\n","      y_vals = []\n","      for i in df.index:\n","        val = decaying_exp(i, popt[0,idx], popt[1,idx])\n","        y_vals.append(val)\n","      \n","      # subtract the extrapolated drift from the signal\n","      drift_error = np.abs(np.array(df.values[:, idx] - y_vals))\n","      \n","      # only keep pixels with drift error of less than 10mV\n","      if((drift_error < 12).all()):\n","        drift_avg = np.add(drift_avg, np.array(y_vals))\n","        pix_count += 1\n","        active[idx] = True\n","      else:\n","        active[idx] = False\n","\n","  drift_avg/=pix_count\n","\n","  df = df.loc[:, active]\n","\n","  return df, drift_avg"],"metadata":{"id":"R9gzaEl7wE7H","executionInfo":{"status":"ok","timestamp":1651223038321,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"W1YMbu9bSW5m","executionInfo":{"status":"ok","timestamp":1651223039764,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vref(X, v_thresh=70):\n","    '''\n","    Identifies active pixels by checking if one of the first 10 derivatives d(i) is > v_thresh\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_thresh : int, optional\n","        Minimum value of the derivative d(i)=X(i+1)-X(i) in mV. Default is 70\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if, during the first 10 samples,\n","        one of the derivatives is > v_thresh. The derivatives are calculated as d(i) = X(i+1)-X(i)\n","    '''\n","    return (np.diff(X[:10, :], axis=0) > v_thresh).any(axis=0)  # check if one of the first 10 derivatives is >v_thresh"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XjXkAhKwSgFB","executionInfo":{"status":"ok","timestamp":1651223047631,"user_tz":-60,"elapsed":388,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vrange(X, v_range=(100, 900)):\n","    '''\n","    Identifies active pixels by checking that all the values are in v_range\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_range : (int, int), optional\n","        tuple containing the minimum and maximum allowable voltage in mV. Default is (100, 900)\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if the value is always in v_range\n","    '''\n","    return (X < v_range[1]).all(axis=0) & (X > v_range[0]).all(axis=0)  # for each pixel, check if all the values are\n","    # within the given range\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"G5a7Uqi9Skg_","executionInfo":{"status":"ok","timestamp":1651223048014,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_derivative(X, vthresh=5):\n","    \"\"\" Identifies active pixels by checking that the absolute value of the derivative is always below vthresh\n","    Parameters\n","    ----------\n","    X : ndarray\n","        input 2D array of shape TxNM\n","    vthresh : int\n","        threshold for active pixels. Default is 5\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if all the derivatives are below vthresh\n","    \"\"\"\n","    x_diff = np.abs(np.diff(X, axis=0))\n","    return (x_diff < vthresh).all(axis=0)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"XUOV5CRYflUO","executionInfo":{"status":"ok","timestamp":1651223048508,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # set pixel values to 0/nan\n","  for idx, col in enumerate(df.columns):\n","    if(not active[idx]):\n","      df.loc[:, col] = 0\n","\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_drop(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"DhuoGbbPutKZ","executionInfo":{"status":"ok","timestamp":1651223048509,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ZZJkYzPiVvd6","executionInfo":{"status":"ok","timestamp":1651223049389,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels_deriv(df, v_thresh_deriv=5): \n","  active = filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # for idx, col in enumerate(df.columns):\n","  #   if(not active[idx]):\n","  #     df.loc[:, col] = 0\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_range(df, v_range=(100, 900)):\n","  active = filter_by_vrange(df.values, v_range)\n","\n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"imVXR8eVUrby","executionInfo":{"status":"ok","timestamp":1651223050046,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def reshape_data(df, rows, cols):\n","  X = df.values #pandas.DataFrame.values: Return a Numpy representation of the DataFrame.\n","  X = X.reshape(-1, rows, cols, order='F') #or C. different reshaping row by row or column by column but this works\n","  return X"],"metadata":{"id":"RTF9Vh78MZSB","executionInfo":{"status":"ok","timestamp":1651223050408,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def filter_chemical_pixels(df, arr_rows, arr_cols):\n","  X = reshape_data(df, arr_rows, arr_cols) # reshape data to T x 78 x 56\n","  X_mean = np.mean(X, axis=0) # get mean to have 78 x 56 shape\n","  X_mean[1::3, 1::3] = np.nan # set temperature pixels to nan\n","  X_mean = X_mean.flatten('F') # restore shape to 4068 \n","\n","  active_chemical = ~(np.isnan(X_mean)) # get bool array of all chemical pixels\n","\n","  # drop pixels \n","  df = df.loc[: , active_chemical]\n","  return df\n"],"metadata":{"id":"D9Xt8X4zL7hc","executionInfo":{"status":"ok","timestamp":1651223050751,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"o82EQTYe9euH","executionInfo":{"status":"ok","timestamp":1651223051125,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def time_to_index(times, time_vect):\n","    '''\n","    Returns index of the times closest to the desired ones time_vect\n","    Arguments\n","    ---------\n","    times : list\n","        list of integers containing the desired times\n","    time_vect : nparray\n","        array of the times at which the values are sampled\n","    Returns\n","    -------\n","    list\n","        for each element in the input list times, return an element in the output list\n","        with the index of the sample closest to the desired time\n","    '''\n","    indices = []\n","    for time in times:  # for each time in the input list\n","        indices.append( np.argmin(np.abs(time_vect - time)) )\n","        # find index of the sampled time (in time_vect) closest to the desired one (time)\n","    return indices\n","\n","\n","def find_loading_time(time_vect, X, bounds=(600, 900), viz=False):  # for v2\n","    ''' Finds loading and settling time for the data of v2 chip\n","    Parameters\n","    ----------\n","    time_vect : ndarray\n","        1D array with dimension T containing the sampling times\n","    X : ndarray\n","        2D array with dimension TxNM containing the sampled data\n","    bounds : list, optional\n","        tuple containing the minimum and maximum times (in ms) where the loading time has to be searched.\n","        Default is (600, 900)\n","    viz : bool, optional\n","        if viz=True, show the plot. Default is False\n","    Returns\n","    -------\n","    tuple\n","        - settled_index : index at which the settling occurs\n","        - settled_time : time at which the settling occurs\n","    '''\n","\n","    search_start, search_end = time_to_index(bounds, time_vect)  # for each time in bounds, find the index\n","    # of the sample (in time_vect) that is closest to the desired one (in bounds)\n","    X_mean = np.mean(X, axis=1)  # for each sample, calculate the mean of all pixels\n","    X_mean_diff = np.diff(X_mean)  # find the derivative\n","\n","    loading_index = np.argmax(X_mean_diff[search_start:search_end]) + search_start + 1  # find the index\n","    # where the derivative is max in the specified interval\n","    loading_index = loading_index  # add settling time\n","    settled_index = loading_index + 10  # add settling time\n","    settled_time = time_vect[settled_index]  # find the time that index corresponds to\n","\n","    if viz:  # if viz is true, plot the following\n","        fig, ax = plt.subplots(3, 1)\n","        fig.suptitle('Finding Loading Time...')\n","\n","        ax[0].set(title='Active Chemical Pixels, ACP')\n","        ax[0].plot(time_vect, X)  # plot the active chemical pixels\n","\n","        ax[1].set(title='Mean(ACP)')\n","        ax[1].plot(time_vect, X_mean)  # plot the average of the pixels\n","        ax[1].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[1].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[1].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        ax[2].set(title='Diff(Mean(ACP))')\n","        ax[2].plot(time_vect[1:], X_mean_diff)  # plot the derivative of the mean\n","        ax[2].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[2].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[2].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        plt.tight_layout()\n","        plt.show()\n","    return settled_index, settled_time"]},{"cell_type":"code","execution_count":218,"metadata":{"id":"9m8OqTUtQVb0","executionInfo":{"status":"ok","timestamp":1651227179580,"user_tz":-60,"elapsed":478,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def preprocess_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","  \n","  df = filter_chemical_pixels(df, 78, 56) # filter all chemical pixels\n","  \n","  df = filter_active_pixels_drop(df=df, v_thresh_deriv=deriv_thresh, v_range=(100,900))\n","\n","  settle_idx, settle_time = find_loading_time(df.index, df, bounds=(600, 900), viz=False) # find settling point\n","  df = df.iloc[settle_idx + 10:, :] # use only the data after the settling time + 30s to allow reaction to settle\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise don't\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +200 added on to see impact on graph after pre-processing\n","  \n","  df.index = df.index - df.index[0]\n","  \n","  X, drift = filter_by_drift(df, 40)\n","\n","  if(len(X.columns) != 0):\n","    df = X\n","  # for col in df.columns:\n","  #   df[col] = savgol_filter(df[col],101, 3)\n","\n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  if(len(X.columns) != 0):\n","    df['Average Output'] = df['Average Output'] - drift\n","   \n","  return df"]},{"cell_type":"code","source":["def preprocess_partial_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","\n","  df = filter_active_pixels_range(df=df, v_range=(100,900)) # filter by range incase of any saturation\n","  \n","  df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh) # filter pixels by deriv\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise dont\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +250 added on to see impact on graph after pre-processing\n","  \n","  df.index = df.index - df.index[0]\n","\n","  X, drift = filter_by_drift(df, 40)\n","\n","  if(len(X.columns) != 0):\n","    df = X\n","  \n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  if(len(X.columns) != 0):\n","    df['Average Output'] = df['Average Output'] - drift\n","    \n","  return df"],"metadata":{"id":"JsSdU8xPZX4U","executionInfo":{"status":"ok","timestamp":1651227179581,"user_tz":-60,"elapsed":10,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":219,"outputs":[]},{"cell_type":"code","source":["def normalise_data(series):\n","  return (series - series.min()) / (series.max() - series.min())"],"metadata":{"id":"M6wMMfHZEADc","executionInfo":{"status":"ok","timestamp":1651223051946,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### Data Loading Helper Functions"],"metadata":{"id":"Dvvp28miEMsF"}},{"cell_type":"code","source":["def load_partial_covid_exp(filepath):\n","\n","  bot_filepath = filepath[:-4] + \"_bot.csv\"\n","  top_filepath = filepath[:-4] + \"_top.csv\"\n","\n","  ## load in 2 sheets\n","  df_neg = pd.read_csv(top_filepath, header=0, index_col=0)\n","  df_pos = pd.read_csv(bot_filepath, header=0, index_col=0)\n","\n","  return df_pos, df_neg"],"metadata":{"id":"vL28HCTcZUUG","executionInfo":{"status":"ok","timestamp":1651223056884,"user_tz":-60,"elapsed":358,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation Metric Helper Functions"],"metadata":{"id":"PaNIFO5iSa9C"}},{"cell_type":"code","source":["def accuracy(classifications):\n","  total = len(classifications)\n","  total_correct = 0\n","  for i in classifications.values():\n","    if(i[0] == i[1]):\n","      total_correct +=1\n","\n","  accuracy = (total_correct/total)\n","\n","  return accuracy"],"metadata":{"id":"U2zoSqPJLatm","executionInfo":{"status":"ok","timestamp":1651223057925,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def sensitivity(classifications):\n","  true_pos = 0\n","  false_neg = 0\n","\n","  for i in classifications.values():\n","\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","\n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 1 and predicted == 0):\n","      false_neg += 1\n","\n","  sensitivity = (true_pos/(true_pos + false_neg))\n","\n","  return sensitivity"],"metadata":{"id":"lzSAF5WsTIuF","executionInfo":{"status":"ok","timestamp":1651223058407,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def specificity(classifications):\n","  true_neg = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 0 and predicted == 0):\n","      true_neg += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  specificity = (true_neg/(true_neg + false_pos))\n","\n","  return specificity"],"metadata":{"id":"WP_kdiXMYeU1","executionInfo":{"status":"ok","timestamp":1651223058408,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def precision(classifications):\n","  true_pos = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  precision = (true_pos/(true_pos + false_pos))\n","\n","  return precision"],"metadata":{"id":"w7-_ZPDDaxRp","executionInfo":{"status":"ok","timestamp":1651223058769,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def f1(classifications):\n","  numerator = 2*precision(classifications)*sensitivity(classifications)\n","  denominator = precision(classifications) + sensitivity(classifications)\n","  return numerator/denominator"],"metadata":{"id":"qkFpU-UJbV1R","executionInfo":{"status":"ok","timestamp":1651223059525,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["### Array Dims"],"metadata":{"id":"W9kgS_-Cx1nm"}},{"cell_type":"code","source":["arr_rows = 78\n","arr_cols = 56"],"metadata":{"id":"whsJZh4Zx0xs","executionInfo":{"status":"ok","timestamp":1651223060711,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["### Load Data"],"metadata":{"id":"KCr7gvB_tf5-"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"AvJiLnQ8tiKx"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  avg_data_g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_data_export.csv\"\n","  avg_g1 = pd.read_csv(avg_data_g1_file, header=0)\n","\n","  ## Gamma 2\n","  avg_data_g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_data_export.csv\"\n","  avg_g2 = pd.read_csv(avg_data_g2_file, header=0)\n","\n","  ## Gamma 3\n","  avg_data_g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_data_export.csv\"\n","  avg_g3 = pd.read_csv(avg_data_g3_file, header=0)\n","  \n","  ## Gamma 5 \n","  avg_data_g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_data_export.csv\"\n","  avg_g5 = pd.read_csv(avg_data_g5_file, header=0)\n","\n","  ## 22RV1.ap1\n","  avg_data_22rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_data_export.csv\"\n","  avg_22rv1_ap1 = pd.read_csv(avg_data_22rv1_ap1_file, header=0)\n","\n","  ## 22RV1.ap2\n","  avg_data_22rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_data_export.csv\"\n","  avg_22rv1_ap2 = pd.read_csv(avg_data_22rv1_ap2_file, header=0)\n","\n","  ## 22RV1y.p1\n","  avg_data_22rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_data_export.csv\"\n","  avg_22rv1y_p1 = pd.read_csv(avg_data_22rv1y_p1_file, header=0)\n","\n","  ## 22RV1y.p3\n","  avg_data_22rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_data_export.csv\"\n","  avg_22rv1y_p3 = pd.read_csv(avg_data_22rv1y_p3_file, header=0)\n","\n","  ## 22RV1y.p4\n","  avg_data_22rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_data_export.csv\"\n","  avg_22rv1y_p4 = pd.read_csv(avg_data_22rv1y_p4_file, header=0)\n","\n","  ## ARV7.p1\n","  avg_data_arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_data_export.csv\"\n","  avg_arv7_p1 = pd.read_csv(avg_data_arv7_p1_file, header=0).iloc[1:, :].reset_index(drop=True) # row 0 was NAN\n","\n","  ## ARV7.p3\n","  avg_data_arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_data_export.csv\"\n","  avg_arv7_p3 = pd.read_csv(avg_data_arv7_p3_file, header=0)\n","\n","  ## ARV7.p4\n","  avg_data_arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_data_export.csv\"\n","  avg_arv7_p4 = pd.read_csv(avg_data_arv7_p4_file, header=0)\n","\n","  ## Beta 1\n","  avg_data_b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_data_export.csv\"\n","  avg_b1 = pd.read_csv(avg_data_b1_file, header=0)\n","\n","  ## Beta 2\n","  avg_data_b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_data_export.csv\"\n","  avg_b2 = pd.read_csv(avg_data_b2_file, header=0)\n","\n","  ## Beta 5\n","  avg_data_b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_data_export.csv\"\n","  avg_b5 = pd.read_csv(avg_data_b5_file, header=0)\n","  "],"metadata":{"id":"Ekqd_pB0tuTS","executionInfo":{"status":"ok","timestamp":1651227211264,"user_tz":-60,"elapsed":507,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":220,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_vsChem_export.csv\"\n","  g1 = pd.read_csv(g1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g1.index = avg_g1[\"Time Elapsed\"]\n","\n","  ## Gamma 2\n","  g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_vsChem_export.csv\"\n","  g2 = pd.read_csv(g2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g2.index = avg_g2[\"Time Elapsed\"]\n","\n","  ## Gamma 3\n","  g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_vsChem_export.csv\"\n","  g3 = pd.read_csv(g3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g3.index = avg_g3[\"Time Elapsed\"]\n","\n","  ## Gamma 5\n","  g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_vsChem_export.csv\"\n","  g5 = pd.read_csv(g5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g5.index = avg_g5[\"Time Elapsed\"]\n","\n","  ## 22RV1.ap1\n","  rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_vsChem_export.csv\"\n","  rv1_ap1 = pd.read_csv(rv1_ap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap1.index = avg_22rv1_ap1['Time Elapsed']\n","\n","  ## 22RV1.ap2\n","  rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_vsChem_export.csv\"\n","  rv1_ap2 = pd.read_csv(rv1_ap2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap2.index = avg_22rv1_ap2['Time Elapsed']\n","\n","  ## 22RV1y.p1\n","  rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_vsChem_export.csv\"\n","  rv1y_p1 = pd.read_csv(rv1y_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p1.index = avg_22rv1y_p1['Time Elapsed']\n","\n","  ## 22RV1y.p3\n","  rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_vsChem_export.csv\"\n","  rv1y_p3 = pd.read_csv(rv1y_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p3.index = avg_22rv1y_p3['Time Elapsed']\n","\n","  ## 22RV1y.p4\n","  rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_vsChem_export.csv\"\n","  rv1y_p4 = pd.read_csv(rv1y_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p4.index = avg_22rv1y_p4['Time Elapsed']\n","\n","  ## ARV7.p1 \n","  arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_vsChem_export.csv\"\n","  arv7_p1 = pd.read_csv(arv7_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)] \n","  arv7_p1.index = avg_arv7_p1[\"Time Elapsed\"]\n","\n","  ## ARV7.p3 \n","  arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_vsChem_export.csv\"\n","  arv7_p3 = pd.read_csv(arv7_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p3.index = avg_arv7_p3[\"Time Elapsed\"]\n","\n","  ## ARV7.p4 \n","  arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_vsChem_export.csv\"\n","  arv7_p4 = pd.read_csv(arv7_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p4.index = avg_arv7_p4[\"Time Elapsed\"]\n","\n","  ## Beta 1\n","  b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_vsChem_export.csv\"\n","  b1 = pd.read_csv(b1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b1.index = avg_b1[\"Time Elapsed\"]\n","\n","  ## Beta 2\n","  b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_vsChem_export.csv\"\n","  b2 = pd.read_csv(b2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b2.index = avg_b2[\"Time Elapsed\"]\n","\n","  ## Beta 5\n","  b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_vsChem_export.csv\"\n","  b5 = pd.read_csv(b5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b5.index = avg_b5[\"Time Elapsed\"]"],"metadata":{"id":"vZRah5zpxXp6","executionInfo":{"status":"ok","timestamp":1651227219741,"user_tz":-60,"elapsed":8121,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":221,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"7qOF9VBstkbe"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):  \n","  ## ARV7.n1\n","  avg_data_arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_data_export.csv\"\n","  avg_arv7 = pd.read_csv(avg_data_arv7_file, header=0)\n","\n","  ## Yap.n2\n","  avg_data_yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_data_export.csv\"\n","  avg_yap = pd.read_csv(avg_data_yap_file, header=0)\n","\n","  ## Yap1.n2\n","  avg_data_yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_data_export.csv\"\n","  avg_yap1 = pd.read_csv(avg_data_yap1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## Yap1.n1.1 \n","  avg_data_yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_data_export.csv\"\n","  avg_yap1n1 = pd.read_csv(avg_data_yap1n1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## ARV7.n2\n","  avg_data_arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_data_export.csv\"\n","  avg_arv72 = pd.read_csv(avg_data_arv72_file, header=0)\n","\n","  ## ARV7.n3\n","  avg_data_arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_data_export.csv\"\n","  avg_arv73 = pd.read_csv(avg_data_arv73_file, header=0)\n","\n","  ## DU145a.p1\n","  avg_data_du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_data_export.csv\"\n","  avg_du145a_p1 = pd.read_csv(avg_data_du145a_p1_file, header=0)\n","\n","  ## DU145a.p2\n","  avg_data_du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_data_export.csv\"\n","  avg_du145a_p2 = pd.read_csv(avg_data_du145a_p2_file, header=0)\n","\n","  ## DU145a.p3\n","  avg_data_du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_data_export.csv\"\n","  avg_du145a_p3 = pd.read_csv(avg_data_du145a_p3_file, header=0)\n","\n","  ## DU145y.n1\n","  avg_data_du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_data_export.csv\"\n","  avg_du145y_n1 = pd.read_csv(avg_data_du145y_n1_file, header=0)"],"metadata":{"id":"mlU83yKsuSHV","executionInfo":{"status":"ok","timestamp":1651227219742,"user_tz":-60,"elapsed":15,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":222,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):   \n","  ## ARV7.n1 \n","  arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_vsChem_export.csv\"\n","  arv7 = pd.read_csv(arv7_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7.index = avg_arv7[\"Time Elapsed\"]\n","\n","  ## Yap.n2\n","  yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_vsChem_export.csv\"\n","  yap = pd.read_csv(yap_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap.index = avg_yap[\"Time Elapsed\"]\n","\n","  ## Yap1.n2\n","  yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_vsChem_export.csv\"\n","  yap1 = pd.read_csv(yap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1.index = avg_yap1[\"Time Elapsed\"]\n","\n","  ## Yap1.n1.1\n","  yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_vsChem_export.csv\"\n","  yap1n1 = pd.read_csv(yap1n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1n1.index = avg_yap1n1[\"Time Elapsed\"]\n","\n","  ## ARV7.n2\n","  arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_vsChem_export.csv\"\n","  arv72 = pd.read_csv(arv72_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv72.index = avg_arv72[\"Time Elapsed\"]\n","\n","  ## ARV7.n3\n","  arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_vsChem_export.csv\"\n","  arv73 = pd.read_csv(arv73_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv73.index = avg_arv73[\"Time Elapsed\"]\n","\n","  ## DU145a.p1\n","  du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_vsChem_export.csv\"\n","  du145a_p1 = pd.read_csv(du145a_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p1.index = avg_du145a_p1[\"Time Elapsed\"]\n","\n","  ## DU145a.p2\n","  du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_vsChem_export.csv\"\n","  du145a_p2 = pd.read_csv(du145a_p2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p2.index = avg_du145a_p2[\"Time Elapsed\"]\n","\n","  ## DU145a.p3\n","  du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_vsChem_export.csv\"\n","  du145a_p3 = pd.read_csv(du145a_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p3.index = avg_du145a_p3[\"Time Elapsed\"]\n","\n","  ## DU145y.n1\n","  du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_vsChem_export.csv\"\n","  du145y_n1 = pd.read_csv(du145y_n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145y_n1.index = avg_du145y_n1[\"Time Elapsed\"]"],"metadata":{"id":"W3_XExOjypwI","executionInfo":{"status":"ok","timestamp":1651227224793,"user_tz":-60,"elapsed":5065,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":223,"outputs":[]},{"cell_type":"markdown","source":["#### Partial Covid Data"],"metadata":{"id":"yjXPLEfmRUJH"}},{"cell_type":"code","source":["## 150520_2_118\n","avg_118_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_2_118/exp_summary_118.csv\"\n","exp_118_pos, exp_118_neg = load_partial_covid_exp(avg_118_file)\n","\n","## 150520_4_2_86\n","avg_86_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_4_2_86/exp_summary_86.csv\"\n","exp_86_pos, exp_86_neg = load_partial_covid_exp(avg_86_file)\n","\n","## 150520_5_129\n","avg_129_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_5_129/exp_summary_129.csv\"\n","exp_129_pos, exp_129_neg = load_partial_covid_exp(avg_129_file)\n","\n","## 180520_4_165\n","avg_165_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_4_165/exp_summary_165.csv\"\n","exp_165_pos, exp_165_neg = load_partial_covid_exp(avg_165_file)\n","\n","## 180520_6_35\n","avg_35_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_6_35/exp_summary_35.csv\"\n","exp_35_pos, exp_35_neg = load_partial_covid_exp(avg_35_file)\n","\n","## 190520_1_28\n","avg_28_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_1_28/exp_summary_28.csv\"\n","exp_28_pos, exp_28_neg = load_partial_covid_exp(avg_28_file) \n","\n","## 190520_2_14\n","avg_14_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_2_14/exp_summary_14.csv\"\n","exp_14_pos, exp_14_neg = load_partial_covid_exp(avg_14_file)\n","\n","## 210520_2_40\n","avg_40_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_2_40/exp_summary_40.csv\"\n","exp_40_pos, exp_40_neg = load_partial_covid_exp(avg_40_file)\n","\n","## 210520_3_88\n","avg_88_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_3_88/exp_summary_88.csv\"\n","exp_88_pos, exp_88_neg = load_partial_covid_exp(avg_88_file)\n","\n","## 210520_6_27\n","avg_27_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_6_27/exp_summary_27.csv\"\n","exp_27_pos, exp_27_neg = load_partial_covid_exp(avg_27_file)\n","\n","## 250520_1_134\n","avg_134_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_1_134/exp_summary_134.csv\"\n","exp_134_pos, exp_134_neg = load_partial_covid_exp(avg_134_file)\n","\n","## 250520_2_97\n","avg_97_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_2_97/exp_summary_97.csv\"\n","exp_97_pos, exp_97_neg = load_partial_covid_exp(avg_97_file)\n","\n","## 250520_6_2D1\n","avg_2d1_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_6_2D1/exp_summary_2D1.csv\"\n","exp_2d1_pos, exp_2d1_neg = load_partial_covid_exp(avg_2d1_file)\n","\n","## 250520_7_64\n","avg_64_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_7_64/exp_summary_64.csv\"\n","exp_64_pos, exp_64_neg = load_partial_covid_exp(avg_64_file)"],"metadata":{"id":"ORRtMFfEZBwV","executionInfo":{"status":"ok","timestamp":1651227227770,"user_tz":-60,"elapsed":2985,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":224,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"7XgnkewwwPki"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"CTcUwvRiwUmJ"}},{"cell_type":"code","source":["g1 = preprocess_data(g1, 500)\n","g2 = preprocess_data(g2, 500)\n","g3 = preprocess_data(g3, 500)\n","g5 = preprocess_data(g5, 500)\n","rv1_ap1 = preprocess_data(rv1_ap1, 500)\n","rv1_ap2 = preprocess_data(rv1_ap2, 500)\n","rv1y_p1 = preprocess_data(rv1y_p1, 500)\n","rv1y_p3 = preprocess_data(rv1y_p3, 500)\n","rv1y_p4 = preprocess_data(rv1y_p4, 500)\n","arv7_p1 = preprocess_data(arv7_p1, 500)\n","arv7_p3 = preprocess_data(arv7_p3, 500)\n","arv7_p4 = preprocess_data(arv7_p4, 500)\n","b1 = preprocess_data(b1, 500)\n","b2 = preprocess_data(b2, 500)\n","b5 = preprocess_data(b5, 500)"],"metadata":{"id":"1-WlDoK49D2Y","executionInfo":{"status":"ok","timestamp":1651227288778,"user_tz":-60,"elapsed":61019,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c18c9933-0db6-45e2-e1dc-20f9c2bf5520"},"execution_count":225,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"]}]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"1WaPBFGuwYN4"}},{"cell_type":"code","source":["arv7 = preprocess_data(arv7, 500)\n","yap = preprocess_data(yap, 500)\n","yap1 = preprocess_data(yap1, 500)\n","yap1n1 = preprocess_data(yap1n1, 500)\n","arv72 = preprocess_data(arv72, 500)\n","arv73 = preprocess_data(arv73, 500)\n","du145y_n1 = preprocess_data(du145y_n1, 500)\n","du145a_p1 = preprocess_data(du145a_p1, 500)\n","du145a_p2 = preprocess_data(du145a_p2, 500)\n","du145a_p3 = preprocess_data(du145a_p3, 500)"],"metadata":{"id":"gazhgzLT9HLV","executionInfo":{"status":"ok","timestamp":1651227328259,"user_tz":-60,"elapsed":39499,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bdf90c5e-3533-4370-ef73-73963c0c0942"},"execution_count":226,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n","/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n"]}]},{"cell_type":"markdown","source":["#### Covid Partial Data"],"metadata":{"id":"nUwBPNQNjQ7w"}},{"cell_type":"code","source":["exp_118_pos = preprocess_partial_data(exp_118_pos, 500)\n","exp_86_pos = preprocess_partial_data(exp_86_pos, 500)\n","exp_129_pos = preprocess_partial_data(exp_129_pos, 500)\n","exp_165_pos = preprocess_partial_data(exp_165_pos, 500)\n","exp_35_pos = preprocess_partial_data(exp_35_pos, 500)\n","exp_28_pos = preprocess_partial_data(exp_28_pos, 500)\n","exp_14_pos = preprocess_partial_data(exp_14_pos, 500)\n","exp_40_pos = preprocess_partial_data(exp_40_pos, 500)\n","exp_88_pos = preprocess_partial_data(exp_88_pos, 500)\n","exp_27_pos = preprocess_partial_data(exp_27_pos, 500)\n","exp_134_pos = preprocess_partial_data(exp_134_pos, 500)\n","exp_97_pos = preprocess_partial_data(exp_97_pos, 500)\n","exp_2d1_pos = preprocess_partial_data(exp_2d1_pos, 500)\n","exp_64_pos = preprocess_partial_data(exp_64_pos, 500)"],"metadata":{"id":"HQBQ_1YF9Oqj","executionInfo":{"status":"ok","timestamp":1651227350967,"user_tz":-60,"elapsed":22730,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9271316f-5260-4f2a-880f-93337d710003"},"execution_count":227,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"]}]},{"cell_type":"code","source":["exp_118_neg = preprocess_partial_data(exp_118_neg, 500)\n","exp_86_neg = preprocess_partial_data(exp_86_neg, 500)\n","exp_129_neg = preprocess_partial_data(exp_129_neg, 500)\n","exp_165_neg = preprocess_partial_data(exp_165_neg, 500)\n","exp_35_neg = preprocess_partial_data(exp_35_neg, 500)\n","exp_28_neg = preprocess_partial_data(exp_28_neg, 500)\n","exp_14_neg = preprocess_partial_data(exp_14_neg, 500)\n","exp_40_neg = preprocess_partial_data(exp_40_neg, 500)\n","exp_88_neg = preprocess_partial_data(exp_88_neg, 500)\n","exp_27_neg = preprocess_partial_data(exp_27_neg, 500)\n","exp_134_neg = preprocess_partial_data(exp_134_neg, 500)\n","exp_97_neg = preprocess_partial_data(exp_97_neg, 500)\n","exp_2d1_neg = preprocess_partial_data(exp_2d1_neg, 500)\n","exp_64_neg = preprocess_partial_data(exp_64_neg, 500)"],"metadata":{"id":"sYsOnsAW9Rob","executionInfo":{"status":"ok","timestamp":1651227373237,"user_tz":-60,"elapsed":22273,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":228,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - Neural Network Ensemble"],"metadata":{"id":"cco-BOwij9af"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"j5qgb5mx3rOW"}},{"cell_type":"code","source":["def get_training_data(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"OIYXEisg2WX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_test_data(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"xH5J1l0cgIHI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"d6Qyl80Wzy-r"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,\n","             \"arv7_p3\":arv7_p3,\n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7,  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3}"],"metadata":{"id":"d-bA8RfjcM35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Model Specs"],"metadata":{"id":"rxkmk6GHqC7g"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_classifiers = 50\n","\n","timestep = int(number_of_samples/number_of_classifiers)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]\n","\n","batch_size = 3\n","epochs = 10\n","loss_function = 'binary_crossentropy'\n","optimiser = 'adam'"],"metadata":{"id":"eztwFZUaloVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBcYHOw_BU4E","executionInfo":{"status":"ok","timestamp":1650888347765,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"62652afd-35c9-48f8-c037-b58efe79e12c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Creating Ensemble"],"metadata":{"id":"qG3eDbNkqG9A"}},{"cell_type":"code","source":["def create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples):\n","\n","  neural_nets = [0]*number_of_classifiers\n","\n","  for i in range(number_of_classifiers):\n","\n","    # print(f\"============================================== Neural Network {i} ============================================\")\n","\n","    ## make model \n","    neural_nets[i] = Sequential()\n","    neural_nets[i].add(Dense(16, activation='relu', input_dim = timestamps[i]))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(1, activation='sigmoid'))\n","\n","    ## compile model \n","    neural_nets[i].compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])\n","\n","    ## model summary\n","    # neural_nets[i].summary()\n","\n","    ## training data\n","    training_data, training_label = get_training_data(positive_samples=positives, negative_samples=negatives, timestamp=timestamps[i], test_samples=[test_samples])\n","\n","    ## train model\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n","    neural_nets[i].fit(training_data, training_label,  batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[callback], verbose=0)\n","\n","    # print(\"\\n\\n\")\n","\n","  return neural_nets"],"metadata":{"id":"GVVPVw4-ndtu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Evaluating Ensemble"],"metadata":{"id":"fGH97jNBfzdu"}},{"cell_type":"code","source":["def get_prediction(ensemble, timestamps, test_sample):\n","  predictions = []\n","\n","  for i in range(number_of_classifiers):\n","    test_data = get_test_data(test_sample, timestamps[i])\n","    prediction = ensemble[i].predict(test_data)\n","    predictions.append(prediction[0][0])\n","\n","  predictions = [int(i >= 0.5) for i in predictions]\n","  classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","\n","  return classification"],"metadata":{"id":"HslDzCxe1PaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with tule label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"TCTzCBpU0S8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  final_classifications = {}\n","\n","  ## use ensemble to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Testing sample: {test_sample_name}...\")\n","\n","    en = create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_sample_name)\n","    classification = get_prediction(en, timestamps, test_sample)\n","    \n","    \n","    final_classifications[key] = (classification, true_label_dict[key])\n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"HlIwk3By0Zqi","colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"status":"error","timestamp":1650888354674,"user_tz":-60,"elapsed":6919,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2e248431-2ec4-4c7b-e50c-96b007673ba4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample: exp_118_pos...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'sequential_1/dense_7/BiasAdd/ReadVariableOp/resource' has no attr named '_class'.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-5086e332c720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing sample: {test_sample_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0men\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-83e0a485fc39>\u001b[0m in \u001b[0;36mcreate_ensemble\u001b[0;34m(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m## train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mneural_nets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# print(\"\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    530\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m    531\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_compute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    673\u001b[0m           \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m           \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m               var.op.name):\n\u001b[1;32m    716\u001b[0m             update_op = distribution.extended.update(\n\u001b[0;32m--> 717\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False)\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_cross_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m               \u001b[0;31m# In cross-replica context, extended.update returns a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n\u001b[0;32m-> 2633\u001b[0;31m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[0m\u001b[1;32m   2634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2509\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3101\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3102\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3108\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3109\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2509\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2628\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2629\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3701\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3702\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3709\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3710\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    174\u001b[0m           \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m           \u001b[0;34m'Please pass these args as kwargs instead.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1447\u001b[0m                              \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m                              \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m                              use_nesterov=use_nesterov, name=name)\n\u001b[0m\u001b[1;32m   1450\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0mResourceApplyAdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_ops.ResourceApplyAdam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_apply_adam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[1;32m   1655\u001b[0m                            \"building a function.\")\n\u001b[0;32m-> 1656\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;31m# Large EagerTensors and resources are captured with Placeholder ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m       placeholder = _create_substitute_placeholder(\n\u001b[0;32m--> 765\u001b[0;31m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0m\u001b[1;32m    766\u001b[0m       \u001b[0;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0;31m# This attribute would be propogated into the arg_attr of the FunctionDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     placeholder = graph_placeholder(\n\u001b[0;32m-> 1306\u001b[0;31m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   1307\u001b[0m   \u001b[0mhandle_data_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       attrs=attrs, name=name)\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3785\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3872\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcolocation_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3874\u001b[0;31m           \u001b[0mall_colocation_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3876\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocation_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \u001b[0mdefault_colocation_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc:@%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m       \u001b[0mclass_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m       \u001b[0;31m# This op has no explicit colocation group, so it is itself its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["final_classifications"],"metadata":{"id":"4AuD_rrC2yYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"mhkc8Lnr9-c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"WCjSN-dLz9Mq"}},{"cell_type":"code","source":["# ## checking the timestap where majority of classifiers agree\n","\n","# from collections import defaultdict\n","\n","# def get_timestamp(timestamps, predictions):\n","\n","#   ## create dict to hold count of predictions\n","#   label_counters = defaultdict(int)\n","\n","#   ## add entries to dict\n","#   for index, pred in enumerate(predictions):\n","#     label_counters[pred] += 1\n","\n","#     ## if label count == half of total possible predictions then majority is achieved\n","#     if(label_counters[pred] == int(len(predictions)/2)+1):\n","#       return timestamps[index], index\n","  \n","#   return -1, -1\n"],"metadata":{"id":"3r69Gbpd99So"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Timestamp where majority aggement is reached: {timestamp_final}\")\n","# print(f\"Index of final time stamp in array : {pred_index}\")"],"metadata":{"id":"ghvOJ4Ot_fRB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Save Ensemble"],"metadata":{"id":"PppLDxSdv5Uk"}},{"cell_type":"code","source":["# !pwd"],"metadata":{"id":"jAJAZJtKv816"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G1Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G2Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G3Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G5Test"],"metadata":{"id":"UgtDxJjmxHQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/ARV7Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAPTest/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1N1Test/"],"metadata":{"id":"bwBDVrvMRsO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for i in range(number_of_classifiers):\n","#   filename = f\"ensemble-model-{i}.h5\"\n","#   neural_nets[i].save(filename)\n","\n","#   print(f\"Saved {filename}\")"],"metadata":{"id":"ZGXuLcuXx99S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - KNN Ensemble"],"metadata":{"id":"GvAKajynLNa9"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"H8ueQFk24bbg"}},{"cell_type":"code","source":["def get_training_data_knn(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"x4q6d44BLwpQ","executionInfo":{"status":"ok","timestamp":1651227373238,"user_tz":-60,"elapsed":26,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":229,"outputs":[]},{"cell_type":"code","source":["def get_test_data_knn(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"GZOfy-0GQuGA","executionInfo":{"status":"ok","timestamp":1651227373238,"user_tz":-60,"elapsed":25,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":230,"outputs":[]},{"cell_type":"code","source":["def get_time_index(timestamps, predictions):\n","\n","  ## create dict to hold count of predictions\n","  label_counters = defaultdict(int)\n","\n","  ## add entries to dict\n","  for index, pred in enumerate(predictions):\n","    label_counters[pred] += 1\n","\n","    ## if label count == half of total possible predictions then majority is achieved\n","    if(label_counters[pred] == int(len(predictions)/2)+1):\n","      return timestamps[index]\n","  \n","  return -1"],"metadata":{"id":"2hib6StpHWbU","executionInfo":{"status":"ok","timestamp":1651227373239,"user_tz":-60,"elapsed":25,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":231,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"FOMhNuiKNGAw"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","            #  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"-prfZYD_VgMB","executionInfo":{"status":"ok","timestamp":1651227373239,"user_tz":-60,"elapsed":24,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":232,"outputs":[]},{"cell_type":"markdown","source":["#### Timestamps"],"metadata":{"id":"Ry9pqKjnNKiI"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"3cDeyMc3M_bN","executionInfo":{"status":"ok","timestamp":1651227373239,"user_tz":-60,"elapsed":24,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":233,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIjHUplVOmH3","executionInfo":{"status":"ok","timestamp":1651227373240,"user_tz":-60,"elapsed":24,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"6dd803fe-7d27-4e3b-a408-45fd45b25a0f"},"execution_count":234,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Model"],"metadata":{"id":"DJBWoo1SNMy3"}},{"cell_type":"code","source":["def KNN(k, test_sample, train_data, train_labels, distance_metric):\n","  test = np.tile(test_sample, (len(train_data),1)) # repeat test sample and stack vertically\n","  \n","  distances = None\n","\n","  if(distance_metric.lower() == 'manhattan' or distance_metric.lower() == 'cityblock'):\n","    distances = manhattan_distances(test, train_data).diagonal() # get pair wise manhattan distance for every row\n","  elif(distance_metric.lower() == 'euclidean'):\n","    distances = euclidean_distances(test, train_data).diagonal() # get pair wise euclidean distance for every row \n","  elif(distance_metric.lower() == 'cosine'):\n","    distances = cosine_distances(test, train_data).diagonal() # get pair wise cosine distance for every row \n","\n","  min_indexes = np.argsort(distances)[:k] # get k smallest indexes\n","\n","  knn_labels = list(train_labels[min_indexes]) # get k predictions\n","  final_pred = max(set(knn_labels), key=knn_labels.count)\n","\n","  return final_pred"],"metadata":{"id":"sGJZphgaLeL0","executionInfo":{"status":"ok","timestamp":1651227373240,"user_tz":-60,"elapsed":23,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":235,"outputs":[]},{"cell_type":"markdown","source":["#### Model Predictions"],"metadata":{"id":"0C0XQKFHFtFV"}},{"cell_type":"markdown","source":["##### Held-out Test Set"],"metadata":{"id":"Vf8LAE4Qbxls"}},{"cell_type":"code","source":["# test_samples = {\"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \"exp_27_neg\":exp_27_neg,\"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg,\n","#                 \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \"g1\":g1, \"exp_86_pos\":exp_86_pos, \"rv1_ap1\":rv1_ap1,\"b5\":b5, \"exp_28_pos\":exp_28_pos}\n","# test_sample_keys = keys = list(test_samples.keys())\n","# test_labels = list(np.concatenate((np.ones(7),np.zeros(7))))\n","# test_label_dict = dict(zip(test_sample_keys, test_labels))"],"metadata":{"id":"AxaTjkExYX9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import time\n","# with tf.device(gpu):\n","\n","#   final_classifications = {}\n","\n","#   ## use KNN to evaluate the prediction for each of the samples individually\n","#   for key, value in test_samples.items():\n","#     test_sample_name = key\n","#     test_sample = value\n","\n","#     predictions = []\n","#     for t in timestamps:\n","#       train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=test_sample_keys)\n","#       test_data = get_test_data_knn(test_sample, t)\n","#       pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","#       predictions.append(pred)\n","    \n","#     print(f\"Testing sample {test_sample_name}\")\n","\n","#     time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","#     time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","#     classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","#     final_classifications[key] = (classification, true_label_dict[key])\n","  \n","#     print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","#     if(classification == 1.0):\n","#       print(f\"TTP: {time_to_result}s\")\n","\n","#     print(\"\")"],"metadata":{"id":"PVYWffD2Z5q6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Accuracy: {accuracy(final_classifications)}\")\n","# print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","# print(f\"Specificity: {specificity(final_classifications)}\")\n","# print(f\"Precision: {precision(final_classifications)}\")\n","# print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"uV2qejqoblws"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Cross Validation"],"metadata":{"id":"DuKAj66EbskM"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             #\"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"RGVdwT8rxS23","executionInfo":{"status":"ok","timestamp":1651227373241,"user_tz":-60,"elapsed":23,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":236,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"SUDmHpF-GigC","executionInfo":{"status":"ok","timestamp":1651227373241,"user_tz":-60,"elapsed":23,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":237,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(5, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    print(f\"Testing sample {test_sample_name}\")\n","    time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","    time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","    classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","    final_classifications[key] = (classification, true_label_dict[key])\n","  \n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","    if(classification == 1.0):\n","      print(f\"TTP: {time_to_result + 30}s\")\n","\n","    print(\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rptrj0arSjSR","executionInfo":{"status":"ok","timestamp":1651227376021,"user_tz":-60,"elapsed":2801,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"070fe8f3-8f96-4796-99c5-29287005a6cd"},"execution_count":238,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1029.0s\n","\n","Testing sample exp_86_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_129_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1119.0s\n","\n","Testing sample exp_35_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1064.0s\n","\n","Testing sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 793.0s\n","\n","Testing sample exp_40_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 731.0s\n","\n","Testing sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 963.0s\n","\n","Testing sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 719.0s\n","\n","Testing sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 670s\n","\n","Testing sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 587.0s\n","\n","Testing sample exp_2d1_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 616.0s\n","\n","Testing sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 624.0s\n","\n","Testing sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 612.0s\n","\n","Testing sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 629.0s\n","\n","Testing sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 738.0s\n","\n","Testing sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1018.0s\n","\n","Testing sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 948.0s\n","\n","Testing sample arv7_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample rv1y_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample rv1y_p4\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 767.0s\n","\n","Testing sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 912.0s\n","\n","Testing sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 758.0s\n","\n","Testing sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1028.0s\n","\n","Testing sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 799.0s\n","\n","Testing sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 617s\n","\n","Testing sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 659s\n","\n","Testing sample exp_165_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 680s\n","\n","Testing sample exp_35_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 646s\n","\n","Testing sample exp_40_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_134_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 624.0s\n","\n","Testing sample exp_97_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 611s\n","\n","Testing sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 641s\n","\n","Testing sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 628.0s\n","\n","Testing sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 648.0s\n","\n","Testing sample yap1n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 948.0s\n","\n","Testing sample arv7\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n"]}]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SilNigCLya5","executionInfo":{"status":"ok","timestamp":1651227389947,"user_tz":-60,"elapsed":374,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"7cfccbbc-3eb2-401c-8dc4-2d51fcd1031f"},"execution_count":240,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6530612244897959\n","Sensitivity/Recall: 0.75\n","Specificity: 0.5238095238095238\n","Precision: 0.6774193548387096\n","F1 Score: 0.7118644067796611\n"]}]},{"cell_type":"code","source":["# Accuracy: 0.6530612244897959\n","# Sensitivity/Recall: 0.7142857142857143\n","# Specificity: 0.5714285714285714\n","# Precision: 0.6896551724137931\n","# F1 Score: 0.7017543859649122"],"metadata":{"id":"hynDsCvoiBIa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Elbow Plot"],"metadata":{"id":"DgvFMAGtSbpy"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"i1xQt-8FxVXG","executionInfo":{"status":"ok","timestamp":1651226719798,"user_tz":-60,"elapsed":426,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":197,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  accuracies = []\n","  for k in range(1,30):\n","    final_classifications = {}\n","\n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = []\n","      for t in timestamps:\n","        train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","        test_data = get_test_data_knn(test_sample, t)\n","        pred = KNN(k, test_data, train_data, train_labels, 'cosine')\n","        predictions.append(pred)\n","      \n","      time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","      \n","      classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","      final_classifications[key] = (classification, true_label_dict[key])\n","\n","    acc = accuracy(final_classifications)\n","    accuracies.append(acc)\n","    print(f\"K: {k} \\t Accuracy: {acc}\")\n","    # print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"WwBbkDraFWF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651226802962,"user_tz":-60,"elapsed":81379,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"dab9f1e9-e85d-4fdc-e9e5-5c8951ba5ef3"},"execution_count":198,"outputs":[{"output_type":"stream","name":"stdout","text":["K: 1 \t Accuracy: 0.42857142857142855\n","K: 2 \t Accuracy: 0.5102040816326531\n","K: 3 \t Accuracy: 0.40816326530612246\n","K: 4 \t Accuracy: 0.4489795918367347\n","K: 5 \t Accuracy: 0.4897959183673469\n","K: 6 \t Accuracy: 0.5306122448979592\n","K: 7 \t Accuracy: 0.5102040816326531\n","K: 8 \t Accuracy: 0.42857142857142855\n","K: 9 \t Accuracy: 0.5102040816326531\n","K: 10 \t Accuracy: 0.4897959183673469\n","K: 11 \t Accuracy: 0.4489795918367347\n","K: 12 \t Accuracy: 0.4897959183673469\n","K: 13 \t Accuracy: 0.46938775510204084\n","K: 14 \t Accuracy: 0.5102040816326531\n","K: 15 \t Accuracy: 0.5102040816326531\n","K: 16 \t Accuracy: 0.4897959183673469\n","K: 17 \t Accuracy: 0.4489795918367347\n","K: 18 \t Accuracy: 0.5714285714285714\n","K: 19 \t Accuracy: 0.42857142857142855\n","K: 20 \t Accuracy: 0.5306122448979592\n","K: 21 \t Accuracy: 0.4489795918367347\n","K: 22 \t Accuracy: 0.5714285714285714\n","K: 23 \t Accuracy: 0.42857142857142855\n","K: 24 \t Accuracy: 0.46938775510204084\n","K: 25 \t Accuracy: 0.46938775510204084\n","K: 26 \t Accuracy: 0.46938775510204084\n","K: 27 \t Accuracy: 0.3469387755102041\n","K: 28 \t Accuracy: 0.46938775510204084\n","K: 29 \t Accuracy: 0.3673469387755102\n"]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = np.arange(1,30)\n","y = accuracies\n","axes.set_xlabel(\"K\")\n","axes.set_ylabel(\"Accuracy (%)\")\n","axes.plot(x,y)"],"metadata":{"id":"P8t0E1pS9YNL","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"ok","timestamp":1651226824053,"user_tz":-60,"elapsed":642,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"0f291594-4b47-428d-8435-cc7a7936baa4"},"execution_count":199,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f5b53ed0a50>]"]},"metadata":{},"execution_count":199},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Confidence "],"metadata":{"id":"qXrQKuQm8ery"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"oZRyLyYo7k36"}},{"cell_type":"code","source":["def get_rH_00(true_vals, classifier_outputs):\n","  correct_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 0)):\n","      correct_pred_0 += 1\n","\n","  return correct_pred_0/total_pred_0\n","\n","\n","def get_rH_01(true_vals, classifier_outputs):\n","  wrong_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 0)):\n","      wrong_pred_1 += 1\n","    \n","  return wrong_pred_1/total_pred_1\n","\n","def get_rH_10(true_vals, classifier_outputs):\n","  wrong_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 1)):\n","      wrong_pred_0 += 1\n","  \n","  return wrong_pred_0/total_pred_0\n","\n","def get_rH_11(true_vals, classifier_outputs):\n","  correct_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 1)):\n","      correct_pred_1 += 1\n","\n","  return correct_pred_1/total_pred_1"],"metadata":{"id":"6IQ6mN5uJ6z1","executionInfo":{"status":"ok","timestamp":1651227398506,"user_tz":-60,"elapsed":344,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":241,"outputs":[]},{"cell_type":"code","source":["def get_confidence_multipliers(sample_predictions, true_labels):\n","\n","  sample_predictions = np.asarray(sample_predictions) # array of all predictions made by every classifer for all samples\n","\n","  #2d array of all possible multipliers for each classifier\n","  multipliers_final = []\n","\n","  # generate 4 multipliers for each classifier\n","  for classifier in range(len(sample_predictions[0])):\n","    classifier_output = sample_predictions[:, classifier]\n","\n","    rH_00 = get_rH_00(true_labels, classifier_output)\n","    rH_01 = get_rH_01(true_labels, classifier_output)\n","    rH_10 = get_rH_10(true_labels, classifier_output)\n","    rH_11 = get_rH_11(true_labels, classifier_output)\n","    multipliers_classfier = [rH_00, rH_01, rH_10, rH_11] \n","\n","    # add multipliers to 2d array\n","    multipliers_final.append(multipliers_classfier)\n","\n","  return multipliers_final"],"metadata":{"id":"5r-wTh3nlga0","executionInfo":{"status":"ok","timestamp":1651227400806,"user_tz":-60,"elapsed":355,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":242,"outputs":[]},{"cell_type":"code","source":["def get_confidence(preds, multipliers):\n","  \n","  # initialise variable\n","  confidence = 1\n","\n","  # the prediction for which the confidence is being calculated -- predication at time t by classifier Ht (most recent prediction)\n","  pred_t = preds[-1]\n","\n","  for idx , pred in enumerate(preds):\n","    # prediction at time k made by classifier Hk\n","    pred_k = pred\n","\n","    # array of multipliers for Hk \n","    multiplier_k = multipliers[idx]\n","\n","    if(pred_t == 0 and pred_k == 0):\n","        confidence*=(1-multiplier_k[0])\n","    elif(pred_t == 0 and pred_k == 1):\n","        confidence*=(1-multiplier_k[1])\n","    elif(pred_t == 1 and pred_k == 0):\n","        confidence*=(1-multiplier_k[2])  \n","    elif(pred_t == 1 and pred_k == 1):\n","        confidence*=(1-multiplier_k[3])\n","        \n","        \n","\n","  confidence = 1 - confidence\n","\n","  return confidence\n","  "],"metadata":{"id":"8SmPp5iDzHQJ","executionInfo":{"status":"ok","timestamp":1651227401741,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":243,"outputs":[]},{"cell_type":"code","source":["def generate_predictions_table(positives, negatives, timestamps):\n","\n","  sample_predictions = []\n","\n","  true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(5, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    sample_predictions.append(predictions)\n","\n","  return sample_predictions, true_labels"],"metadata":{"id":"Qfe-e7-84_Zc","executionInfo":{"status":"ok","timestamp":1651227403054,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":244,"outputs":[]},{"cell_type":"markdown","source":["#### Random Threshold Testing"],"metadata":{"id":"bwcY82bSq0t6"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651227511747,"user_tz":-60,"elapsed":381,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"bZnftjyQxXcw"},"execution_count":258,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651227512152,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"asGaVch58nEo"},"execution_count":259,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651227512525,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"032f1e44-700b-4abd-81db-7b9d219d9e4d","id":"YF_lFeGo8nE2"},"execution_count":260,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"68OVHXKmw-Hg","executionInfo":{"status":"ok","timestamp":1651227512526,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":261,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","  \n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","      if(c >= 0.999999969661240808167): # onfidence threshold\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","        if(pred == 1.0):\n","          print(f\"Earliness:  {time_index/timestamps[-1]}\")\n","          print(f\"TTP: {time_to_result+30}s\")\n","          ttps.append(time_to_result+30) # 30 second delay from reaction start when preprocessing\n","          earliness.append(time_index/timestamps[-1])\n","        break\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxnI-jcElWhV","executionInfo":{"status":"ok","timestamp":1651227567037,"user_tz":-60,"elapsed":5795,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"be22d9ae-549c-48b9-8ebf-7da5052263fd"},"execution_count":264,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.32\n","TTP: 376.0s\n","\n","Sample exp_86_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.36\n","TTP: 416.0s\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.4\n","TTP: 475.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.36\n","TTP: 435.0s\n","\n","Sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.3\n","TTP: 365.0s\n","\n","Sample exp_40_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.38\n","TTP: 460.0s\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.34\n","TTP: 415.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.4\n","TTP: 475.0s\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.42\n","TTP: 502s\n","\n","Sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.46\n","TTP: 523.0s\n","\n","Sample exp_2d1_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.44\n","TTP: 508.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.44\n","TTP: 514.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.46\n","TTP: 545.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.46\n","TTP: 560.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.46\n","TTP: 539.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.3\n","TTP: 359.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.34\n","TTP: 411.0s\n","\n","Sample arv7_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample rv1y_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample rv1y_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.52\n","TTP: 618.0s\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.44\n","TTP: 535.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.44\n","TTP: 766.0s\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.4\n","TTP: 458.0s\n","\n","Sample b2\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.34\n","TTP: 402.0s\n","\n","Sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.46\n","TTP: 550s\n","\n","Sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.42\n","TTP: 485s\n","\n","Sample exp_165_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.46\n","TTP: 546s\n","\n","Sample exp_35_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.44\n","TTP: 533s\n","\n","Sample exp_40_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.4\n","TTP: 484s\n","\n","Sample exp_88_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.4\n","TTP: 487s\n","\n","Sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_134_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.48\n","TTP: 561.0s\n","\n","Sample exp_97_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.48\n","TTP: 546s\n","\n","Sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.46\n","TTP: 532s\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.48\n","TTP: 563.0s\n","\n","Sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.48\n","TTP: 580.0s\n","\n","Sample yap1n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145y_n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv7\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Accuracy: 0.6530612244897959\n","Sensitivity/Recall: 0.7857142857142857\n","Specificity: 0.47619047619047616\n","Precision: 0.6666666666666666\n","F1 Score: 0.721311475409836\n"]}]},{"cell_type":"markdown","source":["#### Learning best threshold"],"metadata":{"id":"KPuLuWoixCSR"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651227410392,"user_tz":-60,"elapsed":341,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"HAfi2bU4phQC"},"execution_count":245,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651227411370,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"ps-swVLHphQD"},"execution_count":246,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651227411848,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"21312954-14d3-4ea9-e9fb-bd10118a7de0","id":"z-c4frksphQD"},"execution_count":247,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651227413694,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"r0eTLRQophQD"},"execution_count":248,"outputs":[]},{"cell_type":"markdown","source":["##### Generating candidates"],"metadata":{"id":"ErEA8XSGqh8a"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"_m7lA1HIer-y","executionInfo":{"status":"ok","timestamp":1651227420594,"user_tz":-60,"elapsed":2889,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":249,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"yVEuBQRb1BpE","executionInfo":{"status":"ok","timestamp":1651227420595,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":250,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are the set of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"rI2uBt6fxLlF","executionInfo":{"status":"ok","timestamp":1651227420595,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":251,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTV9vJPW5zUg","executionInfo":{"status":"ok","timestamp":1651227420595,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2ef36b43-d932-428d-d9c4-7aca63d09e8b"},"execution_count":252,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1560"]},"metadata":{},"execution_count":252}]},{"cell_type":"markdown","source":["##### Evaluating candidates"],"metadata":{"id":"872Hxw3fqlfv"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # array to hold cost function value for each candidate\n","  cost_function_values = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # alpha\n","  alpha = 0.95\n","\n","  # evaluate every candidate\n","  for th in threshold_candidates:\n","\n","    print(f\"Candidate: {th} \")\n","\n","    # array to hold earliness values for the samples \n","    earliness = []  \n","\n","    # dict to hold predictions vs true values for the samples  \n","    final_classifications = {}\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      # get KNN predicition for the sample\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","        \n","        # get the confidence for that prediction \n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","        if(c >= th): # check if confidence is at or above confidence threshold\n","\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          # predicted class for the sample is given by the prediction which led to the gien confidence value\n","          pred = predictions[i]\n","\n","          # update final outcomes dict\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","          # add to earliness array\n","          earliness.append(time_index/timestamps[-1])\n","\n","          break\n","\n","      sample_idx += 1\n","\n","    # get avg accuracy and avg earliness for this threshold\n","    if(len(final_classifications) > 0):\n","      avg_accuracy = accuracy(final_classifications)\n","      avg_earliness = sum(earliness)/len(earliness)\n","\n","      # compute value of cost function and add to array \n","      cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","      cost_function_values.append(cf_score)\n","      print(f\"Score: {cf_score}\")\n","      print(\"\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKc1S0R6ebff","executionInfo":{"status":"ok","timestamp":1651227828734,"user_tz":-60,"elapsed":37029,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"134bff98-4aa1-4acf-b5d3-6e59e4cd4f3c"},"execution_count":280,"outputs":[{"output_type":"stream","name":"stdout","text":["Candidate: 0.45141065830721 \n","Score: 0.3305918367346939\n","\n","Candidate: 0.5648902821316615 \n","Score: 0.3305918367346939\n","\n","Candidate: 0.6171368861024034 \n","Score: 0.44732653061224487\n","\n","Candidate: 0.6353187042842214 \n","Score: 0.44732653061224487\n","\n","Candidate: 0.6602870813397128 \n","Score: 0.4086326530612245\n","\n","Candidate: 0.6869328493647913 \n","Score: 0.4283469387755102\n","\n","Candidate: 0.7084639498432602 \n","Score: 0.5456530612244898\n","\n","Candidate: 0.7288951218170818 \n","Score: 0.5456938775510204\n","\n","Candidate: 0.7427542209756366 \n","Score: 0.5070408163265305\n","\n","Candidate: 0.7714348567343122 \n","Score: 0.5070408163265305\n","\n","Candidate: 0.7986580872243304 \n","Score: 0.526469387755102\n","\n","Candidate: 0.8148911987387486 \n","Score: 0.526469387755102\n","\n","Candidate: 0.8285028139837577 \n","Score: 0.5265510204081633\n","\n","Candidate: 0.8369905956112853 \n","Score: 0.5270816326530612\n","\n","Candidate: 0.8405103668261563 \n","Score: 0.48853061224489797\n","\n","Candidate: 0.8507974481658692 \n","Score: 0.48855102040816323\n","\n","Candidate: 0.8603829362202569 \n","Score: 0.48865306122448976\n","\n","Candidate: 0.8680279245901303 \n","Score: 0.48865306122448976\n","\n","Candidate: 0.8749963605306832 \n","Score: 0.48873469387755103\n","\n","Candidate: 0.8831408458450201 \n","Score: 0.48873469387755103\n","\n","Candidate: 0.8926368952684742 \n","Score: 0.4887959183673469\n","\n","Candidate: 0.8963813430558386 \n","Score: 0.48881632653061224\n","\n","Candidate: 0.8979601293236201 \n","Score: 0.46951020408163263\n","\n","Candidate: 0.8991257110002575 \n","Score: 0.46951020408163263\n","\n","Candidate: 0.9042603480090858 \n","Score: 0.46951020408163263\n","\n","Candidate: 0.9100078274199104 \n","Score: 0.46951020408163263\n","\n","Candidate: 0.9133220856773342 \n","Score: 0.4309183673469388\n","\n","Candidate: 0.9170158178472725 \n","Score: 0.4507551020408163\n","\n","Candidate: 0.9183678615433796 \n","Score: 0.4507551020408163\n","\n","Candidate: 0.9188007918804163 \n","Score: 0.47020408163265304\n","\n","Candidate: 0.9227445804258018 \n","Score: 0.4508775510204081\n","\n","Candidate: 0.9274978891077963 \n","Score: 0.4508979591836734\n","\n","Candidate: 0.9321292446440808 \n","Score: 0.4897142857142857\n","\n","Candidate: 0.9374956825903202 \n","Score: 0.4897142857142857\n","\n","Candidate: 0.9393830777418456 \n","Score: 0.4897551020408163\n","\n","Candidate: 0.9398614657642712 \n","Score: 0.4703877551020408\n","\n","Candidate: 0.940476074937482 \n","Score: 0.4510204081632653\n","\n","Candidate: 0.9432101123953258 \n","Score: 0.4510204081632653\n","\n","Candidate: 0.9464997203025607 \n","Score: 0.4510612244897959\n","\n","Candidate: 0.9495377265632592 \n","Score: 0.4510612244897959\n","\n","Candidate: 0.9521015123789808 \n","Score: 0.4510612244897959\n","\n","Candidate: 0.9525663208801445 \n","Score: 0.451204081632653\n","\n","Candidate: 0.9532841129333385 \n","Score: 0.451204081632653\n","\n","Candidate: 0.9546646699937938 \n","Score: 0.4322244897959184\n","\n","Candidate: 0.9560896983346936 \n","Score: 0.432265306122449\n","\n","Candidate: 0.9574286186578138 \n","Score: 0.4323265306122449\n","\n","Candidate: 0.9599130205143477 \n","Score: 0.4323265306122449\n","\n","Candidate: 0.963157750134604 \n","Score: 0.4129795918367347\n","\n","Candidate: 0.9647512304992572 \n","Score: 0.4129795918367347\n","\n","Candidate: 0.9661044985777778 \n","Score: 0.413\n","\n","Candidate: 0.9681039789431231 \n","Score: 0.4130408163265306\n","\n","Candidate: 0.9691454936333962 \n","Score: 0.41306122448979593\n","\n","Candidate: 0.9706654033531963 \n","Score: 0.4131020408163265\n","\n","Candidate: 0.9719562493143827 \n","Score: 0.41322448979591836\n","\n","Candidate: 0.9730406548228345 \n","Score: 0.413265306122449\n","\n","Candidate: 0.974633188005471 \n","Score: 0.413265306122449\n","\n","Candidate: 0.9752933626476967 \n","Score: 0.43267346938775514\n","\n","Candidate: 0.9754618175550138 \n","Score: 0.4135714285714286\n","\n","Candidate: 0.975771826545118 \n","Score: 0.4135918367346939\n","\n","Candidate: 0.9764600108528863 \n","Score: 0.4136326530612245\n","\n","Candidate: 0.9772583572390375 \n","Score: 0.4136530612244898\n","\n","Candidate: 0.9776082054666446 \n","Score: 0.41369387755102044\n","\n","Candidate: 0.9776778380373017 \n","Score: 0.4137959183673469\n","\n","Candidate: 0.9777599688049521 \n","Score: 0.41381632653061223\n","\n","Candidate: 0.978001820020107 \n","Score: 0.41381632653061223\n","\n","Candidate: 0.9789248259559225 \n","Score: 0.41381632653061223\n","\n","Candidate: 0.9799616396081176 \n","Score: 0.4332448979591837\n","\n","Candidate: 0.9805113839162392 \n","Score: 0.4332448979591837\n","\n","Candidate: 0.9808342984289203 \n","Score: 0.4332857142857143\n","\n","Candidate: 0.9812996788366586 \n","Score: 0.4332857142857143\n","\n","Candidate: 0.9828233306637123 \n","Score: 0.4333061224489796\n","\n","Candidate: 0.9840015474370967 \n","Score: 0.4333061224489796\n","\n","Candidate: 0.9840208787689304 \n","Score: 0.4139591836734694\n","\n","Candidate: 0.9841631777331058 \n","Score: 0.4139591836734694\n","\n","Candidate: 0.9848786062302535 \n","Score: 0.4139795918367347\n","\n","Candidate: 0.9855400265356467 \n","Score: 0.414\n","\n","Candidate: 0.9859177486630253 \n","Score: 0.4140204081632653\n","\n","Candidate: 0.986266959760369 \n","Score: 0.4140204081632653\n","\n","Candidate: 0.9864280185758514 \n","Score: 0.4140204081632653\n","\n","Candidate: 0.9868180824656814 \n","Score: 0.4140408163265306\n","\n","Candidate: 0.9871646566882071 \n","Score: 0.41408163265306125\n","\n","Candidate: 0.9872680346560245 \n","Score: 0.43348979591836734\n","\n","Candidate: 0.9873625884056959 \n","Score: 0.43348979591836734\n","\n","Candidate: 0.9875306360589702 \n","Score: 0.43348979591836734\n","\n","Candidate: 0.9878202559690763 \n","Score: 0.43348979591836734\n","\n","Candidate: 0.9880309538486667 \n","Score: 0.43351020408163266\n","\n","Candidate: 0.988174651497115 \n","Score: 0.4335510204081633\n","\n","Candidate: 0.9883019303507248 \n","Score: 0.4335510204081633\n","\n","Candidate: 0.9883651401668179 \n","Score: 0.4335714285714286\n","\n","Candidate: 0.9886118370047883 \n","Score: 0.43383673469387757\n","\n","Candidate: 0.9889694911766219 \n","Score: 0.45332653061224487\n","\n","Candidate: 0.9891540370559027 \n","Score: 0.4533469387755102\n","\n","Candidate: 0.9894208010639092 \n","Score: 0.4533469387755102\n","\n","Candidate: 0.989701025783488 \n","Score: 0.4533469387755102\n","\n","Candidate: 0.989849655097496 \n","Score: 0.4533469387755102\n","\n","Candidate: 0.9899961135859503 \n","Score: 0.4533469387755102\n","\n","Candidate: 0.9900796098653484 \n","Score: 0.45336734693877545\n","\n","Candidate: 0.9903032327701298 \n","Score: 0.45338775510204077\n","\n","Candidate: 0.9905219413042718 \n","Score: 0.45338775510204077\n","\n","Candidate: 0.9906927357198533 \n","Score: 0.45338775510204077\n","\n","Candidate: 0.990852542412567 \n","Score: 0.4534081632653061\n","\n","Candidate: 0.9909078736363266 \n","Score: 0.47283673469387755\n","\n","Candidate: 0.9910352575551584 \n","Score: 0.4728775510204081\n","\n","Candidate: 0.9912710996857375 \n","Score: 0.4728775510204081\n","\n","Candidate: 0.9914700644800857 \n","Score: 0.4728775510204081\n","\n","Candidate: 0.9917110470379598 \n","Score: 0.47289795918367344\n","\n","Candidate: 0.9919550864867408 \n","Score: 0.47289795918367344\n","\n","Candidate: 0.9921341212792466 \n","Score: 0.47291836734693876\n","\n","Candidate: 0.9923552113725871 \n","Score: 0.4729387755102041\n","\n","Candidate: 0.9925345758647729 \n","Score: 0.4729387755102041\n","\n","Candidate: 0.9926736154141107 \n","Score: 0.47295918367346934\n","\n","Candidate: 0.9929170701507644 \n","Score: 0.47297959183673466\n","\n","Candidate: 0.9930981407739918 \n","Score: 0.47297959183673466\n","\n","Candidate: 0.9934742963011887 \n","Score: 0.4923877551020408\n","\n","Candidate: 0.9938650193312365 \n","Score: 0.4923877551020408\n","\n","Candidate: 0.9939696149351811 \n","Score: 0.492469387755102\n","\n","Candidate: 0.9941146165157708 \n","Score: 0.492469387755102\n","\n","Candidate: 0.9941964850083607 \n","Score: 0.49248979591836733\n","\n","Candidate: 0.9942375364034517 \n","Score: 0.4927551020408163\n","\n","Candidate: 0.9942756323991984 \n","Score: 0.4927551020408163\n","\n","Candidate: 0.9943326603974476 \n","Score: 0.493\n","\n","Candidate: 0.9944295537398478 \n","Score: 0.49304081632653063\n","\n","Candidate: 0.9945232250705662 \n","Score: 0.49304081632653063\n","\n","Candidate: 0.9946028058261103 \n","Score: 0.4930612244897959\n","\n","Candidate: 0.9947194434059579 \n","Score: 0.4930816326530612\n","\n","Candidate: 0.9948643644353306 \n","Score: 0.4930816326530612\n","\n","Candidate: 0.995044352736091 \n","Score: 0.49312244897959184\n","\n","Candidate: 0.9951634809239389 \n","Score: 0.49318367346938774\n","\n","Candidate: 0.9952173467725041 \n","Score: 0.49320408163265306\n","\n","Candidate: 0.9952875089950939 \n","Score: 0.49320408163265306\n","\n","Candidate: 0.9953851888516135 \n","Score: 0.4932244897959184\n","\n","Candidate: 0.9955032764140173 \n","Score: 0.49326530612244895\n","\n","Candidate: 0.9955540108309738 \n","Score: 0.49326530612244895\n","\n","Candidate: 0.9955991836876359 \n","Score: 0.49328571428571427\n","\n","Candidate: 0.9956355817896505 \n","Score: 0.49328571428571427\n","\n","Candidate: 0.9956684595739824 \n","Score: 0.4933061224489796\n","\n","Candidate: 0.9957242138247189 \n","Score: 0.4933061224489796\n","\n","Candidate: 0.9957925691186809 \n","Score: 0.4933265306122449\n","\n","Candidate: 0.9958899991869763 \n","Score: 0.49334693877551017\n","\n","Candidate: 0.9960156317179556 \n","Score: 0.49334693877551017\n","\n","Candidate: 0.9962311046107137 \n","Score: 0.4933673469387755\n","\n","Candidate: 0.996426487140889 \n","Score: 0.4933877551020408\n","\n","Candidate: 0.9966031210506409 \n","Score: 0.4933877551020408\n","\n","Candidate: 0.9967646060121842 \n","Score: 0.4934081632653061\n","\n","Candidate: 0.9968212271894926 \n","Score: 0.49342857142857144\n","\n","Candidate: 0.9968428617604751 \n","Score: 0.4743061224489796\n","\n","Candidate: 0.9968518860586884 \n","Score: 0.4743265306122449\n","\n","Candidate: 0.9969441543903332 \n","Score: 0.4744081632653061\n","\n","Candidate: 0.9970326721389837 \n","Score: 0.4744081632653061\n","\n","Candidate: 0.9971132198987711 \n","Score: 0.4744285714285714\n","\n","Candidate: 0.9972429432611342 \n","Score: 0.474469387755102\n","\n","Candidate: 0.9973076504303804 \n","Score: 0.474469387755102\n","\n","Candidate: 0.9973874618353542 \n","Score: 0.4744897959183673\n","\n","Candidate: 0.9974905717149891 \n","Score: 0.47451020408163264\n","\n","Candidate: 0.9975358420646364 \n","Score: 0.47455102040816327\n","\n","Candidate: 0.997589680437375 \n","Score: 0.47457142857142853\n","\n","Candidate: 0.997642581737689 \n","Score: 0.47459183673469385\n","\n","Candidate: 0.9976527392052208 \n","Score: 0.47461224489795917\n","\n","Candidate: 0.9976537611380372 \n","Score: 0.4746530612244898\n","\n","Candidate: 0.9976542193850633 \n","Score: 0.47467346938775506\n","\n","Candidate: 0.9977129878849806 \n","Score: 0.4746938775510204\n","\n","Candidate: 0.9977836820022981 \n","Score: 0.4746938775510204\n","\n","Candidate: 0.9978115881937031 \n","Score: 0.4746938775510204\n","\n","Candidate: 0.997846572111033 \n","Score: 0.4747142857142857\n","\n","Candidate: 0.9978965350698724 \n","Score: 0.474734693877551\n","\n","Candidate: 0.9979496657762543 \n","Score: 0.474734693877551\n","\n","Candidate: 0.997980596953284 \n","Score: 0.474734693877551\n","\n","Candidate: 0.9979943939848843 \n","Score: 0.45536734693877545\n","\n","Candidate: 0.9980675098737617 \n","Score: 0.45538775510204077\n","\n","Candidate: 0.9981679725751852 \n","Score: 0.45538775510204077\n","\n","Candidate: 0.9982324323207417 \n","Score: 0.4554081632653061\n","\n","Candidate: 0.9983199758320941 \n","Score: 0.47481632653061223\n","\n","Candidate: 0.9983789078846028 \n","Score: 0.4750612244897959\n","\n","Candidate: 0.9983828846051227 \n","Score: 0.47514285714285714\n","\n","Candidate: 0.9983837090732471 \n","Score: 0.47514285714285714\n","\n","Candidate: 0.9984255173951327 \n","Score: 0.4751632653061224\n","\n","Candidate: 0.9984715758452659 \n","Score: 0.47520408163265304\n","\n","Candidate: 0.9984779919392555 \n","Score: 0.45583673469387753\n","\n","Candidate: 0.9985089073200055 \n","Score: 0.45583673469387753\n","\n","Candidate: 0.9985479314819412 \n","Score: 0.45585714285714285\n","\n","Candidate: 0.9985862869288484 \n","Score: 0.45585714285714285\n","\n","Candidate: 0.9986370777127969 \n","Score: 0.45585714285714285\n","\n","Candidate: 0.9986700269860214 \n","Score: 0.4558775510204081\n","\n","Candidate: 0.9986838464541551 \n","Score: 0.45589795918367343\n","\n","Candidate: 0.9986875374806768 \n","Score: 0.45591836734693875\n","\n","Candidate: 0.9986896271489958 \n","Score: 0.45591836734693875\n","\n","Candidate: 0.9987094368819944 \n","Score: 0.45593877551020406\n","\n","Candidate: 0.9987699114764914 \n","Score: 0.45597959183673464\n","\n","Candidate: 0.9988406681822661 \n","Score: 0.45597959183673464\n","\n","Candidate: 0.9988771323595116 \n","Score: 0.45599999999999996\n","\n","Candidate: 0.9988938721735937 \n","Score: 0.45599999999999996\n","\n","Candidate: 0.998908041472803 \n","Score: 0.4560204081632653\n","\n","Candidate: 0.9989567499245077 \n","Score: 0.4560408163265306\n","\n","Candidate: 0.9990151507953555 \n","Score: 0.45616326530612245\n","\n","Candidate: 0.9990318340235695 \n","Score: 0.4561836734693877\n","\n","Candidate: 0.999035262423792 \n","Score: 0.456204081632653\n","\n","Candidate: 0.999040970422661 \n","Score: 0.45622448979591834\n","\n","Candidate: 0.9991038954203033 \n","Score: 0.45622448979591834\n","\n","Candidate: 0.999169622695855 \n","Score: 0.45646938775510204\n","\n","Candidate: 0.9991779609113218 \n","Score: 0.45646938775510204\n","\n","Candidate: 0.9991804772498989 \n","Score: 0.4564897959183673\n","\n","Candidate: 0.9991860856771252 \n","Score: 0.4564897959183673\n","\n","Candidate: 0.9991996893445887 \n","Score: 0.4565714285714285\n","\n","Candidate: 0.9992099924872011 \n","Score: 0.4565714285714285\n","\n","Candidate: 0.999219208969543 \n","Score: 0.45661224489795915\n","\n","Candidate: 0.9992294714344512 \n","Score: 0.4566530612244898\n","\n","Candidate: 0.9992358396479682 \n","Score: 0.4566530612244898\n","\n","Candidate: 0.9992437288045628 \n","Score: 0.45667346938775505\n","\n","Candidate: 0.9992490814228446 \n","Score: 0.4567959183673469\n","\n","Candidate: 0.9992702830137605 \n","Score: 0.4567959183673469\n","\n","Candidate: 0.9992922325794074 \n","Score: 0.4568163265306122\n","\n","Candidate: 0.9993099849973933 \n","Score: 0.45683673469387753\n","\n","Candidate: 0.9993351644543608 \n","Score: 0.45685714285714285\n","\n","Candidate: 0.9993475265375142 \n","Score: 0.45689795918367343\n","\n","Candidate: 0.9993521497656275 \n","Score: 0.45691836734693875\n","\n","Candidate: 0.9993700746272554 \n","Score: 0.45693877551020406\n","\n","Candidate: 0.9993906963903918 \n","Score: 0.45693877551020406\n","\n","Candidate: 0.9994005597977145 \n","Score: 0.4569591836734694\n","\n","Candidate: 0.9994068409145593 \n","Score: 0.4569591836734694\n","\n","Candidate: 0.9994210167117619 \n","Score: 0.45697959183673464\n","\n","Candidate: 0.9994579565505319 \n","Score: 0.45699999999999996\n","\n","Candidate: 0.9994982979269806 \n","Score: 0.4570204081632653\n","\n","Candidate: 0.9995339539886721 \n","Score: 0.4570408163265306\n","\n","Candidate: 0.9995582243156409 \n","Score: 0.4570612244897959\n","\n","Candidate: 0.9995726943472407 \n","Score: 0.4570612244897959\n","\n","Candidate: 0.9995877536498041 \n","Score: 0.4379183673469388\n","\n","Candidate: 0.9995947269711507 \n","Score: 0.4379591836734694\n","\n","Candidate: 0.9995987211465729 \n","Score: 0.43804081632653064\n","\n","Candidate: 0.9996024600345352 \n","Score: 0.43806122448979595\n","\n","Candidate: 0.9996081918014276 \n","Score: 0.43806122448979595\n","\n","Candidate: 0.9996145716652931 \n","Score: 0.43810204081632653\n","\n","Candidate: 0.9996177557720518 \n","Score: 0.43810204081632653\n","\n","Candidate: 0.9996364552559618 \n","Score: 0.43812244897959185\n","\n","Candidate: 0.9996537080942274 \n","Score: 0.45753061224489794\n","\n","Candidate: 0.9996585942449978 \n","Score: 0.45755102040816326\n","\n","Candidate: 0.9996644988653207 \n","Score: 0.4575714285714286\n","\n","Candidate: 0.9996670228175504 \n","Score: 0.45759183673469384\n","\n","Candidate: 0.99967010617941 \n","Score: 0.45759183673469384\n","\n","Candidate: 0.9996780330294834 \n","Score: 0.45763265306122447\n","\n","Candidate: 0.999685097120782 \n","Score: 0.45763265306122447\n","\n","Candidate: 0.9996908030994711 \n","Score: 0.4576530612244898\n","\n","Candidate: 0.9997015422613025 \n","Score: 0.4576734693877551\n","\n","Candidate: 0.999711288111679 \n","Score: 0.45769387755102037\n","\n","Candidate: 0.9997160218409366 \n","Score: 0.45769387755102037\n","\n","Candidate: 0.9997289782752661 \n","Score: 0.4577142857142857\n","\n","Candidate: 0.9997409337796677 \n","Score: 0.457734693877551\n","\n","Candidate: 0.9997471526579875 \n","Score: 0.4577551020408163\n","\n","Candidate: 0.9997602271673203 \n","Score: 0.45799999999999996\n","\n","Candidate: 0.9997686410388176 \n","Score: 0.4580204081632653\n","\n","Candidate: 0.9997718343796376 \n","Score: 0.4580408163265306\n","\n","Candidate: 0.9997770844948941 \n","Score: 0.4580612244897959\n","\n","Candidate: 0.9997804442455303 \n","Score: 0.45814285714285713\n","\n","Candidate: 0.9997828137894513 \n","Score: 0.45814285714285713\n","\n","Candidate: 0.9997871418507958 \n","Score: 0.45814285714285713\n","\n","Candidate: 0.9997899524884464 \n","Score: 0.4581836734693877\n","\n","Candidate: 0.9997916892739511 \n","Score: 0.4584081632653061\n","\n","Candidate: 0.9997947657392511 \n","Score: 0.4584285714285714\n","\n","Candidate: 0.9998014241299851 \n","Score: 0.458469387755102\n","\n","Candidate: 0.9998130810046539 \n","Score: 0.47828571428571426\n","\n","Candidate: 0.9998203251617388 \n","Score: 0.47828571428571426\n","\n","Candidate: 0.9998205734996954 \n","Score: 0.47828571428571426\n","\n","Candidate: 0.9998243622687473 \n","Score: 0.4783061224489796\n","\n","Candidate: 0.9998297194447492 \n","Score: 0.4783265306122449\n","\n","Candidate: 0.9998318395316528 \n","Score: 0.47834693877551016\n","\n","Candidate: 0.9998341376896518 \n","Score: 0.4783673469387755\n","\n","Candidate: 0.9998360892715892 \n","Score: 0.4783877551020408\n","\n","Candidate: 0.9998395609411841 \n","Score: 0.4784285714285714\n","\n","Candidate: 0.9998508294323778 \n","Score: 0.47844897959183674\n","\n","Candidate: 0.9998627702749758 \n","Score: 0.478469387755102\n","\n","Candidate: 0.999868361591469 \n","Score: 0.4784897959183673\n","\n","Candidate: 0.9998747561163701 \n","Score: 0.47851020408163264\n","\n","Candidate: 0.9998799172484995 \n","Score: 0.47853061224489796\n","\n","Candidate: 0.9998804781615735 \n","Score: 0.4593265306122449\n","\n","Candidate: 0.9998811472028213 \n","Score: 0.4594081632653061\n","\n","Candidate: 0.9998824601349647 \n","Score: 0.4594285714285714\n","\n","Candidate: 0.9998836014990811 \n","Score: 0.4594489795918367\n","\n","Candidate: 0.9998840647894305 \n","Score: 0.45946938775510204\n","\n","Candidate: 0.9998853986048524 \n","Score: 0.45946938775510204\n","\n","Candidate: 0.9998889869991954 \n","Score: 0.4790816326530612\n","\n","Candidate: 0.9998924327214376 \n","Score: 0.47912244897959183\n","\n","Candidate: 0.9998953106882885 \n","Score: 0.47914285714285715\n","\n","Candidate: 0.9998978860481333 \n","Score: 0.47914285714285715\n","\n","Candidate: 0.9999003909348602 \n","Score: 0.4791836734693877\n","\n","Candidate: 0.9999032100396948 \n","Score: 0.4791836734693877\n","\n","Candidate: 0.9999046125285346 \n","Score: 0.47920408163265305\n","\n","Candidate: 0.9999062271531027 \n","Score: 0.47922448979591836\n","\n","Candidate: 0.999907930384549 \n","Score: 0.45985714285714285\n","\n","Candidate: 0.9999097723188062 \n","Score: 0.4598775510204081\n","\n","Candidate: 0.999912504191721 \n","Score: 0.45991836734693875\n","\n","Candidate: 0.9999168027425074 \n","Score: 0.45993877551020407\n","\n","Candidate: 0.9999205669676583 \n","Score: 0.45993877551020407\n","\n","Candidate: 0.9999223855978054 \n","Score: 0.4599591836734694\n","\n","Candidate: 0.9999242191088077 \n","Score: 0.45997959183673465\n","\n","Candidate: 0.9999256080295329 \n","Score: 0.45997959183673465\n","\n","Candidate: 0.9999263845471018 \n","Score: 0.45997959183673465\n","\n","Candidate: 0.9999288538031175 \n","Score: 0.45997959183673465\n","\n","Candidate: 0.9999312058580261 \n","Score: 0.45999999999999996\n","\n","Candidate: 0.9999348915875352 \n","Score: 0.4600204081632653\n","\n","Candidate: 0.9999388909349749 \n","Score: 0.46022448979591835\n","\n","Candidate: 0.9999395752643283 \n","Score: 0.46024489795918366\n","\n","Candidate: 0.9999402304332106 \n","Score: 0.46024489795918366\n","\n","Candidate: 0.9999412300674824 \n","Score: 0.460265306122449\n","\n","Candidate: 0.9999429222460634 \n","Score: 0.46028571428571424\n","\n","Candidate: 0.9999445068698568 \n","Score: 0.4603265306122449\n","\n","Candidate: 0.9999449670052373 \n","Score: 0.4603673469387755\n","\n","Candidate: 0.9999451178233919 \n","Score: 0.4603877551020408\n","\n","Candidate: 0.9999452130576767 \n","Score: 0.4604081632653061\n","\n","Candidate: 0.9999454320804881 \n","Score: 0.4604897959183673\n","\n","Candidate: 0.9999474321398065 \n","Score: 0.4604897959183673\n","\n","Candidate: 0.9999497874471508 \n","Score: 0.4605102040816326\n","\n","Candidate: 0.999950398785697 \n","Score: 0.46053061224489794\n","\n","Candidate: 0.9999510804262308 \n","Score: 0.46055102040816326\n","\n","Candidate: 0.9999519200952625 \n","Score: 0.46059183673469384\n","\n","Candidate: 0.9999523642956969 \n","Score: 0.46061224489795916\n","\n","Candidate: 0.9999547897528467 \n","Score: 0.46061224489795916\n","\n","Candidate: 0.9999571167837057 \n","Score: 0.4606326530612245\n","\n","Candidate: 0.9999577928859718 \n","Score: 0.4606326530612245\n","\n","Candidate: 0.9999593266322491 \n","Score: 0.4606530612244898\n","\n","Candidate: 0.9999605326425585 \n","Score: 0.4606530612244898\n","\n","Candidate: 0.9999608410805098 \n","Score: 0.4606734693877551\n","\n","Candidate: 0.9999609611257807 \n","Score: 0.46069387755102037\n","\n","Candidate: 0.999963355517672 \n","Score: 0.46069387755102037\n","\n","Candidate: 0.9999664182962141 \n","Score: 0.4607142857142857\n","\n","Candidate: 0.999968030243892 \n","Score: 0.460734693877551\n","\n","Candidate: 0.9999692431821064 \n","Score: 0.4607551020408163\n","\n","Candidate: 0.9999698138217994 \n","Score: 0.4607551020408163\n","\n","Candidate: 0.9999702263596727 \n","Score: 0.4607959183673469\n","\n","Candidate: 0.9999706150337412 \n","Score: 0.4608163265306122\n","\n","Candidate: 0.9999712667143938 \n","Score: 0.46083673469387754\n","\n","Candidate: 0.9999717316152188 \n","Score: 0.519204081632653\n","\n","Candidate: 0.9999719260238568 \n","Score: 0.5192857142857142\n","\n","Candidate: 0.999972293276734 \n","Score: 0.5193265306122449\n","\n","Candidate: 0.9999727157579786 \n","Score: 0.5193469387755102\n","\n","Candidate: 0.9999741216013021 \n","Score: 0.5193469387755102\n","\n","Candidate: 0.9999759934284598 \n","Score: 0.5193673469387755\n","\n","Candidate: 0.9999769169873862 \n","Score: 0.5193877551020407\n","\n","Candidate: 0.9999772731408476 \n","Score: 0.519408163265306\n","\n","Candidate: 0.999977401693619 \n","Score: 0.519408163265306\n","\n","Candidate: 0.9999775752047201 \n","Score: 0.5194285714285714\n","\n","Candidate: 0.9999777598381399 \n","Score: 0.5194285714285714\n","\n","Candidate: 0.9999782518918328 \n","Score: 0.519469387755102\n","\n","Candidate: 0.9999788964821319 \n","Score: 0.5194897959183673\n","\n","Candidate: 0.9999791193674046 \n","Score: 0.5195102040816326\n","\n","Candidate: 0.9999795536628204 \n","Score: 0.5195306122448979\n","\n","Candidate: 0.9999801294710293 \n","Score: 0.48081632653061224\n","\n","Candidate: 0.9999805763377789 \n","Score: 0.48083673469387755\n","\n","Candidate: 0.999981859141653 \n","Score: 0.4808571428571428\n","\n","Candidate: 0.9999833848377266 \n","Score: 0.48087755102040813\n","\n","Candidate: 0.999983913560317 \n","Score: 0.48089795918367345\n","\n","Candidate: 0.9999840481611738 \n","Score: 0.48091836734693877\n","\n","Candidate: 0.9999845368145197 \n","Score: 0.48095918367346935\n","\n","Candidate: 0.9999850513638755 \n","Score: 0.48097959183673467\n","\n","Candidate: 0.9999853088694048 \n","Score: 0.46161224489795916\n","\n","Candidate: 0.9999855326436419 \n","Score: 0.48114285714285715\n","\n","Candidate: 0.999985844435902 \n","Score: 0.48114285714285715\n","\n","Candidate: 0.999986142676734 \n","Score: 0.48120408163265305\n","\n","Candidate: 0.9999862577105791 \n","Score: 0.4812448979591837\n","\n","Candidate: 0.9999865188451693 \n","Score: 0.48126530612244894\n","\n","Candidate: 0.9999869065155369 \n","Score: 0.48134693877551016\n","\n","Candidate: 0.9999871071285191 \n","Score: 0.46197959183673465\n","\n","Candidate: 0.9999872512604902 \n","Score: 0.46197959183673465\n","\n","Candidate: 0.9999875390075141 \n","Score: 0.46199999999999997\n","\n","Candidate: 0.9999879763806802 \n","Score: 0.4620204081632653\n","\n","Candidate: 0.9999882226863335 \n","Score: 0.4620204081632653\n","\n","Candidate: 0.9999882500630731 \n","Score: 0.4620408163265306\n","\n","Candidate: 0.9999883446738477 \n","Score: 0.46206122448979586\n","\n","Candidate: 0.9999884375149374 \n","Score: 0.44279591836734694\n","\n","Candidate: 0.9999885042425039 \n","Score: 0.44281632653061226\n","\n","Candidate: 0.9999893540198215 \n","Score: 0.42346938775510207\n","\n","Candidate: 0.9999903767391611 \n","Score: 0.42348979591836733\n","\n","Candidate: 0.9999906464067976 \n","Score: 0.42351020408163265\n","\n","Candidate: 0.9999906869155989 \n","Score: 0.42351020408163265\n","\n","Candidate: 0.9999909815032444 \n","Score: 0.42353061224489796\n","\n","Candidate: 0.999991330847726 \n","Score: 0.4235510204081633\n","\n","Candidate: 0.9999915065292653 \n","Score: 0.4235714285714286\n","\n","Candidate: 0.999991624542776 \n","Score: 0.42359183673469386\n","\n","Candidate: 0.9999917572034693 \n","Score: 0.4236122448979592\n","\n","Candidate: 0.9999920514096059 \n","Score: 0.4236326530612245\n","\n","Candidate: 0.999992317383704 \n","Score: 0.4236530612244898\n","\n","Candidate: 0.9999924391280064 \n","Score: 0.42367346938775513\n","\n","Candidate: 0.9999925015749508 \n","Score: 0.42383673469387756\n","\n","Candidate: 0.9999925439716 \n","Score: 0.4238571428571429\n","\n","Candidate: 0.9999927322452562 \n","Score: 0.4238775510204082\n","\n","Candidate: 0.9999930393036589 \n","Score: 0.4239183673469388\n","\n","Candidate: 0.9999932557478971 \n","Score: 0.4240408163265306\n","\n","Candidate: 0.9999933633881704 \n","Score: 0.42406122448979594\n","\n","Candidate: 0.9999934524712355 \n","Score: 0.4240816326530612\n","\n","Candidate: 0.9999938119107148 \n","Score: 0.4240816326530612\n","\n","Candidate: 0.9999941353237258 \n","Score: 0.4240816326530612\n","\n","Candidate: 0.9999941983540053 \n","Score: 0.4241020408163265\n","\n","Candidate: 0.9999942249946405 \n","Score: 0.42412244897959184\n","\n","Candidate: 0.999994281169519 \n","Score: 0.42412244897959184\n","\n","Candidate: 0.9999943698078605 \n","Score: 0.42420408163265305\n","\n","Candidate: 0.9999944485220383 \n","Score: 0.42422448979591837\n","\n","Candidate: 0.9999945656349001 \n","Score: 0.4242448979591837\n","\n","Candidate: 0.9999947948477776 \n","Score: 0.424265306122449\n","\n","Candidate: 0.9999950448096702 \n","Score: 0.42428571428571427\n","\n","Candidate: 0.9999951762750612 \n","Score: 0.4243061224489796\n","\n","Candidate: 0.9999952140244435 \n","Score: 0.4243265306122449\n","\n","Candidate: 0.9999952884683279 \n","Score: 0.4243469387755102\n","\n","Candidate: 0.9999953691915973 \n","Score: 0.4243469387755102\n","\n","Candidate: 0.999995454176336 \n","Score: 0.42436734693877554\n","\n","Candidate: 0.999995642610715 \n","Score: 0.42438775510204085\n","\n","Candidate: 0.9999958192997335 \n","Score: 0.42438775510204085\n","\n","Candidate: 0.9999959174991433 \n","Score: 0.4244081632653061\n","\n","Candidate: 0.9999959698198531 \n","Score: 0.40516326530612246\n","\n","Candidate: 0.999996033332439 \n","Score: 0.4051836734693878\n","\n","Candidate: 0.999996089496337 \n","Score: 0.4051836734693878\n","\n","Candidate: 0.9999961302869264 \n","Score: 0.4052040816326531\n","\n","Candidate: 0.9999961610450294 \n","Score: 0.40522448979591835\n","\n","Candidate: 0.9999962570448977 \n","Score: 0.40522448979591835\n","\n","Candidate: 0.9999964040083711 \n","Score: 0.40524489795918367\n","\n","Candidate: 0.9999965196287224 \n","Score: 0.405265306122449\n","\n","Candidate: 0.9999966319192441 \n","Score: 0.4052857142857143\n","\n","Candidate: 0.9999967715015263 \n","Score: 0.4053673469387755\n","\n","Candidate: 0.9999969038439055 \n","Score: 0.40538775510204084\n","\n","Candidate: 0.9999969726408279 \n","Score: 0.4054081632653061\n","\n","Candidate: 0.9999970342897795 \n","Score: 0.4054285714285714\n","\n","Candidate: 0.9999970784595469 \n","Score: 0.3667755102040816\n","\n","Candidate: 0.9999971459309545 \n","Score: 0.3667755102040816\n","\n","Candidate: 0.9999972070833252 \n","Score: 0.36679591836734693\n","\n","Candidate: 0.9999972314574896 \n","Score: 0.36681632653061225\n","\n","Candidate: 0.9999972770620993 \n","Score: 0.36681632653061225\n","\n","Candidate: 0.99999738334871 \n","Score: 0.36681632653061225\n","\n","Candidate: 0.9999974654686218 \n","Score: 0.34744897959183674\n","\n","Candidate: 0.9999974668770442 \n","Score: 0.34744897959183674\n","\n","Candidate: 0.9999975179219216 \n","Score: 0.34746938775510205\n","\n","Candidate: 0.9999976033809258 \n","Score: 0.3474897959183674\n","\n","Candidate: 0.9999976587922819 \n","Score: 0.3475102040816327\n","\n","Candidate: 0.9999976883100985 \n","Score: 0.347530612244898\n","\n","Candidate: 0.9999977005042024 \n","Score: 0.3476122448979592\n","\n","Candidate: 0.999997787466038 \n","Score: 0.34763265306122454\n","\n","Candidate: 0.9999978950549193 \n","Score: 0.3476530612244898\n","\n","Candidate: 0.9999979259560174 \n","Score: 0.34769387755102044\n","\n","Candidate: 0.9999979559538197 \n","Score: 0.34771428571428575\n","\n","Candidate: 0.9999979848867367 \n","Score: 0.34771428571428575\n","\n","Candidate: 0.999997995256948 \n","Score: 0.34773469387755107\n","\n","Candidate: 0.9999980092555196 \n","Score: 0.34775510204081633\n","\n","Candidate: 0.9999980639399684 \n","Score: 0.34777551020408165\n","\n","Candidate: 0.9999981543416303 \n","Score: 0.34779591836734697\n","\n","Candidate: 0.9999982483697347 \n","Score: 0.3478163265306123\n","\n","Candidate: 0.9999983409852244 \n","Score: 0.3478367346938776\n","\n","Candidate: 0.9999984024577107 \n","Score: 0.3478367346938776\n","\n","Candidate: 0.9999984230185364 \n","Score: 0.3478367346938776\n","\n","Candidate: 0.9999984314643349 \n","Score: 0.34785714285714286\n","\n","Candidate: 0.999998449517069 \n","Score: 0.3478775510204082\n","\n","Candidate: 0.9999984851274919 \n","Score: 0.3478979591836735\n","\n","Candidate: 0.9999985104588534 \n","Score: 0.3479183673469388\n","\n","Candidate: 0.9999985452600986 \n","Score: 0.3479183673469388\n","\n","Candidate: 0.9999985855744178 \n","Score: 0.34800000000000003\n","\n","Candidate: 0.9999986257203466 \n","Score: 0.34802040816326535\n","\n","Candidate: 0.9999986631876382 \n","Score: 0.3480408163265306\n","\n","Candidate: 0.999998680121015 \n","Score: 0.3480408163265306\n","\n","Candidate: 0.9999987181736472 \n","Score: 0.3480408163265306\n","\n","Candidate: 0.9999987690857519 \n","Score: 0.34806122448979593\n","\n","Candidate: 0.9999987988590808 \n","Score: 0.34806122448979593\n","\n","Candidate: 0.9999988067236039 \n","Score: 0.34810204081632656\n","\n","Candidate: 0.9999988490544833 \n","Score: 0.3481836734693878\n","\n","Candidate: 0.9999988902566792 \n","Score: 0.3481836734693878\n","\n","Candidate: 0.9999989041249222 \n","Score: 0.3481836734693878\n","\n","Candidate: 0.9999989228001157 \n","Score: 0.3482040816326531\n","\n","Candidate: 0.9999989299810709 \n","Score: 0.36765306122448976\n","\n","Candidate: 0.9999989334327862 \n","Score: 0.36765306122448976\n","\n","Candidate: 0.9999989465186866 \n","Score: 0.3676734693877551\n","\n","Candidate: 0.9999989594663556 \n","Score: 0.3676938775510204\n","\n","Candidate: 0.9999989786316617 \n","Score: 0.38724489795918365\n","\n","Candidate: 0.9999989971331561 \n","Score: 0.38726530612244897\n","\n","Candidate: 0.9999989996988833 \n","Score: 0.3872857142857143\n","\n","Candidate: 0.9999990132082498 \n","Score: 0.3872857142857143\n","\n","Candidate: 0.9999990284676865 \n","Score: 0.3873061224489796\n","\n","Candidate: 0.9999990343331575 \n","Score: 0.38732653061224487\n","\n","Candidate: 0.9999990390429725 \n","Score: 0.38732653061224487\n","\n","Candidate: 0.9999990538382192 \n","Score: 0.3873469387755102\n","\n","Candidate: 0.9999990878410536 \n","Score: 0.3873673469387755\n","\n","Candidate: 0.9999991258098156 \n","Score: 0.3873673469387755\n","\n","Candidate: 0.9999991529719191 \n","Score: 0.38740816326530614\n","\n","Candidate: 0.9999991695940422 \n","Score: 0.38742857142857146\n","\n","Candidate: 0.9999991857434516 \n","Score: 0.3874489795918367\n","\n","Candidate: 0.9999992019265962 \n","Score: 0.3681020408163265\n","\n","Candidate: 0.999999212986622 \n","Score: 0.36818367346938774\n","\n","Candidate: 0.9999992229960949 \n","Score: 0.36820408163265306\n","\n","Candidate: 0.9999992454632192 \n","Score: 0.3682244897959184\n","\n","Candidate: 0.9999992650961587 \n","Score: 0.3682448979591837\n","\n","Candidate: 0.9999992981729264 \n","Score: 0.36826530612244895\n","\n","Candidate: 0.9999993286759354 \n","Score: 0.36828571428571427\n","\n","Candidate: 0.9999993317236597 \n","Score: 0.3683061224489796\n","\n","Candidate: 0.9999993348495309 \n","Score: 0.3683265306122449\n","\n","Candidate: 0.9999993404369425 \n","Score: 0.36834693877551017\n","\n","Candidate: 0.9999993470377757 \n","Score: 0.36834693877551017\n","\n","Candidate: 0.9999993565779026 \n","Score: 0.3683877551020408\n","\n","Candidate: 0.9999993718731381 \n","Score: 0.3684081632653061\n","\n","Candidate: 0.9999993833224556 \n","Score: 0.3684081632653061\n","\n","Candidate: 0.9999993922232565 \n","Score: 0.3684081632653061\n","\n","Candidate: 0.9999993970060597 \n","Score: 0.3684081632653061\n","\n","Candidate: 0.999999399802026 \n","Score: 0.36842857142857144\n","\n","Candidate: 0.9999994042238397 \n","Score: 0.36844897959183676\n","\n","Candidate: 0.9999994141166879 \n","Score: 0.36844897959183676\n","\n","Candidate: 0.9999994556178233 \n","Score: 0.3491836734693878\n","\n","Candidate: 0.9999994934843264 \n","Score: 0.3492040816326531\n","\n","Candidate: 0.9999995000424597 \n","Score: 0.3689183673469388\n","\n","Candidate: 0.9999995104959565 \n","Score: 0.3689387755102041\n","\n","Candidate: 0.9999995214329027 \n","Score: 0.3689387755102041\n","\n","Candidate: 0.9999995333439011 \n","Score: 0.3689387755102041\n","\n","Candidate: 0.9999995429094433 \n","Score: 0.3689387755102041\n","\n","Candidate: 0.9999995434268207 \n","Score: 0.36895918367346936\n","\n","Candidate: 0.9999995489512793 \n","Score: 0.3689795918367347\n","\n","Candidate: 0.9999995623167711 \n","Score: 0.3689795918367347\n","\n","Candidate: 0.9999995704679885 \n","Score: 0.3689795918367347\n","\n","Candidate: 0.9999995745130713 \n","Score: 0.369\n","\n","Candidate: 0.9999995799429057 \n","Score: 0.3690204081632653\n","\n","Candidate: 0.9999995831612072 \n","Score: 0.36904081632653063\n","\n","Candidate: 0.9999995877265696 \n","Score: 0.3690612244897959\n","\n","Candidate: 0.9999995937418581 \n","Score: 0.3691428571428571\n","\n","Candidate: 0.9999996045113079 \n","Score: 0.3691632653061224\n","\n","Candidate: 0.9999996275622796 \n","Score: 0.36918367346938774\n","\n","Candidate: 0.9999996445866597 \n","Score: 0.36920408163265306\n","\n","Candidate: 0.9999996466564899 \n","Score: 0.3692448979591837\n","\n","Candidate: 0.9999996492228904 \n","Score: 0.3692857142857143\n","\n","Candidate: 0.9999996522415382 \n","Score: 0.3693061224489796\n","\n","Candidate: 0.9999996540346989 \n","Score: 0.3693265306122449\n","\n","Candidate: 0.9999996625150402 \n","Score: 0.3693265306122449\n","\n","Candidate: 0.9999996701613991 \n","Score: 0.3693265306122449\n","\n","Candidate: 0.9999996747568878 \n","Score: 0.36934693877551017\n","\n","Candidate: 0.9999996797623973 \n","Score: 0.3693673469387755\n","\n","Candidate: 0.9999996820538202 \n","Score: 0.3693877551020408\n","\n","Candidate: 0.9999996849196522 \n","Score: 0.3694081632653061\n","\n","Candidate: 0.9999996862904486 \n","Score: 0.36942857142857144\n","\n","Candidate: 0.999999693589447 \n","Score: 0.36944897959183676\n","\n","Candidate: 0.9999997054912282 \n","Score: 0.369469387755102\n","\n","Candidate: 0.9999997118441186 \n","Score: 0.369469387755102\n","\n","Candidate: 0.9999997143246933 \n","Score: 0.36948979591836734\n","\n","Candidate: 0.999999720794168 \n","Score: 0.36951020408163265\n","\n","Candidate: 0.9999997270781655 \n","Score: 0.36953061224489797\n","\n","Candidate: 0.9999997304608951 \n","Score: 0.3696122448979592\n","\n","Candidate: 0.9999997372951028 \n","Score: 0.3696122448979592\n","\n","Candidate: 0.9999997426048797 \n","Score: 0.3696326530612245\n","\n","Candidate: 0.999999743961367 \n","Score: 0.36965306122448977\n","\n","Candidate: 0.999999744452873 \n","Score: 0.3696734693877551\n","\n","Candidate: 0.9999997462419363 \n","Score: 0.3696938775510204\n","\n","Candidate: 0.9999997515309812 \n","Score: 0.3697142857142857\n","\n","Candidate: 0.9999997586206609 \n","Score: 0.35040816326530616\n","\n","Candidate: 0.9999997655293764 \n","Score: 0.35040816326530616\n","\n","Candidate: 0.9999997753247696 \n","Score: 0.35040816326530616\n","\n","Candidate: 0.9999997838761663 \n","Score: 0.3504285714285715\n","\n","Candidate: 0.9999997877730635 \n","Score: 0.3504285714285715\n","\n","Candidate: 0.9999997901069725 \n","Score: 0.3504489795918368\n","\n","Candidate: 0.9999997952720845 \n","Score: 0.3504693877551021\n","\n","Candidate: 0.9999998005648308 \n","Score: 0.3504693877551021\n","\n","Candidate: 0.9999998028012925 \n","Score: 0.350530612244898\n","\n","Candidate: 0.9999998054498686 \n","Score: 0.3505510204081633\n","\n","Candidate: 0.9999998070068457 \n","Score: 0.3505510204081633\n","\n","Candidate: 0.9999998078398424 \n","Score: 0.35057142857142864\n","\n","Candidate: 0.9999998092861371 \n","Score: 0.35057142857142864\n","\n","Candidate: 0.999999810649036 \n","Score: 0.3505918367346939\n","\n","Candidate: 0.9999998115402551 \n","Score: 0.3506122448979592\n","\n","Candidate: 0.9999998150188727 \n","Score: 0.35063265306122454\n","\n","Candidate: 0.999999818562754 \n","Score: 0.35063265306122454\n","\n","Candidate: 0.9999998211743212 \n","Score: 0.35065306122448986\n","\n","Candidate: 0.9999998244404076 \n","Score: 0.3506734693877551\n","\n","Candidate: 0.9999998285048688 \n","Score: 0.35069387755102044\n","\n","Candidate: 0.9999998343929091 \n","Score: 0.35071428571428576\n","\n","Candidate: 0.999999840219272 \n","Score: 0.3507551020408164\n","\n","Candidate: 0.9999998434479129 \n","Score: 0.35077551020408165\n","\n","Candidate: 0.9999998458216438 \n","Score: 0.35079591836734697\n","\n","Candidate: 0.9999998512099812 \n","Score: 0.3508163265306123\n","\n","Candidate: 0.9999998549457028 \n","Score: 0.3508571428571429\n","\n","Candidate: 0.9999998559220593 \n","Score: 0.3508571428571429\n","\n","Candidate: 0.999999857026733 \n","Score: 0.3509183673469388\n","\n","Candidate: 0.9999998575505287 \n","Score: 0.35093877551020414\n","\n","Candidate: 0.9999998584827986 \n","Score: 0.35095918367346945\n","\n","Candidate: 0.9999998628851051 \n","Score: 0.35104081632653067\n","\n","Candidate: 0.9999998690306547 \n","Score: 0.35104081632653067\n","\n","Candidate: 0.9999998731074431 \n","Score: 0.351061224489796\n","\n","Candidate: 0.9999998759549737 \n","Score: 0.3511224489795919\n","\n","Candidate: 0.9999998785393073 \n","Score: 0.3511428571428572\n","\n","Candidate: 0.9999998805463348 \n","Score: 0.3511632653061225\n","\n","Candidate: 0.9999998828847345 \n","Score: 0.3511836734693878\n","\n","Candidate: 0.9999998846061733 \n","Score: 0.3511836734693878\n","\n","Candidate: 0.9999998852602714 \n","Score: 0.3512040816326531\n","\n","Candidate: 0.9999998861026254 \n","Score: 0.3512040816326531\n","\n","Candidate: 0.9999998865245195 \n","Score: 0.3512244897959184\n","\n","Candidate: 0.9999998877081029 \n","Score: 0.35124489795918373\n","\n","Candidate: 0.999999889264 \n","Score: 0.35124489795918373\n","\n","Candidate: 0.9999998910124652 \n","Score: 0.351265306122449\n","\n","Candidate: 0.9999998926562741 \n","Score: 0.3512857142857143\n","\n","Candidate: 0.9999998934468706 \n","Score: 0.3512857142857143\n","\n","Candidate: 0.9999998940431961 \n","Score: 0.35130612244897963\n","\n","Candidate: 0.9999998948190829 \n","Score: 0.35130612244897963\n","\n","Candidate: 0.9999998974902644 \n","Score: 0.35132653061224495\n","\n","Candidate: 0.9999999011374525 \n","Score: 0.35132653061224495\n","\n","Candidate: 0.999999902982909 \n","Score: 0.35134693877551026\n","\n","Candidate: 0.9999999048732966 \n","Score: 0.3513673469387755\n","\n","Candidate: 0.9999999071999386 \n","Score: 0.3514489795918368\n","\n","Candidate: 0.9999999087872096 \n","Score: 0.3514489795918368\n","\n","Candidate: 0.9999999114876952 \n","Score: 0.35146938775510206\n","\n","Candidate: 0.9999999147922338 \n","Score: 0.3514897959183674\n","\n","Candidate: 0.9999999162937376 \n","Score: 0.3515918367346939\n","\n","Candidate: 0.9999999176674732 \n","Score: 0.3516122448979592\n","\n","Candidate: 0.9999999197469918 \n","Score: 0.35163265306122454\n","\n","Candidate: 0.9999999206745247 \n","Score: 0.35165306122448986\n","\n","Candidate: 0.9999999223663449 \n","Score: 0.3516734693877551\n","\n","Candidate: 0.9999999244080524 \n","Score: 0.35169387755102044\n","\n","Candidate: 0.9999999252545242 \n","Score: 0.35171428571428576\n","\n","Candidate: 0.999999925615518 \n","Score: 0.3517346938775511\n","\n","Candidate: 0.9999999260990646 \n","Score: 0.35175510204081634\n","\n","Candidate: 0.9999999275051293 \n","Score: 0.35177551020408165\n","\n","Candidate: 0.999999930086254 \n","Score: 0.35177551020408165\n","\n","Candidate: 0.9999999316992478 \n","Score: 0.35179591836734697\n","\n","Candidate: 0.9999999319057439 \n","Score: 0.35185714285714287\n","\n","Candidate: 0.9999999337181216 \n","Score: 0.3518775510204082\n","\n","Candidate: 0.9999999356247327 \n","Score: 0.3518775510204082\n","\n","Candidate: 0.9999999371254651 \n","Score: 0.3518775510204082\n","\n","Candidate: 0.9999999384847659 \n","Score: 0.3518979591836735\n","\n","Candidate: 0.999999938724627 \n","Score: 0.3518979591836735\n","\n","Candidate: 0.999999938828066 \n","Score: 0.35193877551020414\n","\n","Candidate: 0.9999999395132189 \n","Score: 0.3519591836734694\n","\n","Candidate: 0.999999940320433 \n","Score: 0.3519795918367347\n","\n","Candidate: 0.9999999410508655 \n","Score: 0.3519795918367347\n","\n","Candidate: 0.9999999418336504 \n","Score: 0.3519795918367347\n","\n","Candidate: 0.999999942460019 \n","Score: 0.35200000000000004\n","\n","Candidate: 0.9999999437673046 \n","Score: 0.35200000000000004\n","\n","Candidate: 0.9999999454185763 \n","Score: 0.35200000000000004\n","\n","Candidate: 0.9999999471633436 \n","Score: 0.35200000000000004\n","\n","Candidate: 0.9999999483082159 \n","Score: 0.35202040816326535\n","\n","Candidate: 0.9999999493295983 \n","Score: 0.35204081632653067\n","\n","Candidate: 0.9999999508976121 \n","Score: 0.35206122448979593\n","\n","Candidate: 0.9999999518438129 \n","Score: 0.3521428571428572\n","\n","Candidate: 0.9999999521469793 \n","Score: 0.35216326530612246\n","\n","Candidate: 0.9999999540430118 \n","Score: 0.3521836734693878\n","\n","Candidate: 0.9999999559242458 \n","Score: 0.3522040816326531\n","\n","Candidate: 0.999999956074344 \n","Score: 0.3522040816326531\n","\n","Candidate: 0.9999999565653379 \n","Score: 0.3522040816326531\n","\n","Candidate: 0.99999995733402 \n","Score: 0.3522244897959184\n","\n","Candidate: 0.999999957749997 \n","Score: 0.3522244897959184\n","\n","Candidate: 0.9999999579861238 \n","Score: 0.3522448979591837\n","\n","Candidate: 0.9999999584433288 \n","Score: 0.352265306122449\n","\n","Candidate: 0.999999958989127 \n","Score: 0.3522857142857143\n","\n","Candidate: 0.9999999597243547 \n","Score: 0.3522857142857143\n","\n","Candidate: 0.9999999604716223 \n","Score: 0.35230612244897963\n","\n","Candidate: 0.9999999608907183 \n","Score: 0.35232653061224495\n","\n","Candidate: 0.9999999613602599 \n","Score: 0.35234693877551027\n","\n","Candidate: 0.9999999618950997 \n","Score: 0.35234693877551027\n","\n","Candidate: 0.9999999625355349 \n","Score: 0.3523673469387755\n","\n","Candidate: 0.9999999632122337 \n","Score: 0.35238775510204084\n","\n","Candidate: 0.999999963531917 \n","Score: 0.35240816326530616\n","\n","Candidate: 0.9999999639985883 \n","Score: 0.35240816326530616\n","\n","Candidate: 0.9999999644973925 \n","Score: 0.3524285714285715\n","\n","Candidate: 0.9999999652249633 \n","Score: 0.35244897959183674\n","\n","Candidate: 0.9999999659479222 \n","Score: 0.35246938775510206\n","\n","Candidate: 0.9999999660970786 \n","Score: 0.3524897959183674\n","\n","Candidate: 0.9999999663224949 \n","Score: 0.3524897959183674\n","\n","Candidate: 0.9999999668000217 \n","Score: 0.3525102040816327\n","\n","Candidate: 0.999999967527911 \n","Score: 0.352530612244898\n","\n","Candidate: 0.9999999683484246 \n","Score: 0.352530612244898\n","\n","Candidate: 0.9999999687827792 \n","Score: 0.352530612244898\n","\n","Candidate: 0.9999999688933818 \n","Score: 0.3526122448979592\n","\n","Candidate: 0.9999999696503898 \n","Score: 0.3526122448979592\n","\n","Candidate: 0.9999999708361225 \n","Score: 0.3526122448979592\n","\n","Candidate: 0.9999999713751824 \n","Score: 0.35263265306122454\n","\n","Candidate: 0.9999999715431137 \n","Score: 0.35263265306122454\n","\n","Candidate: 0.9999999718860519 \n","Score: 0.3526530612244898\n","\n","Candidate: 0.9999999722856465 \n","Score: 0.3526530612244898\n","\n","Candidate: 0.9999999725664833 \n","Score: 0.35269387755102044\n","\n","Candidate: 0.9999999730165083 \n","Score: 0.35271428571428576\n","\n","Candidate: 0.999999973784037 \n","Score: 0.3527346938775511\n","\n","Candidate: 0.9999999744724619 \n","Score: 0.35275510204081634\n","\n","Candidate: 0.9999999750206896 \n","Score: 0.35277551020408165\n","\n","Candidate: 0.9999999754140388 \n","Score: 0.352795918367347\n","\n","Candidate: 0.9999999760277041 \n","Score: 0.3528163265306123\n","\n","Candidate: 0.999999976583114 \n","Score: 0.3723469387755102\n","\n","Candidate: 0.9999999769476627 \n","Score: 0.3723673469387755\n","\n","Candidate: 0.9999999775821751 \n","Score: 0.3723877551020408\n","\n","Candidate: 0.9999999779764991 \n","Score: 0.3723877551020408\n","\n","Candidate: 0.999999978059526 \n","Score: 0.3723877551020408\n","\n","Candidate: 0.9999999781617621 \n","Score: 0.35302040816326535\n","\n","Candidate: 0.9999999783681439 \n","Score: 0.35302040816326535\n","\n","Candidate: 0.9999999787818177 \n","Score: 0.3530408163265306\n","\n","Candidate: 0.9999999792223634 \n","Score: 0.35306122448979593\n","\n","Candidate: 0.9999999795760833 \n","Score: 0.35306122448979593\n","\n","Candidate: 0.9999999799258786 \n","Score: 0.35306122448979593\n","\n","Candidate: 0.9999999802073581 \n","Score: 0.35308163265306125\n","\n","Candidate: 0.999999980476436 \n","Score: 0.35310204081632657\n","\n","Candidate: 0.9999999811679917 \n","Score: 0.35310204081632657\n","\n","Candidate: 0.9999999817420502 \n","Score: 0.3531224489795919\n","\n","Candidate: 0.99999998180916 \n","Score: 0.3531428571428572\n","\n","Candidate: 0.9999999819303623 \n","Score: 0.3531428571428572\n","\n","Candidate: 0.9999999821505181 \n","Score: 0.3531428571428572\n","\n","Candidate: 0.9999999826726303 \n","Score: 0.35316326530612246\n","\n","Candidate: 0.9999999831102437 \n","Score: 0.3531836734693878\n","\n","Candidate: 0.9999999832259638 \n","Score: 0.3532040816326531\n","\n","Candidate: 0.999999983302585 \n","Score: 0.3532040816326531\n","\n","Candidate: 0.9999999835178286 \n","Score: 0.3532040816326531\n","\n","Candidate: 0.9999999837475948 \n","Score: 0.3532244897959184\n","\n","Candidate: 0.9999999838331993 \n","Score: 0.3532244897959184\n","\n","Candidate: 0.9999999839621718 \n","Score: 0.35330612244897963\n","\n","Candidate: 0.9999999840551801 \n","Score: 0.35332653061224495\n","\n","Candidate: 0.9999999842709622 \n","Score: 0.35334693877551027\n","\n","Candidate: 0.9999999845505699 \n","Score: 0.35334693877551027\n","\n","Candidate: 0.9999999847226291 \n","Score: 0.35334693877551027\n","\n","Candidate: 0.9999999850140275 \n","Score: 0.35336734693877553\n","\n","Candidate: 0.999999985304161 \n","Score: 0.35338775510204085\n","\n","Candidate: 0.9999999854700949 \n","Score: 0.35340816326530616\n","\n","Candidate: 0.9999999856224906 \n","Score: 0.35340816326530616\n","\n","Candidate: 0.9999999858229991 \n","Score: 0.35340816326530616\n","\n","Candidate: 0.9999999864128164 \n","Score: 0.3534285714285715\n","\n","Candidate: 0.9999999869386975 \n","Score: 0.3534897959183674\n","\n","Candidate: 0.9999999869997425 \n","Score: 0.3535102040816327\n","\n","Candidate: 0.9999999871406915 \n","Score: 0.353530612244898\n","\n","Candidate: 0.9999999873189714 \n","Score: 0.3535510204081633\n","\n","Candidate: 0.9999999875405998 \n","Score: 0.3535714285714286\n","\n","Candidate: 0.9999999877575692 \n","Score: 0.3535918367346939\n","\n","Candidate: 0.99999998788935 \n","Score: 0.3535918367346939\n","\n","Candidate: 0.9999999880716801 \n","Score: 0.3535918367346939\n","\n","Candidate: 0.9999999882015955 \n","Score: 0.3535918367346939\n","\n","Candidate: 0.9999999883879813 \n","Score: 0.3536122448979592\n","\n","Candidate: 0.9999999886144597 \n","Score: 0.3536122448979592\n","\n","Candidate: 0.9999999887373565 \n","Score: 0.35363265306122454\n","\n","Candidate: 0.9999999888150082 \n","Score: 0.3536530612244898\n","\n","Candidate: 0.999999989006941 \n","Score: 0.3536530612244898\n","\n","Candidate: 0.9999999892095706 \n","Score: 0.3536734693877551\n","\n","Candidate: 0.9999999894626291 \n","Score: 0.35375510204081634\n","\n","Candidate: 0.9999999897695959 \n","Score: 0.35377551020408166\n","\n","Candidate: 0.9999999899267684 \n","Score: 0.353795918367347\n","\n","Candidate: 0.9999999900807905 \n","Score: 0.3538163265306123\n","\n","Candidate: 0.999999990383883 \n","Score: 0.3538367346938776\n","\n","Candidate: 0.9999999905996362 \n","Score: 0.3538367346938776\n","\n","Candidate: 0.9999999908525703 \n","Score: 0.35385714285714287\n","\n","Candidate: 0.999999991209643 \n","Score: 0.35385714285714287\n","\n","Candidate: 0.9999999913592774 \n","Score: 0.3538775510204082\n","\n","Candidate: 0.9999999914528359 \n","Score: 0.3538979591836735\n","\n","Candidate: 0.9999999915502005 \n","Score: 0.3539183673469388\n","\n","Candidate: 0.9999999916722058 \n","Score: 0.3539183673469388\n","\n","Candidate: 0.9999999917929254 \n","Score: 0.3539183673469388\n","\n","Candidate: 0.9999999918444302 \n","Score: 0.35393877551020414\n","\n","Candidate: 0.9999999918886724 \n","Score: 0.3539591836734694\n","\n","Candidate: 0.9999999919753848 \n","Score: 0.3539795918367347\n","\n","Candidate: 0.999999992100356 \n","Score: 0.3539795918367347\n","\n","Candidate: 0.999999992267546 \n","Score: 0.35402040816326535\n","\n","Candidate: 0.9999999923820838 \n","Score: 0.35402040816326535\n","\n","Candidate: 0.9999999926054853 \n","Score: 0.3540408163265306\n","\n","Candidate: 0.9999999929230814 \n","Score: 0.35406122448979593\n","\n","Candidate: 0.9999999930941224 \n","Score: 0.35408163265306125\n","\n","Candidate: 0.99999999315367 \n","Score: 0.35410204081632657\n","\n","Candidate: 0.9999999931621861 \n","Score: 0.3541224489795919\n","\n","Candidate: 0.9999999932179079 \n","Score: 0.35414285714285715\n","\n","Candidate: 0.9999999932952298 \n","Score: 0.35414285714285715\n","\n","Candidate: 0.9999999933857426 \n","Score: 0.35414285714285715\n","\n","Candidate: 0.9999999934653305 \n","Score: 0.35414285714285715\n","\n","Candidate: 0.999999993553887 \n","Score: 0.35416326530612247\n","\n","Candidate: 0.9999999936922969 \n","Score: 0.35416326530612247\n","\n","Candidate: 0.9999999937629769 \n","Score: 0.3541836734693878\n","\n","Candidate: 0.9999999938074849 \n","Score: 0.3542040816326531\n","\n","Candidate: 0.9999999939820776 \n","Score: 0.3542040816326531\n","\n","Candidate: 0.9999999941977258 \n","Score: 0.3542244897959184\n","\n","Candidate: 0.9999999943230458 \n","Score: 0.3542244897959184\n","\n","Candidate: 0.9999999944045292 \n","Score: 0.3542448979591837\n","\n","Candidate: 0.9999999944757721 \n","Score: 0.35432653061224495\n","\n","Candidate: 0.9999999945337761 \n","Score: 0.35432653061224495\n","\n","Candidate: 0.9999999945701212 \n","Score: 0.35432653061224495\n","\n","Candidate: 0.9999999946307028 \n","Score: 0.3543469387755102\n","\n","Candidate: 0.999999994730215 \n","Score: 0.35436734693877553\n","\n","Candidate: 0.999999994810355 \n","Score: 0.35438775510204085\n","\n","Candidate: 0.9999999949230116 \n","Score: 0.35440816326530616\n","\n","Candidate: 0.9999999950660632 \n","Score: 0.3544285714285715\n","\n","Candidate: 0.9999999951370282 \n","Score: 0.3544285714285715\n","\n","Candidate: 0.9999999952051204 \n","Score: 0.35444897959183674\n","\n","Candidate: 0.9999999952712278 \n","Score: 0.35446938775510206\n","\n","Candidate: 0.9999999953495289 \n","Score: 0.3544897959183674\n","\n","Candidate: 0.9999999954561529 \n","Score: 0.3544897959183674\n","\n","Candidate: 0.9999999955085457 \n","Score: 0.33512244897959187\n","\n","Candidate: 0.9999999955752602 \n","Score: 0.3351428571428572\n","\n","Candidate: 0.999999995636736 \n","Score: 0.3351428571428572\n","\n","Candidate: 0.9999999956983148 \n","Score: 0.33516326530612245\n","\n","Candidate: 0.9999999957541166 \n","Score: 0.33518367346938777\n","\n","Candidate: 0.9999999957561924 \n","Score: 0.33518367346938777\n","\n","Candidate: 0.9999999957712575 \n","Score: 0.3352040816326531\n","\n","Candidate: 0.99999999581955 \n","Score: 0.3352244897959184\n","\n","Candidate: 0.9999999958873619 \n","Score: 0.3352244897959184\n","\n","Candidate: 0.9999999959272122 \n","Score: 0.3352244897959184\n","\n","Candidate: 0.9999999959477998 \n","Score: 0.3352448979591837\n","\n","Candidate: 0.9999999960373513 \n","Score: 0.335265306122449\n","\n","Candidate: 0.9999999961365343 \n","Score: 0.3352857142857143\n","\n","Candidate: 0.9999999961814695 \n","Score: 0.3353673469387755\n","\n","Candidate: 0.9999999962086181 \n","Score: 0.33538775510204083\n","\n","Candidate: 0.9999999962509942 \n","Score: 0.33538775510204083\n","\n","Candidate: 0.9999999963008164 \n","Score: 0.33538775510204083\n","\n","Candidate: 0.9999999963874064 \n","Score: 0.33538775510204083\n","\n","Candidate: 0.99999999649924 \n","Score: 0.33538775510204083\n","\n","Candidate: 0.9999999966207689 \n","Score: 0.33540816326530615\n","\n","Candidate: 0.9999999967365776 \n","Score: 0.33540816326530615\n","\n","Candidate: 0.9999999968242226 \n","Score: 0.33542857142857146\n","\n","Candidate: 0.9999999968858191 \n","Score: 0.3354489795918367\n","\n","Candidate: 0.9999999968947121 \n","Score: 0.33546938775510204\n","\n","Candidate: 0.999999996953846 \n","Score: 0.33548979591836736\n","\n","Candidate: 0.9999999970135984 \n","Score: 0.3355102040816327\n","\n","Candidate: 0.9999999970251181 \n","Score: 0.335530612244898\n","\n","Candidate: 0.9999999970396725 \n","Score: 0.33555102040816326\n","\n","Candidate: 0.9999999970562965 \n","Score: 0.33555102040816326\n","\n","Candidate: 0.9999999971101515 \n","Score: 0.3355714285714286\n","\n","Candidate: 0.9999999971646545 \n","Score: 0.3355918367346939\n","\n","Candidate: 0.9999999972316223 \n","Score: 0.3356122448979592\n","\n","Candidate: 0.9999999972940461 \n","Score: 0.3356122448979592\n","\n","Candidate: 0.9999999973393319 \n","Score: 0.3356530612244898\n","\n","Candidate: 0.9999999973887039 \n","Score: 0.3356530612244898\n","\n","Candidate: 0.9999999974269747 \n","Score: 0.3356734693877551\n","\n","Candidate: 0.999999997458843 \n","Score: 0.3356734693877551\n","\n","Candidate: 0.9999999974833816 \n","Score: 0.3356734693877551\n","\n","Candidate: 0.9999999975149619 \n","Score: 0.3356734693877551\n","\n","Candidate: 0.9999999975438509 \n","Score: 0.3356938775510204\n","\n","Candidate: 0.9999999975954146 \n","Score: 0.33571428571428574\n","\n","Candidate: 0.9999999976359466 \n","Score: 0.33571428571428574\n","\n","Candidate: 0.9999999976416998 \n","Score: 0.33573469387755106\n","\n","Candidate: 0.9999999976464076 \n","Score: 0.33573469387755106\n","\n","Candidate: 0.9999999976835685 \n","Score: 0.3357551020408163\n","\n","Candidate: 0.9999999977252054 \n","Score: 0.33577551020408164\n","\n","Candidate: 0.9999999977462912 \n","Score: 0.33577551020408164\n","\n","Candidate: 0.9999999977656875 \n","Score: 0.33577551020408164\n","\n","Candidate: 0.9999999978423558 \n","Score: 0.33577551020408164\n","\n","Candidate: 0.9999999979194398 \n","Score: 0.33577551020408164\n","\n","Candidate: 0.9999999979390611 \n","Score: 0.33577551020408164\n","\n","Candidate: 0.9999999979589411 \n","Score: 0.33579591836734696\n","\n","Candidate: 0.9999999979719678 \n","Score: 0.33579591836734696\n","\n","Candidate: 0.9999999979771398 \n","Score: 0.33579591836734696\n","\n","Candidate: 0.9999999979939671 \n","Score: 0.3358163265306123\n","\n","Candidate: 0.9999999980125198 \n","Score: 0.3358163265306123\n","\n","Candidate: 0.999999998023771 \n","Score: 0.3358979591836735\n","\n","Candidate: 0.9999999980476499 \n","Score: 0.3359183673469388\n","\n","Candidate: 0.999999998068126 \n","Score: 0.3359387755102041\n","\n","Candidate: 0.9999999980822236 \n","Score: 0.3359591836734694\n","\n","Candidate: 0.9999999981335952 \n","Score: 0.3359795918367347\n","\n","Candidate: 0.9999999982190462 \n","Score: 0.336\n","\n","Candidate: 0.9999999982645886 \n","Score: 0.33602040816326534\n","\n","Candidate: 0.9999999982761442 \n","Score: 0.33604081632653066\n","\n","Candidate: 0.9999999982850959 \n","Score: 0.3360612244897959\n","\n","Candidate: 0.9999999982882143 \n","Score: 0.33608163265306124\n","\n","Candidate: 0.999999998315115 \n","Score: 0.33608163265306124\n","\n","Candidate: 0.999999998360862 \n","Score: 0.33610204081632655\n","\n","Candidate: 0.9999999983911643 \n","Score: 0.33612244897959187\n","\n","Candidate: 0.9999999984223298 \n","Score: 0.3361428571428572\n","\n","Candidate: 0.99999999845377 \n","Score: 0.33616326530612245\n","\n","Candidate: 0.9999999984778399 \n","Score: 0.33616326530612245\n","\n","Candidate: 0.9999999984970097 \n","Score: 0.33616326530612245\n","\n","Candidate: 0.9999999985192076 \n","Score: 0.33618367346938777\n","\n","Candidate: 0.9999999985438984 \n","Score: 0.3362040816326531\n","\n","Candidate: 0.9999999985697074 \n","Score: 0.3362040816326531\n","\n","Candidate: 0.999999998591731 \n","Score: 0.3362244897959184\n","\n","Candidate: 0.9999999985985073 \n","Score: 0.3362244897959184\n","\n","Candidate: 0.999999998615442 \n","Score: 0.33624489795918366\n","\n","Candidate: 0.999999998636761 \n","Score: 0.33632653061224493\n","\n","Candidate: 0.9999999986501846 \n","Score: 0.3363469387755102\n","\n","Candidate: 0.9999999986589114 \n","Score: 0.3363673469387755\n","\n","Candidate: 0.9999999986628212 \n","Score: 0.3363673469387755\n","\n","Candidate: 0.9999999986792113 \n","Score: 0.33638775510204083\n","\n","Candidate: 0.9999999986969497 \n","Score: 0.33640816326530615\n","\n","Candidate: 0.9999999986996353 \n","Score: 0.33640816326530615\n","\n","Candidate: 0.9999999987052961 \n","Score: 0.33642857142857147\n","\n","Candidate: 0.9999999987202913 \n","Score: 0.33642857142857147\n","\n","Candidate: 0.999999998730424 \n","Score: 0.3364489795918367\n","\n","Candidate: 0.999999998735891 \n","Score: 0.3364489795918367\n","\n","Candidate: 0.9999999987701766 \n","Score: 0.3364489795918367\n","\n","Candidate: 0.9999999988040086 \n","Score: 0.3364489795918367\n","\n","Candidate: 0.9999999988283652 \n","Score: 0.33646938775510205\n","\n","Candidate: 0.999999998879334 \n","Score: 0.33646938775510205\n","\n","Candidate: 0.9999999989107755 \n","Score: 0.33646938775510205\n","\n","Candidate: 0.9999999989164274 \n","Score: 0.33646938775510205\n","\n","Candidate: 0.99999999892272 \n","Score: 0.33646938775510205\n","\n","Candidate: 0.9999999989321561 \n","Score: 0.33648979591836736\n","\n","Candidate: 0.9999999989436302 \n","Score: 0.3365102040816327\n","\n","Candidate: 0.9999999989574384 \n","Score: 0.336530612244898\n","\n","Candidate: 0.9999999989738952 \n","Score: 0.336530612244898\n","\n","Candidate: 0.9999999989839063 \n","Score: 0.336530612244898\n","\n","Candidate: 0.99999999899689 \n","Score: 0.33655102040816326\n","\n","Candidate: 0.9999999990181059 \n","Score: 0.3365714285714286\n","\n","Candidate: 0.9999999990336692 \n","Score: 0.3365918367346939\n","\n","Candidate: 0.9999999990569903 \n","Score: 0.33663265306122453\n","\n","Candidate: 0.9999999990788249 \n","Score: 0.3366530612244898\n","\n","Candidate: 0.9999999990808843 \n","Score: 0.3366530612244898\n","\n","Candidate: 0.9999999990851293 \n","Score: 0.3366734693877551\n","\n","Candidate: 0.9999999990949875 \n","Score: 0.3366938775510204\n","\n","Candidate: 0.9999999991075286 \n","Score: 0.33671428571428574\n","\n","Candidate: 0.9999999991318024 \n","Score: 0.33671428571428574\n","\n","Candidate: 0.9999999991591337 \n","Score: 0.33673469387755106\n","\n","Candidate: 0.999999999180351 \n","Score: 0.33673469387755106\n","\n","Candidate: 0.9999999991939509 \n","Score: 0.3367551020408164\n","\n","Candidate: 0.9999999991981634 \n","Score: 0.33677551020408164\n","\n","Candidate: 0.9999999992067088 \n","Score: 0.33677551020408164\n","\n","Candidate: 0.9999999992181312 \n","Score: 0.33679591836734696\n","\n","Candidate: 0.9999999992242885 \n","Score: 0.33679591836734696\n","\n","Candidate: 0.9999999992359284 \n","Score: 0.33679591836734696\n","\n","Candidate: 0.99999999924885 \n","Score: 0.3368163265306123\n","\n","Candidate: 0.9999999992507401 \n","Score: 0.3368163265306123\n","\n","Candidate: 0.9999999992628608 \n","Score: 0.3368367346938776\n","\n","Candidate: 0.9999999992772539 \n","Score: 0.33685714285714285\n","\n","Candidate: 0.999999999280905 \n","Score: 0.33685714285714285\n","\n","Candidate: 0.9999999992853497 \n","Score: 0.33685714285714285\n","\n","Candidate: 0.9999999992896396 \n","Score: 0.33685714285714285\n","\n","Candidate: 0.999999999293244 \n","Score: 0.3565918367346939\n","\n","Candidate: 0.9999999993005746 \n","Score: 0.35661224489795923\n","\n","Candidate: 0.9999999993064848 \n","Score: 0.35661224489795923\n","\n","Candidate: 0.9999999993119956 \n","Score: 0.35663265306122455\n","\n","Candidate: 0.9999999993272539 \n","Score: 0.35663265306122455\n","\n","Candidate: 0.9999999993380455 \n","Score: 0.3566530612244898\n","\n","Candidate: 0.9999999993597619 \n","Score: 0.3566734693877551\n","\n","Candidate: 0.9999999993821296 \n","Score: 0.35675510204081634\n","\n","Candidate: 0.9999999993915956 \n","Score: 0.35675510204081634\n","\n","Candidate: 0.9999999994052928 \n","Score: 0.35677551020408166\n","\n","Candidate: 0.999999999414111 \n","Score: 0.356795918367347\n","\n","Candidate: 0.9999999994233626 \n","Score: 0.3568163265306123\n","\n","Candidate: 0.9999999994308071 \n","Score: 0.3568367346938776\n","\n","Candidate: 0.9999999994340669 \n","Score: 0.3568571428571429\n","\n","Candidate: 0.9999999994353773 \n","Score: 0.3568571428571429\n","\n","Candidate: 0.999999999437502 \n","Score: 0.3568775510204082\n","\n","Candidate: 0.9999999994419307 \n","Score: 0.3568775510204082\n","\n","Candidate: 0.9999999994533251 \n","Score: 0.3568979591836735\n","\n","Candidate: 0.9999999994637193 \n","Score: 0.3569183673469388\n","\n","Candidate: 0.9999999994713061 \n","Score: 0.3569183673469388\n","\n","Candidate: 0.9999999994842766 \n","Score: 0.35693877551020414\n","\n","Candidate: 0.9999999994979842 \n","Score: 0.3569591836734694\n","\n","Candidate: 0.9999999995121431 \n","Score: 0.3569795918367347\n","\n","Candidate: 0.9999999995205173 \n","Score: 0.35700000000000004\n","\n","Candidate: 0.9999999995223465 \n","Score: 0.35700000000000004\n","\n","Candidate: 0.9999999995234865 \n","Score: 0.35708163265306125\n","\n","Candidate: 0.9999999995314688 \n","Score: 0.35710204081632657\n","\n","Candidate: 0.9999999995400762 \n","Score: 0.35710204081632657\n","\n","Candidate: 0.9999999995478073 \n","Score: 0.35710204081632657\n","\n","Candidate: 0.9999999995694918 \n","Score: 0.3571224489795919\n","\n","Candidate: 0.9999999995845125 \n","Score: 0.3571224489795919\n","\n","Candidate: 0.9999999995846484 \n","Score: 0.35714285714285715\n","\n","Candidate: 0.9999999995876344 \n","Score: 0.35714285714285715\n","\n","Candidate: 0.9999999995938567 \n","Score: 0.35716326530612247\n","\n","Candidate: 0.9999999995978803 \n","Score: 0.3571836734693878\n","\n","Candidate: 0.9999999995991744 \n","Score: 0.3571836734693878\n","\n","Candidate: 0.9999999996072322 \n","Score: 0.3571836734693878\n","\n","Candidate: 0.999999999615087 \n","Score: 0.3572040816326531\n","\n","Candidate: 0.9999999996161439 \n","Score: 0.3572040816326531\n","\n","Candidate: 0.9999999996178172 \n","Score: 0.3572040816326531\n","\n","Candidate: 0.9999999996195482 \n","Score: 0.3572040816326531\n","\n","Candidate: 0.9999999996210175 \n","Score: 0.3572040816326531\n","\n","Candidate: 0.9999999996252567 \n","Score: 0.3572244897959184\n","\n","Candidate: 0.999999999629805 \n","Score: 0.3572448979591837\n","\n","Candidate: 0.9999999996310505 \n","Score: 0.357265306122449\n","\n","Candidate: 0.9999999996318333 \n","Score: 0.3572857142857143\n","\n","Candidate: 0.9999999996392541 \n","Score: 0.35730612244897964\n","\n","Candidate: 0.9999999996494203 \n","Score: 0.35730612244897964\n","\n","Candidate: 0.9999999996542952 \n","Score: 0.35732653061224495\n","\n","Candidate: 0.9999999996563996 \n","Score: 0.35736734693877553\n","\n","Candidate: 0.9999999996575715 \n","Score: 0.35738775510204085\n","\n","Candidate: 0.9999999996667838 \n","Score: 0.35740816326530617\n","\n","Candidate: 0.9999999996760347 \n","Score: 0.3574285714285715\n","\n","Candidate: 0.999999999678326 \n","Score: 0.35744897959183675\n","\n","Candidate: 0.9999999996824619 \n","Score: 0.35744897959183675\n","\n","Candidate: 0.9999999996906657 \n","Score: 0.35746938775510206\n","\n","Candidate: 0.999999999696499 \n","Score: 0.35746938775510206\n","\n","Candidate: 0.9999999997018849 \n","Score: 0.3574897959183674\n","\n","Candidate: 0.9999999997072326 \n","Score: 0.3574897959183674\n","\n","Candidate: 0.9999999997109507 \n","Score: 0.3575102040816327\n","\n","Candidate: 0.9999999997156335 \n","Score: 0.357530612244898\n","\n","Candidate: 0.9999999997177182 \n","Score: 0.3575510204081633\n","\n","Candidate: 0.9999999997189981 \n","Score: 0.3575714285714286\n","\n","Candidate: 0.9999999997205643 \n","Score: 0.3575918367346939\n","\n","Candidate: 0.9999999997221511 \n","Score: 0.3575918367346939\n","\n","Candidate: 0.9999999997245196 \n","Score: 0.35761224489795923\n","\n","Candidate: 0.9999999997316165 \n","Score: 0.35761224489795923\n","\n","Candidate: 0.9999999997448636 \n","Score: 0.35761224489795923\n","\n","Candidate: 0.9999999997532234 \n","Score: 0.3576326530612245\n","\n","Candidate: 0.999999999753741 \n","Score: 0.3576530612244898\n","\n","Candidate: 0.9999999997560243 \n","Score: 0.3576530612244898\n","\n","Candidate: 0.9999999997643414 \n","Score: 0.35771428571428576\n","\n","Candidate: 0.9999999997710443 \n","Score: 0.357734693877551\n","\n","Candidate: 0.9999999997718703 \n","Score: 0.357734693877551\n","\n","Candidate: 0.999999999773681 \n","Score: 0.35775510204081634\n","\n","Candidate: 0.9999999997763362 \n","Score: 0.35775510204081634\n","\n","Candidate: 0.9999999997788855 \n","Score: 0.35777551020408166\n","\n","Candidate: 0.9999999997815144 \n","Score: 0.357795918367347\n","\n","Candidate: 0.9999999997834317 \n","Score: 0.357795918367347\n","\n","Candidate: 0.9999999997842643 \n","Score: 0.357795918367347\n","\n","Candidate: 0.9999999997852645 \n","Score: 0.357795918367347\n","\n","Candidate: 0.9999999997902853 \n","Score: 0.3578163265306123\n","\n","Candidate: 0.9999999997949266 \n","Score: 0.3578163265306123\n","\n","Candidate: 0.9999999997961954 \n","Score: 0.35783673469387756\n","\n","Candidate: 0.9999999997973481 \n","Score: 0.3578571428571429\n","\n","Candidate: 0.9999999997990289 \n","Score: 0.3578775510204082\n","\n","Candidate: 0.9999999998009537 \n","Score: 0.3578775510204082\n","\n","Candidate: 0.9999999998018212 \n","Score: 0.3578979591836735\n","\n","Candidate: 0.9999999998045486 \n","Score: 0.3578979591836735\n","\n","Candidate: 0.9999999998100568 \n","Score: 0.3579183673469388\n","\n","Candidate: 0.9999999998146665 \n","Score: 0.3579387755102041\n","\n","Candidate: 0.9999999998181698 \n","Score: 0.3579387755102041\n","\n","Candidate: 0.9999999998232778 \n","Score: 0.3579591836734694\n","\n","Candidate: 0.9999999998288163 \n","Score: 0.3579795918367347\n","\n","Candidate: 0.999999999831491 \n","Score: 0.35800000000000004\n","\n","Candidate: 0.9999999998327946 \n","Score: 0.35802040816326536\n","\n","Candidate: 0.9999999998344332 \n","Score: 0.35802040816326536\n","\n","Candidate: 0.9999999998379183 \n","Score: 0.3580408163265306\n","\n","Candidate: 0.9999999998410559 \n","Score: 0.3581224489795919\n","\n","Candidate: 0.9999999998417282 \n","Score: 0.3581224489795919\n","\n","Candidate: 0.9999999998443808 \n","Score: 0.35814285714285715\n","\n","Candidate: 0.999999999847053 \n","Score: 0.3390408163265306\n","\n","Candidate: 0.9999999998479778 \n","Score: 0.3390408163265306\n","\n","Candidate: 0.999999999848612 \n","Score: 0.3390612244897959\n","\n","Candidate: 0.9999999998492898 \n","Score: 0.33908163265306124\n","\n","Candidate: 0.9999999998515712 \n","Score: 0.33910204081632656\n","\n","Candidate: 0.9999999998557487 \n","Score: 0.33910204081632656\n","\n","Candidate: 0.9999999998584208 \n","Score: 0.3391224489795919\n","\n","Candidate: 0.9999999998590705 \n","Score: 0.3391224489795919\n","\n","Candidate: 0.9999999998600639 \n","Score: 0.3391428571428572\n","\n","Candidate: 0.9999999998641464 \n","Score: 0.33916326530612245\n","\n","Candidate: 0.9999999998679251 \n","Score: 0.339265306122449\n","\n","Candidate: 0.9999999998700317 \n","Score: 0.3392857142857143\n","\n","Candidate: 0.9999999998720752 \n","Score: 0.3393061224489796\n","\n","Candidate: 0.9999999998746891 \n","Score: 0.3393061224489796\n","\n","Candidate: 0.999999999877031 \n","Score: 0.3393061224489796\n","\n","Candidate: 0.9999999998772959 \n","Score: 0.33932653061224494\n","\n","Candidate: 0.999999999877435 \n","Score: 0.33934693877551025\n","\n","Candidate: 0.9999999998787027 \n","Score: 0.3393673469387755\n","\n","Candidate: 0.9999999998801034 \n","Score: 0.3393673469387755\n","\n","Candidate: 0.9999999998806971 \n","Score: 0.33940816326530615\n","\n","Candidate: 0.9999999998821729 \n","Score: 0.33942857142857147\n","\n","Candidate: 0.9999999998847133 \n","Score: 0.33944897959183673\n","\n","Candidate: 0.9999999998872684 \n","Score: 0.33946938775510205\n","\n","Candidate: 0.9999999998907538 \n","Score: 0.33946938775510205\n","\n","Candidate: 0.9999999998933572 \n","Score: 0.33948979591836737\n","\n","Candidate: 0.9999999998950876 \n","Score: 0.3395102040816327\n","\n","Candidate: 0.9999999998970668 \n","Score: 0.3395102040816327\n","\n","Candidate: 0.9999999998981461 \n","Score: 0.3395102040816327\n","\n","Candidate: 0.9999999998989749 \n","Score: 0.339530612244898\n","\n","Candidate: 0.9999999998993655 \n","Score: 0.3395510204081633\n","\n","Candidate: 0.9999999999002271 \n","Score: 0.3395714285714286\n","\n","Candidate: 0.9999999999016 \n","Score: 0.3395918367346939\n","\n","Candidate: 0.9999999999032008 \n","Score: 0.3396122448979592\n","\n","Candidate: 0.9999999999041997 \n","Score: 0.33963265306122453\n","\n","Candidate: 0.999999999905332 \n","Score: 0.33963265306122453\n","\n","Candidate: 0.9999999999063839 \n","Score: 0.3396530612244898\n","\n","Candidate: 0.9999999999067821 \n","Score: 0.3396734693877551\n","\n","Candidate: 0.999999999907315 \n","Score: 0.33969387755102043\n","\n","Candidate: 0.9999999999102265 \n","Score: 0.3594285714285715\n","\n","Candidate: 0.9999999999139237 \n","Score: 0.3594285714285715\n","\n","Candidate: 0.9999999999163197 \n","Score: 0.3594285714285715\n","\n","Candidate: 0.9999999999194287 \n","Score: 0.35944897959183675\n","\n","Candidate: 0.9999999999211128 \n","Score: 0.35946938775510207\n","\n","Candidate: 0.9999999999214046 \n","Score: 0.35946938775510207\n","\n","Candidate: 0.999999999921722 \n","Score: 0.35946938775510207\n","\n","Candidate: 0.9999999999218939 \n","Score: 0.3594897959183674\n","\n","Candidate: 0.9999999999227642 \n","Score: 0.3595102040816327\n","\n","Candidate: 0.9999999999237694 \n","Score: 0.359530612244898\n","\n","Candidate: 0.9999999999253313 \n","Score: 0.359530612244898\n","\n","Candidate: 0.9999999999271989 \n","Score: 0.3595510204081633\n","\n","Candidate: 0.9999999999280014 \n","Score: 0.3595714285714286\n","\n","Candidate: 0.9999999999295168 \n","Score: 0.3595714285714286\n","\n","Candidate: 0.9999999999310838 \n","Score: 0.3595918367346939\n","\n","Candidate: 0.9999999999319 \n","Score: 0.3595918367346939\n","\n","Candidate: 0.9999999999330909 \n","Score: 0.35961224489795923\n","\n","Candidate: 0.9999999999338327 \n","Score: 0.3596326530612245\n","\n","Candidate: 0.9999999999341072 \n","Score: 0.3596326530612245\n","\n","Candidate: 0.9999999999346019 \n","Score: 0.3596530612244898\n","\n","Candidate: 0.9999999999349887 \n","Score: 0.35967346938775513\n","\n","Candidate: 0.9999999999353333 \n","Score: 0.35969387755102045\n","\n","Candidate: 0.999999999935772 \n","Score: 0.35971428571428576\n","\n","Candidate: 0.9999999999361471 \n","Score: 0.35971428571428576\n","\n","Candidate: 0.9999999999367685 \n","Score: 0.359734693877551\n","\n","Candidate: 0.9999999999395743 \n","Score: 0.35975510204081634\n","\n","Candidate: 0.999999999942713 \n","Score: 0.35977551020408166\n","\n","Candidate: 0.9999999999437346 \n","Score: 0.359795918367347\n","\n","Candidate: 0.9999999999443461 \n","Score: 0.3598163265306123\n","\n","Candidate: 0.9999999999447572 \n","Score: 0.3598979591836735\n","\n","Candidate: 0.9999999999448717 \n","Score: 0.35991836734693883\n","\n","Candidate: 0.999999999945129 \n","Score: 0.35993877551020415\n","\n","Candidate: 0.9999999999457818 \n","Score: 0.3599591836734694\n","\n","Candidate: 0.9999999999463631 \n","Score: 0.3599591836734694\n","\n","Candidate: 0.999999999946597 \n","Score: 0.3599795918367347\n","\n","Candidate: 0.9999999999473557 \n","Score: 0.3599795918367347\n","\n","Candidate: 0.9999999999481703 \n","Score: 0.36000000000000004\n","\n","Candidate: 0.9999999999483802 \n","Score: 0.36002040816326536\n","\n","Candidate: 0.9999999999485232 \n","Score: 0.3600408163265306\n","\n","Candidate: 0.9999999999494303 \n","Score: 0.36006122448979594\n","\n","Candidate: 0.999999999950926 \n","Score: 0.36006122448979594\n","\n","Candidate: 0.9999999999520834 \n","Score: 0.36008163265306126\n","\n","Candidate: 0.9999999999529674 \n","Score: 0.3601020408163266\n","\n","Candidate: 0.9999999999537708 \n","Score: 0.3601020408163266\n","\n","Candidate: 0.9999999999541838 \n","Score: 0.3601020408163266\n","\n","Candidate: 0.999999999954557 \n","Score: 0.3601224489795919\n","\n","Candidate: 0.9999999999555255 \n","Score: 0.3601428571428572\n","\n","Candidate: 0.9999999999561685 \n","Score: 0.36016326530612247\n","\n","Candidate: 0.9999999999562181 \n","Score: 0.36016326530612247\n","\n","Candidate: 0.99999999995666 \n","Score: 0.3601836734693878\n","\n","Candidate: 0.9999999999574316 \n","Score: 0.3601836734693878\n","\n","Candidate: 0.9999999999586751 \n","Score: 0.3601836734693878\n","\n","Candidate: 0.9999999999597124 \n","Score: 0.3602040816326531\n","\n","Candidate: 0.9999999999599802 \n","Score: 0.3796326530612245\n","\n","Candidate: 0.9999999999603988 \n","Score: 0.3796734693877551\n","\n","Candidate: 0.9999999999607814 \n","Score: 0.3796938775510204\n","\n","Candidate: 0.9999999999611129 \n","Score: 0.3797142857142857\n","\n","Candidate: 0.9999999999614559 \n","Score: 0.3797142857142857\n","\n","Candidate: 0.9999999999622997 \n","Score: 0.379734693877551\n","\n","Candidate: 0.9999999999634401 \n","Score: 0.379734693877551\n","\n","Candidate: 0.9999999999644461 \n","Score: 0.3797551020408163\n","\n","Candidate: 0.9999999999650857 \n","Score: 0.3797755102040816\n","\n","Candidate: 0.9999999999652315 \n","Score: 0.37979591836734694\n","\n","Candidate: 0.9999999999654922 \n","Score: 0.37981632653061226\n","\n","Candidate: 0.9999999999657844 \n","Score: 0.37981632653061226\n","\n","Candidate: 0.9999999999659847 \n","Score: 0.3798367346938775\n","\n","Candidate: 0.9999999999663653 \n","Score: 0.37985714285714284\n","\n","Candidate: 0.9999999999667626 \n","Score: 0.37985714285714284\n","\n","Candidate: 0.9999999999669055 \n","Score: 0.37987755102040816\n","\n","Candidate: 0.9999999999678266 \n","Score: 0.3798979591836735\n","\n","Candidate: 0.9999999999687738 \n","Score: 0.3799183673469388\n","\n","Candidate: 0.9999999999690807 \n","Score: 0.37993877551020405\n","\n","Candidate: 0.9999999999694141 \n","Score: 0.37993877551020405\n","\n","Candidate: 0.9999999999699087 \n","Score: 0.37993877551020405\n","\n","Candidate: 0.9999999999704892 \n","Score: 0.37995918367346937\n","\n","Candidate: 0.9999999999710043 \n","Score: 0.3799795918367347\n","\n","Candidate: 0.999999999971306 \n","Score: 0.38\n","\n","Candidate: 0.9999999999713287 \n","Score: 0.3800204081632653\n","\n","Candidate: 0.9999999999713727 \n","Score: 0.3800408163265306\n","\n","Candidate: 0.9999999999714484 \n","Score: 0.3800612244897959\n","\n","Candidate: 0.999999999971982 \n","Score: 0.3800816326530612\n","\n","Candidate: 0.9999999999727558 \n","Score: 0.3610408163265306\n","\n","Candidate: 0.9999999999732028 \n","Score: 0.3610408163265306\n","\n","Candidate: 0.9999999999733793 \n","Score: 0.3416734693877551\n","\n","Candidate: 0.9999999999735281 \n","Score: 0.34169387755102043\n","\n","Candidate: 0.9999999999737922 \n","Score: 0.34171428571428575\n","\n","Candidate: 0.9999999999742291 \n","Score: 0.34173469387755107\n","\n","Candidate: 0.9999999999747156 \n","Score: 0.34173469387755107\n","\n","Candidate: 0.9999999999749325 \n","Score: 0.34173469387755107\n","\n","Candidate: 0.9999999999754039 \n","Score: 0.34173469387755107\n","\n","Candidate: 0.9999999999758606 \n","Score: 0.3417551020408163\n","\n","Candidate: 0.9999999999762879 \n","Score: 0.3417551020408163\n","\n","Candidate: 0.9999999999768285 \n","Score: 0.34177551020408165\n","\n","Candidate: 0.9999999999769932 \n","Score: 0.34179591836734696\n","\n","Candidate: 0.9999999999773095 \n","Score: 0.3418163265306123\n","\n","Candidate: 0.9999999999776361 \n","Score: 0.3418367346938776\n","\n","Candidate: 0.9999999999780202 \n","Score: 0.3418367346938776\n","\n","Candidate: 0.9999999999784486 \n","Score: 0.34185714285714286\n","\n","Candidate: 0.9999999999785867 \n","Score: 0.34185714285714286\n","\n","Candidate: 0.9999999999787385 \n","Score: 0.3418775510204082\n","\n","Candidate: 0.9999999999789054 \n","Score: 0.3418979591836735\n","\n","Candidate: 0.9999999999793182 \n","Score: 0.3419183673469388\n","\n","Candidate: 0.9999999999797848 \n","Score: 0.34193877551020413\n","\n","Candidate: 0.9999999999801323 \n","Score: 0.3419591836734694\n","\n","Candidate: 0.9999999999804661 \n","Score: 0.3419591836734694\n","\n","Candidate: 0.9999999999807923 \n","Score: 0.3419795918367347\n","\n","Candidate: 0.999999999981205 \n","Score: 0.34210204081632656\n","\n","Candidate: 0.999999999981419 \n","Score: 0.3421224489795919\n","\n","Candidate: 0.9999999999818338 \n","Score: 0.3421428571428572\n","\n","Candidate: 0.9999999999822831 \n","Score: 0.34216326530612245\n","\n","Candidate: 0.9999999999825848 \n","Score: 0.3421836734693878\n","\n","Candidate: 0.999999999982832 \n","Score: 0.32281632653061226\n","\n","Candidate: 0.9999999999829612 \n","Score: 0.3228367346938776\n","\n","Candidate: 0.9999999999832863 \n","Score: 0.3228571428571429\n","\n","Candidate: 0.9999999999835132 \n","Score: 0.32287755102040816\n","\n","Candidate: 0.9999999999835716 \n","Score: 0.3228979591836735\n","\n","Candidate: 0.9999999999836432 \n","Score: 0.3229183673469388\n","\n","Candidate: 0.9999999999837791 \n","Score: 0.3229183673469388\n","\n","Candidate: 0.9999999999840219 \n","Score: 0.3229387755102041\n","\n","Candidate: 0.9999999999841813 \n","Score: 0.32295918367346943\n","\n","Candidate: 0.9999999999841962 \n","Score: 0.3229795918367347\n","\n","Candidate: 0.9999999999844662 \n","Score: 0.32310204081632654\n","\n","Candidate: 0.9999999999847387 \n","Score: 0.32312244897959186\n","\n","Candidate: 0.999999999984764 \n","Score: 0.3231428571428572\n","\n","Candidate: 0.9999999999847965 \n","Score: 0.3231632653061225\n","\n","Candidate: 0.9999999999851295 \n","Score: 0.32318367346938776\n","\n","Candidate: 0.999999999985751 \n","Score: 0.32318367346938776\n","\n","Candidate: 0.9999999999860878 \n","Score: 0.32318367346938776\n","\n","Candidate: 0.9999999999863203 \n","Score: 0.3232244897959184\n","\n","Candidate: 0.9999999999865332 \n","Score: 0.3232244897959184\n","\n","Candidate: 0.9999999999867689 \n","Score: 0.3232448979591837\n","\n","Candidate: 0.9999999999870018 \n","Score: 0.32326530612244897\n","\n","Candidate: 0.9999999999872393 \n","Score: 0.32326530612244897\n","\n","Candidate: 0.9999999999875027 \n","Score: 0.3232857142857143\n","\n","Candidate: 0.9999999999876366 \n","Score: 0.3233061224489796\n","\n","Candidate: 0.999999999987822 \n","Score: 0.3233061224489796\n","\n","Candidate: 0.9999999999879465 \n","Score: 0.3233061224489796\n","\n","Candidate: 0.9999999999880989 \n","Score: 0.3233265306122449\n","\n","Candidate: 0.999999999988229 \n","Score: 0.32334693877551024\n","\n","Candidate: 0.9999999999882991 \n","Score: 0.3233673469387755\n","\n","Candidate: 0.9999999999885406 \n","Score: 0.3233877551020408\n","\n","Candidate: 0.9999999999888199 \n","Score: 0.3233877551020408\n","\n","Candidate: 0.999999999989424 \n","Score: 0.32340816326530614\n","\n","Candidate: 0.9999999999900626 \n","Score: 0.32342857142857145\n","\n","Candidate: 0.9999999999902833 \n","Score: 0.32344897959183677\n","\n","Candidate: 0.9999999999904032 \n","Score: 0.32346938775510203\n","\n","Candidate: 0.9999999999906232 \n","Score: 0.32348979591836735\n","\n","Candidate: 0.9999999999908518 \n","Score: 0.32351020408163267\n","\n","Candidate: 0.9999999999909481 \n","Score: 0.323530612244898\n","\n","Candidate: 0.9999999999910707 \n","Score: 0.3235510204081633\n","\n","Candidate: 0.9999999999911355 \n","Score: 0.3235714285714286\n","\n","Candidate: 0.9999999999911765 \n","Score: 0.3235918367346939\n","\n","Candidate: 0.999999999991215 \n","Score: 0.3236122448979592\n","\n","Candidate: 0.9999999999912467 \n","Score: 0.3236122448979592\n","\n","Candidate: 0.9999999999913991 \n","Score: 0.3236326530612245\n","\n","Candidate: 0.9999999999915989 \n","Score: 0.32365306122448984\n","\n","Candidate: 0.999999999991708 \n","Score: 0.3236734693877551\n","\n","Candidate: 0.9999999999917804 \n","Score: 0.3236938775510204\n","\n","Candidate: 0.9999999999918252 \n","Score: 0.32371428571428573\n","\n","Candidate: 0.99999999999193 \n","Score: 0.32373469387755105\n","\n","Candidate: 0.9999999999920569 \n","Score: 0.32373469387755105\n","\n","Candidate: 0.9999999999921035 \n","Score: 0.32375510204081637\n","\n","Candidate: 0.9999999999921442 \n","Score: 0.32377551020408163\n","\n","Candidate: 0.9999999999921794 \n","Score: 0.32377551020408163\n","\n","Candidate: 0.9999999999923344 \n","Score: 0.32379591836734695\n","\n","Candidate: 0.9999999999926235 \n","Score: 0.32381632653061226\n","\n","Candidate: 0.9999999999928818 \n","Score: 0.3238367346938776\n","\n","Candidate: 0.9999999999930915 \n","Score: 0.3238367346938776\n","\n","Candidate: 0.9999999999932194 \n","Score: 0.32385714285714284\n","\n","Candidate: 0.9999999999932643 \n","Score: 0.32385714285714284\n","\n","Candidate: 0.999999999993302 \n","Score: 0.32387755102040816\n","\n","Candidate: 0.9999999999933586 \n","Score: 0.3238979591836735\n","\n","Candidate: 0.9999999999934064 \n","Score: 0.3238979591836735\n","\n","Candidate: 0.9999999999934573 \n","Score: 0.3239183673469388\n","\n","Candidate: 0.9999999999935301 \n","Score: 0.3239387755102041\n","\n","Candidate: 0.9999999999935805 \n","Score: 0.32395918367346943\n","\n","Candidate: 0.9999999999936018 \n","Score: 0.3239795918367347\n","\n","Candidate: 0.9999999999937443 \n","Score: 0.324\n","\n","Candidate: 0.9999999999941609 \n","Score: 0.3240204081632653\n","\n","Candidate: 0.9999999999945136 \n","Score: 0.32404081632653065\n","\n","Candidate: 0.9999999999946361 \n","Score: 0.3240612244897959\n","\n","Candidate: 0.999999999994714 \n","Score: 0.3240816326530612\n","\n","Candidate: 0.9999999999947484 \n","Score: 0.32410204081632654\n","\n","Candidate: 0.9999999999948397 \n","Score: 0.32412244897959186\n","\n","Candidate: 0.9999999999949496 \n","Score: 0.3241428571428572\n","\n","Candidate: 0.9999999999949911 \n","Score: 0.32416326530612244\n","\n","Candidate: 0.9999999999950435 \n","Score: 0.32418367346938776\n","\n","Candidate: 0.9999999999950984 \n","Score: 0.3242040816326531\n","\n","Candidate: 0.9999999999951725 \n","Score: 0.3242040816326531\n","\n","Candidate: 0.9999999999952474 \n","Score: 0.3242244897959184\n","\n","Candidate: 0.9999999999952942 \n","Score: 0.3242448979591837\n","\n","Candidate: 0.9999999999953232 \n","Score: 0.3243061224489796\n","\n","Candidate: 0.9999999999953513 \n","Score: 0.3243265306122449\n","\n","Candidate: 0.9999999999954893 \n","Score: 0.32434693877551024\n","\n","Candidate: 0.9999999999956226 \n","Score: 0.3243673469387755\n","\n","Candidate: 0.9999999999956537 \n","Score: 0.3243877551020408\n","\n","Candidate: 0.999999999995768 \n","Score: 0.32440816326530614\n","\n","Candidate: 0.9999999999958795 \n","Score: 0.32442857142857146\n","\n","Candidate: 0.9999999999958915 \n","Score: 0.32442857142857146\n","\n","Candidate: 0.9999999999958997 \n","Score: 0.3244489795918367\n","\n","Candidate: 0.999999999995915 \n","Score: 0.32446938775510203\n","\n","Candidate: 0.9999999999959372 \n","Score: 0.32446938775510203\n","\n","Candidate: 0.9999999999959919 \n","Score: 0.32448979591836735\n","\n","Candidate: 0.9999999999961947 \n","Score: 0.324530612244898\n","\n","Candidate: 0.9999999999963689 \n","Score: 0.324530612244898\n","\n","Candidate: 0.9999999999964354 \n","Score: 0.3245510204081633\n","\n","Candidate: 0.9999999999965022 \n","Score: 0.3245510204081633\n","\n","Candidate: 0.9999999999965251 \n","Score: 0.3245714285714286\n","\n","Candidate: 0.9999999999965496 \n","Score: 0.3245918367346939\n","\n","Candidate: 0.9999999999966444 \n","Score: 0.3245918367346939\n","\n","Candidate: 0.999999999996751 \n","Score: 0.3246122448979592\n","\n","Candidate: 0.999999999996784 \n","Score: 0.3246326530612245\n","\n","Candidate: 0.9999999999968368 \n","Score: 0.3246530612244898\n","\n","Candidate: 0.9999999999969001 \n","Score: 0.3246734693877551\n","\n","Candidate: 0.9999999999969389 \n","Score: 0.3246938775510204\n","\n","Candidate: 0.9999999999969948 \n","Score: 0.32471428571428573\n","\n","Candidate: 0.9999999999970939 \n","Score: 0.32473469387755105\n","\n","Candidate: 0.9999999999971652 \n","Score: 0.32475510204081637\n","\n","Candidate: 0.9999999999971785 \n","Score: 0.3247755102040817\n","\n","Candidate: 0.9999999999971878 \n","Score: 0.324795918367347\n","\n","Candidate: 0.9999999999972 \n","Score: 0.3442040816326531\n","\n","Candidate: 0.999999999997259 \n","Score: 0.3442040816326531\n","\n","Candidate: 0.9999999999973392 \n","Score: 0.3442244897959184\n","\n","Candidate: 0.9999999999973885 \n","Score: 0.3442448979591837\n","\n","Candidate: 0.9999999999974127 \n","Score: 0.344265306122449\n","\n","Candidate: 0.9999999999974614 \n","Score: 0.3442857142857143\n","\n","Candidate: 0.9999999999975397 \n","Score: 0.34448979591836737\n","\n","Candidate: 0.9999999999975779 \n","Score: 0.3445102040816327\n","\n","Candidate: 0.9999999999976147 \n","Score: 0.344530612244898\n","\n","Candidate: 0.9999999999976552 \n","Score: 0.344530612244898\n","\n","Candidate: 0.9999999999976821 \n","Score: 0.3445510204081633\n","\n","Candidate: 0.9999999999977123 \n","Score: 0.34457142857142864\n","\n","Candidate: 0.9999999999977482 \n","Score: 0.3445918367346939\n","\n","Candidate: 0.9999999999977813 \n","Score: 0.3446122448979592\n","\n","Candidate: 0.999999999997794 \n","Score: 0.34463265306122454\n","\n","Candidate: 0.9999999999978118 \n","Score: 0.34465306122448985\n","\n","Candidate: 0.9999999999978356 \n","Score: 0.3446734693877551\n","\n","Candidate: 0.9999999999978574 \n","Score: 0.34469387755102043\n","\n","Candidate: 0.999999999997873 \n","Score: 0.34471428571428575\n","\n","Candidate: 0.9999999999979062 \n","Score: 0.34471428571428575\n","\n","Candidate: 0.9999999999979726 \n","Score: 0.34473469387755107\n","\n","Candidate: 0.9999999999980317 \n","Score: 0.3447551020408164\n","\n","Candidate: 0.999999999998062 \n","Score: 0.34477551020408165\n","\n","Candidate: 0.9999999999980888 \n","Score: 0.34479591836734697\n","\n","Candidate: 0.999999999998104 \n","Score: 0.3448163265306123\n","\n","Candidate: 0.9999999999981118 \n","Score: 0.3448163265306123\n","\n","Candidate: 0.9999999999981464 \n","Score: 0.3448367346938776\n","\n","Candidate: 0.9999999999981837 \n","Score: 0.3448367346938776\n","\n","Candidate: 0.9999999999982039 \n","Score: 0.34485714285714286\n","\n","Candidate: 0.9999999999982249 \n","Score: 0.34485714285714286\n","\n","Candidate: 0.9999999999982496 \n","Score: 0.3448775510204082\n","\n","Candidate: 0.9999999999982823 \n","Score: 0.3448979591836735\n","\n","Candidate: 0.9999999999983324 \n","Score: 0.3449183673469388\n","\n","Candidate: 0.999999999998396 \n","Score: 0.34493877551020413\n","\n","Candidate: 0.9999999999984432 \n","Score: 0.34495918367346945\n","\n","Candidate: 0.9999999999984719 \n","Score: 0.3449795918367347\n","\n","Candidate: 0.9999999999984917 \n","Score: 0.34500000000000003\n","\n","Candidate: 0.9999999999984983 \n","Score: 0.34502040816326535\n","\n","Candidate: 0.9999999999985003 \n","Score: 0.34502040816326535\n","\n","Candidate: 0.9999999999985096 \n","Score: 0.34508163265306124\n","\n","Candidate: 0.9999999999985363 \n","Score: 0.34510204081632656\n","\n","Candidate: 0.9999999999985794 \n","Score: 0.3451224489795919\n","\n","Candidate: 0.9999999999986429 \n","Score: 0.3451428571428572\n","\n","Candidate: 0.9999999999986955 \n","Score: 0.3451632653061225\n","\n","Candidate: 0.9999999999987218 \n","Score: 0.3451836734693878\n","\n","Candidate: 0.9999999999987392 \n","Score: 0.3451836734693878\n","\n","Candidate: 0.999999999998745 \n","Score: 0.3452040816326531\n","\n","Candidate: 0.9999999999987632 \n","Score: 0.3452244897959184\n","\n","Candidate: 0.9999999999987973 \n","Score: 0.3452448979591837\n","\n","Candidate: 0.9999999999988198 \n","Score: 0.345265306122449\n","\n","Candidate: 0.9999999999988338 \n","Score: 0.3453061224489796\n","\n","Candidate: 0.9999999999988431 \n","Score: 0.34532653061224494\n","\n","Candidate: 0.9999999999988485 \n","Score: 0.34534693877551026\n","\n","Candidate: 0.9999999999988601 \n","Score: 0.3453673469387756\n","\n","Candidate: 0.9999999999988827 \n","Score: 0.34538775510204084\n","\n","Candidate: 0.9999999999988989 \n","Score: 0.34538775510204084\n","\n","Candidate: 0.9999999999989329 \n","Score: 0.34540816326530616\n","\n","Candidate: 0.9999999999989697 \n","Score: 0.3454285714285715\n","\n","Candidate: 0.9999999999989921 \n","Score: 0.3454285714285715\n","\n","Candidate: 0.9999999999990163 \n","Score: 0.3454285714285715\n","\n","Candidate: 0.9999999999990228 \n","Score: 0.3454489795918368\n","\n","Candidate: 0.9999999999990437 \n","Score: 0.3454693877551021\n","\n","Candidate: 0.9999999999990674 \n","Score: 0.34548979591836737\n","\n","Candidate: 0.999999999999083 \n","Score: 0.34548979591836737\n","\n","Candidate: 0.999999999999098 \n","Score: 0.3455102040816327\n","\n","Candidate: 0.9999999999991053 \n","Score: 0.345530612244898\n","\n","Candidate: 0.9999999999991138 \n","Score: 0.3455510204081633\n","\n","Candidate: 0.9999999999991189 \n","Score: 0.3455714285714286\n","\n","Candidate: 0.9999999999991341 \n","Score: 0.3455918367346939\n","\n","Candidate: 0.9999999999991516 \n","Score: 0.3262244897959184\n","\n","Candidate: 0.9999999999991726 \n","Score: 0.3262448979591837\n","\n","Candidate: 0.9999999999991984 \n","Score: 0.32626530612244903\n","\n","Candidate: 0.999999999999209 \n","Score: 0.3262857142857143\n","\n","Candidate: 0.9999999999992157 \n","Score: 0.3263061224489796\n","\n","Candidate: 0.9999999999992222 \n","Score: 0.3263061224489796\n","\n","Candidate: 0.99999999999923 \n","Score: 0.3263265306122449\n","\n","Candidate: 0.9999999999992353 \n","Score: 0.32634693877551024\n","\n","Candidate: 0.9999999999992399 \n","Score: 0.32636734693877556\n","\n","Candidate: 0.9999999999992601 \n","Score: 0.3263877551020408\n","\n","Candidate: 0.9999999999992832 \n","Score: 0.32640816326530614\n","\n","Candidate: 0.9999999999993066 \n","Score: 0.32642857142857146\n","\n","Candidate: 0.9999999999993238 \n","Score: 0.3264489795918368\n","\n","Candidate: 0.9999999999993336 \n","Score: 0.3264693877551021\n","\n","Candidate: 0.9999999999993443 \n","Score: 0.3264693877551021\n","\n","Candidate: 0.9999999999993466 \n","Score: 0.32648979591836735\n","\n","Candidate: 0.9999999999993547 \n","Score: 0.32651020408163267\n","\n","Candidate: 0.9999999999993657 \n","Score: 0.326530612244898\n","\n","Candidate: 0.9999999999993723 \n","Score: 0.3265510204081633\n","\n","Candidate: 0.9999999999993816 \n","Score: 0.3265714285714286\n","\n","Candidate: 0.9999999999993902 \n","Score: 0.3266326530612245\n","\n","Candidate: 0.9999999999993958 \n","Score: 0.32665306122448984\n","\n","Candidate: 0.9999999999994009 \n","Score: 0.3266734693877551\n","\n","Candidate: 0.9999999999994054 \n","Score: 0.3266734693877551\n","\n","Candidate: 0.9999999999994154 \n","Score: 0.3266938775510204\n","\n","Candidate: 0.999999999999442 \n","Score: 0.3266938775510204\n","\n","Candidate: 0.9999999999994647 \n","Score: 0.32671428571428573\n","\n","Candidate: 0.99999999999948 \n","Score: 0.32673469387755105\n","\n","Candidate: 0.9999999999994936 \n","Score: 0.32675510204081637\n","\n","Candidate: 0.9999999999994964 \n","Score: 0.3267755102040817\n","\n","Candidate: 0.9999999999994973 \n","Score: 0.3267755102040817\n","\n","Candidate: 0.9999999999995053 \n","Score: 0.32679591836734695\n","\n","Candidate: 0.9999999999995146 \n","Score: 0.32681632653061227\n","\n","Candidate: 0.999999999999529 \n","Score: 0.3268367346938776\n","\n","Candidate: 0.999999999999557 \n","Score: 0.3268571428571429\n","\n","Candidate: 0.9999999999995759 \n","Score: 0.32687755102040816\n","\n","Candidate: 0.9999999999995831 \n","Score: 0.3268979591836735\n","\n","Candidate: 0.9999999999995874 \n","Score: 0.3269183673469388\n","\n","Candidate: 0.9999999999995892 \n","Score: 0.3269387755102041\n","\n","Candidate: 0.9999999999995922 \n","Score: 0.32695918367346943\n","\n","Candidate: 0.9999999999995975 \n","Score: 0.32695918367346943\n","\n","Candidate: 0.9999999999996123 \n","Score: 0.32697959183673475\n","\n","Candidate: 0.9999999999996236 \n","Score: 0.327\n","\n","Candidate: 0.9999999999996245 \n","Score: 0.32704081632653065\n","\n","Candidate: 0.9999999999996259 \n","Score: 0.32706122448979597\n","\n","Candidate: 0.9999999999996311 \n","Score: 0.3270816326530612\n","\n","Candidate: 0.9999999999996363 \n","Score: 0.32710204081632654\n","\n","Candidate: 0.9999999999996374 \n","Score: 0.32712244897959186\n","\n","Candidate: 0.999999999999643 \n","Score: 0.3271428571428572\n","\n","Candidate: 0.9999999999996517 \n","Score: 0.3271632653061225\n","\n","Candidate: 0.9999999999996563 \n","Score: 0.32718367346938776\n","\n","Candidate: 0.9999999999996575 \n","Score: 0.3272040816326531\n","\n","Candidate: 0.9999999999996597 \n","Score: 0.3272040816326531\n","\n","Candidate: 0.9999999999996629 \n","Score: 0.3272244897959184\n","\n","Candidate: 0.9999999999996738 \n","Score: 0.3272448979591837\n","\n","Candidate: 0.9999999999996851 \n","Score: 0.327265306122449\n","\n","Candidate: 0.9999999999996875 \n","Score: 0.3272857142857143\n","\n","Candidate: 0.9999999999996898 \n","Score: 0.3272857142857143\n","\n","Candidate: 0.9999999999997068 \n","Score: 0.3273061224489796\n","\n","Candidate: 0.9999999999997231 \n","Score: 0.3273265306122449\n","\n","Candidate: 0.9999999999997303 \n","Score: 0.3133125\n","\n","Candidate: 0.9999999999997371 \n","Score: 0.3133333333333333\n","\n","Candidate: 0.9999999999997385 \n","Score: 0.31335416666666666\n","\n","Candidate: 0.9999999999997418 \n","Score: 0.31337499999999996\n","\n","Candidate: 0.9999999999997464 \n","Score: 0.3133958333333333\n","\n","Candidate: 0.9999999999997482 \n","Score: 0.3134166666666667\n","\n","Candidate: 0.9999999999997489 \n","Score: 0.3134375\n","\n","Candidate: 0.9999999999997504 \n","Score: 0.29400000000000004\n","\n","Candidate: 0.9999999999997524 \n","Score: 0.2941458333333334\n","\n","Candidate: 0.9999999999997544 \n","Score: 0.29416666666666674\n","\n","Candidate: 0.9999999999997589 \n","Score: 0.29418750000000005\n","\n","Candidate: 0.9999999999997629 \n","Score: 0.2942083333333334\n","\n","Candidate: 0.9999999999997722 \n","Score: 0.2942291666666667\n","\n","Candidate: 0.9999999999997828 \n","Score: 0.29425000000000007\n","\n","Candidate: 0.9999999999997846 \n","Score: 0.29427083333333337\n","\n","Candidate: 0.9999999999997853 \n","Score: 0.29429166666666673\n","\n","Candidate: 0.9999999999997864 \n","Score: 0.2943125000000001\n","\n","Candidate: 0.999999999999788 \n","Score: 0.2943333333333334\n","\n","Candidate: 0.9999999999997925 \n","Score: 0.31414583333333335\n","\n","Candidate: 0.9999999999997982 \n","Score: 0.3144375\n","\n","Candidate: 0.9999999999998023 \n","Score: 0.31445833333333334\n","\n","Candidate: 0.9999999999998046 \n","Score: 0.31447916666666664\n","\n","Candidate: 0.9999999999998055 \n","Score: 0.3145\n","\n","Candidate: 0.9999999999998084 \n","Score: 0.31456249999999997\n","\n","Candidate: 0.9999999999998161 \n","Score: 0.3145833333333333\n","\n","Candidate: 0.9999999999998264 \n","Score: 0.3145833333333333\n","\n","Candidate: 0.9999999999998308 \n","Score: 0.3\n","\n","Candidate: 0.9999999999998354 \n","Score: 0.3000212765957447\n","\n","Candidate: 0.9999999999998427 \n","Score: 0.30004255319148937\n","\n","Candidate: 0.9999999999998459 \n","Score: 0.300063829787234\n","\n","Candidate: 0.9999999999998485 \n","Score: 0.3001063829787234\n","\n","Candidate: 0.9999999999998508 \n","Score: 0.3001276595744681\n","\n","Candidate: 0.9999999999998526 \n","Score: 0.30014893617021277\n","\n","Candidate: 0.9999999999998547 \n","Score: 0.30017021276595746\n","\n","Candidate: 0.9999999999998558 \n","Score: 0.30019148936170215\n","\n","Candidate: 0.9999999999998581 \n","Score: 0.3002127659574468\n","\n","Candidate: 0.999999999999862 \n","Score: 0.30023404255319147\n","\n","Candidate: 0.9999999999998643 \n","Score: 0.30025531914893616\n","\n","Candidate: 0.9999999999998658 \n","Score: 0.30027659574468085\n","\n","Candidate: 0.9999999999998681 \n","Score: 0.30029787234042554\n","\n","Candidate: 0.9999999999998698 \n","Score: 0.3003191489361702\n","\n","Candidate: 0.9999999999998752 \n","Score: 0.30034042553191487\n","\n","Candidate: 0.9999999999998823 \n","Score: 0.30036170212765956\n","\n","Candidate: 0.9999999999998848 \n","Score: 0.3058260869565218\n","\n","Candidate: 0.9999999999998855 \n","Score: 0.30584782608695654\n","\n","Candidate: 0.9999999999998872 \n","Score: 0.30586956521739134\n","\n","Candidate: 0.9999999999998883 \n","Score: 0.30589130434782613\n","\n","Candidate: 0.9999999999998893 \n","Score: 0.3059130434782609\n","\n","Candidate: 0.9999999999998909 \n","Score: 0.31199999999999994\n","\n","Candidate: 0.9999999999998919 \n","Score: 0.3120222222222222\n","\n","Candidate: 0.9999999999998939 \n","Score: 0.3120444444444444\n","\n","Candidate: 0.999999999999897 \n","Score: 0.31206666666666666\n","\n","Candidate: 0.9999999999998992 \n","Score: 0.31208888888888886\n","\n","Candidate: 0.9999999999998999 \n","Score: 0.3121333333333333\n","\n","Candidate: 0.9999999999999019 \n","Score: 0.3121555555555555\n","\n","Candidate: 0.9999999999999047 \n","Score: 0.3121555555555555\n","\n","Candidate: 0.9999999999999094 \n","Score: 0.3121777777777778\n","\n","Candidate: 0.9999999999999134 \n","Score: 0.3122\n","\n","Candidate: 0.9999999999999151 \n","Score: 0.3122222222222222\n","\n","Candidate: 0.9999999999999165 \n","Score: 0.31224444444444444\n","\n","Candidate: 0.9999999999999172 \n","Score: 0.31226666666666664\n","\n","Candidate: 0.9999999999999187 \n","Score: 0.31228888888888884\n","\n","Candidate: 0.9999999999999221 \n","Score: 0.3123111111111111\n","\n","Candidate: 0.9999999999999256 \n","Score: 0.3123333333333333\n","\n","Candidate: 0.9999999999999288 \n","Score: 0.3123555555555555\n","\n","Candidate: 0.9999999999999314 \n","Score: 0.31237777777777775\n","\n","Candidate: 0.999999999999932 \n","Score: 0.29128888888888893\n","\n","Candidate: 0.9999999999999329 \n","Score: 0.2913111111111112\n","\n","Candidate: 0.9999999999999354 \n","Score: 0.2913333333333334\n","\n","Candidate: 0.9999999999999375 \n","Score: 0.29137777777777785\n","\n","Candidate: 0.9999999999999382 \n","Score: 0.29142222222222225\n","\n","Candidate: 0.9999999999999392 \n","Score: 0.2969090909090909\n","\n","Candidate: 0.9999999999999399 \n","Score: 0.29693181818181813\n","\n","Candidate: 0.99999999999994 \n","Score: 0.29693181818181813\n","\n","Candidate: 0.9999999999999406 \n","Score: 0.2969772727272727\n","\n","Candidate: 0.9999999999999414 \n","Score: 0.297\n","\n","Candidate: 0.9999999999999433 \n","Score: 0.29702272727272727\n","\n","Candidate: 0.9999999999999465 \n","Score: 0.2970454545454545\n","\n","Candidate: 0.9999999999999483 \n","Score: 0.2970681818181818\n","\n","Candidate: 0.9999999999999503 \n","Score: 0.29709090909090907\n","\n","Candidate: 0.9999999999999529 \n","Score: 0.29711363636363636\n","\n","Candidate: 0.9999999999999543 \n","Score: 0.29713636363636364\n","\n","Candidate: 0.9999999999999551 \n","Score: 0.30288372093023264\n","\n","Candidate: 0.9999999999999565 \n","Score: 0.3029069767441861\n","\n","Candidate: 0.9999999999999576 \n","Score: 0.3029302325581396\n","\n","Candidate: 0.9999999999999578 \n","Score: 0.30295348837209307\n","\n","Candidate: 0.9999999999999581 \n","Score: 0.3029767441860466\n","\n","Candidate: 0.9999999999999587 \n","Score: 0.30300000000000005\n","\n","Candidate: 0.9999999999999595 \n","Score: 0.30302325581395356\n","\n","Candidate: 0.9999999999999607 \n","Score: 0.30306976744186054\n","\n","Candidate: 0.9999999999999614 \n","Score: 0.30306976744186054\n","\n","Candidate: 0.9999999999999618 \n","Score: 0.3031162790697675\n","\n","Candidate: 0.9999999999999638 \n","Score: 0.303139534883721\n","\n","Candidate: 0.9999999999999656 \n","Score: 0.3031627906976745\n","\n","Candidate: 0.999999999999966 \n","Score: 0.303232558139535\n","\n","Candidate: 0.9999999999999665 \n","Score: 0.30325581395348844\n","\n","Candidate: 0.9999999999999669 \n","Score: 0.30327906976744196\n","\n","Candidate: 0.9999999999999679 \n","Score: 0.3033023255813954\n","\n","Candidate: 0.9999999999999687 \n","Score: 0.3033023255813954\n","\n","Candidate: 0.9999999999999689 \n","Score: 0.3033488372093024\n","\n","Candidate: 0.9999999999999702 \n","Score: 0.3033720930232559\n","\n","Candidate: 0.9999999999999718 \n","Score: 0.30339534883720937\n","\n","Candidate: 0.9999999999999734 \n","Score: 0.3034186046511629\n","\n","Candidate: 0.9999999999999746 \n","Score: 0.30344186046511634\n","\n","Candidate: 0.9999999999999747 \n","Score: 0.30344186046511634\n","\n","Candidate: 0.9999999999999754 \n","Score: 0.3035348837209303\n","\n","Candidate: 0.9999999999999762 \n","Score: 0.3035581395348838\n","\n","Candidate: 0.9999999999999771 \n","Score: 0.30358139534883727\n","\n","Candidate: 0.9999999999999778 \n","Score: 0.30358139534883727\n","\n","Candidate: 0.9999999999999786 \n","Score: 0.30362790697674424\n","\n","Candidate: 0.9999999999999796 \n","Score: 0.30365116279069776\n","\n","Candidate: 0.99999999999998 \n","Score: 0.3036744186046512\n","\n","Candidate: 0.9999999999999802 \n","Score: 0.3036744186046512\n","\n","Candidate: 0.9999999999999805 \n","Score: 0.3037209302325582\n","\n","Candidate: 0.9999999999999809 \n","Score: 0.3037441860465117\n","\n","Candidate: 0.9999999999999813 \n","Score: 0.30376744186046517\n","\n","Candidate: 0.9999999999999821 \n","Score: 0.3037906976744187\n","\n","Candidate: 0.9999999999999829 \n","Score: 0.30381395348837215\n","\n","Candidate: 0.9999999999999835 \n","Score: 0.30383720930232566\n","\n","Candidate: 0.9999999999999838 \n","Score: 0.30388372093023264\n","\n","Candidate: 0.9999999999999842 \n","Score: 0.3039069767441861\n","\n","Candidate: 0.9999999999999848 \n","Score: 0.30395348837209313\n","\n","Candidate: 0.9999999999999851 \n","Score: 0.3039767441860466\n","\n","Candidate: 0.9999999999999856 \n","Score: 0.3040000000000001\n","\n","Candidate: 0.9999999999999861 \n","Score: 0.30402325581395356\n","\n","Candidate: 0.9999999999999862 \n","Score: 0.30402325581395356\n","\n","Candidate: 0.9999999999999866 \n","Score: 0.3105476190476191\n","\n","Candidate: 0.9999999999999869 \n","Score: 0.3105714285714286\n","\n","Candidate: 0.9999999999999876 \n","Score: 0.3105952380952381\n","\n","Candidate: 0.9999999999999882 \n","Score: 0.31061904761904763\n","\n","Candidate: 0.9999999999999887 \n","Score: 0.31064285714285716\n","\n","Candidate: 0.9999999999999891 \n","Score: 0.31069047619047624\n","\n","Candidate: 0.9999999999999896 \n","Score: 0.3107142857142857\n","\n","Candidate: 0.9999999999999898 \n","Score: 0.3107619047619048\n","\n","Candidate: 0.99999999999999 \n","Score: 0.31083333333333335\n","\n","Candidate: 0.9999999999999902 \n","Score: 0.3108571428571429\n","\n","Candidate: 0.9999999999999905 \n","Score: 0.3108571428571429\n","\n","Candidate: 0.9999999999999908 \n","Score: 0.3109047619047619\n","\n","Candidate: 0.9999999999999911 \n","Score: 0.31092857142857144\n","\n","Candidate: 0.9999999999999913 \n","Score: 0.29412195121951223\n","\n","Candidate: 0.9999999999999917 \n","Score: 0.2941463414634147\n","\n","Candidate: 0.9999999999999918 \n","Score: 0.2941463414634147\n","\n","Candidate: 0.999999999999992 \n","Score: 0.29419512195121955\n","\n","Candidate: 0.9999999999999925 \n","Score: 0.29426829268292687\n","\n","Candidate: 0.9999999999999928 \n","Score: 0.2942926829268293\n","\n","Candidate: 0.9999999999999931 \n","Score: 0.29431707317073175\n","\n","Candidate: 0.9999999999999933 \n","Score: 0.2943414634146342\n","\n","Candidate: 0.9999999999999936 \n","Score: 0.29439024390243906\n","\n","Candidate: 0.9999999999999938 \n","Score: 0.2944146341463415\n","\n","Candidate: 0.9999999999999941 \n","Score: 0.29443902439024394\n","\n","Candidate: 0.9999999999999947 \n","Score: 0.30065000000000003\n","\n","Candidate: 0.9999999999999951 \n","Score: 0.300675\n","\n","Candidate: 0.9999999999999952 \n","Score: 0.300725\n","\n","Candidate: 0.9999999999999953 \n","Score: 0.300725\n","\n","Candidate: 0.9999999999999956 \n","Score: 0.30717948717948723\n","\n","Candidate: 0.9999999999999958 \n","Score: 0.30720512820512824\n","\n","Candidate: 0.999999999999996 \n","Score: 0.30730769230769234\n","\n","Candidate: 0.9999999999999962 \n","Score: 0.3074871794871795\n","\n","Candidate: 0.9999999999999964 \n","Score: 0.3075384615384616\n","\n","Candidate: 0.9999999999999967 \n","Score: 0.3075641025641026\n","\n","Candidate: 0.9999999999999969 \n","Score: 0.3076153846153846\n","\n","Candidate: 0.9999999999999971 \n","Score: 0.3076153846153846\n","\n","Candidate: 0.9999999999999973 \n","Score: 0.3077435897435898\n","\n","Candidate: 0.9999999999999976 \n","Score: 0.31460526315789483\n","\n","Candidate: 0.9999999999999978 \n","Score: 0.31468421052631584\n","\n","Candidate: 0.9999999999999979 \n","Score: 0.31471052631578955\n","\n","Candidate: 0.999999999999998 \n","Score: 0.31471052631578955\n","\n","Candidate: 0.9999999999999982 \n","Score: 0.3147894736842106\n","\n","Candidate: 0.9999999999999984 \n","Score: 0.314921052631579\n","\n","Candidate: 0.9999999999999987 \n","Score: 0.3222162162162162\n","\n","Candidate: 0.9999999999999989 \n","Score: 0.3226216216216216\n","\n","Candidate: 0.9999999999999991 \n","Score: 0.33831428571428573\n","\n","Candidate: 0.9999999999999993 \n","Score: 0.34705882352941175\n","\n","Candidate: 0.9999999999999996 \n","Score: 0.3473235294117647\n","\n","Candidate: 0.9999999999999998 \n","Score: 0.3570303030303031\n","\n","Candidate: 1.0 \n","Score: 0.3393125\n","\n"]}]},{"cell_type":"code","source":["# aim is to minimise cost function -- find index in array where this is the case\n","lowest_cf_score = np.min(np.array(cost_function_values))\n","index_best_th = np.argmin(np.array(cost_function_values))"],"metadata":{"id":"P2IsLZXQ77oZ","executionInfo":{"status":"ok","timestamp":1651227828735,"user_tz":-60,"elapsed":57,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":281,"outputs":[]},{"cell_type":"code","source":["lowest_cf_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iZ3ba0jhY0I","executionInfo":{"status":"ok","timestamp":1651227828735,"user_tz":-60,"elapsed":56,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"665feeb3-232e-4753-bcf1-10b8cce767c2"},"execution_count":282,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.29128888888888893"]},"metadata":{},"execution_count":282}]},{"cell_type":"code","source":["index_best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBS0v3GAh77m","executionInfo":{"status":"ok","timestamp":1651227828735,"user_tz":-60,"elapsed":22,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"bb182f01-d30f-4acf-dcdf-fb767104df3e"},"execution_count":283,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1450"]},"metadata":{},"execution_count":283}]},{"cell_type":"code","source":["best_th = list(threshold_candidates)[index_best_th]\n","best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmy0bv8N8YvW","executionInfo":{"status":"ok","timestamp":1651227828736,"user_tz":-60,"elapsed":19,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"4dd29c78-8b1f-42ff-8c40-4d75b9f8ea1e"},"execution_count":284,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.999999999999932"]},"metadata":{},"execution_count":284}]},{"cell_type":"markdown","source":["#### Testing with best threshold"],"metadata":{"id":"ypFTpLSAir09"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions excluding the current test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # count inconclusive results\n","  inconc_count = 0\n","  \n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    for i in range(len(predictions)):\n","\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","    \n","      if(c >= best_th ): # best confidence threshold from cost function\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","\n","        earliness.append(time_index/timestamps[-1])\n","\n","        if(pred == 1.0):\n","          print(f\"TTP: {time_to_result + 30}s\")\n","\n","        break\n","\n","      if(i == len(predictions)-1):\n","        print(\"Inconclusive\")\n","        inconc_count += 1\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","  print(f\"Average Earliness: {sum(earliness)/len(earliness)}\")\n","  print(f\"Total Inconclusive: {inconc_count}/{sample_idx}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfPwqWWHiqnY","executionInfo":{"status":"ok","timestamp":1651227839082,"user_tz":-60,"elapsed":3447,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"be8efce5-a124-4b2a-c873-8882f08f27d6"},"execution_count":285,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 550.0s\n","\n","Sample exp_86_pos\n","Inconclusive\n","\n","Sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1065.0s\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 609.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1162.0s\n","\n","Sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 682.0s\n","\n","Sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 680.0s\n","\n","Sample exp_40_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 731.0s\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 780.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 741.0s\n","\n","Sample exp_134_pos\n","Inconclusive\n","\n","Sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 930.0s\n","\n","Sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 829.0s\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1027.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 779.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 814.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 929.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 826.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 600.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 590.0s\n","\n","Sample arv7_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample rv1y_p3\n","Inconclusive\n","\n","Sample rv1y_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 618.0s\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 883.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1075.0s\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 758.0s\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 939.0s\n","\n","Sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 689.0s\n","\n","Sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 865s\n","\n","Sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 745s\n","\n","Sample exp_165_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 813s\n","\n","Sample exp_35_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 1008s\n","\n","Sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 826s\n","\n","Sample exp_40_neg\n","Inconclusive\n","\n","Sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_134_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 1110.0s\n","\n","Sample exp_97_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 804s\n","\n","Sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 901s\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 845.0s\n","\n","Sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 854.0s\n","\n","Sample yap1n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 994.0s\n","\n","Sample arv7\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Accuracy: 0.7333333333333333\n","Sensitivity/Recall: 0.96\n","Specificity: 0.45\n","Precision: 0.6857142857142857\n","F1 Score: 0.7999999999999999\n","Average Earliness: 0.7591111111111111\n","Total Inconclusive: 4/49\n"]}]},{"cell_type":"markdown","source":["#### Testing with different alpha values"],"metadata":{"id":"w43_TkUVitvi"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"pJXWD05RjB-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"NSkTWcddjB-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981439090,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"f742fd4d-fa2c-4f24-c18f-ffde40f1d377","id":"KWOXfxRKjB-i"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"NXrd_74JjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"wcE9LintjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"qb9FWSPgjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are mad of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"bM7ILJSwjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981450827,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"23bf8873-4159-42ca-fc01-82fcb7e27198","id":"36WDfG-TjB-l"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1184"]},"metadata":{},"execution_count":497}]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  acc = []\n","  ear = []\n","\n","  for i in range(0,100,5):\n","\n","    # alpha\n","    alpha = i/100\n","\n","    print(f\"Alpha: {alpha}\")\n","\n","    # array to hold cost function value for each candidate\n","    cost_function_values = []\n","\n","    # create nN predictions using each dataset as the test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # evaluate every candidate\n","    for th in threshold_candidates:\n","\n","      # print(f\"Candidate: {th} \")\n","\n","      # array to hold earliness values for the samples \n","      earliness = []  \n","\n","      # dict to hold predictions vs true values for the samples  \n","      final_classifications = {}\n","\n","      # sample index\n","      sample_idx = 0\n","\n","      for key, value in all_samples.items():\n","        test_sample_name = key\n","        test_sample = value\n","  \n","        # get KNN predicition for the sample\n","        predictions = sample_predictions[sample_idx]\n","\n","        for i in range(len(predictions)):\n","\n","          # get the confidence for that prediction \n","          c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","          if(c >= th): # check if confidence is above confidence threshold\n","\n","            time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","            time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","            # predicted class for the sample is given by the prediction which led to the gien confidence value\n","            pred = predictions[i]\n","\n","            # update final outcomes dict\n","            final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","            # add to earliness array\n","            earliness.append(time_index/timestamps[-1])\n","\n","            break\n","        sample_idx += 1\n","\n","      # get avg accuracy and avg earliness for this threshold\n","      if(len(final_classifications) > 0):\n","        avg_accuracy = accuracy(final_classifications)\n","        avg_earliness = sum(earliness)/len(earliness)\n","\n","        # compute value of cost function and add to array \n","        cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","        cost_function_values.append(cf_score)\n","\n","    index_best_th = np.argmin(np.array(cost_function_values))    \n","    best_th = list(threshold_candidates)[index_best_th]\n","\n","###########################################################################################################\n","\n","    ## teating with best th\n","    final_classifications = {}\n","    earliness = []\n","\n","    # create nN predictions excluding the current test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    # count inconclusive results\n","    inconc_count = 0\n","    \n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      \n","        if(c >= best_th): # best confidence threshold from cost function\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          pred = predictions[i]\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","          earliness.append(time_index/timestamps[-1])\n","          break\n","\n","        if(i == len(predictions)-1):\n","          inconc_count += 1\n","      \n","      sample_idx += 1\n","\n","    print(f\"Avg Accuracy: {accuracy(final_classifications)}\")\n","    print(f\"Avg Earliness: {sum(earliness)/len(earliness)}\")\n","    print(\"\")\n","    acc.append(accuracy(final_classifications))\n","    ear.append(sum(earliness)/len(earliness))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"V6Fhz4hsiui6","executionInfo":{"status":"error","timestamp":1650981574100,"user_tz":-60,"elapsed":121427,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"5e8c4f9a-49b2-44fb-eed4-3494af98bb4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Alpha: 0.0\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.05\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.1\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.15\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-498-89cc9171be6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# create nN predictions excluding the current test sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0msample_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_predictions_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# create multipliers for every classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-66-ab459af536aa>\u001b[0m in \u001b[0;36mgenerate_predictions_table\u001b[0;34m(positives, negatives, timestamps)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_sample_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-100-5619c2d01103>\u001b[0m in \u001b[0;36mget_training_data_knn\u001b[0;34m(positive_samples, negative_samples, timestamp, test_samples)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m## truncate sample to length t = timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpos_subsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Average Output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## append subsample of length t to training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m             \u001b[0;31m# shortcut if the key is in columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3424\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3425\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4538\u001b[0m         \"\"\"\n\u001b[1;32m   4539\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = acc\n","y = ear\n","axes.set_xlabel(\"Accuracy\")\n","axes.set_ylabel(\"Earliness\")\n","axes.plot(x,y, '-o')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"R0a7Bbrabp6R","executionInfo":{"status":"ok","timestamp":1650975154308,"user_tz":-60,"elapsed":485,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"ecaa763d-1bfa-4fdc-9a86-c2e35604c565"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f4beae35050>]"]},"metadata":{},"execution_count":347},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAmEAAAE9CAYAAABDUbVaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxUd73/8dc3k42EEAg7CSFkoexrSvcCkSq1C63doLZatVJtqffqT+/qdqv33qr36m0TaEGK2lZbbbWK2tqrHQKUpRC6Q5dMEgIJOyEhELJNPr8/MvWmyBIgkzOTvJ+PB4/MOec7M284Ocmbc86c48wMEREREeleMV4HEBEREemNVMJEREREPKASJiIiIuIBlTARERERD6iEiYiIiHhAJUxERETEA7FeBzhbgwYNsqysLK9jiIiIiJzR1q1bD5rZ4JMti7oSlpWVRUlJidcxRERERM7IOVd5qmU6HCkiIiLiAZUwEREREQ+ohImIiIh4QCVMRERExAMqYSIiIiIeUAkTERER8YBKmIiIiIgHou46YSIiIiLnI+uf/vg383Y8eE2359CeMBEREek1TlbATjc/nFTCRERERDygEiYiIiK9QlNr0OsIH6JzwkRERKRHO94c5KnNO1m2tszrKB+iEiYiIiI90rGmVp7cVMmP15Vz8GgzF41OY9+RJq9j/ZVKmIiIiPQoRxpb+Nn6HTy2voLahhauyBvE/QV5zBydBkTOpyNVwkRERKRHOHysmZXrK/jphh3UN7bykbFDWFyQy7TMAR8a50XhOhmVMBEREYlqB4828eN15Ty5sZJjzUHmTRjG4oJcJqaneh3ttFTCREREJCrtrWtk2doyntq8k+bWNq6dPILFBbmMGZridbROUQkTERGRqFJ1uIFH15Txqy1VBM24cVo6987OIXtwX6+jnRWVMBEREYkKOw4eY2lxgN+8Wo1zcPOMkdw7O4eRaUleRzsnKmEiIiIS0QL761myuozfvV5NnC+GOy4exT2zshme2sfraOdFJUxEREQi0jt7jlDkD/D823tIjPVx9xXZ3H3FaIakJHodrUuohImIiEhEebOqlkJ/gD9v30ffhFjunZ3D5y7PJi053utoXUolTERERCJCyY4aCv0B1rx/gNQ+cXx57hjuujSL1KQ4r6OFhUqYiIiIeMbM2Fh+iMKXAmwsP0Racjz/MO8C7rx4FCmJPbN8fSCsJcw5Nw94CPABK8zswROW/wiYE5pMAoaYWf9wZhIRERHvmRlr3j9AkT9ASeVhhqQk8PVrxnH7RZkkxfeOfURh+1s653zAEuAqoArY4pxbZWbbPxhjZl/uMP5+YFq48oiIiIj3zIy/vLOfQn8pb1bVMSI1ke/Mn8At+SNJjPN5Ha9bhbNqzgQCZlYO4Jx7GpgPbD/F+IXAt8KYR0RERDzS1ma88PZeCv2lvLu3nsy0JB78xCQ+MT2D+NgYr+N5IpwlLB3Y1WG6CrjoZAOdc6OA0YA/jHlERESkm7UG2/j9m7tZsrqMwP6jZA9O5oe3TuH6KSOI9fXO8vWBSDnougB41syCJ1vonFsELALIzMzszlwiIiJyDppb2/jta9UsLQ6w41ADY4elUHT7NK6eOBxfjPM6XkQIZwmrBkZ2mM4IzTuZBcB9p3ohM1sOLAfIz8+3rgooIiIiXaupNcivSqp4tLiM6trjTEzvx7I7Z3DVuKHEqHx9SDhL2BYgzzk3mvbytQC4/cRBzrmxwABgYxiziIiISBgdbw7y1OadLFtbxr4jTUzP7M93b5zI7DGDcU7l62TCVsLMrNU5txh4kfZLVKw0s23OuQeAEjNbFRq6AHjazLSHS0REJMocbWrlyU2VrFhXzsGjzVw0Oo0f3jqVS3MGqnydQVjPCTOz54HnT5j3zROmvx3ODCIiItL16o638LMNO1i5voLahhauyBvE/QV5zByd5nW0qBEpJ+aLiIhIFDh8rJmV6yv46fod1De1MnfcEBYX5DF1pK61frZUwkREROSMDtQ3sWJdOU9sqqShOcjVE4exuCCXCSNSvY4WtVTCRERE5JT21jWybG0ZT23eSXNrG9dNGcF9c3IZMzTF62hRTyVMRERE/kbV4QYeKS7jmZIq2sy4cVo6987JZfSgZK+j9RgqYSIiIvJXOw4eY8nqAM+9Vk2Mc9ycn8EXZ+UwMi3J62g9jkqYiIiIENhfT5E/wKo3dhPni+GOi0dxz6xshqf28Tpaj6USJiIi0ott332EotWlvPD2XvrE+bj7imzuvmI0Q1ISvY7W46mEiYiI9EJv7Kql0B/gL+/sIyUhlvtm5/LZy0eTlhzvdbReQyVMRESkFynZUcPD/gBr3z9Aap84vnLVGD59aRapfeK8jtbrqISJiIj0cGbGxrJDPOwvZVN5DQOT4/nHeWO585JR9E1QFfCK/uVFRER6KDOj+P0DFPkDbK08zJCUBL5x7XgWzhxJUrwqgNe0BkRERHqYtjbjL+/so2h1gDer6kjv34fv3DCRW2ZkkBjn8zqehKiEiYiI9BDBNuOFt/dQ5A/w7t56MtOS+N5Nk7hxWgbxsTFex5MTqISJiIhEudZgG79/czdF/gBlB46RMziZH902hesmjyDWp/IVqVTCREREolRzaxvPvVbF0uIyKg81MHZYCkW3T+PqicPxxTiv48kZqISJiIhEmcaWIM9sreLR4jKqa48zKT2V5XfOYO64ocSofEUNlTAREZEocbw5yC8272T52jL2HWliemZ/vnvjRGaPGYxzKl/RRiVMREQkwh1tauWJjZWsWFfOoWPNXJydxo9uncolOQNVvqKYSpiIiEiEqjvews827GDl+gpqG1q4csxg7i/I5cKsNK+jSRdQCRMREYkwNceaWflyBT/bsIP6plbmjhvK4oJcpo7s73U06UIqYSIiIhFif30jK9ZV8OSmSo63BLl64jDum5PLhBGpXkeTMFAJExER8djeukYeXVPGU5t30hJs4/opI7hvTi55Q1O8jiZhpBImIiLikV01DTyypoxnS6poM+MT09P54uxcRg9K9jqadAOVMBERkW5WcfAYS1cHeO61amKc45b8DL4wK4eRaUleR5NupBImIiLSTUr31VO0OsDv39hNnC+GOy8ZxaIrsxme2sfraOKBsJYw59w84CHAB6wwswdPMuZW4NuAAW+Y2e3hzCQiItLdtu2uo8gf4E/b9tInzsfnr8jm7iuyGZyS4HU08VDYSphzzgcsAa4CqoAtzrlVZra9w5g84J+By8zssHNuSLjyiIiIdLfXd9VS5C/lL+/sJyUhlsVzcvnMZaNJS473OppEgHDuCZsJBMysHMA59zQwH9jeYczngSVmdhjAzPaHMY+IiEi32LKjhodfKmVd6UH6J8XxlavG8OlLs0jtE+d1NIkg4Sxh6cCuDtNVwEUnjBkD4JxbT/shy2+b2Z/CmElERCQszIwNZYd4+KVSXqmoYVDfeP7p6rHccfEo+iboFGz5W15/V8QCecBsIANY65ybZGa1HQc55xYBiwAyMzO7O6OIiMgpmRnF7x+g8KVSXt1Zy9B+CXzz2vEsnJlJn3if1/EkgoWzhFUDIztMZ4TmdVQFvGJmLUCFc+592kvZlo6DzGw5sBwgPz/fwpZYRESkk9rajD+/s48if4C3qutI79+H79wwkVtmZJAYp/IlZxbOErYFyHPOjaa9fC0ATvzk42+BhcBPnHODaD88WR7GTCIiIucl2Ga88PYeivwB3t1bz6iBSXz/psncMC2d+NgYr+NJFAlbCTOzVufcYuBF2s/3Wmlm25xzDwAlZrYqtOyjzrntQBD4mpkdClcmERGRc9UabGPVG7tZsjpA2YFj5AxO5ke3TeG6ySOI9al8ydlzZtF1dC8/P99KSkq8jiEiIr1Ec2sbv3m1iqXFZeysaWDssBTuL8hj3sRh+GKc1/EkwjnntppZ/smWeX1ivoiISERqbAnyTMkuHl1TTnXtcSZnpPKNa/P5yNghxKh8SRdQCRMREengeHOQn79SyfK15eyvb2LGqAH8+40TmTVmMM6pfEnXUQkTEREBjja18vjGHTy2roJDx5q5JHsg/7NgKpdkD1T5krBQCRMRkV6t7ngLP12/g5XrK6g73sKsMYO5vyCX/Kw0r6NJD6cSJiIivVLNsWYee7mcxzdUUt/UylXjh7J4Ti5TRvb3Opr0EiphIiLSq+yvb2TFugqe3FTJ8ZYgH584nPvm5DJ+RD+vo0kvoxImIiK9wp664yxbU85Tm3fSEmxj/tR07p2dQ97QFK+jSS+lEiYiIj3arpoGlhaX8ezWXZjBJ6anc+/sXLIGJXsdTXo5lTAREemRyg8cZWlxGc+9Vo3POW67cCT3XJnDyLQkr6OJACphIiLSw7y/r54if4A/vLmbOF8Mn7pkFPdcmcOw1ESvo4l8iEqYiIj0CG9X11HkD/CnbXtJivfx+SuzufvybAanJHgdTeSkVMJERCSqvb6rlsKXSnnp3f2kJMbypYJcPnPZaAYkx3sdTeS0VMJERCQqba6oodBfyrrSg/RPiuP/XTWGT12aRWqfOK+jiXSKSpiIiEQNM2ND2SEefqmUVypqGNQ3nn++eix3XDyK5AT9SpPoou9YERGJeGZG8XsHeNhfyms7axnaL4FvXjuehTMz6RPv8zqeyDlRCRMRkYjV1mb87/Z9FK0u5e3qI6T378N3b5jILfkZJMSqfEl0UwkTEZGIE2wznn9rD0X+AO/tqydrYBLfv3kyN05LJ84X43U8kS6hEiYiIhGjNdjG717fzZLiAOUHjpE7pC//c9tUrp08nFiVL+lhVMJERMRzza1t/PrVKh4pLmNnTQPjhvdj6SenM2/CMGJinNfxRMJCJUxERDzT2BLkVyW7eLS4jN11jUzOSOUb1+Yzd9wQnFP5kp5NJUxERLpdQ3Mrv3hlJ8vWlnOgvon8UQP4z5smc2XeIJUv6TVUwkREpNvUN7bwxKZKVqyroOZYM5fmDOThBdO4ODtN5Ut6HZUwEREJu7qGFn6yoYKfrN9B3fEWZl8wmPsLcpkxKs3raCKeUQkTEZGwqTnWzIp15Ty+sZKjTa1cNX4o9xfkMjmjv9fRRDynEiYiIl1uf30jP15bzpObdtLYGuTjk4azeE4u44b38zqaSMRQCRMRkS6zu/Y4y9aU8dSWXbQG25g/NZ375uSQOyTF62giESesJcw5Nw94CPABK8zswROW3wX8AKgOzSoysxXhzCQiIl1vV00DS4sDPLu1CjO4aXoGX5ydQ9agZK+jiUSssJUw55wPWAJcBVQBW5xzq8xs+wlDf2lmi8OVQ0REwqf8wFGWrC7jt69X43OO2y4cyRdm5ZAxIMnraCIRL5x7wmYCATMrB3DOPQ3MB04sYSIiEmXe21tP0eoAf3xzN/GxMXz6kizumZXN0H6JXkcTiRrhLGHpwK4O01XARScZd5Nz7krgfeDLZrbrxAHOuUXAIoDMzMwwRBURkc54u7qOIn+AP23bS3K8j0VX5nD3FaMZ1DfB62giUcfrE/N/DzxlZk3OuXuAnwEFJw4ys+XAcoD8/Hzr3ogiIvLazsMU+gP4391PSmIsXyrI5TOXjWZAcrzX0USiVjhLWDUwssN0Bv93Aj4AZnaow+QK4PthzCMiImfplfJDFK0OsK70IAOS4vjqR8fwqUuz6JcY53U0kagXzhK2Bchzzo2mvXwtAG7vOMA5N9zM9oQmrwfeCWMeERHpBDNjfeAQD/tL2VxRw6C+CfzLx8fyyYtGkZzg9QEUkZ4jbFuTmbU65xYDL9J+iYqVZrbNOfcAUGJmq4AvOeeuB1qBGuCucOUREZHTMzNWv7efh18K8PquWob1S+Rb141n4cxMEuN8XscT6XGcWXSdYpWfn28lJSVexxAR6THa2oz/3b6XQn+AbbuPkN6/D/fOyeHmGRkkxKp8iZwP59xWM8s/2TLtVxYR6aWCbcYf39rDEn+A9/bVkzUwie/fPJkbp6UT54vxOp5Ij6cSJiLSy7QE2/jd67tZujpA+cFj5A3py0MLpnLNpOHEqnyJdBuVMBGRXqK5tY1fv1rF0uIAu2qOM254P5Z+cjrzJgwjJsZ5HU+k11EJExHp4Rpbgvxyyy4eXVPGnrpGpmSk8q1rJ/CRcUNwTuVLxCsqYSIiPVRDcys/37ST5evKOVDfxIVZA/jeTZO5Im+QypdIBFAJExHpYeobW3h8YyWPvVxBzbFmLssdyMMLpnFxdprKl0gEUQkTEekh6hpaWLm+gp+sr+BIYyuzLxjM/QV5zBg1wOtoInISKmEiIlHu0NEmVrxcwRMbKzna1MpHxw/l/oI8JmWkeh1NRE5DJUxEJErtP9LI8rXl/PyVnTS2Bvn4pOEsnpPLuOH9vI4mIp2gEiYiEmV21x7n0TVlPL1lF8E2Y/6UEdw7J5fcIX29jiYiZ0ElTEQkSuw81MAjawI8u7UKM7h5RgZfnJ3DqIHJXkcTkXOgEiYiEuHKDhxlyeoAv3t9N74Yx4ILM/nC7BzS+/fxOpqInIdOlTDn3C3An8ys3jn3dWA68F0zezWs6UREerH39tZTtDrAH97cTUJsDHddmsWiK7MZ2i/R62gi0gU6uyfsG2b2jHPucmAu8APgEeCisCUTEeml3q6uo9Bfyovb9pEc7+MLs3L43OWjGdQ3wetoItKFOlvCgqGv1wDLzeyPzrnvhimTiEiv9OrOwxT5A/jf3U9KYixf+kgen70si/5J8V5HE5Ew6GwJq3bOLQOuAr7nnEsAYsIXS0Sk99hUfogif4CXAwcZkBTH1z52AXdeMop+iXFeRxORMOpsCbsVmAf8l5nVOueGA18LXywRkZ7NzHg5cJDClwJs3lHDoL4J/MvHx/LJi0aRnKDPTIn0Bp3d0ocDfzSzJufcbGAy8HjYUomI9FBmhv/d/RT6A7y+q5Zh/RL59nXjWTAzk8Q4n9fxRKQbdbaE/RrId87lAsuB3wG/AD4ermAiIj1JW5vxv9v3UugPsG33ETIG9OE/bpzETTPSSYhV+RLpjTpbwtrMrNU59wmg0MwKnXOvhTOYiEhPEGwz/vDmbpasDvD+vqOMHpTMD26ezA3T0onz6dRakd6ssyWsxTm3EPgUcF1ons4YFRE5hZZgG799rZqlxWVUHDxG3pC+PLRgKtdOHoEvxnkdT0QiQGdL2GeALwD/bmYVzrnRwBPhiyUiEp2aWoP8ems1j6wJsKvmOOOH9+ORT07nYxOGEaPyJSIddKqEmdl259w/Apmh6Qrge+EMJiISTRpbgjy9eSfL1pazp66RKSP78+3rJlAwdgjOqXyJyN/q7G2LrgP+C4gHRjvnpgIPmNn14QwnIhLpjjW18otXdrJ8XTkH6puYmZXG92+ezOW5g1S+ROS0Ons48tvATKAYwMxed85lhymTiEjEq29s4fGNlaxYV87hhhYuyx1I4cJpXJw90OtoIhIlOn1ivpnVnfC/urYzPck5Nw94CPABK8zswVOMuwl4FrjQzEo6mUlEpNvVNjSzcv0Ofrq+giONrcy5YDCLC/KYMWqA19FEJMp0toRtc87dDvicc3nAl4ANp3uCc84HLKH9VkdVwBbn3Coz237CuBTg74BXzja8iEh3OXi0icderuCJjZUcbWrlYxOGsnhOHpMyUr2OJiJRqrMl7H7gX4Em4CngReA7Z3jOTCBgZuUAzrmngfnA9hPGfYf2k/x1GyQRiTj7jzSybG05P3+lkqbWNq6ZNJzFBbmMHdbP62giEuU6++nIBtpL2L+exWunA7s6TFcBF3Uc4JybDow0sz8651TCRCRiVNceZ9maMp7esotgmzF/6gjum5NLzuC+XkcTkR6is5+OHAN8Fcjq+BwzKzjXN3bOxQA/BO7qxNhFwCKAzMzMc31LEZEz2nmogaXFAX79ahUAN8/I4IuzcskcmORxMhHpaTp7OPIZ4FFgBRDs5HOqgZEdpjNC8z6QAkwEikMn/A8DVjnnrj/x5HwzW077PSvJz8+3Tr6/iEinBfYfZWlxgN+9vhtfjGPhzEzumZVDev8+XkcTkR6qsyWs1cweOcvX3gLkha6uXw0sAG7/YKGZ1QGDPph2zhUDX9WnI0WkO7279whF/gB/fGsPibE+PnNpFouuzGZIv0Svo4lID9fZEvZ759y9wHO0n5wPgJnVnOoJoRt+L6b9JH4fsNLMtjnnHgBKzGzVeeQWETkvb1XVUegv5X+37yM53scXZuVw9+WjGdg3wetoItJLOLMzH91zzlWcZLaZWbdfsDU/P99KSrSzTETOzdbKwxT5S1n93gH6JcbymctG85nLsuifFO91NBHpgZxzW80s/2TLOvvpyNFdG0lEpHttKj9Eob+U9YFDpCXH87WPXcCdl4yiX2Kc19FEpJc6bQlzzhWYmd8594mTLTez34QnlojI+TMz1pUepMgfYPOOGgb1TeBfPz6OT16cSVJ8Z8/GEBEJjzP9FJoF+IHrTrLMAJUwEYk4Zob/3f087A/wxq5ahqcm8m/XT+C2C0eSGOfzOp6ICHCGEmZm3wp9/Uz3xBEROXdtbcaL2/ZS6A+wfc8RMgb04T9unMRNM9JJiFX5EpHIcqbDkV853XIz+2HXxhEROXvBNuMPb+6myB+gdP9Rsgcl81+3TGH+1BHE+WK8jiciclJnOhyZ0i0pRETOQUuwjd++Vs3S4jIqDh5jzNC+PLxwGtdMGo4vxnkdT0TktM50OPLfnHM+4Etm9qNuyiQiclpNrUGe3VrFI8VlVB0+zoQR/Xj0jul8dPwwYlS+RCRKnPHjQWYWdM4tBFTCRMRTjS1Bntq8k2Vrytl7pJGpI/vzwPwJzLlgCKHbn4mIRI3OfkZ7vXOuCPglcOyDmWb2alhSiYh0cKyplZ+/UsnytRUcPNrEzKw0fnDLZC7PHaTyJSJRq7MlbGro6wMd5hlQ0LVxRET+z5HGFh7fsIPHXq7gcEMLl+cO4v6CaVyUPdDraCIi562zV8yfE+4gIiIfqG1oZuX6Hfx0fQVHGlspGDuExQW5TM8c4HU0EZEu0+lLRjvnrgEmAIkfzDOzB079DBGRs3PwaBMr1lXwxMYdHGsO8rEJQ7m/II+J6aleRxMR6XKdKmHOuUeBJGAOsAK4Gdgcxlwi0ovsO9LI8rXl/PyVSppa27h28ggWz8nlgmG6So6I9Fyd3RN2qZlNds69GbpsxX8DL4QzmIj0fNW1x3m0uIxfluwi2GbcMDWde+fkkDO4r9fRRETCrrMl7Hjoa4NzbgRwCBgenkgi0tNVHjrG0tVl/PrVKpyDm2dk8MVZuWQOTPI6mohIt+lsCfuDc64/8APgVdo/GbkibKlEpEcK7D/K0tUBfvfGbnwxjk9elMk9s3IY0b+P19FERLpdZz8d+Z3Qw1875/4AJJpZXfhiiUhP8u7eIxT6Azz/1h4SY3189rIsPn9FNkP6JZ75ySIiPdSZbuD9D2b2/dDjW8zsGTNrApqcc/9hZv/SLSlFJCq9VVXHw/5S/rx9H30TYvnirBw+d/loBvZN8DqaiIjnzrQnbAHw/dDjfwae6bBsHqASJiJ/Y2vlYQr9pRS/d4B+ibH8/dw87ro0i/5J8V5HExGJGGcqYe4Uj082LSK9mJmxqbyGQn8pG8oOkZYcz9c+dgGfumQUKYlxXscTEYk4ZyphdorHJ5sWkV7IzFhbepAifylbdhxmcEoCX79mHLdflElSfKevBy0i0uuc6SfkFOfcEdr3evUJPSY0rTNqRXoxM+Old/ZTuDrAG7tqGZGayAPzJ3Br/kgS43xexxMRiXinLWFmpp+kIvIhbW3Gn7btpdAf4J09RxiZ1of//MQkbpqeQXxsjNfxRESiho4ViEintAbb+ONbeyjyByjdf5TsQcn89y1TuH7qCOJ8Kl8iImdLJUxETqsl2MZzr1WzdHWAHYcaGDO0Lw8vnMY1k4bji9Hnc0REzlVYS5hzbh7wEOADVpjZgycs/wJwHxAEjgKLzGx7ODOJSOc0tQZ5pqSKR4rLqK49zoQR/Xj0jhl8dPxQYlS+RETOW9hKmHPOBywBrgKqgC3OuVUnlKxfmNmjofHXAz+k/fpjIuKR481Bnt6yk2Vrytl7pJGpI/vznRsmMOeCITin8iUi0lXCuSdsJhAws3IA59zTwHzgryXMzI50GJ+MLnsh4pljTa08uamSH68r5+DRZmaOTuO/bpnCZbkDVb5ERMIgnCUsHdjVYboKuOjEQc65+4CvAPFAQRjziMhJHGls4fENO3js5QoON7RwRd4gFs/J5aLsgV5HExHp0Tw/Md/MlgBLnHO3A18HPn3iGOfcImARQGZmZvcGFOmhahuaWflyBT/ZsIP6xlY+MnYIiwtymZY5wOtoIiK9QjhLWDUwssN0RmjeqTwNPHKyBWa2HFgOkJ+fr0OWIufh4NEmfryunCc3VnKsOci8CcNYXJDLxPRUr6OJiPQq4SxhW4A859xo2svXAuD2jgOcc3lmVhqavAYoRUTCYt+RRpatKecXmytpbm3j2skjWFyQy5ihKV5HExHplcJWwsys1Tm3GHiR9ktUrDSzbc65B4ASM1sFLHbOzQVagMOc5FCkiJyfqsMNPLqmjF9tqSJoxo3T0rl3dg7Zg/t6HU1EpFcL6zlhZvY88PwJ877Z4fHfhfP9RXqzHQePsbQ4wG9ercY5uHnGSO6dncPItCSvo4mICBFwYr6IdK3A/nqWrC7jd69XE+eL4Y6LR7HoymxG9O/jdTQREelAJUykh3hnzxGK/AGef3sPibE+Pnf5aD5/ZTZDUhK9jiYiIiehEiYS5d6sqqXQH+DP2/fRNyGWe2fn8NnLRjOwb4LX0URE5DRUwkSi1NbKGh5+KcCa9w+Q2ieOL88dw12XZpGaFOd1NBER6QSVMJEoYmZsLD9E4UsBNpYfIi05nn+YdwF3XjyKlESVLxGRaKISJhIFzIy1pQcpfKmUksrDDElJ4OvXjOP2izJJitdmLCISjfTTWySCmRl/eWc/Rf5S3qiqY0RqIg/Mn8Ct+SNJjPN5HU9ERM6DSphIBGprM154ey9FqwO8s+cImWlJPPiJSXxiegbxsTFexxMRkS6gEiYSQVqDbfzhzT0UrQ4Q2JUp11UAABRLSURBVH+U7MHJ/PctU5g/dQSxPpUvEZGeRCVMJAK0BNt47tVqlhYH2HGogQuGplC4cBofnzQcX4zzOp6IiISBSpiIh5pagzxTUsUjxWVU1x5nYno/lt05g6vGDSVG5UtEpEdTCRPxwPHmIE9t3smytWXsO9LEtMz+fPeGicy+YDDOqXyJiPQGKmEi3ehoUytPbqpkxbpyDh5t5qLRafzw1qlcmjNQ5UtEpJdRCRPpBkcaW/jZ+h08tr6C2oYWrsgbxP0FecwcneZ1NBER8YhKmEgYHT7WzMr1Ffx0ww7qG1uZO24I983JZVrmAK+jiYiIx1TCRMLgQH0TK9aV88SmShqag1w9cRiLC3KZMCLV62giIhIhVMJEutDeukaWrS3jqc07aW5t47opI7hvTi5jhqZ4HU1ERCKMSphIF6g63MAjxWU8U1JF0Iwbp6Vz7+wcsgf39TqaiIhEKJUwkfOw4+AxlhYH+M2r1TgHt+SP5IuzchiZluR1NBERiXAqYSLnILC/niJ/gFVv7CbOF8MdF4/inlnZDE/t43U0ERGJEiphImdh++4jFK0u5YW399InzsfdV2Rz9xWjGZKS6HU0ERGJMiphIp3wxq5aCv0B/vLOPlISYrlvdi6fvXw0acnxXkcTEZEopRImcholO2p42B9g7fsHSO0Tx5fnjuGuy7JI7RPndTQREYlyKmEiJzAzNpYdotAfYGP5IQYmx/OP88Zy5yWj6JugTUZERLqGfqOIhJgZa94/QKE/wNbKwwxJSeDr14zj9osySYrXpiIiIl0rrL9ZnHPzgIcAH7DCzB48YflXgLuBVuAA8FkzqwxnJpETmRl/3r6PotUB3qyqY0RqIt+ZP4Fb8keSGOfzOp6IiPRQYSthzjkfsAS4CqgCtjjnVpnZ9g7DXgPyzazBOfdF4PvAbeHKJNJRsM3409t7KfSX8u7eejLTkvjeTZO4cVoG8bExXscTEZEeLpx7wmYCATMrB3DOPQ3MB/5awsxsdYfxm4A7wphHBIDWYBu/f3M3Rf4AZQeOkT04mR/eOoXrp4wg1qfyJSIi3SOcJSwd2NVhugq46DTjPwe8EMY80ss1t7bx3GtVLC0uo/JQA2OHpVB0+zSunjgcX4zzOp6IiPQyEXG2sXPuDiAfmHWK5YuARQCZmZndmEx6gsaWIM9sreLR4jKqa48zKT2VZXfO4KpxQ4lR+RIREY+Es4RVAyM7TGeE5n2Ic24u8K/ALDNrOtkLmdlyYDlAfn6+dX1U6YmONwf5xeadLF9bxr4jTUzP7M93b5zI7DGDcU7lS0REvBXOErYFyHPOjaa9fC0Abu84wDk3DVgGzDOz/WHMIr3I0aZWntxUyYp15Rw82szF2Wn86NapXJIzUOVLREQiRthKmJm1OucWAy/SfomKlWa2zTn3AFBiZquAHwB9gWdCvxx3mtn14cokPVvd8RZ+tmEHK9dXUNvQwpVjBnN/QS4XZqV5HU1ERORvhPWcMDN7Hnj+hHnf7PB4bjjfX3qHmmPNrHy5gp9t2EF9Uytzxw1hcUEeU0f29zqaiIjIKUXEifki5+JAfRMr1pXzxKZKjrcEuXriMO6bk8uEEaleRxMRETkjlTCJOnvrGnl0TRlPbd5JS7CN66aMYPGcXPKGpngdTUREpNNUwiRq7Kpp4JE1ZTxbUkWbGTdOS+feObmMHpTsdTQREZGzphImEa/i4DGWrg7w3GvVxDjHLfkZfGFWDiPTkryOJiIics5UwiRile6rp2h1gN+/sZs4Xwx3XDyKe2ZlMzy1j9fRREREzptKmEScbbvrWLI6wAtv76VPnI/PX5HN3VdkMzglwetoIiIiXUYlTCLGG7tqKfSX8pd39pOSEMt9s3P57OWjSUuO9zqaiIhIl1MJE89t2VFDoT/A2vcP0D8pjq9cNYZPX5pFap84r6OJiIiEjUqYeMLM2Fh2iIf9pWwqr2Fgcjz/dPVY7rh4FH0T9G0pIiI9n37bSbcyM4rfP0DhS6W8urOWISkJfOPa8dw+M5M+8T6v44mIiHQblTDpFm1txp/f2UeRP8Bb1XWk9+/Dd26YyC0zMkiMU/kSEZHeRyVMwirYZrzw9h6K/AHe3VvPqIFJfO+mSdw4LYP42Biv44mIiHhGJUzCojXYxqo3drNkdYCyA8fIGZzMj26bwnWTRxDrU/kSERFRCZMu1dzaxnOvVbG0uIzKQw2MHZbCktunM2/iMHwxzut4IiIiEUMlTLpEY0uQZ0p28eiacqprjzM5I5Xld85g7rihxKh8iYiI/A2VMDkvx5uD/PyVSpavLWd/fRMzRg3g32+cyKwxg3FO5UtERORUVMLknBxtauWJjZWsWFfOoWPNXJI9kP+5bSqX5AxU+RIREekElTA5K3XHW/jp+h2sXF9B3fEWrhwzmC8V5JKfleZ1NBERkaiiEiadUnOsmcdeLufxDZXUN7Uyd9xQ7i/IZcrI/l5HExERiUoqYXJa++sbWbGugic3VXK8JcjVE4exeE4e40f08zqaiIhIVFMJk5PaU3ecZWvKeWrzTlqCbVw/ZQT3zcklb2iK19FERER6BJUw+ZBdNQ08sqaMZ0uqaDPjE9PTuXd2LlmDkr2OJiIi0qOohAkAFQePsWR1gOdeq8bnHLfkZ/CFWTmMTEvyOpqIiEiPpBLWy72/r54lqwP8/o3dxPli+NQlo7jnyhyGpSZ6HU1ERKRHUwnrpbbtrqPIH+CFt/eSFO/j81dmc/fl2QxOSfA6moiISK8Q1hLmnJsHPAT4gBVm9uAJy68E/geYDCwws2fDmUfg9V21FPlL+cs7+0lJiOX+glw+e9loBiTHex1NRESkVwlbCXPO+YAlwFVAFbDFObfKzLZ3GLYTuAv4arhySLvNFTUU+ktZV3qQ/klx/L+rxvCpS7NI7RPndTQREZFeKZx7wmYCATMrB3DOPQ3MB/5awsxsR2hZWxhz9FpmxoayQzz8UimvVNQwqG88/3T1WO64eBR9E3QkWkRExEvh/E2cDuzqMF0FXBTG95MQM6P4vQMU+kt5dWctQ/sl8M1rx7NwZiZ94n1exxMRERGi5MR859wiYBFAZmamx2kiV1ub8ed39lHkD/BWdR3p/fvw3RsmcvOMDBLjVL5EREQiSThLWDUwssN0RmjeWTOz5cBygPz8fDv/aD1LsM14/q09LFkd4N299YwamMT3b5rMjdPTifPFeB1PRERETiKcJWwLkOecG017+VoA3B7G9+t1WoNt/O713SwpDlB+4Bi5Q/ryP7dN5drJw4lV+RIREYloYSthZtbqnFsMvEj7JSpWmtk259wDQImZrXLOXQg8BwwArnPO/ZuZTQhXpp6iubWN37xaxdLiMnbWNDBueD+WfnI68yYMIybGeR1PREREOiGs54SZ2fPA8yfM+2aHx1toP0wpndDYEuRXJbt4tLiM3XWNTM5I5RvX5jN33BCcU/kSERGJJlFxYn5v19Dcyi9e2cmyteUcqG8if9QA/vOmyVyZN0jlS0REJEqphEWw+sYWnthUyWPrKjh0rJlLsgfy0IKpXJI9UOVLREQkyqmERaC6hhZ+sqGCn6zfQd3xFmaNGcz9BbnkZ6V5HU1ERES6iEpYBKk51sxjL5fz+IZK6ptauWr8UBbPyWXKyP5eRxMREZEuphIWAfbXN/LjteU8uWknja1BPj5xOPfNyWX8iH5eRxMREZEwUQnz0O7a4yxfW85Tm3fSEmxj/tR07puTQ+6QFK+jiYiISJiphHlgV00DS4vLeHbrLszgpukZfHF2DlmDkr2OJiIiIt1EJawblR84ytLiMp57rRqfc9x24Ui+MCuHjAFJXkcTERGRbqYS1g3e21vPktUB/vDmbuJjY/j0JVncMyubof0SvY4mIiIiHlEJC6O3q+so8gf407a9JMf7+PyV2dx9eTaDUxK8jiYiIiIeUwkLg9d2HqbIH+Cld/eTkhjLlwpy+cxloxmQHO91NBEREYkQKmFdaHNFDYX+UtaVHqR/Uhxf/egY7rwki9Q+cV5HExERkQijEnaezIz1gUM87C9lc0UNg/rG889Xj+WOi0eRnKB/XhERETk5tYRzZGasfm8/hf4Ar+2sZVi/RL513XgWzswkMc7ndTwRERGJcCphZ6mtzfjf7fsoWl3K29VHSO/fh3+/cSI3z8ggIVblS0RERDpHJayTgm3GH9/awxJ/gPf21ZM1MInv3zyZG6elE+eL8TqeiIiIRBmVsA4mf+tPHGkK/nW6X4KPV7/5UX73+m6WFAcoP3CMvCF9eWjBVK6ZNJxYlS8RERE5RyphIScWMIAjTUFy//UFAMYN78fST05n3oRhxMQ4LyKKiIhID6ISFnJiAetoxafy+ci4ITin8iUiIiJdQyWsE+aOH+p1BBEREelhdFKTiIiIiAdUwkL6JZz88hKnmi8iIiJyPlTCQt78t3l/U7j6Jfh489/meZRIREREejKdE9aBCpeIiIh0F+0JExEREfGASpiIiIiIB8Jawpxz85xz7znnAs65fzrJ8gTn3C9Dy19xzmWFM4+IiIhIpAhbCXPO+YAlwNXAeGChc278CcM+Bxw2s1zgR8D3wpVHREREJJKEc0/YTCBgZuVm1gw8Dcw/Ycx84Gehx88CH3G6LL2IiIj0AuEsYenArg7TVaF5Jx1jZq1AHTDwxBdyzi1yzpU450oOHDgQprgiIiIi3ScqTsw3s+Vmlm9m+YMHD/Y6joiIiMh5C2cJqwZGdpjOCM076RjnXCyQChwKYyYRERGRiBDOi7VuAfKcc6NpL1sLgNtPGLMK+DSwEbgZ8JuZne5Ft27detA5VxmGvD3BIOCg1yEkLLRuey6t255L67bnOpt1O+pUC8JWwsys1Tm3GHgR8AErzWybc+4BoMTMVgGPAU845wJADe1F7Uyvq+ORp+CcKzGzfK9zSNfTuu25tG57Lq3bnqur1m1Yb1tkZs8Dz58w75sdHjcCt4Qzg4iIiEgkiooT80VERER6GpWwnmW51wEkbLRuey6t255L67bn6pJ1685wHryIiIiIhIH2hImIiIh4QCUsSnTiZuh3OecOOOdeD/25u8OyTzvnSkN/Pt29yeVMznPdBjvMX9W9yeVMzrRuQ2Nudc5td85tc879osN8bbcR7DzXrbbbCNaJn8k/6rD+3nfO1XZYdlbbrQ5HRoHQzdDfB66i/fZPW4CFZra9w5i7gHwzW3zCc9OAEiAfMGArMMPMDndPejmd81m3oWVHzaxvN8WVs9DJdZsH/AooMLPDzrkhZrZf221kO591G1qm7TZCdWbdnjD+fmCamX32XLZb7QmLDp25GfqpfAz4s5nVhL4R/gzMC1NOOXvns24lsnVm3X4eWPLBD+kPfkmj7TbSnc+6lch2tj+TFwJPhR6f9XarEhYdOnMzdICbnHNvOueedc59cMuozj5XvHE+6xYgMXRz+03OuRvCmlTOVmfW7RhgjHNufWgdzjuL54p3zmfdgrbbSNbpbc85NwoYDfjP9rkfCOvFWqVb/R54ysyanHP3AD8DCjzOJF3jdOt2lJlVO+eyAb9z7i0zK/MsqZytWCAPmE37/XXXOucmeZpIuspJ162Z1aLttqdYADxrZsFzfQHtCYsOZ7wZupkdMrOm0OQKYEZnnyueOp91i5lVh76WA8XAtHCGlbPSmW2vClhlZi1mVkH7uSh5nXyueOd81q2228h2NtveAv7vUOTZPhdQCYsWf70ZunMunvYV/6FP1DjnhneYvB54J/T4ReCjzrkBzrkBwEdD8yQynPO6Da3ThNDjQcBlwElPHhVPnHHdAr+lfU/JB+twDFCOtttId87rVtttxOvMusU5NxYYAGzsMPust1sdjowCnbwZ+pecc9cDrbTfDP2u0HNrnHPfof0bC+ABM6vp9r+EnNT5rFtgHLDMOddG+3+oHjzVJ3ik+3Vy3X7wQ3s7EAS+ZmaHALTdRq7zWbfOuUvRdhuxOrluob2cPW0dLjFxLr9vdYkKEREREQ/ocKSIiIiIB1TCRERERDygEiYiIiLiAZUwEREREQ+ohImIiIh4QCVMRKKOc+4G55yFrtUjIhKVVMJEJBotBF4OfQ0L55wvXK8tIgIqYSISZZxzfYHLgc/RfsFEnHM+59x/OefeDt3o/P7Q/Audcxucc2845zY751Kcc3c554o6vN4fnHOzQ4+POuf+2zn3BnCJc+6bzrktoddd7pxzoXG5zrm/hF73VedcjnPu8Y43Y3bO/dw5N7/b/mFEJOqohIlItJkP/MnM3gcOOedmAIuALGCqmU0Gfh665cgvgb8zsynAXOD4GV47GXjFzKaY2ctAkZldaGYTgT7AtaFxPweWhF73UmAP8Bihuxk451JD8//YRX9nEemBVMJEJNosBJ4OPX46ND0XWGZmrdB++xDgAmCPmW0JzTvywfLTCAK/7jA9xzn3inPuLaAAmOCcSwHSzey50Os2mlmDma2h/Z5zg0OZft2J9xORXkz3jhSRqOGcS6O9DE1yzhnt93Yz/u9ebZ3Ryof/A5rY4XGjmQVD75UILAXyzWyXc+7bJ4w9mceBO2g/TPqZs8gkIr2Q9oSJSDS5GXjCzEaZWZaZjQQqgDeAe5xzsfDXsvYeMNw5d2FoXkpo+Q5gqnMuxjk3Eph5ivf6oHAdDJ2HdjOAmdUDVR+c/+WcS3DOJYXG/hT4+9A43ZRZRE5LJUxEoslC4LkT5v0aGA7sBN4MnVR/u5k1A7cBhaF5f6a9WK2nvbhtBx4GXj3ZG5lZLfBj4G3gRT68t+1O4EvOuTeBDcCw0HP2Ae8APznvv6mI9HjOzLzOICLSI4T2iL0FTDezOq/ziEhk054wEZEu4JybS/tesEIVMBHpDO0JExEREfGA9oSJiIiIeEAlTERERMQDKmEiIiIiHlAJExEREfGASpiIiIiIB1TCRERERDzw/wEfm7lxCeZQFAAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"simepEdKIiL0"},"source":["### Github Commands"]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"YdlGDV3AzZ1L","executionInfo":{"status":"ok","timestamp":1651225335811,"user_tz":-60,"elapsed":385,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"4d90ee9f-94fc-4c17-f323-3a2dcffacca0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":152,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":153,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143904,"status":"ok","timestamp":1651225480043,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"itbAqo9qGukN","outputId":"8c7dd349-8f22-4199-ac4b-d472f9233b7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   Early Time Series Classification - Average Ouput.ipynb\u001b[m\n","\t\u001b[31mmodified:   Early Time Series Classification - Pixel Data NN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Visualisations.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}],"source":["username = \"adityag16\"\n","git_token = \"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\"\n","repository = \"/content/drive/MyDrive/Final-Year-Project\"\n","%cd {repository}\n","!git status"]},{"cell_type":"code","execution_count":154,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2783,"status":"ok","timestamp":1651225482822,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"pNInxPqdG7nx","outputId":"c8a3019a-fc3c-4081-8f93-989060d3e12b"},"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git reset HEAD <file>...\" to unstage)\n","\n","\t\u001b[32mmodified:   Early Time Series Classification - Average Ouput.ipynb\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   Early Time Series Classification - Pixel Data NN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Visualisations.ipynb\u001b[m\n","\n"]}],"source":["!git add 'Early Time Series Classification - Average Ouput.ipynb' 'Best Performances.docx'\n","!git status"]},{"cell_type":"code","execution_count":155,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60238,"status":"ok","timestamp":1651225543050,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"K1tS6nonHF9u","outputId":"af26bca6-f6d3-4319-bf2d-f3147fc3feac"},"outputs":[{"output_type":"stream","name":"stdout","text":["[main 6f39a26] Testing KNN and Confidence with drift removal -- confidence still not working\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite Early Time Series Classification - Average Ouput.ipynb (91%)\n","Counting objects: 3, done.\n","Delta compression using up to 2 threads.\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 49.01 KiB | 3.50 MiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/adityag16/Final-Year-Project\n","   c2a8e46..6f39a26  main -> main\n"]}],"source":["!git config --global user.email \"aditya.gupta18@imperial.ac.uk\"\n","!git config --global user.name \"adityag16\"\n","\n","!git commit -m \"Testing KNN and Confidence with drift removal -- confidence still not working\"\n","!git push origin main"]},{"cell_type":"code","source":[""],"metadata":{"id":"8KO_iVTj0cIP"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Early Time Series Classification - Average Ouput.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1WYaF_HRa3IGG6auTN3SvWNlJMYRlk-43","authorship_tag":"ABX9TyNfNVzAjbkUhY2fP6jcFBWs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Connect Drive"],"metadata":{"id":"XVaAULW6qhh1"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15568,"status":"ok","timestamp":1651222988336,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"_DdiqzlkZMhe","outputId":"173d86fb-c436-48ed-9bee-e9da3cd6e650"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"markdown","metadata":{"id":"ttpluWU4tHLq"},"source":["### Package Imports"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"Z_3NHgGwZIsI","executionInfo":{"status":"ok","timestamp":1651223164006,"user_tz":-60,"elapsed":343,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.signal import savgol_filter\n","from collections import Counter\n","import copy\n","from collections import defaultdict\n","from scipy.optimize import curve_fit\n","from scipy.signal import filtfilt"]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from scipy.spatial import distance\n","from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances"],"metadata":{"id":"5vMvjgqYCd2d","executionInfo":{"status":"ok","timestamp":1651222993537,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### GPU Device"],"metadata":{"id":"6cosBM9Jd74f"}},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kElpooT1fLzz","executionInfo":{"status":"ok","timestamp":1651223000192,"user_tz":-60,"elapsed":407,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"49e9288f-c227-4169-cf69-f48641dae443"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-670de5ef-3f12-9bce-204a-30bb253f0b26)\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1651223004699,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"bLu_lZGKu9dp","outputId":"3d1801c0-5b6b-4320-c488-7b03e536b558"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["gpu = tf.test.gpu_device_name()\n","print(gpu)"]},{"cell_type":"markdown","metadata":{"id":"ihJkU1v2STVo"},"source":["### Pre-Processing Helper Functions"]},{"cell_type":"code","source":["def decaying_exp(x, a, b):\n","    \"\"\" Returns exponential function\n","    Parameters\n","    ----------\n","    x : ndarray\n","        times\n","    a : double\n","        t(inf) value\n","    b : double\n","        slope to t=0\n","    Returns\n","    -------\n","    ndarray\n","        y-axis values of the function\n","    \"\"\"\n","    return a*(1-np.exp(-b * x))\n","\n","\n","def fit_pixels_interpolate(time, X, interpolate_idx):\n","    \"\"\" Interpolates the curves for each pixel\n","    Parameters\n","    ----------\n","    time : ndarray\n","        times\n","    X : ndarray\n","        TxNM array to be interpolated\n","    idx_active : ndarray\n","        NM array specifying pixels that are active\n","    interpolate_idx : int\n","        interpolation is performed until this index\n","    Returns\n","    -------\n","    popt : ndarray\n","        optimal parameters for interpolation of each pixel, with shape 2xNM\n","    \"\"\"\n","    popt = np.zeros((2, X.shape[1]))\n","\n","    # for every pixel\n","    for i in range(X.shape[1]):\n","\n","      data = filtfilt(b=np.ones(10) / 10, a=[1], x=X[:, i])\n","\n","      # Fit the curve (interpolate)\n","      try:\n","        popt[:, i], pcov = curve_fit(decaying_exp, time[:interpolate_idx], data[:interpolate_idx], p0=[-10, 0.1])\n","      except:\n","        # print('EXCEPT: could not fit this pixel', i)\n","        popt[:, i] = None\n","\n","    return popt"],"metadata":{"id":"g1nRYshEtGy2","executionInfo":{"status":"ok","timestamp":1651223036942,"user_tz":-60,"elapsed":368,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def filter_by_drift(df, interpolate_idx):\n","\n","  popt = fit_pixels_interpolate(np.array(df.index), df.values, interpolate_idx)\n","\n","  drift_avg = np.zeros(df.shape[0])\n","  pix_count = 0\n","  active = np.array(np.zeros(df.shape[1]), dtype=bool)\n","\n","  for idx in range(df.shape[1]):\n","\n","  # check if any of the drift params for the pixel are nan\n","    if(np.isnan(popt[0, idx]) and np.isnan(popt[1, idx])):\n","      active[idx] = False\n","    else:\n","      # if drift params exist then iterate over the values of the index and use these as x values for the drift curve\n","      y_vals = []\n","      for i in df.index:\n","        val = decaying_exp(i, popt[0,idx], popt[1,idx])\n","        y_vals.append(val)\n","      \n","      # subtract the extrapolated drift from the signal\n","      drift_error = np.abs(np.array(df.values[:, idx] - y_vals))\n","      \n","      # only keep pixels with drift error of less than 10mV\n","      if((drift_error < 12).all()):\n","        drift_avg = np.add(drift_avg, np.array(y_vals))\n","        pix_count += 1\n","        active[idx] = True\n","      else:\n","        active[idx] = False\n","\n","  drift_avg/=pix_count\n","\n","  df = df.loc[:, active]\n","\n","  return df, drift_avg"],"metadata":{"id":"R9gzaEl7wE7H","executionInfo":{"status":"ok","timestamp":1651223038321,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"W1YMbu9bSW5m","executionInfo":{"status":"ok","timestamp":1651223039764,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vref(X, v_thresh=70):\n","    '''\n","    Identifies active pixels by checking if one of the first 10 derivatives d(i) is > v_thresh\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_thresh : int, optional\n","        Minimum value of the derivative d(i)=X(i+1)-X(i) in mV. Default is 70\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if, during the first 10 samples,\n","        one of the derivatives is > v_thresh. The derivatives are calculated as d(i) = X(i+1)-X(i)\n","    '''\n","    return (np.diff(X[:10, :], axis=0) > v_thresh).any(axis=0)  # check if one of the first 10 derivatives is >v_thresh"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XjXkAhKwSgFB","executionInfo":{"status":"ok","timestamp":1651223047631,"user_tz":-60,"elapsed":388,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vrange(X, v_range=(100, 900)):\n","    '''\n","    Identifies active pixels by checking that all the values are in v_range\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_range : (int, int), optional\n","        tuple containing the minimum and maximum allowable voltage in mV. Default is (100, 900)\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if the value is always in v_range\n","    '''\n","    return (X < v_range[1]).all(axis=0) & (X > v_range[0]).all(axis=0)  # for each pixel, check if all the values are\n","    # within the given range\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"G5a7Uqi9Skg_","executionInfo":{"status":"ok","timestamp":1651223048014,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_derivative(X, vthresh=5):\n","    \"\"\" Identifies active pixels by checking that the absolute value of the derivative is always below vthresh\n","    Parameters\n","    ----------\n","    X : ndarray\n","        input 2D array of shape TxNM\n","    vthresh : int\n","        threshold for active pixels. Default is 5\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if all the derivatives are below vthresh\n","    \"\"\"\n","    x_diff = np.abs(np.diff(X, axis=0))\n","    return (x_diff < vthresh).all(axis=0)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"XUOV5CRYflUO","executionInfo":{"status":"ok","timestamp":1651223048508,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # set pixel values to 0/nan\n","  for idx, col in enumerate(df.columns):\n","    if(not active[idx]):\n","      df.loc[:, col] = 0\n","\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_drop(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"DhuoGbbPutKZ","executionInfo":{"status":"ok","timestamp":1651223048509,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ZZJkYzPiVvd6","executionInfo":{"status":"ok","timestamp":1651223049389,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels_deriv(df, v_thresh_deriv=5): \n","  active = filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # for idx, col in enumerate(df.columns):\n","  #   if(not active[idx]):\n","  #     df.loc[:, col] = 0\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_range(df, v_range=(100, 900)):\n","  active = filter_by_vrange(df.values, v_range)\n","\n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"imVXR8eVUrby","executionInfo":{"status":"ok","timestamp":1651223050046,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def reshape_data(df, rows, cols):\n","  X = df.values #pandas.DataFrame.values: Return a Numpy representation of the DataFrame.\n","  X = X.reshape(-1, rows, cols, order='F') #or C. different reshaping row by row or column by column but this works\n","  return X"],"metadata":{"id":"RTF9Vh78MZSB","executionInfo":{"status":"ok","timestamp":1651223050408,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def filter_chemical_pixels(df, arr_rows, arr_cols):\n","  X = reshape_data(df, arr_rows, arr_cols) # reshape data to T x 78 x 56\n","  X_mean = np.mean(X, axis=0) # get mean to have 78 x 56 shape\n","  X_mean[1::3, 1::3] = np.nan # set temperature pixels to nan\n","  X_mean = X_mean.flatten('F') # restore shape to 4068 \n","\n","  active_chemical = ~(np.isnan(X_mean)) # get bool array of all chemical pixels\n","\n","  # drop pixels \n","  df = df.loc[: , active_chemical]\n","  return df\n"],"metadata":{"id":"D9Xt8X4zL7hc","executionInfo":{"status":"ok","timestamp":1651223050751,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"o82EQTYe9euH","executionInfo":{"status":"ok","timestamp":1651223051125,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def time_to_index(times, time_vect):\n","    '''\n","    Returns index of the times closest to the desired ones time_vect\n","    Arguments\n","    ---------\n","    times : list\n","        list of integers containing the desired times\n","    time_vect : nparray\n","        array of the times at which the values are sampled\n","    Returns\n","    -------\n","    list\n","        for each element in the input list times, return an element in the output list\n","        with the index of the sample closest to the desired time\n","    '''\n","    indices = []\n","    for time in times:  # for each time in the input list\n","        indices.append( np.argmin(np.abs(time_vect - time)) )\n","        # find index of the sampled time (in time_vect) closest to the desired one (time)\n","    return indices\n","\n","\n","def find_loading_time(time_vect, X, bounds=(600, 900), viz=False):  # for v2\n","    ''' Finds loading and settling time for the data of v2 chip\n","    Parameters\n","    ----------\n","    time_vect : ndarray\n","        1D array with dimension T containing the sampling times\n","    X : ndarray\n","        2D array with dimension TxNM containing the sampled data\n","    bounds : list, optional\n","        tuple containing the minimum and maximum times (in ms) where the loading time has to be searched.\n","        Default is (600, 900)\n","    viz : bool, optional\n","        if viz=True, show the plot. Default is False\n","    Returns\n","    -------\n","    tuple\n","        - settled_index : index at which the settling occurs\n","        - settled_time : time at which the settling occurs\n","    '''\n","\n","    search_start, search_end = time_to_index(bounds, time_vect)  # for each time in bounds, find the index\n","    # of the sample (in time_vect) that is closest to the desired one (in bounds)\n","    X_mean = np.mean(X, axis=1)  # for each sample, calculate the mean of all pixels\n","    X_mean_diff = np.diff(X_mean)  # find the derivative\n","\n","    loading_index = np.argmax(X_mean_diff[search_start:search_end]) + search_start + 1  # find the index\n","    # where the derivative is max in the specified interval\n","    loading_index = loading_index  # add settling time\n","    settled_index = loading_index + 10  # add settling time\n","    settled_time = time_vect[settled_index]  # find the time that index corresponds to\n","\n","    if viz:  # if viz is true, plot the following\n","        fig, ax = plt.subplots(3, 1)\n","        fig.suptitle('Finding Loading Time...')\n","\n","        ax[0].set(title='Active Chemical Pixels, ACP')\n","        ax[0].plot(time_vect, X)  # plot the active chemical pixels\n","\n","        ax[1].set(title='Mean(ACP)')\n","        ax[1].plot(time_vect, X_mean)  # plot the average of the pixels\n","        ax[1].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[1].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[1].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        ax[2].set(title='Diff(Mean(ACP))')\n","        ax[2].plot(time_vect[1:], X_mean_diff)  # plot the derivative of the mean\n","        ax[2].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[2].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[2].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        plt.tight_layout()\n","        plt.show()\n","    return settled_index, settled_time"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"9m8OqTUtQVb0","executionInfo":{"status":"ok","timestamp":1651224837105,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def preprocess_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","  \n","  df = filter_chemical_pixels(df, 78, 56) # filter all chemical pixels\n","  \n","  df = filter_active_pixels_drop(df=df, v_thresh_deriv=deriv_thresh, v_range=(100,900))\n","\n","  settle_idx, settle_time = find_loading_time(df.index, df, bounds=(600, 900), viz=False) # find settling point\n","  df = df.iloc[settle_idx + 10:, :] # use only the data after the settling time + 30s to allow reaction to settle\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise don't\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +200 added on to see impact on graph after pre-processing\n","  \n","  df.index = df.index - df.index[0]\n","  \n","  X, drift = filter_by_drift(df, 40)\n","\n","  if(len(X.columns) != 0):\n","    df = X\n","  # for col in df.columns:\n","  #   df[col] = savgol_filter(df[col],101, 3)\n","\n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  if(len(X.columns) != 0):\n","    df['Average Output'] = df['Average Output'] - drift\n","\n","  # df = df.iloc[40:, :]\n","  \n","  # df.index = df.index - df.index[0]\n","   \n","  return df"]},{"cell_type":"code","source":["def preprocess_partial_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","\n","  df = filter_active_pixels_range(df=df, v_range=(100,900)) # filter by range incase of any saturation\n","  \n","  df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh) # filter pixels by deriv\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise dont\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +250 added on to see impact on graph after pre-processing\n","  \n","  df.index = df.index - df.index[0]\n","\n","  X, drift = filter_by_drift(df, 40)\n","\n","  if(len(X.columns) != 0):\n","    df = X\n","  \n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  if(len(X.columns) != 0):\n","    df['Average Output'] = df['Average Output'] - drift\n","\n","  # df = df.iloc[50:, :]\n","  \n","  # df.index = df.index - df.index[0]\n","    \n","  return df"],"metadata":{"id":"JsSdU8xPZX4U","executionInfo":{"status":"ok","timestamp":1651224837946,"user_tz":-60,"elapsed":409,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["def normalise_data(series):\n","  return (series - series.min()) / (series.max() - series.min())"],"metadata":{"id":"M6wMMfHZEADc","executionInfo":{"status":"ok","timestamp":1651223051946,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### Data Loading Helper Functions"],"metadata":{"id":"Dvvp28miEMsF"}},{"cell_type":"code","source":["def load_partial_covid_exp(filepath):\n","\n","  bot_filepath = filepath[:-4] + \"_bot.csv\"\n","  top_filepath = filepath[:-4] + \"_top.csv\"\n","\n","  ## load in 2 sheets\n","  df_neg = pd.read_csv(top_filepath, header=0, index_col=0)\n","  df_pos = pd.read_csv(bot_filepath, header=0, index_col=0)\n","\n","  return df_pos, df_neg"],"metadata":{"id":"vL28HCTcZUUG","executionInfo":{"status":"ok","timestamp":1651223056884,"user_tz":-60,"elapsed":358,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation Metric Helper Functions"],"metadata":{"id":"PaNIFO5iSa9C"}},{"cell_type":"code","source":["def accuracy(classifications):\n","  total = len(classifications)\n","  total_correct = 0\n","  for i in classifications.values():\n","    if(i[0] == i[1]):\n","      total_correct +=1\n","\n","  accuracy = (total_correct/total)\n","\n","  return accuracy"],"metadata":{"id":"U2zoSqPJLatm","executionInfo":{"status":"ok","timestamp":1651223057925,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def sensitivity(classifications):\n","  true_pos = 0\n","  false_neg = 0\n","\n","  for i in classifications.values():\n","\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","\n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 1 and predicted == 0):\n","      false_neg += 1\n","\n","  sensitivity = (true_pos/(true_pos + false_neg))\n","\n","  return sensitivity"],"metadata":{"id":"lzSAF5WsTIuF","executionInfo":{"status":"ok","timestamp":1651223058407,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def specificity(classifications):\n","  true_neg = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 0 and predicted == 0):\n","      true_neg += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  specificity = (true_neg/(true_neg + false_pos))\n","\n","  return specificity"],"metadata":{"id":"WP_kdiXMYeU1","executionInfo":{"status":"ok","timestamp":1651223058408,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def precision(classifications):\n","  true_pos = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  precision = (true_pos/(true_pos + false_pos))\n","\n","  return precision"],"metadata":{"id":"w7-_ZPDDaxRp","executionInfo":{"status":"ok","timestamp":1651223058769,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def f1(classifications):\n","  numerator = 2*precision(classifications)*sensitivity(classifications)\n","  denominator = precision(classifications) + sensitivity(classifications)\n","  return numerator/denominator"],"metadata":{"id":"qkFpU-UJbV1R","executionInfo":{"status":"ok","timestamp":1651223059525,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["### Array Dims"],"metadata":{"id":"W9kgS_-Cx1nm"}},{"cell_type":"code","source":["arr_rows = 78\n","arr_cols = 56"],"metadata":{"id":"whsJZh4Zx0xs","executionInfo":{"status":"ok","timestamp":1651223060711,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["### Load Data"],"metadata":{"id":"KCr7gvB_tf5-"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"AvJiLnQ8tiKx"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  avg_data_g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_data_export.csv\"\n","  avg_g1 = pd.read_csv(avg_data_g1_file, header=0)\n","\n","  ## Gamma 2\n","  avg_data_g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_data_export.csv\"\n","  avg_g2 = pd.read_csv(avg_data_g2_file, header=0)\n","\n","  ## Gamma 3\n","  avg_data_g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_data_export.csv\"\n","  avg_g3 = pd.read_csv(avg_data_g3_file, header=0)\n","  \n","  ## Gamma 5 \n","  avg_data_g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_data_export.csv\"\n","  avg_g5 = pd.read_csv(avg_data_g5_file, header=0)\n","\n","  ## 22RV1.ap1\n","  avg_data_22rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_data_export.csv\"\n","  avg_22rv1_ap1 = pd.read_csv(avg_data_22rv1_ap1_file, header=0)\n","\n","  ## 22RV1.ap2\n","  avg_data_22rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_data_export.csv\"\n","  avg_22rv1_ap2 = pd.read_csv(avg_data_22rv1_ap2_file, header=0)\n","\n","  ## 22RV1y.p1\n","  avg_data_22rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_data_export.csv\"\n","  avg_22rv1y_p1 = pd.read_csv(avg_data_22rv1y_p1_file, header=0)\n","\n","  ## 22RV1y.p3\n","  avg_data_22rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_data_export.csv\"\n","  avg_22rv1y_p3 = pd.read_csv(avg_data_22rv1y_p3_file, header=0)\n","\n","  ## 22RV1y.p4\n","  avg_data_22rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_data_export.csv\"\n","  avg_22rv1y_p4 = pd.read_csv(avg_data_22rv1y_p4_file, header=0)\n","\n","  ## ARV7.p1\n","  avg_data_arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_data_export.csv\"\n","  avg_arv7_p1 = pd.read_csv(avg_data_arv7_p1_file, header=0).iloc[1:, :].reset_index(drop=True) # row 0 was NAN\n","\n","  ## ARV7.p3\n","  avg_data_arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_data_export.csv\"\n","  avg_arv7_p3 = pd.read_csv(avg_data_arv7_p3_file, header=0)\n","\n","  ## ARV7.p4\n","  avg_data_arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_data_export.csv\"\n","  avg_arv7_p4 = pd.read_csv(avg_data_arv7_p4_file, header=0)\n","\n","  ## Beta 1\n","  avg_data_b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_data_export.csv\"\n","  avg_b1 = pd.read_csv(avg_data_b1_file, header=0)\n","\n","  ## Beta 2\n","  avg_data_b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_data_export.csv\"\n","  avg_b2 = pd.read_csv(avg_data_b2_file, header=0)\n","\n","  ## Beta 5\n","  avg_data_b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_data_export.csv\"\n","  avg_b5 = pd.read_csv(avg_data_b5_file, header=0)\n","  "],"metadata":{"id":"Ekqd_pB0tuTS","executionInfo":{"status":"ok","timestamp":1651224843310,"user_tz":-60,"elapsed":508,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_vsChem_export.csv\"\n","  g1 = pd.read_csv(g1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g1.index = avg_g1[\"Time Elapsed\"]\n","\n","  ## Gamma 2\n","  g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_vsChem_export.csv\"\n","  g2 = pd.read_csv(g2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g2.index = avg_g2[\"Time Elapsed\"]\n","\n","  ## Gamma 3\n","  g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_vsChem_export.csv\"\n","  g3 = pd.read_csv(g3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g3.index = avg_g3[\"Time Elapsed\"]\n","\n","  ## Gamma 5\n","  g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_vsChem_export.csv\"\n","  g5 = pd.read_csv(g5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g5.index = avg_g5[\"Time Elapsed\"]\n","\n","  ## 22RV1.ap1\n","  rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_vsChem_export.csv\"\n","  rv1_ap1 = pd.read_csv(rv1_ap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap1.index = avg_22rv1_ap1['Time Elapsed']\n","\n","  ## 22RV1.ap2\n","  rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_vsChem_export.csv\"\n","  rv1_ap2 = pd.read_csv(rv1_ap2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap2.index = avg_22rv1_ap2['Time Elapsed']\n","\n","  ## 22RV1y.p1\n","  rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_vsChem_export.csv\"\n","  rv1y_p1 = pd.read_csv(rv1y_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p1.index = avg_22rv1y_p1['Time Elapsed']\n","\n","  ## 22RV1y.p3\n","  rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_vsChem_export.csv\"\n","  rv1y_p3 = pd.read_csv(rv1y_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p3.index = avg_22rv1y_p3['Time Elapsed']\n","\n","  ## 22RV1y.p4\n","  rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_vsChem_export.csv\"\n","  rv1y_p4 = pd.read_csv(rv1y_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p4.index = avg_22rv1y_p4['Time Elapsed']\n","\n","  ## ARV7.p1 \n","  arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_vsChem_export.csv\"\n","  arv7_p1 = pd.read_csv(arv7_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)] \n","  arv7_p1.index = avg_arv7_p1[\"Time Elapsed\"]\n","\n","  ## ARV7.p3 \n","  arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_vsChem_export.csv\"\n","  arv7_p3 = pd.read_csv(arv7_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p3.index = avg_arv7_p3[\"Time Elapsed\"]\n","\n","  ## ARV7.p4 \n","  arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_vsChem_export.csv\"\n","  arv7_p4 = pd.read_csv(arv7_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p4.index = avg_arv7_p4[\"Time Elapsed\"]\n","\n","  ## Beta 1\n","  b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_vsChem_export.csv\"\n","  b1 = pd.read_csv(b1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b1.index = avg_b1[\"Time Elapsed\"]\n","\n","  ## Beta 2\n","  b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_vsChem_export.csv\"\n","  b2 = pd.read_csv(b2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b2.index = avg_b2[\"Time Elapsed\"]\n","\n","  ## Beta 5\n","  b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_vsChem_export.csv\"\n","  b5 = pd.read_csv(b5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b5.index = avg_b5[\"Time Elapsed\"]"],"metadata":{"id":"vZRah5zpxXp6","executionInfo":{"status":"ok","timestamp":1651224851634,"user_tz":-60,"elapsed":8329,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"7qOF9VBstkbe"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):  \n","  ## ARV7.n1\n","  avg_data_arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_data_export.csv\"\n","  avg_arv7 = pd.read_csv(avg_data_arv7_file, header=0)\n","\n","  ## Yap.n2\n","  avg_data_yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_data_export.csv\"\n","  avg_yap = pd.read_csv(avg_data_yap_file, header=0)\n","\n","  ## Yap1.n2\n","  avg_data_yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_data_export.csv\"\n","  avg_yap1 = pd.read_csv(avg_data_yap1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## Yap1.n1.1 \n","  avg_data_yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_data_export.csv\"\n","  avg_yap1n1 = pd.read_csv(avg_data_yap1n1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## ARV7.n2\n","  avg_data_arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_data_export.csv\"\n","  avg_arv72 = pd.read_csv(avg_data_arv72_file, header=0)\n","\n","  ## ARV7.n3\n","  avg_data_arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_data_export.csv\"\n","  avg_arv73 = pd.read_csv(avg_data_arv73_file, header=0)\n","\n","  ## DU145a.p1\n","  avg_data_du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_data_export.csv\"\n","  avg_du145a_p1 = pd.read_csv(avg_data_du145a_p1_file, header=0)\n","\n","  ## DU145a.p2\n","  avg_data_du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_data_export.csv\"\n","  avg_du145a_p2 = pd.read_csv(avg_data_du145a_p2_file, header=0)\n","\n","  ## DU145a.p3\n","  avg_data_du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_data_export.csv\"\n","  avg_du145a_p3 = pd.read_csv(avg_data_du145a_p3_file, header=0)\n","\n","  ## DU145y.n1\n","  avg_data_du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_data_export.csv\"\n","  avg_du145y_n1 = pd.read_csv(avg_data_du145y_n1_file, header=0)"],"metadata":{"id":"mlU83yKsuSHV","executionInfo":{"status":"ok","timestamp":1651224851634,"user_tz":-60,"elapsed":10,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):   \n","  ## ARV7.n1 \n","  arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_vsChem_export.csv\"\n","  arv7 = pd.read_csv(arv7_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7.index = avg_arv7[\"Time Elapsed\"]\n","\n","  ## Yap.n2\n","  yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_vsChem_export.csv\"\n","  yap = pd.read_csv(yap_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap.index = avg_yap[\"Time Elapsed\"]\n","\n","  ## Yap1.n2\n","  yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_vsChem_export.csv\"\n","  yap1 = pd.read_csv(yap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1.index = avg_yap1[\"Time Elapsed\"]\n","\n","  ## Yap1.n1.1\n","  yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_vsChem_export.csv\"\n","  yap1n1 = pd.read_csv(yap1n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1n1.index = avg_yap1n1[\"Time Elapsed\"]\n","\n","  ## ARV7.n2\n","  arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_vsChem_export.csv\"\n","  arv72 = pd.read_csv(arv72_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv72.index = avg_arv72[\"Time Elapsed\"]\n","\n","  ## ARV7.n3\n","  arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_vsChem_export.csv\"\n","  arv73 = pd.read_csv(arv73_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv73.index = avg_arv73[\"Time Elapsed\"]\n","\n","  ## DU145a.p1\n","  du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_vsChem_export.csv\"\n","  du145a_p1 = pd.read_csv(du145a_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p1.index = avg_du145a_p1[\"Time Elapsed\"]\n","\n","  ## DU145a.p2\n","  du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_vsChem_export.csv\"\n","  du145a_p2 = pd.read_csv(du145a_p2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p2.index = avg_du145a_p2[\"Time Elapsed\"]\n","\n","  ## DU145a.p3\n","  du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_vsChem_export.csv\"\n","  du145a_p3 = pd.read_csv(du145a_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p3.index = avg_du145a_p3[\"Time Elapsed\"]\n","\n","  ## DU145y.n1\n","  du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_vsChem_export.csv\"\n","  du145y_n1 = pd.read_csv(du145y_n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145y_n1.index = avg_du145y_n1[\"Time Elapsed\"]"],"metadata":{"id":"W3_XExOjypwI","executionInfo":{"status":"ok","timestamp":1651224856485,"user_tz":-60,"elapsed":4860,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":["#### Partial Covid Data"],"metadata":{"id":"yjXPLEfmRUJH"}},{"cell_type":"code","source":["## 150520_2_118\n","avg_118_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_2_118/exp_summary_118.csv\"\n","exp_118_pos, exp_118_neg = load_partial_covid_exp(avg_118_file)\n","\n","## 150520_4_2_86\n","avg_86_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_4_2_86/exp_summary_86.csv\"\n","exp_86_pos, exp_86_neg = load_partial_covid_exp(avg_86_file)\n","\n","## 150520_5_129\n","avg_129_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_5_129/exp_summary_129.csv\"\n","exp_129_pos, exp_129_neg = load_partial_covid_exp(avg_129_file)\n","\n","## 180520_4_165\n","avg_165_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_4_165/exp_summary_165.csv\"\n","exp_165_pos, exp_165_neg = load_partial_covid_exp(avg_165_file)\n","\n","## 180520_6_35\n","avg_35_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_6_35/exp_summary_35.csv\"\n","exp_35_pos, exp_35_neg = load_partial_covid_exp(avg_35_file)\n","\n","## 190520_1_28\n","avg_28_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_1_28/exp_summary_28.csv\"\n","exp_28_pos, exp_28_neg = load_partial_covid_exp(avg_28_file) \n","\n","## 190520_2_14\n","avg_14_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_2_14/exp_summary_14.csv\"\n","exp_14_pos, exp_14_neg = load_partial_covid_exp(avg_14_file)\n","\n","## 210520_2_40\n","avg_40_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_2_40/exp_summary_40.csv\"\n","exp_40_pos, exp_40_neg = load_partial_covid_exp(avg_40_file)\n","\n","## 210520_3_88\n","avg_88_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_3_88/exp_summary_88.csv\"\n","exp_88_pos, exp_88_neg = load_partial_covid_exp(avg_88_file)\n","\n","## 210520_6_27\n","avg_27_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_6_27/exp_summary_27.csv\"\n","exp_27_pos, exp_27_neg = load_partial_covid_exp(avg_27_file)\n","\n","## 250520_1_134\n","avg_134_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_1_134/exp_summary_134.csv\"\n","exp_134_pos, exp_134_neg = load_partial_covid_exp(avg_134_file)\n","\n","## 250520_2_97\n","avg_97_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_2_97/exp_summary_97.csv\"\n","exp_97_pos, exp_97_neg = load_partial_covid_exp(avg_97_file)\n","\n","## 250520_6_2D1\n","avg_2d1_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_6_2D1/exp_summary_2D1.csv\"\n","exp_2d1_pos, exp_2d1_neg = load_partial_covid_exp(avg_2d1_file)\n","\n","## 250520_7_64\n","avg_64_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_7_64/exp_summary_64.csv\"\n","exp_64_pos, exp_64_neg = load_partial_covid_exp(avg_64_file)"],"metadata":{"id":"ORRtMFfEZBwV","executionInfo":{"status":"ok","timestamp":1651224859580,"user_tz":-60,"elapsed":3102,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"7XgnkewwwPki"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"CTcUwvRiwUmJ"}},{"cell_type":"code","source":["g1 = preprocess_data(g1, 500)\n","g2 = preprocess_data(g2, 500)\n","g3 = preprocess_data(g3, 500)\n","g5 = preprocess_data(g5, 500)\n","rv1_ap1 = preprocess_data(rv1_ap1, 500)\n","rv1_ap2 = preprocess_data(rv1_ap2, 500)\n","rv1y_p1 = preprocess_data(rv1y_p1, 500)\n","rv1y_p3 = preprocess_data(rv1y_p3, 500)\n","rv1y_p4 = preprocess_data(rv1y_p4, 500)\n","arv7_p1 = preprocess_data(arv7_p1, 500)\n","arv7_p3 = preprocess_data(arv7_p3, 500)\n","arv7_p4 = preprocess_data(arv7_p4, 500)\n","b1 = preprocess_data(b1, 500)\n","b2 = preprocess_data(b2, 500)\n","b5 = preprocess_data(b5, 500)"],"metadata":{"id":"1-WlDoK49D2Y","executionInfo":{"status":"ok","timestamp":1651224926702,"user_tz":-60,"elapsed":67139,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a4a9deba-b75a-48fd-f76f-18af69f36982"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"1WaPBFGuwYN4"}},{"cell_type":"code","source":["arv7 = preprocess_data(arv7, 500)\n","yap = preprocess_data(yap, 500)\n","yap1 = preprocess_data(yap1, 500)\n","yap1n1 = preprocess_data(yap1n1, 500)\n","arv72 = preprocess_data(arv72, 500)\n","arv73 = preprocess_data(arv73, 500)\n","du145y_n1 = preprocess_data(du145y_n1, 500)\n","du145a_p1 = preprocess_data(du145a_p1, 500)\n","du145a_p2 = preprocess_data(du145a_p2, 500)\n","du145a_p3 = preprocess_data(du145a_p3, 500)"],"metadata":{"id":"gazhgzLT9HLV","executionInfo":{"status":"ok","timestamp":1651224966570,"user_tz":-60,"elapsed":39882,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6b76b64-0b72-45ce-cb30-5e69710f2f40"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n","/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}]},{"cell_type":"markdown","source":["#### Covid Partial Data"],"metadata":{"id":"nUwBPNQNjQ7w"}},{"cell_type":"code","source":["exp_118_pos = preprocess_partial_data(exp_118_pos, 500)\n","exp_86_pos = preprocess_partial_data(exp_86_pos, 500)\n","exp_129_pos = preprocess_partial_data(exp_129_pos, 500)\n","exp_165_pos = preprocess_partial_data(exp_165_pos, 500)\n","exp_35_pos = preprocess_partial_data(exp_35_pos, 500)\n","exp_28_pos = preprocess_partial_data(exp_28_pos, 500)\n","exp_14_pos = preprocess_partial_data(exp_14_pos, 500)\n","exp_40_pos = preprocess_partial_data(exp_40_pos, 500)\n","exp_88_pos = preprocess_partial_data(exp_88_pos, 500)\n","exp_27_pos = preprocess_partial_data(exp_27_pos, 500)\n","exp_134_pos = preprocess_partial_data(exp_134_pos, 500)\n","exp_97_pos = preprocess_partial_data(exp_97_pos, 500)\n","exp_2d1_pos = preprocess_partial_data(exp_2d1_pos, 500)\n","exp_64_pos = preprocess_partial_data(exp_64_pos, 500)"],"metadata":{"id":"HQBQ_1YF9Oqj","executionInfo":{"status":"ok","timestamp":1651224988689,"user_tz":-60,"elapsed":22148,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a0cd3b0f-4d1b-4d51-d85d-89c5735bf207"},"execution_count":119,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"]}]},{"cell_type":"code","source":["exp_118_neg = preprocess_partial_data(exp_118_neg, 500)\n","exp_86_neg = preprocess_partial_data(exp_86_neg, 500)\n","exp_129_neg = preprocess_partial_data(exp_129_neg, 500)\n","exp_165_neg = preprocess_partial_data(exp_165_neg, 500)\n","exp_35_neg = preprocess_partial_data(exp_35_neg, 500)\n","exp_28_neg = preprocess_partial_data(exp_28_neg, 500)\n","exp_14_neg = preprocess_partial_data(exp_14_neg, 500)\n","exp_40_neg = preprocess_partial_data(exp_40_neg, 500)\n","exp_88_neg = preprocess_partial_data(exp_88_neg, 500)\n","exp_27_neg = preprocess_partial_data(exp_27_neg, 500)\n","exp_134_neg = preprocess_partial_data(exp_134_neg, 500)\n","exp_97_neg = preprocess_partial_data(exp_97_neg, 500)\n","exp_2d1_neg = preprocess_partial_data(exp_2d1_neg, 500)\n","exp_64_neg = preprocess_partial_data(exp_64_neg, 500)"],"metadata":{"id":"sYsOnsAW9Rob","executionInfo":{"status":"ok","timestamp":1651225010687,"user_tz":-60,"elapsed":22009,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"54f44416-c279-4add-dafc-da411c312df1"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}]},{"cell_type":"markdown","source":["### Machine Learning - Neural Network Ensemble"],"metadata":{"id":"cco-BOwij9af"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"j5qgb5mx3rOW"}},{"cell_type":"code","source":["def get_training_data(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"OIYXEisg2WX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_test_data(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"xH5J1l0cgIHI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"d6Qyl80Wzy-r"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,\n","             \"arv7_p3\":arv7_p3,\n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7,  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3}"],"metadata":{"id":"d-bA8RfjcM35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Model Specs"],"metadata":{"id":"rxkmk6GHqC7g"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_classifiers = 50\n","\n","timestep = int(number_of_samples/number_of_classifiers)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]\n","\n","batch_size = 3\n","epochs = 10\n","loss_function = 'binary_crossentropy'\n","optimiser = 'adam'"],"metadata":{"id":"eztwFZUaloVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBcYHOw_BU4E","executionInfo":{"status":"ok","timestamp":1650888347765,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"62652afd-35c9-48f8-c037-b58efe79e12c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Creating Ensemble"],"metadata":{"id":"qG3eDbNkqG9A"}},{"cell_type":"code","source":["def create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples):\n","\n","  neural_nets = [0]*number_of_classifiers\n","\n","  for i in range(number_of_classifiers):\n","\n","    # print(f\"============================================== Neural Network {i} ============================================\")\n","\n","    ## make model \n","    neural_nets[i] = Sequential()\n","    neural_nets[i].add(Dense(16, activation='relu', input_dim = timestamps[i]))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(1, activation='sigmoid'))\n","\n","    ## compile model \n","    neural_nets[i].compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])\n","\n","    ## model summary\n","    # neural_nets[i].summary()\n","\n","    ## training data\n","    training_data, training_label = get_training_data(positive_samples=positives, negative_samples=negatives, timestamp=timestamps[i], test_samples=[test_samples])\n","\n","    ## train model\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n","    neural_nets[i].fit(training_data, training_label,  batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[callback], verbose=0)\n","\n","    # print(\"\\n\\n\")\n","\n","  return neural_nets"],"metadata":{"id":"GVVPVw4-ndtu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Evaluating Ensemble"],"metadata":{"id":"fGH97jNBfzdu"}},{"cell_type":"code","source":["def get_prediction(ensemble, timestamps, test_sample):\n","  predictions = []\n","\n","  for i in range(number_of_classifiers):\n","    test_data = get_test_data(test_sample, timestamps[i])\n","    prediction = ensemble[i].predict(test_data)\n","    predictions.append(prediction[0][0])\n","\n","  predictions = [int(i >= 0.5) for i in predictions]\n","  classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","\n","  return classification"],"metadata":{"id":"HslDzCxe1PaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with tule label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"TCTzCBpU0S8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  final_classifications = {}\n","\n","  ## use ensemble to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Testing sample: {test_sample_name}...\")\n","\n","    en = create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_sample_name)\n","    classification = get_prediction(en, timestamps, test_sample)\n","    \n","    \n","    final_classifications[key] = (classification, true_label_dict[key])\n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"HlIwk3By0Zqi","colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"status":"error","timestamp":1650888354674,"user_tz":-60,"elapsed":6919,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2e248431-2ec4-4c7b-e50c-96b007673ba4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample: exp_118_pos...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'sequential_1/dense_7/BiasAdd/ReadVariableOp/resource' has no attr named '_class'.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-5086e332c720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing sample: {test_sample_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0men\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-83e0a485fc39>\u001b[0m in \u001b[0;36mcreate_ensemble\u001b[0;34m(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m## train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mneural_nets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# print(\"\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    530\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m    531\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_compute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    673\u001b[0m           \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m           \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m               var.op.name):\n\u001b[1;32m    716\u001b[0m             update_op = distribution.extended.update(\n\u001b[0;32m--> 717\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False)\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_cross_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m               \u001b[0;31m# In cross-replica context, extended.update returns a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n\u001b[0;32m-> 2633\u001b[0;31m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[0m\u001b[1;32m   2634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2509\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3101\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3102\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3108\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3109\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2509\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2628\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2629\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3701\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3702\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3709\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3710\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    174\u001b[0m           \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m           \u001b[0;34m'Please pass these args as kwargs instead.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1447\u001b[0m                              \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m                              \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m                              use_nesterov=use_nesterov, name=name)\n\u001b[0m\u001b[1;32m   1450\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0mResourceApplyAdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_ops.ResourceApplyAdam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_apply_adam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[1;32m   1655\u001b[0m                            \"building a function.\")\n\u001b[0;32m-> 1656\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;31m# Large EagerTensors and resources are captured with Placeholder ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m       placeholder = _create_substitute_placeholder(\n\u001b[0;32m--> 765\u001b[0;31m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0m\u001b[1;32m    766\u001b[0m       \u001b[0;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0;31m# This attribute would be propogated into the arg_attr of the FunctionDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     placeholder = graph_placeholder(\n\u001b[0;32m-> 1306\u001b[0;31m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   1307\u001b[0m   \u001b[0mhandle_data_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       attrs=attrs, name=name)\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3785\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3872\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcolocation_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3874\u001b[0;31m           \u001b[0mall_colocation_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3876\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocation_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \u001b[0mdefault_colocation_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc:@%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m       \u001b[0mclass_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m       \u001b[0;31m# This op has no explicit colocation group, so it is itself its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["final_classifications"],"metadata":{"id":"4AuD_rrC2yYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"mhkc8Lnr9-c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"WCjSN-dLz9Mq"}},{"cell_type":"code","source":["# ## checking the timestap where majority of classifiers agree\n","\n","# from collections import defaultdict\n","\n","# def get_timestamp(timestamps, predictions):\n","\n","#   ## create dict to hold count of predictions\n","#   label_counters = defaultdict(int)\n","\n","#   ## add entries to dict\n","#   for index, pred in enumerate(predictions):\n","#     label_counters[pred] += 1\n","\n","#     ## if label count == half of total possible predictions then majority is achieved\n","#     if(label_counters[pred] == int(len(predictions)/2)+1):\n","#       return timestamps[index], index\n","  \n","#   return -1, -1\n"],"metadata":{"id":"3r69Gbpd99So"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Timestamp where majority aggement is reached: {timestamp_final}\")\n","# print(f\"Index of final time stamp in array : {pred_index}\")"],"metadata":{"id":"ghvOJ4Ot_fRB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Save Ensemble"],"metadata":{"id":"PppLDxSdv5Uk"}},{"cell_type":"code","source":["# !pwd"],"metadata":{"id":"jAJAZJtKv816"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G1Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G2Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G3Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G5Test"],"metadata":{"id":"UgtDxJjmxHQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/ARV7Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAPTest/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1N1Test/"],"metadata":{"id":"bwBDVrvMRsO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for i in range(number_of_classifiers):\n","#   filename = f\"ensemble-model-{i}.h5\"\n","#   neural_nets[i].save(filename)\n","\n","#   print(f\"Saved {filename}\")"],"metadata":{"id":"ZGXuLcuXx99S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - KNN Ensemble"],"metadata":{"id":"GvAKajynLNa9"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"H8ueQFk24bbg"}},{"cell_type":"code","source":["def get_training_data_knn(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"x4q6d44BLwpQ","executionInfo":{"status":"ok","timestamp":1651225010689,"user_tz":-60,"elapsed":47,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["def get_test_data_knn(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"GZOfy-0GQuGA","executionInfo":{"status":"ok","timestamp":1651225010690,"user_tz":-60,"elapsed":46,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["def get_time_index(timestamps, predictions):\n","\n","  ## create dict to hold count of predictions\n","  label_counters = defaultdict(int)\n","\n","  ## add entries to dict\n","  for index, pred in enumerate(predictions):\n","    label_counters[pred] += 1\n","\n","    ## if label count == half of total possible predictions then majority is achieved\n","    if(label_counters[pred] == int(len(predictions)/2)+1):\n","      return timestamps[index]\n","  \n","  return -1"],"metadata":{"id":"2hib6StpHWbU","executionInfo":{"status":"ok","timestamp":1651225010690,"user_tz":-60,"elapsed":44,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"FOMhNuiKNGAw"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","            #  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"-prfZYD_VgMB","executionInfo":{"status":"ok","timestamp":1651225010691,"user_tz":-60,"elapsed":44,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":124,"outputs":[]},{"cell_type":"markdown","source":["#### Timestamps"],"metadata":{"id":"Ry9pqKjnNKiI"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"3cDeyMc3M_bN","executionInfo":{"status":"ok","timestamp":1651225010691,"user_tz":-60,"elapsed":43,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":125,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIjHUplVOmH3","executionInfo":{"status":"ok","timestamp":1651225010691,"user_tz":-60,"elapsed":42,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8ceed6bf-d455-4301-992b-6cba576e115f"},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Model"],"metadata":{"id":"DJBWoo1SNMy3"}},{"cell_type":"code","source":["def KNN(k, test_sample, train_data, train_labels, distance_metric):\n","  test = np.tile(test_sample, (len(train_data),1)) # repeat test sample and stack vertically\n","  \n","  distances = None\n","\n","  if(distance_metric.lower() == 'manhattan' or distance_metric.lower() == 'cityblock'):\n","    distances = manhattan_distances(test, train_data).diagonal() # get pair wise manhattan distance for every row\n","  elif(distance_metric.lower() == 'euclidean'):\n","    distances = euclidean_distances(test, train_data).diagonal() # get pair wise euclidean distance for every row \n","  elif(distance_metric.lower() == 'cosine'):\n","    distances = cosine_distances(test, train_data).diagonal() # get pair wise cosine distance for every row \n","\n","  min_indexes = np.argsort(distances)[:k] # get k smallest indexes\n","\n","  knn_labels = list(train_labels[min_indexes]) # get k predictions\n","  final_pred = max(set(knn_labels), key=knn_labels.count)\n","\n","  return final_pred"],"metadata":{"id":"sGJZphgaLeL0","executionInfo":{"status":"ok","timestamp":1651225010692,"user_tz":-60,"elapsed":38,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":127,"outputs":[]},{"cell_type":"markdown","source":["#### Model Predictions"],"metadata":{"id":"0C0XQKFHFtFV"}},{"cell_type":"markdown","source":["##### Held-out Test Set"],"metadata":{"id":"Vf8LAE4Qbxls"}},{"cell_type":"code","source":["# test_samples = {\"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \"exp_27_neg\":exp_27_neg,\"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg,\n","#                 \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \"g1\":g1, \"exp_86_pos\":exp_86_pos, \"rv1_ap1\":rv1_ap1,\"b5\":b5, \"exp_28_pos\":exp_28_pos}\n","# test_sample_keys = keys = list(test_samples.keys())\n","# test_labels = list(np.concatenate((np.ones(7),np.zeros(7))))\n","# test_label_dict = dict(zip(test_sample_keys, test_labels))"],"metadata":{"id":"AxaTjkExYX9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import time\n","# with tf.device(gpu):\n","\n","#   final_classifications = {}\n","\n","#   ## use KNN to evaluate the prediction for each of the samples individually\n","#   for key, value in test_samples.items():\n","#     test_sample_name = key\n","#     test_sample = value\n","\n","#     predictions = []\n","#     for t in timestamps:\n","#       train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=test_sample_keys)\n","#       test_data = get_test_data_knn(test_sample, t)\n","#       pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","#       predictions.append(pred)\n","    \n","#     print(f\"Testing sample {test_sample_name}\")\n","\n","#     time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","#     time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","#     classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","#     final_classifications[key] = (classification, true_label_dict[key])\n","  \n","#     print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","#     if(classification == 1.0):\n","#       print(f\"TTP: {time_to_result}s\")\n","\n","#     print(\"\")"],"metadata":{"id":"PVYWffD2Z5q6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Accuracy: {accuracy(final_classifications)}\")\n","# print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","# print(f\"Specificity: {specificity(final_classifications)}\")\n","# print(f\"Precision: {precision(final_classifications)}\")\n","# print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"uV2qejqoblws"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Cross Validation"],"metadata":{"id":"DuKAj66EbskM"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             #\"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"RGVdwT8rxS23","executionInfo":{"status":"ok","timestamp":1651225010692,"user_tz":-60,"elapsed":37,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":128,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"SUDmHpF-GigC","executionInfo":{"status":"ok","timestamp":1651225010692,"user_tz":-60,"elapsed":36,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(5, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    print(f\"Testing sample {test_sample_name}\")\n","    time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","    time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","    classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","    final_classifications[key] = (classification, true_label_dict[key])\n","  \n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","    if(classification == 1.0):\n","      print(f\"TTP: {time_to_result + 30}s\")\n","\n","    print(\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rptrj0arSjSR","executionInfo":{"status":"ok","timestamp":1651225029557,"user_tz":-60,"elapsed":3157,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"9771bc49-1d88-453b-f775-df7996b9643e"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1029.0s\n","\n","Testing sample exp_86_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_129_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1119.0s\n","\n","Testing sample exp_35_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1064.0s\n","\n","Testing sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 793.0s\n","\n","Testing sample exp_40_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 731.0s\n","\n","Testing sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 963.0s\n","\n","Testing sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 719.0s\n","\n","Testing sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 670s\n","\n","Testing sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 587.0s\n","\n","Testing sample exp_2d1_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 616.0s\n","\n","Testing sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 624.0s\n","\n","Testing sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 612.0s\n","\n","Testing sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 629.0s\n","\n","Testing sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 738.0s\n","\n","Testing sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1018.0s\n","\n","Testing sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 948.0s\n","\n","Testing sample arv7_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample rv1y_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample rv1y_p4\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 767.0s\n","\n","Testing sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 912.0s\n","\n","Testing sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 758.0s\n","\n","Testing sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1028.0s\n","\n","Testing sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 799.0s\n","\n","Testing sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 617s\n","\n","Testing sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 659s\n","\n","Testing sample exp_165_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 680s\n","\n","Testing sample exp_35_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 646s\n","\n","Testing sample exp_40_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_134_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 624.0s\n","\n","Testing sample exp_97_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 611s\n","\n","Testing sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 641s\n","\n","Testing sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 628.0s\n","\n","Testing sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 648.0s\n","\n","Testing sample yap1n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 948.0s\n","\n","Testing sample arv7\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n"]}]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SilNigCLya5","executionInfo":{"status":"ok","timestamp":1651225033230,"user_tz":-60,"elapsed":359,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"fb00573d-b0f3-4e83-cad8-4307e827efe2"},"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6530612244897959\n","Sensitivity/Recall: 0.75\n","Specificity: 0.5238095238095238\n","Precision: 0.6774193548387096\n","F1 Score: 0.7118644067796611\n"]}]},{"cell_type":"code","source":["# Accuracy: 0.6530612244897959\n","# Sensitivity/Recall: 0.7142857142857143\n","# Specificity: 0.5714285714285714\n","# Precision: 0.6896551724137931\n","# F1 Score: 0.7017543859649122"],"metadata":{"id":"hynDsCvoiBIa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Elbow Plot"],"metadata":{"id":"DgvFMAGtSbpy"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"i1xQt-8FxVXG","executionInfo":{"status":"ok","timestamp":1651223356990,"user_tz":-60,"elapsed":440,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  accuracies = []\n","  for k in range(1,30):\n","    final_classifications = {}\n","\n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = []\n","      for t in timestamps:\n","        train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","        test_data = get_test_data_knn(test_sample, t)\n","        pred = KNN(k, test_data, train_data, train_labels, 'cosine')\n","        predictions.append(pred)\n","      \n","      time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","      \n","      classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","      final_classifications[key] = (classification, true_label_dict[key])\n","\n","    acc = accuracy(final_classifications)\n","    accuracies.append(acc)\n","    print(f\"K: {k} \\t Accuracy: {acc}\")\n","    # print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"WwBbkDraFWF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651223439592,"user_tz":-60,"elapsed":80389,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"121c194c-3cf6-4f11-bc17-63a2cb7324bc"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["K: 1 \t Accuracy: 0.5306122448979592\n","K: 2 \t Accuracy: 0.5306122448979592\n","K: 3 \t Accuracy: 0.6326530612244898\n","K: 4 \t Accuracy: 0.5102040816326531\n","K: 5 \t Accuracy: 0.6530612244897959\n","K: 6 \t Accuracy: 0.42857142857142855\n","K: 7 \t Accuracy: 0.5714285714285714\n","K: 8 \t Accuracy: 0.5102040816326531\n","K: 9 \t Accuracy: 0.42857142857142855\n","K: 10 \t Accuracy: 0.4489795918367347\n","K: 11 \t Accuracy: 0.30612244897959184\n","K: 12 \t Accuracy: 0.2857142857142857\n","K: 13 \t Accuracy: 0.42857142857142855\n","K: 14 \t Accuracy: 0.2857142857142857\n","K: 15 \t Accuracy: 0.4489795918367347\n","K: 16 \t Accuracy: 0.3469387755102041\n","K: 17 \t Accuracy: 0.5306122448979592\n","K: 18 \t Accuracy: 0.4897959183673469\n","K: 19 \t Accuracy: 0.5510204081632653\n","K: 20 \t Accuracy: 0.5102040816326531\n","K: 21 \t Accuracy: 0.5714285714285714\n","K: 22 \t Accuracy: 0.5102040816326531\n","K: 23 \t Accuracy: 0.5510204081632653\n","K: 24 \t Accuracy: 0.3877551020408163\n","K: 25 \t Accuracy: 0.4489795918367347\n","K: 26 \t Accuracy: 0.42857142857142855\n","K: 27 \t Accuracy: 0.5714285714285714\n","K: 28 \t Accuracy: 0.5714285714285714\n","K: 29 \t Accuracy: 0.5714285714285714\n"]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = np.arange(1,30)\n","y = accuracies\n","axes.set_xlabel(\"K\")\n","axes.set_ylabel(\"Accuracy (%)\")\n","axes.plot(x,y)"],"metadata":{"id":"P8t0E1pS9YNL","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"ok","timestamp":1651163589172,"user_tz":-60,"elapsed":375,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"47731886-39e2-42ae-8886-ef0571cebd08"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7efd8e0d7dd0>]"]},"metadata":{},"execution_count":62},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Confidence "],"metadata":{"id":"qXrQKuQm8ery"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"oZRyLyYo7k36"}},{"cell_type":"code","source":["def get_rH_00(true_vals, classifier_outputs):\n","  correct_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 0)):\n","      correct_pred_0 += 1\n","\n","  return correct_pred_0/total_pred_0\n","\n","\n","def get_rH_01(true_vals, classifier_outputs):\n","  wrong_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 0)):\n","      wrong_pred_1 += 1\n","    \n","  return wrong_pred_1/total_pred_1\n","\n","def get_rH_10(true_vals, classifier_outputs):\n","  wrong_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 1)):\n","      wrong_pred_0 += 1\n","  \n","  return wrong_pred_0/total_pred_0\n","\n","def get_rH_11(true_vals, classifier_outputs):\n","  correct_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 1)):\n","      correct_pred_1 += 1\n","\n","  return correct_pred_1/total_pred_1"],"metadata":{"id":"6IQ6mN5uJ6z1","executionInfo":{"status":"ok","timestamp":1651225096409,"user_tz":-60,"elapsed":410,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["def get_confidence_multipliers(sample_predictions, true_labels):\n","\n","  sample_predictions = np.asarray(sample_predictions) # array of all predictions made by every classifer for all samples\n","\n","  #2d array of all possible multipliers for each classifier\n","  multipliers_final = []\n","\n","  # generate 4 multipliers for each classifier\n","  for classifier in range(len(sample_predictions[0])):\n","    classifier_output = sample_predictions[:, classifier]\n","\n","    rH_00 = get_rH_00(true_labels, classifier_output)\n","    rH_01 = get_rH_01(true_labels, classifier_output)\n","    rH_10 = get_rH_10(true_labels, classifier_output)\n","    rH_11 = get_rH_11(true_labels, classifier_output)\n","    multipliers_classfier = [rH_00, rH_01, rH_10, rH_11] \n","\n","    # add multipliers to 2d array\n","    multipliers_final.append(multipliers_classfier)\n","\n","  return multipliers_final"],"metadata":{"id":"5r-wTh3nlga0","executionInfo":{"status":"ok","timestamp":1651225096901,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["def get_confidence(preds, multipliers):\n","  \n","  # initialise variable\n","  confidence = 1\n","\n","  # the prediction for which the confidence is being calculated -- predication at time t by classifier Ht (most recent prediction)\n","  pred_t = preds[-1]\n","\n","  for idx , pred in enumerate(preds):\n","    # prediction at time k made by classifier Hk\n","    pred_k = pred\n","\n","    # array of multipliers for Hk \n","    multiplier_k = multipliers[idx]\n","\n","    if(pred_t == 0 and pred_k == 0):\n","        confidence*=(1-multiplier_k[0])\n","    elif(pred_t == 0 and pred_k == 1):\n","        confidence*=(1-multiplier_k[1])\n","    elif(pred_t == 1 and pred_k == 0):\n","        confidence*=(1-multiplier_k[2])  \n","    elif(pred_t == 1 and pred_k == 1):\n","        confidence*=(1-multiplier_k[3])\n","        \n","        \n","\n","  confidence = 1 - confidence\n","\n","  return confidence\n","  "],"metadata":{"id":"8SmPp5iDzHQJ","executionInfo":{"status":"ok","timestamp":1651225097280,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":135,"outputs":[]},{"cell_type":"code","source":["def generate_predictions_table(positives, negatives, timestamps):\n","\n","  sample_predictions = []\n","\n","  true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(5, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    sample_predictions.append(predictions)\n","\n","  return sample_predictions, true_labels"],"metadata":{"id":"Qfe-e7-84_Zc","executionInfo":{"status":"ok","timestamp":1651225097648,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":136,"outputs":[]},{"cell_type":"markdown","source":["#### Random Threshold Testing"],"metadata":{"id":"bwcY82bSq0t6"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651225099379,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"bZnftjyQxXcw"},"execution_count":137,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651223602989,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"asGaVch58nEo"},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651223603723,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8abc0258-5e16-4277-d6ca-13b394647341","id":"YF_lFeGo8nE2"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"68OVHXKmw-Hg","executionInfo":{"status":"ok","timestamp":1651223605301,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","  \n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","      if(c >= 0.9869661240808167): # onfidence threshold\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","        if(pred == 1.0):\n","          print(f\"Earliness:  {time_index/timestamps[-1]}\")\n","          print(f\"TTP: {time_to_result+30}s\")\n","          ttps.append(time_to_result+30) # 30 second delay from reaction start when preprocessing\n","          earliness.append(time_index/timestamps[-1])\n","        break\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxnI-jcElWhV","executionInfo":{"status":"ok","timestamp":1651223613483,"user_tz":-60,"elapsed":5452,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8d54f2a8-f69d-4a98-b6c1-49dd64ea773b"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.32\n","TTP: 376.0s\n","\n","Sample exp_86_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 156.0s\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.16\n","TTP: 207.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.14\n","TTP: 188.0s\n","\n","Sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 164.0s\n","\n","Sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.2\n","TTP: 253.0s\n","\n","Sample exp_40_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 164.0s\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.08\n","TTP: 118.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 140.0s\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.14\n","TTP: 204s\n","\n","Sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 157.0s\n","\n","Sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 158.0s\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 159.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 139.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 163.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 167.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 164.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 161.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.18\n","TTP: 231.0s\n","\n","Sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 154.0s\n","\n","Sample rv1y_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.18\n","TTP: 226.0s\n","\n","Sample rv1y_p4\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 166.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 224.0s\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 157.0s\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 161.0s\n","\n","Sample b5\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_118_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 162s\n","\n","Sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 168s\n","\n","Sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 161s\n","\n","Sample exp_165_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_35_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 169s\n","\n","Sample exp_28_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 150s\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 174s\n","\n","Sample exp_40_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 166s\n","\n","Sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_134_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.14\n","TTP: 201.0s\n","\n","Sample exp_97_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.14\n","TTP: 181s\n","\n","Sample exp_2d1_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 138s\n","\n","Sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 162s\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.14\n","TTP: 190.0s\n","\n","Sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.14\n","TTP: 189.0s\n","\n","Sample yap1n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 159.0s\n","\n","Sample arv72\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 157.0s\n","\n","Sample arv73\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.14\n","TTP: 182.0s\n","\n","Sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 165.0s\n","\n","Sample arv7\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.16\n","TTP: 213.0s\n","\n","Accuracy: 0.5714285714285714\n","Sensitivity/Recall: 0.8928571428571429\n","Specificity: 0.14285714285714285\n","Precision: 0.5813953488372093\n","F1 Score: 0.7042253521126761\n"]}]},{"cell_type":"markdown","source":["#### Learning best threshold"],"metadata":{"id":"KPuLuWoixCSR"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651225105749,"user_tz":-60,"elapsed":479,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"HAfi2bU4phQC"},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651225107306,"user_tz":-60,"elapsed":1,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"ps-swVLHphQD"},"execution_count":139,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651225108231,"user_tz":-60,"elapsed":450,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"a38a2c92-e714-4867-c1e6-f3a27c561acb","id":"z-c4frksphQD"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651225110056,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"r0eTLRQophQD"},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":["##### Generating candidates"],"metadata":{"id":"ErEA8XSGqh8a"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"_m7lA1HIer-y","executionInfo":{"status":"ok","timestamp":1651225119794,"user_tz":-60,"elapsed":3449,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":142,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"yVEuBQRb1BpE","executionInfo":{"status":"ok","timestamp":1651225119794,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":143,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are the set of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"rI2uBt6fxLlF","executionInfo":{"status":"ok","timestamp":1651225119795,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTV9vJPW5zUg","executionInfo":{"status":"ok","timestamp":1651225119795,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8b22375d-a956-4b13-f021-d43e3a98430c"},"execution_count":145,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1560"]},"metadata":{},"execution_count":145}]},{"cell_type":"markdown","source":["##### Evaluating candidates"],"metadata":{"id":"872Hxw3fqlfv"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # array to hold cost function value for each candidate\n","  cost_function_values = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # alpha\n","  alpha = 0.75\n","\n","  # evaluate every candidate\n","  for th in threshold_candidates:\n","\n","    print(f\"Candidate: {th} \")\n","\n","    # array to hold earliness values for the samples \n","    earliness = []  \n","\n","    # dict to hold predictions vs true values for the samples  \n","    final_classifications = {}\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      # get KNN predicition for the sample\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","        \n","        # get the confidence for that prediction \n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","        if(c >= th): # check if confidence is at or above confidence threshold\n","\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          # predicted class for the sample is given by the prediction which led to the gien confidence value\n","          pred = predictions[i]\n","\n","          # update final outcomes dict\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","          # add to earliness array\n","          earliness.append(time_index/timestamps[-1])\n","\n","          break\n","\n","      sample_idx += 1\n","\n","    # get avg accuracy and avg earliness for this threshold\n","    if(len(final_classifications) > 0):\n","      avg_accuracy = accuracy(final_classifications)\n","      avg_earliness = sum(earliness)/len(earliness)\n","\n","      # compute value of cost function and add to array \n","      cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","      cost_function_values.append(cf_score)\n","      print(f\"Score: {cf_score}\")\n","      print(\"\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKc1S0R6ebff","executionInfo":{"status":"ok","timestamp":1651225163657,"user_tz":-60,"elapsed":39178,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"a7d2e0e8-0b90-43a0-b03b-9f2af90cb836"},"execution_count":146,"outputs":[{"output_type":"stream","name":"stdout","text":["Candidate: 0.45141065830721 \n","Score: 0.2652040816326531\n","\n","Candidate: 0.5648902821316615 \n","Score: 0.2652040816326531\n","\n","Candidate: 0.6171368861024034 \n","Score: 0.35908163265306126\n","\n","Candidate: 0.6353187042842214 \n","Score: 0.35908163265306126\n","\n","Candidate: 0.6602870813397128 \n","Score: 0.32887755102040817\n","\n","Candidate: 0.6869328493647913 \n","Score: 0.3458163265306123\n","\n","Candidate: 0.7084639498432602 \n","Score: 0.44255102040816324\n","\n","Candidate: 0.7288951218170818 \n","Score: 0.4427551020408163\n","\n","Candidate: 0.7427542209756366 \n","Score: 0.4127551020408163\n","\n","Candidate: 0.7714348567343122 \n","Score: 0.4127551020408163\n","\n","Candidate: 0.7986580872243304 \n","Score: 0.42826530612244895\n","\n","Candidate: 0.8148911987387486 \n","Score: 0.42826530612244895\n","\n","Candidate: 0.8285028139837577 \n","Score: 0.4286734693877551\n","\n","Candidate: 0.8369905956112853 \n","Score: 0.43132653061224485\n","\n","Candidate: 0.8405103668261563 \n","Score: 0.4018367346938776\n","\n","Candidate: 0.8507974481658692 \n","Score: 0.4019387755102041\n","\n","Candidate: 0.8603829362202569 \n","Score: 0.4024489795918368\n","\n","Candidate: 0.8680279245901303 \n","Score: 0.4024489795918368\n","\n","Candidate: 0.8749963605306832 \n","Score: 0.4028571428571429\n","\n","Candidate: 0.8831408458450201 \n","Score: 0.4028571428571429\n","\n","Candidate: 0.8926368952684742 \n","Score: 0.4031632653061225\n","\n","Candidate: 0.8963813430558386 \n","Score: 0.40326530612244904\n","\n","Candidate: 0.8979601293236201 \n","Score: 0.3883673469387755\n","\n","Candidate: 0.8991257110002575 \n","Score: 0.3883673469387755\n","\n","Candidate: 0.9042603480090858 \n","Score: 0.3883673469387755\n","\n","Candidate: 0.9100078274199104 \n","Score: 0.3883673469387755\n","\n","Candidate: 0.9133220856773342 \n","Score: 0.35867346938775513\n","\n","Candidate: 0.9170158178472725 \n","Score: 0.3762244897959184\n","\n","Candidate: 0.9183678615433796 \n","Score: 0.3762244897959184\n","\n","Candidate: 0.9188007918804163 \n","Score: 0.39183673469387753\n","\n","Candidate: 0.9227445804258018 \n","Score: 0.3768367346938776\n","\n","Candidate: 0.9274978891077963 \n","Score: 0.3769387755102041\n","\n","Candidate: 0.9321292446440808 \n","Score: 0.4077551020408164\n","\n","Candidate: 0.9374956825903202 \n","Score: 0.4077551020408164\n","\n","Candidate: 0.9393830777418456 \n","Score: 0.4079591836734694\n","\n","Candidate: 0.9398614657642712 \n","Score: 0.3927551020408163\n","\n","Candidate: 0.940476074937482 \n","Score: 0.37755102040816324\n","\n","Candidate: 0.9432101123953258 \n","Score: 0.37755102040816324\n","\n","Candidate: 0.9464997203025607 \n","Score: 0.3777551020408163\n","\n","Candidate: 0.9495377265632592 \n","Score: 0.3777551020408163\n","\n","Candidate: 0.9521015123789808 \n","Score: 0.3777551020408163\n","\n","Candidate: 0.9525663208801445 \n","Score: 0.378469387755102\n","\n","Candidate: 0.9532841129333385 \n","Score: 0.378469387755102\n","\n","Candidate: 0.9546646699937938 \n","Score: 0.3652040816326531\n","\n","Candidate: 0.9560896983346936 \n","Score: 0.3654081632653062\n","\n","Candidate: 0.9574286186578138 \n","Score: 0.36571428571428577\n","\n","Candidate: 0.9599130205143477 \n","Score: 0.36571428571428577\n","\n","Candidate: 0.963157750134604 \n","Score: 0.3506122448979592\n","\n","Candidate: 0.9647512304992572 \n","Score: 0.3506122448979592\n","\n","Candidate: 0.9661044985777778 \n","Score: 0.35071428571428576\n","\n","Candidate: 0.9681039789431231 \n","Score: 0.3509183673469388\n","\n","Candidate: 0.9691454936333962 \n","Score: 0.3510204081632653\n","\n","Candidate: 0.9706654033531963 \n","Score: 0.3512244897959184\n","\n","Candidate: 0.9719562493143827 \n","Score: 0.35183673469387755\n","\n","Candidate: 0.9730406548228345 \n","Score: 0.3520408163265306\n","\n","Candidate: 0.974633188005471 \n","Score: 0.3520408163265306\n","\n","Candidate: 0.9752933626476967 \n","Score: 0.36744897959183676\n","\n","Candidate: 0.9754618175550138 \n","Score: 0.3535714285714286\n","\n","Candidate: 0.975771826545118 \n","Score: 0.3536734693877551\n","\n","Candidate: 0.9764600108528863 \n","Score: 0.3538775510204082\n","\n","Candidate: 0.9772583572390375 \n","Score: 0.3539795918367347\n","\n","Candidate: 0.9776082054666446 \n","Score: 0.3541836734693878\n","\n","Candidate: 0.9776778380373017 \n","Score: 0.35469387755102044\n","\n","Candidate: 0.9777599688049521 \n","Score: 0.354795918367347\n","\n","Candidate: 0.978001820020107 \n","Score: 0.354795918367347\n","\n","Candidate: 0.9789248259559225 \n","Score: 0.354795918367347\n","\n","Candidate: 0.9799616396081176 \n","Score: 0.37030612244897965\n","\n","Candidate: 0.9805113839162392 \n","Score: 0.37030612244897965\n","\n","Candidate: 0.9808342984289203 \n","Score: 0.3705102040816327\n","\n","Candidate: 0.9812996788366586 \n","Score: 0.3705102040816327\n","\n","Candidate: 0.9828233306637123 \n","Score: 0.37061224489795924\n","\n","Candidate: 0.9840015474370967 \n","Score: 0.37061224489795924\n","\n","Candidate: 0.9840208787689304 \n","Score: 0.3555102040816327\n","\n","Candidate: 0.9841631777331058 \n","Score: 0.3555102040816327\n","\n","Candidate: 0.9848786062302535 \n","Score: 0.35561224489795923\n","\n","Candidate: 0.9855400265356467 \n","Score: 0.35571428571428576\n","\n","Candidate: 0.9859177486630253 \n","Score: 0.3558163265306123\n","\n","Candidate: 0.986266959760369 \n","Score: 0.3558163265306123\n","\n","Candidate: 0.9864280185758514 \n","Score: 0.3558163265306123\n","\n","Candidate: 0.9868180824656814 \n","Score: 0.3559183673469388\n","\n","Candidate: 0.9871646566882071 \n","Score: 0.3561224489795919\n","\n","Candidate: 0.9872680346560245 \n","Score: 0.37153061224489803\n","\n","Candidate: 0.9873625884056959 \n","Score: 0.37153061224489803\n","\n","Candidate: 0.9875306360589702 \n","Score: 0.37153061224489803\n","\n","Candidate: 0.9878202559690763 \n","Score: 0.37153061224489803\n","\n","Candidate: 0.9880309538486667 \n","Score: 0.3716326530612245\n","\n","Candidate: 0.988174651497115 \n","Score: 0.37183673469387757\n","\n","Candidate: 0.9883019303507248 \n","Score: 0.37183673469387757\n","\n","Candidate: 0.9883651401668179 \n","Score: 0.3719387755102041\n","\n","Candidate: 0.9886118370047883 \n","Score: 0.373265306122449\n","\n","Candidate: 0.9889694911766219 \n","Score: 0.3890816326530612\n","\n","Candidate: 0.9891540370559027 \n","Score: 0.38918367346938776\n","\n","Candidate: 0.9894208010639092 \n","Score: 0.38918367346938776\n","\n","Candidate: 0.989701025783488 \n","Score: 0.38918367346938776\n","\n","Candidate: 0.989849655097496 \n","Score: 0.38918367346938776\n","\n","Candidate: 0.9899961135859503 \n","Score: 0.38918367346938776\n","\n","Candidate: 0.9900796098653484 \n","Score: 0.3892857142857143\n","\n","Candidate: 0.9903032327701298 \n","Score: 0.3893877551020408\n","\n","Candidate: 0.9905219413042718 \n","Score: 0.3893877551020408\n","\n","Candidate: 0.9906927357198533 \n","Score: 0.3893877551020408\n","\n","Candidate: 0.990852542412567 \n","Score: 0.38948979591836735\n","\n","Candidate: 0.9909078736363266 \n","Score: 0.40499999999999997\n","\n","Candidate: 0.9910352575551584 \n","Score: 0.40520408163265303\n","\n","Candidate: 0.9912710996857375 \n","Score: 0.40520408163265303\n","\n","Candidate: 0.9914700644800857 \n","Score: 0.40520408163265303\n","\n","Candidate: 0.9917110470379598 \n","Score: 0.40530612244897957\n","\n","Candidate: 0.9919550864867408 \n","Score: 0.40530612244897957\n","\n","Candidate: 0.9921341212792466 \n","Score: 0.4054081632653061\n","\n","Candidate: 0.9923552113725871 \n","Score: 0.40551020408163263\n","\n","Candidate: 0.9925345758647729 \n","Score: 0.40551020408163263\n","\n","Candidate: 0.9926736154141107 \n","Score: 0.40561224489795916\n","\n","Candidate: 0.9929170701507644 \n","Score: 0.4057142857142857\n","\n","Candidate: 0.9930981407739918 \n","Score: 0.4057142857142857\n","\n","Candidate: 0.9934742963011887 \n","Score: 0.42112244897959183\n","\n","Candidate: 0.9938650193312365 \n","Score: 0.42112244897959183\n","\n","Candidate: 0.9939696149351811 \n","Score: 0.42153061224489796\n","\n","Candidate: 0.9941146165157708 \n","Score: 0.42153061224489796\n","\n","Candidate: 0.9941964850083607 \n","Score: 0.4216326530612245\n","\n","Candidate: 0.9942375364034517 \n","Score: 0.4229591836734694\n","\n","Candidate: 0.9942756323991984 \n","Score: 0.4229591836734694\n","\n","Candidate: 0.9943326603974476 \n","Score: 0.4241836734693878\n","\n","Candidate: 0.9944295537398478 \n","Score: 0.42438775510204085\n","\n","Candidate: 0.9945232250705662 \n","Score: 0.42438775510204085\n","\n","Candidate: 0.9946028058261103 \n","Score: 0.4244897959183674\n","\n","Candidate: 0.9947194434059579 \n","Score: 0.4245918367346939\n","\n","Candidate: 0.9948643644353306 \n","Score: 0.4245918367346939\n","\n","Candidate: 0.995044352736091 \n","Score: 0.424795918367347\n","\n","Candidate: 0.9951634809239389 \n","Score: 0.4251020408163266\n","\n","Candidate: 0.9952173467725041 \n","Score: 0.4252040816326531\n","\n","Candidate: 0.9952875089950939 \n","Score: 0.4252040816326531\n","\n","Candidate: 0.9953851888516135 \n","Score: 0.42530612244897964\n","\n","Candidate: 0.9955032764140173 \n","Score: 0.4255102040816327\n","\n","Candidate: 0.9955540108309738 \n","Score: 0.4255102040816327\n","\n","Candidate: 0.9955991836876359 \n","Score: 0.42561224489795924\n","\n","Candidate: 0.9956355817896505 \n","Score: 0.42561224489795924\n","\n","Candidate: 0.9956684595739824 \n","Score: 0.42571428571428577\n","\n","Candidate: 0.9957242138247189 \n","Score: 0.42571428571428577\n","\n","Candidate: 0.9957925691186809 \n","Score: 0.4258163265306123\n","\n","Candidate: 0.9958899991869763 \n","Score: 0.42591836734693883\n","\n","Candidate: 0.9960156317179556 \n","Score: 0.42591836734693883\n","\n","Candidate: 0.9962311046107137 \n","Score: 0.42602040816326536\n","\n","Candidate: 0.996426487140889 \n","Score: 0.4261224489795919\n","\n","Candidate: 0.9966031210506409 \n","Score: 0.4261224489795919\n","\n","Candidate: 0.9967646060121842 \n","Score: 0.4262244897959184\n","\n","Candidate: 0.9968212271894926 \n","Score: 0.42632653061224496\n","\n","Candidate: 0.9968428617604751 \n","Score: 0.41234693877551015\n","\n","Candidate: 0.9968518860586884 \n","Score: 0.4124489795918367\n","\n","Candidate: 0.9969441543903332 \n","Score: 0.4128571428571428\n","\n","Candidate: 0.9970326721389837 \n","Score: 0.4128571428571428\n","\n","Candidate: 0.9971132198987711 \n","Score: 0.41295918367346934\n","\n","Candidate: 0.9972429432611342 \n","Score: 0.4131632653061224\n","\n","Candidate: 0.9973076504303804 \n","Score: 0.4131632653061224\n","\n","Candidate: 0.9973874618353542 \n","Score: 0.41326530612244894\n","\n","Candidate: 0.9974905717149891 \n","Score: 0.41336734693877547\n","\n","Candidate: 0.9975358420646364 \n","Score: 0.41357142857142853\n","\n","Candidate: 0.997589680437375 \n","Score: 0.41367346938775507\n","\n","Candidate: 0.997642581737689 \n","Score: 0.4137755102040816\n","\n","Candidate: 0.9976527392052208 \n","Score: 0.41387755102040813\n","\n","Candidate: 0.9976537611380372 \n","Score: 0.4140816326530612\n","\n","Candidate: 0.9976542193850633 \n","Score: 0.4141836734693877\n","\n","Candidate: 0.9977129878849806 \n","Score: 0.41428571428571426\n","\n","Candidate: 0.9977836820022981 \n","Score: 0.41428571428571426\n","\n","Candidate: 0.9978115881937031 \n","Score: 0.41428571428571426\n","\n","Candidate: 0.997846572111033 \n","Score: 0.4143877551020408\n","\n","Candidate: 0.9978965350698724 \n","Score: 0.4144897959183673\n","\n","Candidate: 0.9979496657762543 \n","Score: 0.4144897959183673\n","\n","Candidate: 0.997980596953284 \n","Score: 0.4144897959183673\n","\n","Candidate: 0.9979943939848843 \n","Score: 0.39928571428571424\n","\n","Candidate: 0.9980675098737617 \n","Score: 0.39938775510204083\n","\n","Candidate: 0.9981679725751852 \n","Score: 0.39938775510204083\n","\n","Candidate: 0.9982324323207417 \n","Score: 0.3994897959183673\n","\n","Candidate: 0.9983199758320941 \n","Score: 0.4148979591836734\n","\n","Candidate: 0.9983789078846028 \n","Score: 0.4161224489795918\n","\n","Candidate: 0.9983828846051227 \n","Score: 0.4165306122448979\n","\n","Candidate: 0.9983837090732471 \n","Score: 0.4165306122448979\n","\n","Candidate: 0.9984255173951327 \n","Score: 0.41663265306122443\n","\n","Candidate: 0.9984715758452659 \n","Score: 0.4168367346938775\n","\n","Candidate: 0.9984779919392555 \n","Score: 0.4016326530612245\n","\n","Candidate: 0.9985089073200055 \n","Score: 0.4016326530612245\n","\n","Candidate: 0.9985479314819412 \n","Score: 0.401734693877551\n","\n","Candidate: 0.9985862869288484 \n","Score: 0.401734693877551\n","\n","Candidate: 0.9986370777127969 \n","Score: 0.401734693877551\n","\n","Candidate: 0.9986700269860214 \n","Score: 0.40183673469387754\n","\n","Candidate: 0.9986838464541551 \n","Score: 0.40193877551020407\n","\n","Candidate: 0.9986875374806768 \n","Score: 0.4020408163265306\n","\n","Candidate: 0.9986896271489958 \n","Score: 0.4020408163265306\n","\n","Candidate: 0.9987094368819944 \n","Score: 0.40214285714285714\n","\n","Candidate: 0.9987699114764914 \n","Score: 0.4023469387755102\n","\n","Candidate: 0.9988406681822661 \n","Score: 0.4023469387755102\n","\n","Candidate: 0.9988771323595116 \n","Score: 0.40244897959183673\n","\n","Candidate: 0.9988938721735937 \n","Score: 0.40244897959183673\n","\n","Candidate: 0.998908041472803 \n","Score: 0.40255102040816326\n","\n","Candidate: 0.9989567499245077 \n","Score: 0.4026530612244898\n","\n","Candidate: 0.9990151507953555 \n","Score: 0.403265306122449\n","\n","Candidate: 0.9990318340235695 \n","Score: 0.4033673469387755\n","\n","Candidate: 0.999035262423792 \n","Score: 0.40346938775510205\n","\n","Candidate: 0.999040970422661 \n","Score: 0.4035714285714286\n","\n","Candidate: 0.9991038954203033 \n","Score: 0.4035714285714286\n","\n","Candidate: 0.999169622695855 \n","Score: 0.40479591836734696\n","\n","Candidate: 0.9991779609113218 \n","Score: 0.40479591836734696\n","\n","Candidate: 0.9991804772498989 \n","Score: 0.4048979591836735\n","\n","Candidate: 0.9991860856771252 \n","Score: 0.4048979591836735\n","\n","Candidate: 0.9991996893445887 \n","Score: 0.40530612244897957\n","\n","Candidate: 0.9992099924872011 \n","Score: 0.40530612244897957\n","\n","Candidate: 0.999219208969543 \n","Score: 0.40551020408163263\n","\n","Candidate: 0.9992294714344512 \n","Score: 0.4057142857142857\n","\n","Candidate: 0.9992358396479682 \n","Score: 0.4057142857142857\n","\n","Candidate: 0.9992437288045628 \n","Score: 0.4058163265306123\n","\n","Candidate: 0.9992490814228446 \n","Score: 0.4064285714285714\n","\n","Candidate: 0.9992702830137605 \n","Score: 0.4064285714285714\n","\n","Candidate: 0.9992922325794074 \n","Score: 0.40653061224489795\n","\n","Candidate: 0.9993099849973933 \n","Score: 0.4066326530612245\n","\n","Candidate: 0.9993351644543608 \n","Score: 0.406734693877551\n","\n","Candidate: 0.9993475265375142 \n","Score: 0.4069387755102041\n","\n","Candidate: 0.9993521497656275 \n","Score: 0.4070408163265306\n","\n","Candidate: 0.9993700746272554 \n","Score: 0.40714285714285714\n","\n","Candidate: 0.9993906963903918 \n","Score: 0.40714285714285714\n","\n","Candidate: 0.9994005597977145 \n","Score: 0.40724489795918367\n","\n","Candidate: 0.9994068409145593 \n","Score: 0.40724489795918367\n","\n","Candidate: 0.9994210167117619 \n","Score: 0.4073469387755102\n","\n","Candidate: 0.9994579565505319 \n","Score: 0.4074489795918368\n","\n","Candidate: 0.9994982979269806 \n","Score: 0.40755102040816327\n","\n","Candidate: 0.9995339539886721 \n","Score: 0.4076530612244898\n","\n","Candidate: 0.9995582243156409 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.9995726943472407 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.9995877536498041 \n","Score: 0.39367346938775516\n","\n","Candidate: 0.9995947269711507 \n","Score: 0.3938775510204082\n","\n","Candidate: 0.9995987211465729 \n","Score: 0.39428571428571435\n","\n","Candidate: 0.9996024600345352 \n","Score: 0.3943877551020409\n","\n","Candidate: 0.9996081918014276 \n","Score: 0.3943877551020409\n","\n","Candidate: 0.9996145716652931 \n","Score: 0.39459183673469395\n","\n","Candidate: 0.9996177557720518 \n","Score: 0.39459183673469395\n","\n","Candidate: 0.9996364552559618 \n","Score: 0.3946938775510205\n","\n","Candidate: 0.9996537080942274 \n","Score: 0.41010204081632656\n","\n","Candidate: 0.9996585942449978 \n","Score: 0.4102040816326531\n","\n","Candidate: 0.9996644988653207 \n","Score: 0.4103061224489796\n","\n","Candidate: 0.9996670228175504 \n","Score: 0.41040816326530616\n","\n","Candidate: 0.99967010617941 \n","Score: 0.41040816326530616\n","\n","Candidate: 0.9996780330294834 \n","Score: 0.4106122448979592\n","\n","Candidate: 0.999685097120782 \n","Score: 0.4106122448979592\n","\n","Candidate: 0.9996908030994711 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9997015422613025 \n","Score: 0.4108163265306123\n","\n","Candidate: 0.999711288111679 \n","Score: 0.41091836734693876\n","\n","Candidate: 0.9997160218409366 \n","Score: 0.41091836734693876\n","\n","Candidate: 0.9997289782752661 \n","Score: 0.41102040816326535\n","\n","Candidate: 0.9997409337796677 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9997471526579875 \n","Score: 0.4112244897959184\n","\n","Candidate: 0.9997602271673203 \n","Score: 0.41244897959183674\n","\n","Candidate: 0.9997686410388176 \n","Score: 0.41255102040816327\n","\n","Candidate: 0.9997718343796376 \n","Score: 0.4126530612244898\n","\n","Candidate: 0.9997770844948941 \n","Score: 0.41275510204081634\n","\n","Candidate: 0.9997804442455303 \n","Score: 0.41316326530612246\n","\n","Candidate: 0.9997828137894513 \n","Score: 0.41316326530612246\n","\n","Candidate: 0.9997871418507958 \n","Score: 0.41316326530612246\n","\n","Candidate: 0.9997899524884464 \n","Score: 0.4133673469387755\n","\n","Candidate: 0.9997916892739511 \n","Score: 0.4144897959183673\n","\n","Candidate: 0.9997947657392511 \n","Score: 0.41459183673469385\n","\n","Candidate: 0.9998014241299851 \n","Score: 0.4147959183673469\n","\n","Candidate: 0.9998130810046539 \n","Score: 0.43224489795918364\n","\n","Candidate: 0.9998203251617388 \n","Score: 0.43224489795918364\n","\n","Candidate: 0.9998205734996954 \n","Score: 0.43224489795918364\n","\n","Candidate: 0.9998243622687473 \n","Score: 0.4323469387755101\n","\n","Candidate: 0.9998297194447492 \n","Score: 0.4324489795918367\n","\n","Candidate: 0.9998318395316528 \n","Score: 0.4325510204081632\n","\n","Candidate: 0.9998341376896518 \n","Score: 0.43265306122448977\n","\n","Candidate: 0.9998360892715892 \n","Score: 0.43275510204081624\n","\n","Candidate: 0.9998395609411841 \n","Score: 0.4329591836734693\n","\n","Candidate: 0.9998508294323778 \n","Score: 0.4330612244897959\n","\n","Candidate: 0.9998627702749758 \n","Score: 0.43316326530612237\n","\n","Candidate: 0.999868361591469 \n","Score: 0.4332653061224489\n","\n","Candidate: 0.9998747561163701 \n","Score: 0.43336734693877543\n","\n","Candidate: 0.9998799172484995 \n","Score: 0.43346938775510196\n","\n","Candidate: 0.9998804781615735 \n","Score: 0.4190816326530612\n","\n","Candidate: 0.9998811472028213 \n","Score: 0.4194897959183673\n","\n","Candidate: 0.9998824601349647 \n","Score: 0.4195918367346939\n","\n","Candidate: 0.9998836014990811 \n","Score: 0.4196938775510204\n","\n","Candidate: 0.9998840647894305 \n","Score: 0.419795918367347\n","\n","Candidate: 0.9998853986048524 \n","Score: 0.419795918367347\n","\n","Candidate: 0.9998889869991954 \n","Score: 0.4362244897959183\n","\n","Candidate: 0.9998924327214376 \n","Score: 0.4364285714285714\n","\n","Candidate: 0.9998953106882885 \n","Score: 0.4365306122448979\n","\n","Candidate: 0.9998978860481333 \n","Score: 0.4365306122448979\n","\n","Candidate: 0.9999003909348602 \n","Score: 0.436734693877551\n","\n","Candidate: 0.9999032100396948 \n","Score: 0.436734693877551\n","\n","Candidate: 0.9999046125285346 \n","Score: 0.4368367346938775\n","\n","Candidate: 0.9999062271531027 \n","Score: 0.43693877551020405\n","\n","Candidate: 0.999907930384549 \n","Score: 0.421734693877551\n","\n","Candidate: 0.9999097723188062 \n","Score: 0.42183673469387756\n","\n","Candidate: 0.999912504191721 \n","Score: 0.4220408163265306\n","\n","Candidate: 0.9999168027425074 \n","Score: 0.42214285714285715\n","\n","Candidate: 0.9999205669676583 \n","Score: 0.42214285714285715\n","\n","Candidate: 0.9999223855978054 \n","Score: 0.4222448979591837\n","\n","Candidate: 0.9999242191088077 \n","Score: 0.4223469387755102\n","\n","Candidate: 0.9999256080295329 \n","Score: 0.4223469387755102\n","\n","Candidate: 0.9999263845471018 \n","Score: 0.4223469387755102\n","\n","Candidate: 0.9999288538031175 \n","Score: 0.4223469387755102\n","\n","Candidate: 0.9999312058580261 \n","Score: 0.42244897959183675\n","\n","Candidate: 0.9999348915875352 \n","Score: 0.4225510204081633\n","\n","Candidate: 0.9999388909349749 \n","Score: 0.4235714285714286\n","\n","Candidate: 0.9999395752643283 \n","Score: 0.4236734693877551\n","\n","Candidate: 0.9999402304332106 \n","Score: 0.4236734693877551\n","\n","Candidate: 0.9999412300674824 \n","Score: 0.42377551020408166\n","\n","Candidate: 0.9999429222460634 \n","Score: 0.42387755102040814\n","\n","Candidate: 0.9999445068698568 \n","Score: 0.4240816326530612\n","\n","Candidate: 0.9999449670052373 \n","Score: 0.42428571428571427\n","\n","Candidate: 0.9999451178233919 \n","Score: 0.42438775510204085\n","\n","Candidate: 0.9999452130576767 \n","Score: 0.42448979591836733\n","\n","Candidate: 0.9999454320804881 \n","Score: 0.42489795918367346\n","\n","Candidate: 0.9999474321398065 \n","Score: 0.42489795918367346\n","\n","Candidate: 0.9999497874471508 \n","Score: 0.425\n","\n","Candidate: 0.999950398785697 \n","Score: 0.4251020408163265\n","\n","Candidate: 0.9999510804262308 \n","Score: 0.42520408163265305\n","\n","Candidate: 0.9999519200952625 \n","Score: 0.42540816326530617\n","\n","Candidate: 0.9999523642956969 \n","Score: 0.42551020408163265\n","\n","Candidate: 0.9999547897528467 \n","Score: 0.42551020408163265\n","\n","Candidate: 0.9999571167837057 \n","Score: 0.42561224489795924\n","\n","Candidate: 0.9999577928859718 \n","Score: 0.42561224489795924\n","\n","Candidate: 0.9999593266322491 \n","Score: 0.4257142857142857\n","\n","Candidate: 0.9999605326425585 \n","Score: 0.4257142857142857\n","\n","Candidate: 0.9999608410805098 \n","Score: 0.4258163265306123\n","\n","Candidate: 0.9999609611257807 \n","Score: 0.4259183673469388\n","\n","Candidate: 0.999963355517672 \n","Score: 0.4259183673469388\n","\n","Candidate: 0.9999664182962141 \n","Score: 0.4260204081632653\n","\n","Candidate: 0.999968030243892 \n","Score: 0.42612244897959184\n","\n","Candidate: 0.9999692431821064 \n","Score: 0.4262244897959184\n","\n","Candidate: 0.9999698138217994 \n","Score: 0.4262244897959184\n","\n","Candidate: 0.9999702263596727 \n","Score: 0.4264285714285715\n","\n","Candidate: 0.9999706150337412 \n","Score: 0.42653061224489797\n","\n","Candidate: 0.9999712667143938 \n","Score: 0.4266326530612245\n","\n","Candidate: 0.9999717316152188 \n","Score: 0.47357142857142853\n","\n","Candidate: 0.9999719260238568 \n","Score: 0.47397959183673466\n","\n","Candidate: 0.999972293276734 \n","Score: 0.4741836734693877\n","\n","Candidate: 0.9999727157579786 \n","Score: 0.47428571428571425\n","\n","Candidate: 0.9999741216013021 \n","Score: 0.47428571428571425\n","\n","Candidate: 0.9999759934284598 \n","Score: 0.4743877551020408\n","\n","Candidate: 0.9999769169873862 \n","Score: 0.4744897959183673\n","\n","Candidate: 0.9999772731408476 \n","Score: 0.47459183673469385\n","\n","Candidate: 0.999977401693619 \n","Score: 0.47459183673469385\n","\n","Candidate: 0.9999775752047201 \n","Score: 0.4746938775510204\n","\n","Candidate: 0.9999777598381399 \n","Score: 0.4746938775510204\n","\n","Candidate: 0.9999782518918328 \n","Score: 0.4748979591836734\n","\n","Candidate: 0.9999788964821319 \n","Score: 0.475\n","\n","Candidate: 0.9999791193674046 \n","Score: 0.47510204081632645\n","\n","Candidate: 0.9999795536628204 \n","Score: 0.475204081632653\n","\n","Candidate: 0.9999801294710293 \n","Score: 0.4448979591836734\n","\n","Candidate: 0.9999805763377789 \n","Score: 0.44499999999999995\n","\n","Candidate: 0.999981859141653 \n","Score: 0.4451020408163265\n","\n","Candidate: 0.9999833848377266 \n","Score: 0.445204081632653\n","\n","Candidate: 0.999983913560317 \n","Score: 0.44530612244897955\n","\n","Candidate: 0.9999840481611738 \n","Score: 0.4454081632653061\n","\n","Candidate: 0.9999845368145197 \n","Score: 0.44561224489795914\n","\n","Candidate: 0.9999850513638755 \n","Score: 0.4457142857142857\n","\n","Candidate: 0.9999853088694048 \n","Score: 0.43051020408163265\n","\n","Candidate: 0.9999855326436419 \n","Score: 0.4465306122448979\n","\n","Candidate: 0.999985844435902 \n","Score: 0.4465306122448979\n","\n","Candidate: 0.999986142676734 \n","Score: 0.4468367346938775\n","\n","Candidate: 0.9999862577105791 \n","Score: 0.4470408163265306\n","\n","Candidate: 0.9999865188451693 \n","Score: 0.44714285714285706\n","\n","Candidate: 0.9999869065155369 \n","Score: 0.4475510204081632\n","\n","Candidate: 0.9999871071285191 \n","Score: 0.43234693877551017\n","\n","Candidate: 0.9999872512604902 \n","Score: 0.43234693877551017\n","\n","Candidate: 0.9999875390075141 \n","Score: 0.4324489795918367\n","\n","Candidate: 0.9999879763806802 \n","Score: 0.43255102040816323\n","\n","Candidate: 0.9999882226863335 \n","Score: 0.43255102040816323\n","\n","Candidate: 0.9999882500630731 \n","Score: 0.43265306122448977\n","\n","Candidate: 0.9999883446738477 \n","Score: 0.4327551020408163\n","\n","Candidate: 0.9999884375149374 \n","Score: 0.41806122448979594\n","\n","Candidate: 0.9999885042425039 \n","Score: 0.41816326530612247\n","\n","Candidate: 0.9999893540198215 \n","Score: 0.4030612244897959\n","\n","Candidate: 0.9999903767391611 \n","Score: 0.40316326530612245\n","\n","Candidate: 0.9999906464067976 \n","Score: 0.40326530612244893\n","\n","Candidate: 0.9999906869155989 \n","Score: 0.40326530612244893\n","\n","Candidate: 0.9999909815032444 \n","Score: 0.4033673469387755\n","\n","Candidate: 0.999991330847726 \n","Score: 0.40346938775510205\n","\n","Candidate: 0.9999915065292653 \n","Score: 0.4035714285714286\n","\n","Candidate: 0.999991624542776 \n","Score: 0.4036734693877551\n","\n","Candidate: 0.9999917572034693 \n","Score: 0.40377551020408164\n","\n","Candidate: 0.9999920514096059 \n","Score: 0.4038775510204081\n","\n","Candidate: 0.999992317383704 \n","Score: 0.4039795918367347\n","\n","Candidate: 0.9999924391280064 \n","Score: 0.4040816326530612\n","\n","Candidate: 0.9999925015749508 \n","Score: 0.40489795918367344\n","\n","Candidate: 0.9999925439716 \n","Score: 0.405\n","\n","Candidate: 0.9999927322452562 \n","Score: 0.4051020408163265\n","\n","Candidate: 0.9999930393036589 \n","Score: 0.40530612244897957\n","\n","Candidate: 0.9999932557478971 \n","Score: 0.40591836734693876\n","\n","Candidate: 0.9999933633881704 \n","Score: 0.4060204081632653\n","\n","Candidate: 0.9999934524712355 \n","Score: 0.4061224489795918\n","\n","Candidate: 0.9999938119107148 \n","Score: 0.4061224489795918\n","\n","Candidate: 0.9999941353237258 \n","Score: 0.4061224489795918\n","\n","Candidate: 0.9999941983540053 \n","Score: 0.40622448979591835\n","\n","Candidate: 0.9999942249946405 \n","Score: 0.4063265306122449\n","\n","Candidate: 0.999994281169519 \n","Score: 0.4063265306122449\n","\n","Candidate: 0.9999943698078605 \n","Score: 0.406734693877551\n","\n","Candidate: 0.9999944485220383 \n","Score: 0.4068367346938776\n","\n","Candidate: 0.9999945656349001 \n","Score: 0.4069387755102041\n","\n","Candidate: 0.9999947948477776 \n","Score: 0.4070408163265306\n","\n","Candidate: 0.9999950448096702 \n","Score: 0.40714285714285714\n","\n","Candidate: 0.9999951762750612 \n","Score: 0.40724489795918367\n","\n","Candidate: 0.9999952140244435 \n","Score: 0.4073469387755102\n","\n","Candidate: 0.9999952884683279 \n","Score: 0.40744897959183674\n","\n","Candidate: 0.9999953691915973 \n","Score: 0.40744897959183674\n","\n","Candidate: 0.999995454176336 \n","Score: 0.40755102040816327\n","\n","Candidate: 0.999995642610715 \n","Score: 0.4076530612244898\n","\n","Candidate: 0.9999958192997335 \n","Score: 0.4076530612244898\n","\n","Candidate: 0.9999959174991433 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.9999959698198531 \n","Score: 0.39316326530612244\n","\n","Candidate: 0.999996033332439 \n","Score: 0.393265306122449\n","\n","Candidate: 0.999996089496337 \n","Score: 0.393265306122449\n","\n","Candidate: 0.9999961302869264 \n","Score: 0.3933673469387755\n","\n","Candidate: 0.9999961610450294 \n","Score: 0.39346938775510204\n","\n","Candidate: 0.9999962570448977 \n","Score: 0.39346938775510204\n","\n","Candidate: 0.9999964040083711 \n","Score: 0.39357142857142857\n","\n","Candidate: 0.9999965196287224 \n","Score: 0.3936734693877551\n","\n","Candidate: 0.9999966319192441 \n","Score: 0.39377551020408164\n","\n","Candidate: 0.9999967715015263 \n","Score: 0.39418367346938776\n","\n","Candidate: 0.9999969038439055 \n","Score: 0.3942857142857143\n","\n","Candidate: 0.9999969726408279 \n","Score: 0.3943877551020408\n","\n","Candidate: 0.9999970342897795 \n","Score: 0.3944897959183673\n","\n","Candidate: 0.9999970784595469 \n","Score: 0.3644897959183673\n","\n","Candidate: 0.9999971459309545 \n","Score: 0.3644897959183673\n","\n","Candidate: 0.9999972070833252 \n","Score: 0.36459183673469386\n","\n","Candidate: 0.9999972314574896 \n","Score: 0.36469387755102034\n","\n","Candidate: 0.9999972770620993 \n","Score: 0.36469387755102034\n","\n","Candidate: 0.99999738334871 \n","Score: 0.36469387755102034\n","\n","Candidate: 0.9999974654686218 \n","Score: 0.3494897959183674\n","\n","Candidate: 0.9999974668770442 \n","Score: 0.3494897959183674\n","\n","Candidate: 0.9999975179219216 \n","Score: 0.34959183673469385\n","\n","Candidate: 0.9999976033809258 \n","Score: 0.3496938775510204\n","\n","Candidate: 0.9999976587922819 \n","Score: 0.3497959183673469\n","\n","Candidate: 0.9999976883100985 \n","Score: 0.3498979591836735\n","\n","Candidate: 0.9999977005042024 \n","Score: 0.3503061224489796\n","\n","Candidate: 0.999997787466038 \n","Score: 0.3504081632653061\n","\n","Candidate: 0.9999978950549193 \n","Score: 0.35051020408163264\n","\n","Candidate: 0.9999979259560174 \n","Score: 0.3507142857142857\n","\n","Candidate: 0.9999979559538197 \n","Score: 0.35081632653061223\n","\n","Candidate: 0.9999979848867367 \n","Score: 0.35081632653061223\n","\n","Candidate: 0.999997995256948 \n","Score: 0.35091836734693876\n","\n","Candidate: 0.9999980092555196 \n","Score: 0.3510204081632653\n","\n","Candidate: 0.9999980639399684 \n","Score: 0.35112244897959183\n","\n","Candidate: 0.9999981543416303 \n","Score: 0.35122448979591836\n","\n","Candidate: 0.9999982483697347 \n","Score: 0.3513265306122449\n","\n","Candidate: 0.9999983409852244 \n","Score: 0.3514285714285714\n","\n","Candidate: 0.9999984024577107 \n","Score: 0.3514285714285714\n","\n","Candidate: 0.9999984230185364 \n","Score: 0.3514285714285714\n","\n","Candidate: 0.9999984314643349 \n","Score: 0.35153061224489796\n","\n","Candidate: 0.999998449517069 \n","Score: 0.3516326530612245\n","\n","Candidate: 0.9999984851274919 \n","Score: 0.351734693877551\n","\n","Candidate: 0.9999985104588534 \n","Score: 0.35183673469387755\n","\n","Candidate: 0.9999985452600986 \n","Score: 0.35183673469387755\n","\n","Candidate: 0.9999985855744178 \n","Score: 0.3522448979591837\n","\n","Candidate: 0.9999986257203466 \n","Score: 0.3523469387755102\n","\n","Candidate: 0.9999986631876382 \n","Score: 0.35244897959183674\n","\n","Candidate: 0.999998680121015 \n","Score: 0.35244897959183674\n","\n","Candidate: 0.9999987181736472 \n","Score: 0.35244897959183674\n","\n","Candidate: 0.9999987690857519 \n","Score: 0.3525510204081633\n","\n","Candidate: 0.9999987988590808 \n","Score: 0.3525510204081633\n","\n","Candidate: 0.9999988067236039 \n","Score: 0.35275510204081634\n","\n","Candidate: 0.9999988490544833 \n","Score: 0.35316326530612246\n","\n","Candidate: 0.9999988902566792 \n","Score: 0.35316326530612246\n","\n","Candidate: 0.9999989041249222 \n","Score: 0.35316326530612246\n","\n","Candidate: 0.9999989228001157 \n","Score: 0.353265306122449\n","\n","Candidate: 0.9999989299810709 \n","Score: 0.36887755102040815\n","\n","Candidate: 0.9999989334327862 \n","Score: 0.36887755102040815\n","\n","Candidate: 0.9999989465186866 \n","Score: 0.3689795918367347\n","\n","Candidate: 0.9999989594663556 \n","Score: 0.3690816326530612\n","\n","Candidate: 0.9999989786316617 \n","Score: 0.3852040816326531\n","\n","Candidate: 0.9999989971331561 \n","Score: 0.38530612244897955\n","\n","Candidate: 0.9999989996988833 \n","Score: 0.38540816326530614\n","\n","Candidate: 0.9999990132082498 \n","Score: 0.38540816326530614\n","\n","Candidate: 0.9999990284676865 \n","Score: 0.38551020408163267\n","\n","Candidate: 0.9999990343331575 \n","Score: 0.3856122448979592\n","\n","Candidate: 0.9999990390429725 \n","Score: 0.3856122448979592\n","\n","Candidate: 0.9999990538382192 \n","Score: 0.38571428571428573\n","\n","Candidate: 0.9999990878410536 \n","Score: 0.38581632653061226\n","\n","Candidate: 0.9999991258098156 \n","Score: 0.38581632653061226\n","\n","Candidate: 0.9999991529719191 \n","Score: 0.3860204081632653\n","\n","Candidate: 0.9999991695940422 \n","Score: 0.38612244897959186\n","\n","Candidate: 0.9999991857434516 \n","Score: 0.3862244897959184\n","\n","Candidate: 0.9999992019265962 \n","Score: 0.3711224489795919\n","\n","Candidate: 0.999999212986622 \n","Score: 0.37153061224489803\n","\n","Candidate: 0.9999992229960949 \n","Score: 0.3716326530612245\n","\n","Candidate: 0.9999992454632192 \n","Score: 0.3717346938775511\n","\n","Candidate: 0.9999992650961587 \n","Score: 0.37183673469387757\n","\n","Candidate: 0.9999992981729264 \n","Score: 0.3719387755102041\n","\n","Candidate: 0.9999993286759354 \n","Score: 0.37204081632653063\n","\n","Candidate: 0.9999993317236597 \n","Score: 0.37214285714285716\n","\n","Candidate: 0.9999993348495309 \n","Score: 0.3722448979591837\n","\n","Candidate: 0.9999993404369425 \n","Score: 0.37234693877551023\n","\n","Candidate: 0.9999993470377757 \n","Score: 0.37234693877551023\n","\n","Candidate: 0.9999993565779026 \n","Score: 0.3725510204081633\n","\n","Candidate: 0.9999993718731381 \n","Score: 0.3726530612244898\n","\n","Candidate: 0.9999993833224556 \n","Score: 0.3726530612244898\n","\n","Candidate: 0.9999993922232565 \n","Score: 0.3726530612244898\n","\n","Candidate: 0.9999993970060597 \n","Score: 0.3726530612244898\n","\n","Candidate: 0.999999399802026 \n","Score: 0.37275510204081636\n","\n","Candidate: 0.9999994042238397 \n","Score: 0.3728571428571429\n","\n","Candidate: 0.9999994141166879 \n","Score: 0.3728571428571429\n","\n","Candidate: 0.9999994556178233 \n","Score: 0.3581632653061225\n","\n","Candidate: 0.9999994934843264 \n","Score: 0.35826530612244906\n","\n","Candidate: 0.9999995000424597 \n","Score: 0.37520408163265306\n","\n","Candidate: 0.9999995104959565 \n","Score: 0.3753061224489796\n","\n","Candidate: 0.9999995214329027 \n","Score: 0.3753061224489796\n","\n","Candidate: 0.9999995333439011 \n","Score: 0.3753061224489796\n","\n","Candidate: 0.9999995429094433 \n","Score: 0.3753061224489796\n","\n","Candidate: 0.9999995434268207 \n","Score: 0.3754081632653061\n","\n","Candidate: 0.9999995489512793 \n","Score: 0.37551020408163266\n","\n","Candidate: 0.9999995623167711 \n","Score: 0.37551020408163266\n","\n","Candidate: 0.9999995704679885 \n","Score: 0.37551020408163266\n","\n","Candidate: 0.9999995745130713 \n","Score: 0.3756122448979592\n","\n","Candidate: 0.9999995799429057 \n","Score: 0.3757142857142857\n","\n","Candidate: 0.9999995831612072 \n","Score: 0.37581632653061225\n","\n","Candidate: 0.9999995877265696 \n","Score: 0.3759183673469388\n","\n","Candidate: 0.9999995937418581 \n","Score: 0.3763265306122449\n","\n","Candidate: 0.9999996045113079 \n","Score: 0.37642857142857145\n","\n","Candidate: 0.9999996275622796 \n","Score: 0.3765306122448979\n","\n","Candidate: 0.9999996445866597 \n","Score: 0.3766326530612245\n","\n","Candidate: 0.9999996466564899 \n","Score: 0.3768367346938776\n","\n","Candidate: 0.9999996492228904 \n","Score: 0.37704081632653064\n","\n","Candidate: 0.9999996522415382 \n","Score: 0.3771428571428571\n","\n","Candidate: 0.9999996540346989 \n","Score: 0.3772448979591837\n","\n","Candidate: 0.9999996625150402 \n","Score: 0.3772448979591837\n","\n","Candidate: 0.9999996701613991 \n","Score: 0.3772448979591837\n","\n","Candidate: 0.9999996747568878 \n","Score: 0.3773469387755102\n","\n","Candidate: 0.9999996797623973 \n","Score: 0.37744897959183676\n","\n","Candidate: 0.9999996820538202 \n","Score: 0.37755102040816324\n","\n","Candidate: 0.9999996849196522 \n","Score: 0.3776530612244898\n","\n","Candidate: 0.9999996862904486 \n","Score: 0.37775510204081636\n","\n","Candidate: 0.999999693589447 \n","Score: 0.3778571428571429\n","\n","Candidate: 0.9999997054912282 \n","Score: 0.3779591836734694\n","\n","Candidate: 0.9999997118441186 \n","Score: 0.3779591836734694\n","\n","Candidate: 0.9999997143246933 \n","Score: 0.37806122448979596\n","\n","Candidate: 0.999999720794168 \n","Score: 0.37816326530612243\n","\n","Candidate: 0.9999997270781655 \n","Score: 0.378265306122449\n","\n","Candidate: 0.9999997304608951 \n","Score: 0.37867346938775515\n","\n","Candidate: 0.9999997372951028 \n","Score: 0.37867346938775515\n","\n","Candidate: 0.9999997426048797 \n","Score: 0.3787755102040816\n","\n","Candidate: 0.999999743961367 \n","Score: 0.3788775510204082\n","\n","Candidate: 0.999999744452873 \n","Score: 0.37897959183673474\n","\n","Candidate: 0.9999997462419363 \n","Score: 0.3790816326530613\n","\n","Candidate: 0.9999997515309812 \n","Score: 0.3791836734693878\n","\n","Candidate: 0.9999997586206609 \n","Score: 0.3642857142857144\n","\n","Candidate: 0.9999997655293764 \n","Score: 0.3642857142857144\n","\n","Candidate: 0.9999997753247696 \n","Score: 0.3642857142857144\n","\n","Candidate: 0.9999997838761663 \n","Score: 0.3643877551020409\n","\n","Candidate: 0.9999997877730635 \n","Score: 0.3643877551020409\n","\n","Candidate: 0.9999997901069725 \n","Score: 0.36448979591836744\n","\n","Candidate: 0.9999997952720845 \n","Score: 0.364591836734694\n","\n","Candidate: 0.9999998005648308 \n","Score: 0.364591836734694\n","\n","Candidate: 0.9999998028012925 \n","Score: 0.36489795918367357\n","\n","Candidate: 0.9999998054498686 \n","Score: 0.3650000000000001\n","\n","Candidate: 0.9999998070068457 \n","Score: 0.3650000000000001\n","\n","Candidate: 0.9999998078398424 \n","Score: 0.36510204081632663\n","\n","Candidate: 0.9999998092861371 \n","Score: 0.36510204081632663\n","\n","Candidate: 0.999999810649036 \n","Score: 0.36520408163265317\n","\n","Candidate: 0.9999998115402551 \n","Score: 0.3653061224489797\n","\n","Candidate: 0.9999998150188727 \n","Score: 0.36540816326530623\n","\n","Candidate: 0.999999818562754 \n","Score: 0.36540816326530623\n","\n","Candidate: 0.9999998211743212 \n","Score: 0.3655102040816327\n","\n","Candidate: 0.9999998244404076 \n","Score: 0.3656122448979593\n","\n","Candidate: 0.9999998285048688 \n","Score: 0.36571428571428577\n","\n","Candidate: 0.9999998343929091 \n","Score: 0.36581632653061236\n","\n","Candidate: 0.999999840219272 \n","Score: 0.36602040816326536\n","\n","Candidate: 0.9999998434479129 \n","Score: 0.3661224489795919\n","\n","Candidate: 0.9999998458216438 \n","Score: 0.36622448979591843\n","\n","Candidate: 0.9999998512099812 \n","Score: 0.36632653061224496\n","\n","Candidate: 0.9999998549457028 \n","Score: 0.366530612244898\n","\n","Candidate: 0.9999998559220593 \n","Score: 0.366530612244898\n","\n","Candidate: 0.999999857026733 \n","Score: 0.3668367346938776\n","\n","Candidate: 0.9999998575505287 \n","Score: 0.36693877551020415\n","\n","Candidate: 0.9999998584827986 \n","Score: 0.3670408163265307\n","\n","Candidate: 0.9999998628851051 \n","Score: 0.3674489795918368\n","\n","Candidate: 0.9999998690306547 \n","Score: 0.3674489795918368\n","\n","Candidate: 0.9999998731074431 \n","Score: 0.36755102040816334\n","\n","Candidate: 0.9999998759549737 \n","Score: 0.36785714285714294\n","\n","Candidate: 0.9999998785393073 \n","Score: 0.36795918367346947\n","\n","Candidate: 0.9999998805463348 \n","Score: 0.368061224489796\n","\n","Candidate: 0.9999998828847345 \n","Score: 0.36816326530612253\n","\n","Candidate: 0.9999998846061733 \n","Score: 0.36816326530612253\n","\n","Candidate: 0.9999998852602714 \n","Score: 0.36826530612244907\n","\n","Candidate: 0.9999998861026254 \n","Score: 0.36826530612244907\n","\n","Candidate: 0.9999998865245195 \n","Score: 0.3683673469387756\n","\n","Candidate: 0.9999998877081029 \n","Score: 0.36846938775510213\n","\n","Candidate: 0.999999889264 \n","Score: 0.36846938775510213\n","\n","Candidate: 0.9999998910124652 \n","Score: 0.36857142857142866\n","\n","Candidate: 0.9999998926562741 \n","Score: 0.3686734693877552\n","\n","Candidate: 0.9999998934468706 \n","Score: 0.3686734693877552\n","\n","Candidate: 0.9999998940431961 \n","Score: 0.3687755102040817\n","\n","Candidate: 0.9999998948190829 \n","Score: 0.3687755102040817\n","\n","Candidate: 0.9999998974902644 \n","Score: 0.3688775510204082\n","\n","Candidate: 0.9999999011374525 \n","Score: 0.3688775510204082\n","\n","Candidate: 0.999999902982909 \n","Score: 0.3689795918367348\n","\n","Candidate: 0.9999999048732966 \n","Score: 0.36908163265306126\n","\n","Candidate: 0.9999999071999386 \n","Score: 0.3694897959183674\n","\n","Candidate: 0.9999999087872096 \n","Score: 0.3694897959183674\n","\n","Candidate: 0.9999999114876952 \n","Score: 0.3695918367346939\n","\n","Candidate: 0.9999999147922338 \n","Score: 0.36969387755102046\n","\n","Candidate: 0.9999999162937376 \n","Score: 0.3702040816326531\n","\n","Candidate: 0.9999999176674732 \n","Score: 0.37030612244897965\n","\n","Candidate: 0.9999999197469918 \n","Score: 0.3704081632653062\n","\n","Candidate: 0.9999999206745247 \n","Score: 0.3705102040816327\n","\n","Candidate: 0.9999999223663449 \n","Score: 0.37061224489795924\n","\n","Candidate: 0.9999999244080524 \n","Score: 0.3707142857142858\n","\n","Candidate: 0.9999999252545242 \n","Score: 0.3708163265306123\n","\n","Candidate: 0.999999925615518 \n","Score: 0.37091836734693884\n","\n","Candidate: 0.9999999260990646 \n","Score: 0.3710204081632653\n","\n","Candidate: 0.9999999275051293 \n","Score: 0.3711224489795919\n","\n","Candidate: 0.999999930086254 \n","Score: 0.3711224489795919\n","\n","Candidate: 0.9999999316992478 \n","Score: 0.3712244897959184\n","\n","Candidate: 0.9999999319057439 \n","Score: 0.371530612244898\n","\n","Candidate: 0.9999999337181216 \n","Score: 0.3716326530612245\n","\n","Candidate: 0.9999999356247327 \n","Score: 0.3716326530612245\n","\n","Candidate: 0.9999999371254651 \n","Score: 0.3716326530612245\n","\n","Candidate: 0.9999999384847659 \n","Score: 0.37173469387755104\n","\n","Candidate: 0.999999938724627 \n","Score: 0.37173469387755104\n","\n","Candidate: 0.999999938828066 \n","Score: 0.3719387755102041\n","\n","Candidate: 0.9999999395132189 \n","Score: 0.37204081632653063\n","\n","Candidate: 0.999999940320433 \n","Score: 0.37214285714285716\n","\n","Candidate: 0.9999999410508655 \n","Score: 0.37214285714285716\n","\n","Candidate: 0.9999999418336504 \n","Score: 0.37214285714285716\n","\n","Candidate: 0.999999942460019 \n","Score: 0.3722448979591837\n","\n","Candidate: 0.9999999437673046 \n","Score: 0.3722448979591837\n","\n","Candidate: 0.9999999454185763 \n","Score: 0.3722448979591837\n","\n","Candidate: 0.9999999471633436 \n","Score: 0.3722448979591837\n","\n","Candidate: 0.9999999483082159 \n","Score: 0.37234693877551023\n","\n","Candidate: 0.9999999493295983 \n","Score: 0.37244897959183676\n","\n","Candidate: 0.9999999508976121 \n","Score: 0.3725510204081633\n","\n","Candidate: 0.9999999518438129 \n","Score: 0.3729591836734694\n","\n","Candidate: 0.9999999521469793 \n","Score: 0.37306122448979595\n","\n","Candidate: 0.9999999540430118 \n","Score: 0.3731632653061225\n","\n","Candidate: 0.9999999559242458 \n","Score: 0.373265306122449\n","\n","Candidate: 0.999999956074344 \n","Score: 0.373265306122449\n","\n","Candidate: 0.9999999565653379 \n","Score: 0.373265306122449\n","\n","Candidate: 0.99999995733402 \n","Score: 0.37336734693877555\n","\n","Candidate: 0.999999957749997 \n","Score: 0.37336734693877555\n","\n","Candidate: 0.9999999579861238 \n","Score: 0.3734693877551021\n","\n","Candidate: 0.9999999584433288 \n","Score: 0.3735714285714286\n","\n","Candidate: 0.999999958989127 \n","Score: 0.37367346938775514\n","\n","Candidate: 0.9999999597243547 \n","Score: 0.37367346938775514\n","\n","Candidate: 0.9999999604716223 \n","Score: 0.3737755102040816\n","\n","Candidate: 0.9999999608907183 \n","Score: 0.3738775510204082\n","\n","Candidate: 0.9999999613602599 \n","Score: 0.37397959183673474\n","\n","Candidate: 0.9999999618950997 \n","Score: 0.37397959183673474\n","\n","Candidate: 0.9999999625355349 \n","Score: 0.37408163265306127\n","\n","Candidate: 0.9999999632122337 \n","Score: 0.3741836734693878\n","\n","Candidate: 0.999999963531917 \n","Score: 0.37428571428571433\n","\n","Candidate: 0.9999999639985883 \n","Score: 0.37428571428571433\n","\n","Candidate: 0.9999999644973925 \n","Score: 0.3743877551020408\n","\n","Candidate: 0.9999999652249633 \n","Score: 0.3744897959183674\n","\n","Candidate: 0.9999999659479222 \n","Score: 0.37459183673469393\n","\n","Candidate: 0.9999999660970786 \n","Score: 0.37469387755102046\n","\n","Candidate: 0.9999999663224949 \n","Score: 0.37469387755102046\n","\n","Candidate: 0.9999999668000217 \n","Score: 0.374795918367347\n","\n","Candidate: 0.999999967527911 \n","Score: 0.3748979591836735\n","\n","Candidate: 0.9999999683484246 \n","Score: 0.3748979591836735\n","\n","Candidate: 0.9999999687827792 \n","Score: 0.3748979591836735\n","\n","Candidate: 0.9999999688933818 \n","Score: 0.3753061224489796\n","\n","Candidate: 0.9999999696503898 \n","Score: 0.3753061224489796\n","\n","Candidate: 0.9999999708361225 \n","Score: 0.3753061224489796\n","\n","Candidate: 0.9999999713751824 \n","Score: 0.3754081632653061\n","\n","Candidate: 0.9999999715431137 \n","Score: 0.3754081632653061\n","\n","Candidate: 0.9999999718860519 \n","Score: 0.37551020408163266\n","\n","Candidate: 0.9999999722856465 \n","Score: 0.37551020408163266\n","\n","Candidate: 0.9999999725664833 \n","Score: 0.3757142857142857\n","\n","Candidate: 0.9999999730165083 \n","Score: 0.37581632653061225\n","\n","Candidate: 0.999999973784037 \n","Score: 0.3759183673469388\n","\n","Candidate: 0.9999999744724619 \n","Score: 0.3760204081632653\n","\n","Candidate: 0.9999999750206896 \n","Score: 0.37612244897959185\n","\n","Candidate: 0.9999999754140388 \n","Score: 0.3762244897959184\n","\n","Candidate: 0.9999999760277041 \n","Score: 0.3763265306122449\n","\n","Candidate: 0.999999976583114 \n","Score: 0.3923469387755102\n","\n","Candidate: 0.9999999769476627 \n","Score: 0.3924489795918367\n","\n","Candidate: 0.9999999775821751 \n","Score: 0.39255102040816325\n","\n","Candidate: 0.9999999779764991 \n","Score: 0.39255102040816325\n","\n","Candidate: 0.999999978059526 \n","Score: 0.39255102040816325\n","\n","Candidate: 0.9999999781617621 \n","Score: 0.37734693877551023\n","\n","Candidate: 0.9999999783681439 \n","Score: 0.37734693877551023\n","\n","Candidate: 0.9999999787818177 \n","Score: 0.37744897959183676\n","\n","Candidate: 0.9999999792223634 \n","Score: 0.3775510204081633\n","\n","Candidate: 0.9999999795760833 \n","Score: 0.3775510204081633\n","\n","Candidate: 0.9999999799258786 \n","Score: 0.3775510204081633\n","\n","Candidate: 0.9999999802073581 \n","Score: 0.3776530612244898\n","\n","Candidate: 0.999999980476436 \n","Score: 0.37775510204081636\n","\n","Candidate: 0.9999999811679917 \n","Score: 0.37775510204081636\n","\n","Candidate: 0.9999999817420502 \n","Score: 0.3778571428571429\n","\n","Candidate: 0.99999998180916 \n","Score: 0.3779591836734694\n","\n","Candidate: 0.9999999819303623 \n","Score: 0.3779591836734694\n","\n","Candidate: 0.9999999821505181 \n","Score: 0.3779591836734694\n","\n","Candidate: 0.9999999826726303 \n","Score: 0.37806122448979596\n","\n","Candidate: 0.9999999831102437 \n","Score: 0.37816326530612243\n","\n","Candidate: 0.9999999832259638 \n","Score: 0.378265306122449\n","\n","Candidate: 0.999999983302585 \n","Score: 0.378265306122449\n","\n","Candidate: 0.9999999835178286 \n","Score: 0.378265306122449\n","\n","Candidate: 0.9999999837475948 \n","Score: 0.3783673469387755\n","\n","Candidate: 0.9999999838331993 \n","Score: 0.3783673469387755\n","\n","Candidate: 0.9999999839621718 \n","Score: 0.3787755102040816\n","\n","Candidate: 0.9999999840551801 \n","Score: 0.3788775510204082\n","\n","Candidate: 0.9999999842709622 \n","Score: 0.3789795918367347\n","\n","Candidate: 0.9999999845505699 \n","Score: 0.3789795918367347\n","\n","Candidate: 0.9999999847226291 \n","Score: 0.3789795918367347\n","\n","Candidate: 0.9999999850140275 \n","Score: 0.3790816326530613\n","\n","Candidate: 0.999999985304161 \n","Score: 0.37918367346938775\n","\n","Candidate: 0.9999999854700949 \n","Score: 0.3792857142857143\n","\n","Candidate: 0.9999999856224906 \n","Score: 0.3792857142857143\n","\n","Candidate: 0.9999999858229991 \n","Score: 0.3792857142857143\n","\n","Candidate: 0.9999999864128164 \n","Score: 0.3793877551020408\n","\n","Candidate: 0.9999999869386975 \n","Score: 0.3796938775510204\n","\n","Candidate: 0.9999999869997425 \n","Score: 0.37979591836734694\n","\n","Candidate: 0.9999999871406915 \n","Score: 0.3798979591836735\n","\n","Candidate: 0.9999999873189714 \n","Score: 0.38\n","\n","Candidate: 0.9999999875405998 \n","Score: 0.38010204081632654\n","\n","Candidate: 0.9999999877575692 \n","Score: 0.38020408163265307\n","\n","Candidate: 0.99999998788935 \n","Score: 0.38020408163265307\n","\n","Candidate: 0.9999999880716801 \n","Score: 0.38020408163265307\n","\n","Candidate: 0.9999999882015955 \n","Score: 0.38020408163265307\n","\n","Candidate: 0.9999999883879813 \n","Score: 0.3803061224489796\n","\n","Candidate: 0.9999999886144597 \n","Score: 0.3803061224489796\n","\n","Candidate: 0.9999999887373565 \n","Score: 0.38040816326530613\n","\n","Candidate: 0.9999999888150082 \n","Score: 0.38051020408163266\n","\n","Candidate: 0.999999989006941 \n","Score: 0.38051020408163266\n","\n","Candidate: 0.9999999892095706 \n","Score: 0.3806122448979592\n","\n","Candidate: 0.9999999894626291 \n","Score: 0.3810204081632653\n","\n","Candidate: 0.9999999897695959 \n","Score: 0.38112244897959185\n","\n","Candidate: 0.9999999899267684 \n","Score: 0.3812244897959184\n","\n","Candidate: 0.9999999900807905 \n","Score: 0.3813265306122449\n","\n","Candidate: 0.999999990383883 \n","Score: 0.38142857142857145\n","\n","Candidate: 0.9999999905996362 \n","Score: 0.38142857142857145\n","\n","Candidate: 0.9999999908525703 \n","Score: 0.381530612244898\n","\n","Candidate: 0.999999991209643 \n","Score: 0.381530612244898\n","\n","Candidate: 0.9999999913592774 \n","Score: 0.3816326530612245\n","\n","Candidate: 0.9999999914528359 \n","Score: 0.38173469387755105\n","\n","Candidate: 0.9999999915502005 \n","Score: 0.3818367346938776\n","\n","Candidate: 0.9999999916722058 \n","Score: 0.3818367346938776\n","\n","Candidate: 0.9999999917929254 \n","Score: 0.3818367346938776\n","\n","Candidate: 0.9999999918444302 \n","Score: 0.3819387755102041\n","\n","Candidate: 0.9999999918886724 \n","Score: 0.38204081632653064\n","\n","Candidate: 0.9999999919753848 \n","Score: 0.3821428571428571\n","\n","Candidate: 0.999999992100356 \n","Score: 0.3821428571428571\n","\n","Candidate: 0.999999992267546 \n","Score: 0.3823469387755102\n","\n","Candidate: 0.9999999923820838 \n","Score: 0.3823469387755102\n","\n","Candidate: 0.9999999926054853 \n","Score: 0.3824489795918367\n","\n","Candidate: 0.9999999929230814 \n","Score: 0.38255102040816324\n","\n","Candidate: 0.9999999930941224 \n","Score: 0.3826530612244898\n","\n","Candidate: 0.99999999315367 \n","Score: 0.3827551020408163\n","\n","Candidate: 0.9999999931621861 \n","Score: 0.38285714285714284\n","\n","Candidate: 0.9999999932179079 \n","Score: 0.38295918367346937\n","\n","Candidate: 0.9999999932952298 \n","Score: 0.38295918367346937\n","\n","Candidate: 0.9999999933857426 \n","Score: 0.38295918367346937\n","\n","Candidate: 0.9999999934653305 \n","Score: 0.38295918367346937\n","\n","Candidate: 0.999999993553887 \n","Score: 0.3830612244897959\n","\n","Candidate: 0.9999999936922969 \n","Score: 0.3830612244897959\n","\n","Candidate: 0.9999999937629769 \n","Score: 0.38316326530612244\n","\n","Candidate: 0.9999999938074849 \n","Score: 0.38326530612244897\n","\n","Candidate: 0.9999999939820776 \n","Score: 0.38326530612244897\n","\n","Candidate: 0.9999999941977258 \n","Score: 0.3833673469387755\n","\n","Candidate: 0.9999999943230458 \n","Score: 0.3833673469387755\n","\n","Candidate: 0.9999999944045292 \n","Score: 0.38346938775510203\n","\n","Candidate: 0.9999999944757721 \n","Score: 0.38387755102040816\n","\n","Candidate: 0.9999999945337761 \n","Score: 0.38387755102040816\n","\n","Candidate: 0.9999999945701212 \n","Score: 0.38387755102040816\n","\n","Candidate: 0.9999999946307028 \n","Score: 0.3839795918367347\n","\n","Candidate: 0.999999994730215 \n","Score: 0.3840816326530612\n","\n","Candidate: 0.999999994810355 \n","Score: 0.38418367346938775\n","\n","Candidate: 0.9999999949230116 \n","Score: 0.3842857142857143\n","\n","Candidate: 0.9999999950660632 \n","Score: 0.3843877551020408\n","\n","Candidate: 0.9999999951370282 \n","Score: 0.3843877551020408\n","\n","Candidate: 0.9999999952051204 \n","Score: 0.38448979591836735\n","\n","Candidate: 0.9999999952712278 \n","Score: 0.3845918367346939\n","\n","Candidate: 0.9999999953495289 \n","Score: 0.3846938775510204\n","\n","Candidate: 0.9999999954561529 \n","Score: 0.3846938775510204\n","\n","Candidate: 0.9999999955085457 \n","Score: 0.3694897959183674\n","\n","Candidate: 0.9999999955752602 \n","Score: 0.36959183673469387\n","\n","Candidate: 0.999999995636736 \n","Score: 0.36959183673469387\n","\n","Candidate: 0.9999999956983148 \n","Score: 0.3696938775510204\n","\n","Candidate: 0.9999999957541166 \n","Score: 0.36979591836734693\n","\n","Candidate: 0.9999999957561924 \n","Score: 0.36979591836734693\n","\n","Candidate: 0.9999999957712575 \n","Score: 0.36989795918367346\n","\n","Candidate: 0.99999999581955 \n","Score: 0.37\n","\n","Candidate: 0.9999999958873619 \n","Score: 0.37\n","\n","Candidate: 0.9999999959272122 \n","Score: 0.37\n","\n","Candidate: 0.9999999959477998 \n","Score: 0.3701020408163266\n","\n","Candidate: 0.9999999960373513 \n","Score: 0.37020408163265306\n","\n","Candidate: 0.9999999961365343 \n","Score: 0.37030612244897965\n","\n","Candidate: 0.9999999961814695 \n","Score: 0.3707142857142857\n","\n","Candidate: 0.9999999962086181 \n","Score: 0.37081632653061225\n","\n","Candidate: 0.9999999962509942 \n","Score: 0.37081632653061225\n","\n","Candidate: 0.9999999963008164 \n","Score: 0.37081632653061225\n","\n","Candidate: 0.9999999963874064 \n","Score: 0.37081632653061225\n","\n","Candidate: 0.99999999649924 \n","Score: 0.37081632653061225\n","\n","Candidate: 0.9999999966207689 \n","Score: 0.3709183673469388\n","\n","Candidate: 0.9999999967365776 \n","Score: 0.3709183673469388\n","\n","Candidate: 0.9999999968242226 \n","Score: 0.3710204081632653\n","\n","Candidate: 0.9999999968858191 \n","Score: 0.37112244897959185\n","\n","Candidate: 0.9999999968947121 \n","Score: 0.3712244897959184\n","\n","Candidate: 0.999999996953846 \n","Score: 0.37132653061224485\n","\n","Candidate: 0.9999999970135984 \n","Score: 0.37142857142857144\n","\n","Candidate: 0.9999999970251181 \n","Score: 0.3715306122448979\n","\n","Candidate: 0.9999999970396725 \n","Score: 0.3716326530612245\n","\n","Candidate: 0.9999999970562965 \n","Score: 0.3716326530612245\n","\n","Candidate: 0.9999999971101515 \n","Score: 0.371734693877551\n","\n","Candidate: 0.9999999971646545 \n","Score: 0.37183673469387757\n","\n","Candidate: 0.9999999972316223 \n","Score: 0.37193877551020404\n","\n","Candidate: 0.9999999972940461 \n","Score: 0.37193877551020404\n","\n","Candidate: 0.9999999973393319 \n","Score: 0.3721428571428571\n","\n","Candidate: 0.9999999973887039 \n","Score: 0.3721428571428571\n","\n","Candidate: 0.9999999974269747 \n","Score: 0.37224489795918364\n","\n","Candidate: 0.999999997458843 \n","Score: 0.37224489795918364\n","\n","Candidate: 0.9999999974833816 \n","Score: 0.37224489795918364\n","\n","Candidate: 0.9999999975149619 \n","Score: 0.37224489795918364\n","\n","Candidate: 0.9999999975438509 \n","Score: 0.3723469387755102\n","\n","Candidate: 0.9999999975954146 \n","Score: 0.37244897959183676\n","\n","Candidate: 0.9999999976359466 \n","Score: 0.37244897959183676\n","\n","Candidate: 0.9999999976416998 \n","Score: 0.37255102040816324\n","\n","Candidate: 0.9999999976464076 \n","Score: 0.37255102040816324\n","\n","Candidate: 0.9999999976835685 \n","Score: 0.3726530612244898\n","\n","Candidate: 0.9999999977252054 \n","Score: 0.3727551020408163\n","\n","Candidate: 0.9999999977462912 \n","Score: 0.3727551020408163\n","\n","Candidate: 0.9999999977656875 \n","Score: 0.3727551020408163\n","\n","Candidate: 0.9999999978423558 \n","Score: 0.3727551020408163\n","\n","Candidate: 0.9999999979194398 \n","Score: 0.3727551020408163\n","\n","Candidate: 0.9999999979390611 \n","Score: 0.3727551020408163\n","\n","Candidate: 0.9999999979589411 \n","Score: 0.3728571428571429\n","\n","Candidate: 0.9999999979719678 \n","Score: 0.3728571428571429\n","\n","Candidate: 0.9999999979771398 \n","Score: 0.3728571428571429\n","\n","Candidate: 0.9999999979939671 \n","Score: 0.37295918367346936\n","\n","Candidate: 0.9999999980125198 \n","Score: 0.37295918367346936\n","\n","Candidate: 0.999999998023771 \n","Score: 0.3733673469387755\n","\n","Candidate: 0.9999999980476499 \n","Score: 0.3734693877551021\n","\n","Candidate: 0.999999998068126 \n","Score: 0.37357142857142855\n","\n","Candidate: 0.9999999980822236 \n","Score: 0.3736734693877551\n","\n","Candidate: 0.9999999981335952 \n","Score: 0.3737755102040816\n","\n","Candidate: 0.9999999982190462 \n","Score: 0.3738775510204082\n","\n","Candidate: 0.9999999982645886 \n","Score: 0.3739795918367347\n","\n","Candidate: 0.9999999982761442 \n","Score: 0.37408163265306127\n","\n","Candidate: 0.9999999982850959 \n","Score: 0.37418367346938775\n","\n","Candidate: 0.9999999982882143 \n","Score: 0.3742857142857143\n","\n","Candidate: 0.999999998315115 \n","Score: 0.3742857142857143\n","\n","Candidate: 0.999999998360862 \n","Score: 0.3743877551020408\n","\n","Candidate: 0.9999999983911643 \n","Score: 0.37448979591836734\n","\n","Candidate: 0.9999999984223298 \n","Score: 0.3745918367346939\n","\n","Candidate: 0.99999999845377 \n","Score: 0.3746938775510204\n","\n","Candidate: 0.9999999984778399 \n","Score: 0.3746938775510204\n","\n","Candidate: 0.9999999984970097 \n","Score: 0.3746938775510204\n","\n","Candidate: 0.9999999985192076 \n","Score: 0.37479591836734694\n","\n","Candidate: 0.9999999985438984 \n","Score: 0.37489795918367347\n","\n","Candidate: 0.9999999985697074 \n","Score: 0.37489795918367347\n","\n","Candidate: 0.999999998591731 \n","Score: 0.375\n","\n","Candidate: 0.9999999985985073 \n","Score: 0.375\n","\n","Candidate: 0.999999998615442 \n","Score: 0.3751020408163265\n","\n","Candidate: 0.999999998636761 \n","Score: 0.3755102040816326\n","\n","Candidate: 0.9999999986501846 \n","Score: 0.3756122448979592\n","\n","Candidate: 0.9999999986589114 \n","Score: 0.37571428571428567\n","\n","Candidate: 0.9999999986628212 \n","Score: 0.37571428571428567\n","\n","Candidate: 0.9999999986792113 \n","Score: 0.37581632653061225\n","\n","Candidate: 0.9999999986969497 \n","Score: 0.37591836734693873\n","\n","Candidate: 0.9999999986996353 \n","Score: 0.37591836734693873\n","\n","Candidate: 0.9999999987052961 \n","Score: 0.3760204081632653\n","\n","Candidate: 0.9999999987202913 \n","Score: 0.3760204081632653\n","\n","Candidate: 0.999999998730424 \n","Score: 0.3761224489795918\n","\n","Candidate: 0.999999998735891 \n","Score: 0.3761224489795918\n","\n","Candidate: 0.9999999987701766 \n","Score: 0.3761224489795918\n","\n","Candidate: 0.9999999988040086 \n","Score: 0.3761224489795918\n","\n","Candidate: 0.9999999988283652 \n","Score: 0.3762244897959184\n","\n","Candidate: 0.999999998879334 \n","Score: 0.3762244897959184\n","\n","Candidate: 0.9999999989107755 \n","Score: 0.3762244897959184\n","\n","Candidate: 0.9999999989164274 \n","Score: 0.3762244897959184\n","\n","Candidate: 0.99999999892272 \n","Score: 0.3762244897959184\n","\n","Candidate: 0.9999999989321561 \n","Score: 0.37632653061224486\n","\n","Candidate: 0.9999999989436302 \n","Score: 0.37642857142857145\n","\n","Candidate: 0.9999999989574384 \n","Score: 0.3765306122448979\n","\n","Candidate: 0.9999999989738952 \n","Score: 0.3765306122448979\n","\n","Candidate: 0.9999999989839063 \n","Score: 0.3765306122448979\n","\n","Candidate: 0.99999999899689 \n","Score: 0.3766326530612245\n","\n","Candidate: 0.9999999990181059 \n","Score: 0.376734693877551\n","\n","Candidate: 0.9999999990336692 \n","Score: 0.3768367346938776\n","\n","Candidate: 0.9999999990569903 \n","Score: 0.37704081632653064\n","\n","Candidate: 0.9999999990788249 \n","Score: 0.37714285714285717\n","\n","Candidate: 0.9999999990808843 \n","Score: 0.37714285714285717\n","\n","Candidate: 0.9999999990851293 \n","Score: 0.3772448979591837\n","\n","Candidate: 0.9999999990949875 \n","Score: 0.3773469387755103\n","\n","Candidate: 0.9999999991075286 \n","Score: 0.37744897959183676\n","\n","Candidate: 0.9999999991318024 \n","Score: 0.37744897959183676\n","\n","Candidate: 0.9999999991591337 \n","Score: 0.3775510204081633\n","\n","Candidate: 0.999999999180351 \n","Score: 0.3775510204081633\n","\n","Candidate: 0.9999999991939509 \n","Score: 0.3776530612244898\n","\n","Candidate: 0.9999999991981634 \n","Score: 0.37775510204081636\n","\n","Candidate: 0.9999999992067088 \n","Score: 0.37775510204081636\n","\n","Candidate: 0.9999999992181312 \n","Score: 0.3778571428571429\n","\n","Candidate: 0.9999999992242885 \n","Score: 0.3778571428571429\n","\n","Candidate: 0.9999999992359284 \n","Score: 0.3778571428571429\n","\n","Candidate: 0.99999999924885 \n","Score: 0.3779591836734694\n","\n","Candidate: 0.9999999992507401 \n","Score: 0.3779591836734694\n","\n","Candidate: 0.9999999992628608 \n","Score: 0.37806122448979596\n","\n","Candidate: 0.9999999992772539 \n","Score: 0.3781632653061225\n","\n","Candidate: 0.999999999280905 \n","Score: 0.3781632653061225\n","\n","Candidate: 0.9999999992853497 \n","Score: 0.3781632653061225\n","\n","Candidate: 0.9999999992896396 \n","Score: 0.3781632653061225\n","\n","Candidate: 0.999999999293244 \n","Score: 0.3952040816326531\n","\n","Candidate: 0.9999999993005746 \n","Score: 0.3953061224489796\n","\n","Candidate: 0.9999999993064848 \n","Score: 0.3953061224489796\n","\n","Candidate: 0.9999999993119956 \n","Score: 0.39540816326530615\n","\n","Candidate: 0.9999999993272539 \n","Score: 0.39540816326530615\n","\n","Candidate: 0.9999999993380455 \n","Score: 0.3955102040816327\n","\n","Candidate: 0.9999999993597619 \n","Score: 0.3956122448979592\n","\n","Candidate: 0.9999999993821296 \n","Score: 0.39602040816326534\n","\n","Candidate: 0.9999999993915956 \n","Score: 0.39602040816326534\n","\n","Candidate: 0.9999999994052928 \n","Score: 0.39612244897959187\n","\n","Candidate: 0.999999999414111 \n","Score: 0.3962244897959184\n","\n","Candidate: 0.9999999994233626 \n","Score: 0.39632653061224493\n","\n","Candidate: 0.9999999994308071 \n","Score: 0.39642857142857146\n","\n","Candidate: 0.9999999994340669 \n","Score: 0.396530612244898\n","\n","Candidate: 0.9999999994353773 \n","Score: 0.396530612244898\n","\n","Candidate: 0.999999999437502 \n","Score: 0.3966326530612245\n","\n","Candidate: 0.9999999994419307 \n","Score: 0.3966326530612245\n","\n","Candidate: 0.9999999994533251 \n","Score: 0.396734693877551\n","\n","Candidate: 0.9999999994637193 \n","Score: 0.3968367346938776\n","\n","Candidate: 0.9999999994713061 \n","Score: 0.3968367346938776\n","\n","Candidate: 0.9999999994842766 \n","Score: 0.39693877551020407\n","\n","Candidate: 0.9999999994979842 \n","Score: 0.39704081632653065\n","\n","Candidate: 0.9999999995121431 \n","Score: 0.39714285714285713\n","\n","Candidate: 0.9999999995205173 \n","Score: 0.3972448979591837\n","\n","Candidate: 0.9999999995223465 \n","Score: 0.3972448979591837\n","\n","Candidate: 0.9999999995234865 \n","Score: 0.3976530612244898\n","\n","Candidate: 0.9999999995314688 \n","Score: 0.3977551020408163\n","\n","Candidate: 0.9999999995400762 \n","Score: 0.3977551020408163\n","\n","Candidate: 0.9999999995478073 \n","Score: 0.3977551020408163\n","\n","Candidate: 0.9999999995694918 \n","Score: 0.39785714285714285\n","\n","Candidate: 0.9999999995845125 \n","Score: 0.39785714285714285\n","\n","Candidate: 0.9999999995846484 \n","Score: 0.3979591836734694\n","\n","Candidate: 0.9999999995876344 \n","Score: 0.3979591836734694\n","\n","Candidate: 0.9999999995938567 \n","Score: 0.3980612244897959\n","\n","Candidate: 0.9999999995978803 \n","Score: 0.39816326530612245\n","\n","Candidate: 0.9999999995991744 \n","Score: 0.39816326530612245\n","\n","Candidate: 0.9999999996072322 \n","Score: 0.39816326530612245\n","\n","Candidate: 0.999999999615087 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999996161439 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999996178172 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999996195482 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999996210175 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999996252567 \n","Score: 0.3983673469387755\n","\n","Candidate: 0.999999999629805 \n","Score: 0.39846938775510204\n","\n","Candidate: 0.9999999996310505 \n","Score: 0.3985714285714286\n","\n","Candidate: 0.9999999996318333 \n","Score: 0.3986734693877551\n","\n","Candidate: 0.9999999996392541 \n","Score: 0.39877551020408164\n","\n","Candidate: 0.9999999996494203 \n","Score: 0.39877551020408164\n","\n","Candidate: 0.9999999996542952 \n","Score: 0.3988775510204081\n","\n","Candidate: 0.9999999996563996 \n","Score: 0.39908163265306124\n","\n","Candidate: 0.9999999996575715 \n","Score: 0.39918367346938777\n","\n","Candidate: 0.9999999996667838 \n","Score: 0.3992857142857143\n","\n","Candidate: 0.9999999996760347 \n","Score: 0.39938775510204083\n","\n","Candidate: 0.999999999678326 \n","Score: 0.3994897959183673\n","\n","Candidate: 0.9999999996824619 \n","Score: 0.3994897959183673\n","\n","Candidate: 0.9999999996906657 \n","Score: 0.3995918367346939\n","\n","Candidate: 0.999999999696499 \n","Score: 0.3995918367346939\n","\n","Candidate: 0.9999999997018849 \n","Score: 0.39969387755102037\n","\n","Candidate: 0.9999999997072326 \n","Score: 0.39969387755102037\n","\n","Candidate: 0.9999999997109507 \n","Score: 0.39979591836734696\n","\n","Candidate: 0.9999999997156335 \n","Score: 0.39989795918367343\n","\n","Candidate: 0.9999999997177182 \n","Score: 0.4\n","\n","Candidate: 0.9999999997189981 \n","Score: 0.4001020408163265\n","\n","Candidate: 0.9999999997205643 \n","Score: 0.40020408163265303\n","\n","Candidate: 0.9999999997221511 \n","Score: 0.40020408163265303\n","\n","Candidate: 0.9999999997245196 \n","Score: 0.40030612244897956\n","\n","Candidate: 0.9999999997316165 \n","Score: 0.40030612244897956\n","\n","Candidate: 0.9999999997448636 \n","Score: 0.40030612244897956\n","\n","Candidate: 0.9999999997532234 \n","Score: 0.4004081632653061\n","\n","Candidate: 0.999999999753741 \n","Score: 0.4005102040816326\n","\n","Candidate: 0.9999999997560243 \n","Score: 0.4005102040816326\n","\n","Candidate: 0.9999999997643414 \n","Score: 0.4008163265306122\n","\n","Candidate: 0.9999999997710443 \n","Score: 0.40091836734693875\n","\n","Candidate: 0.9999999997718703 \n","Score: 0.40091836734693875\n","\n","Candidate: 0.999999999773681 \n","Score: 0.40102040816326523\n","\n","Candidate: 0.9999999997763362 \n","Score: 0.40102040816326523\n","\n","Candidate: 0.9999999997788855 \n","Score: 0.4011224489795918\n","\n","Candidate: 0.9999999997815144 \n","Score: 0.4012244897959183\n","\n","Candidate: 0.9999999997834317 \n","Score: 0.4012244897959183\n","\n","Candidate: 0.9999999997842643 \n","Score: 0.4012244897959183\n","\n","Candidate: 0.9999999997852645 \n","Score: 0.4012244897959183\n","\n","Candidate: 0.9999999997902853 \n","Score: 0.4013265306122449\n","\n","Candidate: 0.9999999997949266 \n","Score: 0.4013265306122449\n","\n","Candidate: 0.9999999997961954 \n","Score: 0.40142857142857136\n","\n","Candidate: 0.9999999997973481 \n","Score: 0.40153061224489794\n","\n","Candidate: 0.9999999997990289 \n","Score: 0.4016326530612244\n","\n","Candidate: 0.9999999998009537 \n","Score: 0.4016326530612244\n","\n","Candidate: 0.9999999998018212 \n","Score: 0.401734693877551\n","\n","Candidate: 0.9999999998045486 \n","Score: 0.401734693877551\n","\n","Candidate: 0.9999999998100568 \n","Score: 0.4018367346938775\n","\n","Candidate: 0.9999999998146665 \n","Score: 0.40193877551020407\n","\n","Candidate: 0.9999999998181698 \n","Score: 0.40193877551020407\n","\n","Candidate: 0.9999999998232778 \n","Score: 0.4020408163265306\n","\n","Candidate: 0.9999999998288163 \n","Score: 0.40214285714285714\n","\n","Candidate: 0.999999999831491 \n","Score: 0.4022448979591836\n","\n","Candidate: 0.9999999998327946 \n","Score: 0.4023469387755102\n","\n","Candidate: 0.9999999998344332 \n","Score: 0.4023469387755102\n","\n","Candidate: 0.9999999998379183 \n","Score: 0.4024489795918367\n","\n","Candidate: 0.9999999998410559 \n","Score: 0.4028571428571428\n","\n","Candidate: 0.9999999998417282 \n","Score: 0.4028571428571428\n","\n","Candidate: 0.9999999998443808 \n","Score: 0.40295918367346933\n","\n","Candidate: 0.999999999847053 \n","Score: 0.38908163265306117\n","\n","Candidate: 0.9999999998479778 \n","Score: 0.38908163265306117\n","\n","Candidate: 0.999999999848612 \n","Score: 0.38918367346938776\n","\n","Candidate: 0.9999999998492898 \n","Score: 0.38928571428571423\n","\n","Candidate: 0.9999999998515712 \n","Score: 0.3893877551020408\n","\n","Candidate: 0.9999999998557487 \n","Score: 0.3893877551020408\n","\n","Candidate: 0.9999999998584208 \n","Score: 0.38948979591836735\n","\n","Candidate: 0.9999999998590705 \n","Score: 0.38948979591836735\n","\n","Candidate: 0.9999999998600639 \n","Score: 0.3895918367346939\n","\n","Candidate: 0.9999999998641464 \n","Score: 0.3896938775510204\n","\n","Candidate: 0.9999999998679251 \n","Score: 0.3902040816326531\n","\n","Candidate: 0.9999999998700317 \n","Score: 0.3903061224489796\n","\n","Candidate: 0.9999999998720752 \n","Score: 0.39040816326530614\n","\n","Candidate: 0.9999999998746891 \n","Score: 0.39040816326530614\n","\n","Candidate: 0.999999999877031 \n","Score: 0.39040816326530614\n","\n","Candidate: 0.9999999998772959 \n","Score: 0.3905102040816327\n","\n","Candidate: 0.999999999877435 \n","Score: 0.3906122448979592\n","\n","Candidate: 0.9999999998787027 \n","Score: 0.39071428571428574\n","\n","Candidate: 0.9999999998801034 \n","Score: 0.39071428571428574\n","\n","Candidate: 0.9999999998806971 \n","Score: 0.39091836734693874\n","\n","Candidate: 0.9999999998821729 \n","Score: 0.39102040816326533\n","\n","Candidate: 0.9999999998847133 \n","Score: 0.3911224489795918\n","\n","Candidate: 0.9999999998872684 \n","Score: 0.3912244897959184\n","\n","Candidate: 0.9999999998907538 \n","Score: 0.3912244897959184\n","\n","Candidate: 0.9999999998933572 \n","Score: 0.39132653061224487\n","\n","Candidate: 0.9999999998950876 \n","Score: 0.39142857142857146\n","\n","Candidate: 0.9999999998970668 \n","Score: 0.39142857142857146\n","\n","Candidate: 0.9999999998981461 \n","Score: 0.39142857142857146\n","\n","Candidate: 0.9999999998989749 \n","Score: 0.39153061224489794\n","\n","Candidate: 0.9999999998993655 \n","Score: 0.3916326530612245\n","\n","Candidate: 0.9999999999002271 \n","Score: 0.391734693877551\n","\n","Candidate: 0.9999999999016 \n","Score: 0.3918367346938776\n","\n","Candidate: 0.9999999999032008 \n","Score: 0.39193877551020406\n","\n","Candidate: 0.9999999999041997 \n","Score: 0.39204081632653065\n","\n","Candidate: 0.999999999905332 \n","Score: 0.39204081632653065\n","\n","Candidate: 0.9999999999063839 \n","Score: 0.3921428571428571\n","\n","Candidate: 0.9999999999067821 \n","Score: 0.3922448979591837\n","\n","Candidate: 0.999999999907315 \n","Score: 0.3923469387755102\n","\n","Candidate: 0.9999999999102265 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.9999999999139237 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.9999999999163197 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.9999999999194287 \n","Score: 0.4094897959183673\n","\n","Candidate: 0.9999999999211128 \n","Score: 0.40959183673469385\n","\n","Candidate: 0.9999999999214046 \n","Score: 0.40959183673469385\n","\n","Candidate: 0.999999999921722 \n","Score: 0.40959183673469385\n","\n","Candidate: 0.9999999999218939 \n","Score: 0.4096938775510204\n","\n","Candidate: 0.9999999999227642 \n","Score: 0.4097959183673469\n","\n","Candidate: 0.9999999999237694 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.9999999999253313 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.9999999999271989 \n","Score: 0.41\n","\n","Candidate: 0.9999999999280014 \n","Score: 0.4101020408163265\n","\n","Candidate: 0.9999999999295168 \n","Score: 0.4101020408163265\n","\n","Candidate: 0.9999999999310838 \n","Score: 0.41020408163265304\n","\n","Candidate: 0.9999999999319 \n","Score: 0.41020408163265304\n","\n","Candidate: 0.9999999999330909 \n","Score: 0.41030612244897957\n","\n","Candidate: 0.9999999999338327 \n","Score: 0.41040816326530605\n","\n","Candidate: 0.9999999999341072 \n","Score: 0.41040816326530605\n","\n","Candidate: 0.9999999999346019 \n","Score: 0.41051020408163263\n","\n","Candidate: 0.9999999999349887 \n","Score: 0.41061224489795917\n","\n","Candidate: 0.9999999999353333 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.999999999935772 \n","Score: 0.41081632653061223\n","\n","Candidate: 0.9999999999361471 \n","Score: 0.41081632653061223\n","\n","Candidate: 0.9999999999367685 \n","Score: 0.41091836734693876\n","\n","Candidate: 0.9999999999395743 \n","Score: 0.41102040816326524\n","\n","Candidate: 0.999999999942713 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9999999999437346 \n","Score: 0.4112244897959183\n","\n","Candidate: 0.9999999999443461 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999999447572 \n","Score: 0.411734693877551\n","\n","Candidate: 0.9999999999448717 \n","Score: 0.4118367346938776\n","\n","Candidate: 0.999999999945129 \n","Score: 0.4119387755102041\n","\n","Candidate: 0.9999999999457818 \n","Score: 0.41204081632653067\n","\n","Candidate: 0.9999999999463631 \n","Score: 0.41204081632653067\n","\n","Candidate: 0.999999999946597 \n","Score: 0.41214285714285714\n","\n","Candidate: 0.9999999999473557 \n","Score: 0.41214285714285714\n","\n","Candidate: 0.9999999999481703 \n","Score: 0.4122448979591837\n","\n","Candidate: 0.9999999999483802 \n","Score: 0.4123469387755102\n","\n","Candidate: 0.9999999999485232 \n","Score: 0.41244897959183674\n","\n","Candidate: 0.9999999999494303 \n","Score: 0.41255102040816327\n","\n","Candidate: 0.999999999950926 \n","Score: 0.41255102040816327\n","\n","Candidate: 0.9999999999520834 \n","Score: 0.4126530612244898\n","\n","Candidate: 0.9999999999529674 \n","Score: 0.41275510204081634\n","\n","Candidate: 0.9999999999537708 \n","Score: 0.41275510204081634\n","\n","Candidate: 0.9999999999541838 \n","Score: 0.41275510204081634\n","\n","Candidate: 0.999999999954557 \n","Score: 0.41285714285714287\n","\n","Candidate: 0.9999999999555255 \n","Score: 0.4129591836734694\n","\n","Candidate: 0.9999999999561685 \n","Score: 0.41306122448979593\n","\n","Candidate: 0.9999999999562181 \n","Score: 0.41306122448979593\n","\n","Candidate: 0.99999999995666 \n","Score: 0.41316326530612246\n","\n","Candidate: 0.9999999999574316 \n","Score: 0.41316326530612246\n","\n","Candidate: 0.9999999999586751 \n","Score: 0.41316326530612246\n","\n","Candidate: 0.9999999999597124 \n","Score: 0.413265306122449\n","\n","Candidate: 0.9999999999599802 \n","Score: 0.4287755102040816\n","\n","Candidate: 0.9999999999603988 \n","Score: 0.4289795918367346\n","\n","Candidate: 0.9999999999607814 \n","Score: 0.4290816326530612\n","\n","Candidate: 0.9999999999611129 \n","Score: 0.42918367346938774\n","\n","Candidate: 0.9999999999614559 \n","Score: 0.42918367346938774\n","\n","Candidate: 0.9999999999622997 \n","Score: 0.42928571428571427\n","\n","Candidate: 0.9999999999634401 \n","Score: 0.42928571428571427\n","\n","Candidate: 0.9999999999644461 \n","Score: 0.4293877551020408\n","\n","Candidate: 0.9999999999650857 \n","Score: 0.42948979591836733\n","\n","Candidate: 0.9999999999652315 \n","Score: 0.4295918367346938\n","\n","Candidate: 0.9999999999654922 \n","Score: 0.4296938775510204\n","\n","Candidate: 0.9999999999657844 \n","Score: 0.4296938775510204\n","\n","Candidate: 0.9999999999659847 \n","Score: 0.4297959183673469\n","\n","Candidate: 0.9999999999663653 \n","Score: 0.42989795918367346\n","\n","Candidate: 0.9999999999667626 \n","Score: 0.42989795918367346\n","\n","Candidate: 0.9999999999669055 \n","Score: 0.42999999999999994\n","\n","Candidate: 0.9999999999678266 \n","Score: 0.4301020408163265\n","\n","Candidate: 0.9999999999687738 \n","Score: 0.430204081632653\n","\n","Candidate: 0.9999999999690807 \n","Score: 0.4303061224489796\n","\n","Candidate: 0.9999999999694141 \n","Score: 0.4303061224489796\n","\n","Candidate: 0.9999999999699087 \n","Score: 0.4303061224489796\n","\n","Candidate: 0.9999999999704892 \n","Score: 0.43040816326530607\n","\n","Candidate: 0.9999999999710043 \n","Score: 0.43051020408163265\n","\n","Candidate: 0.999999999971306 \n","Score: 0.43061224489795913\n","\n","Candidate: 0.9999999999713287 \n","Score: 0.4307142857142857\n","\n","Candidate: 0.9999999999713727 \n","Score: 0.4308163265306122\n","\n","Candidate: 0.9999999999714484 \n","Score: 0.4309183673469387\n","\n","Candidate: 0.999999999971982 \n","Score: 0.43102040816326526\n","\n","Candidate: 0.9999999999727558 \n","Score: 0.4174489795918367\n","\n","Candidate: 0.9999999999732028 \n","Score: 0.4174489795918367\n","\n","Candidate: 0.9999999999733793 \n","Score: 0.40224489795918367\n","\n","Candidate: 0.9999999999735281 \n","Score: 0.4023469387755102\n","\n","Candidate: 0.9999999999737922 \n","Score: 0.40244897959183673\n","\n","Candidate: 0.9999999999742291 \n","Score: 0.40255102040816326\n","\n","Candidate: 0.9999999999747156 \n","Score: 0.40255102040816326\n","\n","Candidate: 0.9999999999749325 \n","Score: 0.40255102040816326\n","\n","Candidate: 0.9999999999754039 \n","Score: 0.40255102040816326\n","\n","Candidate: 0.9999999999758606 \n","Score: 0.4026530612244898\n","\n","Candidate: 0.9999999999762879 \n","Score: 0.4026530612244898\n","\n","Candidate: 0.9999999999768285 \n","Score: 0.4027551020408163\n","\n","Candidate: 0.9999999999769932 \n","Score: 0.40285714285714286\n","\n","Candidate: 0.9999999999773095 \n","Score: 0.4029591836734694\n","\n","Candidate: 0.9999999999776361 \n","Score: 0.403061224489796\n","\n","Candidate: 0.9999999999780202 \n","Score: 0.403061224489796\n","\n","Candidate: 0.9999999999784486 \n","Score: 0.40316326530612245\n","\n","Candidate: 0.9999999999785867 \n","Score: 0.40316326530612245\n","\n","Candidate: 0.9999999999787385 \n","Score: 0.403265306122449\n","\n","Candidate: 0.9999999999789054 \n","Score: 0.4033673469387755\n","\n","Candidate: 0.9999999999793182 \n","Score: 0.40346938775510205\n","\n","Candidate: 0.9999999999797848 \n","Score: 0.4035714285714286\n","\n","Candidate: 0.9999999999801323 \n","Score: 0.4036734693877551\n","\n","Candidate: 0.9999999999804661 \n","Score: 0.4036734693877551\n","\n","Candidate: 0.9999999999807923 \n","Score: 0.40377551020408164\n","\n","Candidate: 0.999999999981205 \n","Score: 0.40438775510204084\n","\n","Candidate: 0.999999999981419 \n","Score: 0.40448979591836737\n","\n","Candidate: 0.9999999999818338 \n","Score: 0.4045918367346939\n","\n","Candidate: 0.9999999999822831 \n","Score: 0.40469387755102043\n","\n","Candidate: 0.9999999999825848 \n","Score: 0.40479591836734696\n","\n","Candidate: 0.999999999982832 \n","Score: 0.3895918367346939\n","\n","Candidate: 0.9999999999829612 \n","Score: 0.3896938775510204\n","\n","Candidate: 0.9999999999832863 \n","Score: 0.38979591836734695\n","\n","Candidate: 0.9999999999835132 \n","Score: 0.3898979591836734\n","\n","Candidate: 0.9999999999835716 \n","Score: 0.39\n","\n","Candidate: 0.9999999999836432 \n","Score: 0.3901020408163265\n","\n","Candidate: 0.9999999999837791 \n","Score: 0.3901020408163265\n","\n","Candidate: 0.9999999999840219 \n","Score: 0.3902040816326531\n","\n","Candidate: 0.9999999999841813 \n","Score: 0.39030612244897955\n","\n","Candidate: 0.9999999999841962 \n","Score: 0.39040816326530614\n","\n","Candidate: 0.9999999999844662 \n","Score: 0.3910204081632653\n","\n","Candidate: 0.9999999999847387 \n","Score: 0.3911224489795918\n","\n","Candidate: 0.999999999984764 \n","Score: 0.3912244897959184\n","\n","Candidate: 0.9999999999847965 \n","Score: 0.39132653061224487\n","\n","Candidate: 0.9999999999851295 \n","Score: 0.39142857142857146\n","\n","Candidate: 0.999999999985751 \n","Score: 0.39142857142857146\n","\n","Candidate: 0.9999999999860878 \n","Score: 0.39142857142857146\n","\n","Candidate: 0.9999999999863203 \n","Score: 0.3916326530612245\n","\n","Candidate: 0.9999999999865332 \n","Score: 0.3916326530612245\n","\n","Candidate: 0.9999999999867689 \n","Score: 0.391734693877551\n","\n","Candidate: 0.9999999999870018 \n","Score: 0.3918367346938776\n","\n","Candidate: 0.9999999999872393 \n","Score: 0.3918367346938776\n","\n","Candidate: 0.9999999999875027 \n","Score: 0.39193877551020406\n","\n","Candidate: 0.9999999999876366 \n","Score: 0.39204081632653065\n","\n","Candidate: 0.999999999987822 \n","Score: 0.39204081632653065\n","\n","Candidate: 0.9999999999879465 \n","Score: 0.39204081632653065\n","\n","Candidate: 0.9999999999880989 \n","Score: 0.3921428571428571\n","\n","Candidate: 0.999999999988229 \n","Score: 0.3922448979591837\n","\n","Candidate: 0.9999999999882991 \n","Score: 0.3923469387755102\n","\n","Candidate: 0.9999999999885406 \n","Score: 0.3924489795918367\n","\n","Candidate: 0.9999999999888199 \n","Score: 0.3924489795918367\n","\n","Candidate: 0.999999999989424 \n","Score: 0.39255102040816325\n","\n","Candidate: 0.9999999999900626 \n","Score: 0.3926530612244898\n","\n","Candidate: 0.9999999999902833 \n","Score: 0.3927551020408163\n","\n","Candidate: 0.9999999999904032 \n","Score: 0.39285714285714285\n","\n","Candidate: 0.9999999999906232 \n","Score: 0.3929591836734694\n","\n","Candidate: 0.9999999999908518 \n","Score: 0.3930612244897959\n","\n","Candidate: 0.9999999999909481 \n","Score: 0.39316326530612244\n","\n","Candidate: 0.9999999999910707 \n","Score: 0.393265306122449\n","\n","Candidate: 0.9999999999911355 \n","Score: 0.3933673469387755\n","\n","Candidate: 0.9999999999911765 \n","Score: 0.39346938775510204\n","\n","Candidate: 0.999999999991215 \n","Score: 0.39357142857142857\n","\n","Candidate: 0.9999999999912467 \n","Score: 0.39357142857142857\n","\n","Candidate: 0.9999999999913991 \n","Score: 0.39367346938775505\n","\n","Candidate: 0.9999999999915989 \n","Score: 0.39377551020408164\n","\n","Candidate: 0.999999999991708 \n","Score: 0.3938775510204081\n","\n","Candidate: 0.9999999999917804 \n","Score: 0.3939795918367347\n","\n","Candidate: 0.9999999999918252 \n","Score: 0.3940816326530612\n","\n","Candidate: 0.99999999999193 \n","Score: 0.39418367346938776\n","\n","Candidate: 0.9999999999920569 \n","Score: 0.39418367346938776\n","\n","Candidate: 0.9999999999921035 \n","Score: 0.39428571428571424\n","\n","Candidate: 0.9999999999921442 \n","Score: 0.3943877551020408\n","\n","Candidate: 0.9999999999921794 \n","Score: 0.3943877551020408\n","\n","Candidate: 0.9999999999923344 \n","Score: 0.3944897959183673\n","\n","Candidate: 0.9999999999926235 \n","Score: 0.3945918367346939\n","\n","Candidate: 0.9999999999928818 \n","Score: 0.39469387755102037\n","\n","Candidate: 0.9999999999930915 \n","Score: 0.39469387755102037\n","\n","Candidate: 0.9999999999932194 \n","Score: 0.39479591836734695\n","\n","Candidate: 0.9999999999932643 \n","Score: 0.39479591836734695\n","\n","Candidate: 0.999999999993302 \n","Score: 0.39489795918367343\n","\n","Candidate: 0.9999999999933586 \n","Score: 0.395\n","\n","Candidate: 0.9999999999934064 \n","Score: 0.395\n","\n","Candidate: 0.9999999999934573 \n","Score: 0.3951020408163265\n","\n","Candidate: 0.9999999999935301 \n","Score: 0.395204081632653\n","\n","Candidate: 0.9999999999935805 \n","Score: 0.39530612244897956\n","\n","Candidate: 0.9999999999936018 \n","Score: 0.3954081632653061\n","\n","Candidate: 0.9999999999937443 \n","Score: 0.3955102040816326\n","\n","Candidate: 0.9999999999941609 \n","Score: 0.39561224489795915\n","\n","Candidate: 0.9999999999945136 \n","Score: 0.3957142857142857\n","\n","Candidate: 0.9999999999946361 \n","Score: 0.3958163265306122\n","\n","Candidate: 0.999999999994714 \n","Score: 0.39591836734693875\n","\n","Candidate: 0.9999999999947484 \n","Score: 0.3960204081632652\n","\n","Candidate: 0.9999999999948397 \n","Score: 0.3961224489795918\n","\n","Candidate: 0.9999999999949496 \n","Score: 0.39622448979591834\n","\n","Candidate: 0.9999999999949911 \n","Score: 0.3963265306122449\n","\n","Candidate: 0.9999999999950435 \n","Score: 0.3964285714285714\n","\n","Candidate: 0.9999999999950984 \n","Score: 0.39653061224489794\n","\n","Candidate: 0.9999999999951725 \n","Score: 0.39653061224489794\n","\n","Candidate: 0.9999999999952474 \n","Score: 0.39663265306122447\n","\n","Candidate: 0.9999999999952942 \n","Score: 0.396734693877551\n","\n","Candidate: 0.9999999999953232 \n","Score: 0.39704081632653054\n","\n","Candidate: 0.9999999999953513 \n","Score: 0.39714285714285713\n","\n","Candidate: 0.9999999999954893 \n","Score: 0.3972448979591836\n","\n","Candidate: 0.9999999999956226 \n","Score: 0.3973469387755102\n","\n","Candidate: 0.9999999999956537 \n","Score: 0.3974489795918367\n","\n","Candidate: 0.999999999995768 \n","Score: 0.39755102040816326\n","\n","Candidate: 0.9999999999958795 \n","Score: 0.3976530612244898\n","\n","Candidate: 0.9999999999958915 \n","Score: 0.3976530612244898\n","\n","Candidate: 0.9999999999958997 \n","Score: 0.3977551020408163\n","\n","Candidate: 0.999999999995915 \n","Score: 0.39785714285714285\n","\n","Candidate: 0.9999999999959372 \n","Score: 0.39785714285714285\n","\n","Candidate: 0.9999999999959919 \n","Score: 0.3979591836734694\n","\n","Candidate: 0.9999999999961947 \n","Score: 0.39816326530612245\n","\n","Candidate: 0.9999999999963689 \n","Score: 0.39816326530612245\n","\n","Candidate: 0.9999999999964354 \n","Score: 0.3982653061224489\n","\n","Candidate: 0.9999999999965022 \n","Score: 0.3982653061224489\n","\n","Candidate: 0.9999999999965251 \n","Score: 0.3983673469387755\n","\n","Candidate: 0.9999999999965496 \n","Score: 0.398469387755102\n","\n","Candidate: 0.9999999999966444 \n","Score: 0.398469387755102\n","\n","Candidate: 0.999999999996751 \n","Score: 0.3985714285714286\n","\n","Candidate: 0.999999999996784 \n","Score: 0.3986734693877551\n","\n","Candidate: 0.9999999999968368 \n","Score: 0.39877551020408164\n","\n","Candidate: 0.9999999999969001 \n","Score: 0.39887755102040817\n","\n","Candidate: 0.9999999999969389 \n","Score: 0.3989795918367347\n","\n","Candidate: 0.9999999999969948 \n","Score: 0.3990816326530613\n","\n","Candidate: 0.9999999999970939 \n","Score: 0.39918367346938777\n","\n","Candidate: 0.9999999999971652 \n","Score: 0.39928571428571435\n","\n","Candidate: 0.9999999999971785 \n","Score: 0.39938775510204083\n","\n","Candidate: 0.9999999999971878 \n","Score: 0.3994897959183674\n","\n","Candidate: 0.9999999999972 \n","Score: 0.41489795918367356\n","\n","Candidate: 0.999999999997259 \n","Score: 0.41489795918367356\n","\n","Candidate: 0.9999999999973392 \n","Score: 0.41500000000000004\n","\n","Candidate: 0.9999999999973885 \n","Score: 0.4151020408163266\n","\n","Candidate: 0.9999999999974127 \n","Score: 0.4152040816326531\n","\n","Candidate: 0.9999999999974614 \n","Score: 0.4153061224489797\n","\n","Candidate: 0.9999999999975397 \n","Score: 0.416326530612245\n","\n","Candidate: 0.9999999999975779 \n","Score: 0.4164285714285715\n","\n","Candidate: 0.9999999999976147 \n","Score: 0.416530612244898\n","\n","Candidate: 0.9999999999976552 \n","Score: 0.416530612244898\n","\n","Candidate: 0.9999999999976821 \n","Score: 0.41663265306122454\n","\n","Candidate: 0.9999999999977123 \n","Score: 0.4167346938775511\n","\n","Candidate: 0.9999999999977482 \n","Score: 0.4168367346938776\n","\n","Candidate: 0.9999999999977813 \n","Score: 0.41693877551020414\n","\n","Candidate: 0.999999999997794 \n","Score: 0.41704081632653067\n","\n","Candidate: 0.9999999999978118 \n","Score: 0.4171428571428572\n","\n","Candidate: 0.9999999999978356 \n","Score: 0.41724489795918374\n","\n","Candidate: 0.9999999999978574 \n","Score: 0.4173469387755102\n","\n","Candidate: 0.999999999997873 \n","Score: 0.4174489795918368\n","\n","Candidate: 0.9999999999979062 \n","Score: 0.4174489795918368\n","\n","Candidate: 0.9999999999979726 \n","Score: 0.4175510204081633\n","\n","Candidate: 0.9999999999980317 \n","Score: 0.41765306122448986\n","\n","Candidate: 0.999999999998062 \n","Score: 0.41775510204081634\n","\n","Candidate: 0.9999999999980888 \n","Score: 0.4178571428571429\n","\n","Candidate: 0.999999999998104 \n","Score: 0.4179591836734694\n","\n","Candidate: 0.9999999999981118 \n","Score: 0.4179591836734694\n","\n","Candidate: 0.9999999999981464 \n","Score: 0.418061224489796\n","\n","Candidate: 0.9999999999981837 \n","Score: 0.418061224489796\n","\n","Candidate: 0.9999999999982039 \n","Score: 0.41816326530612247\n","\n","Candidate: 0.9999999999982249 \n","Score: 0.41816326530612247\n","\n","Candidate: 0.9999999999982496 \n","Score: 0.41826530612244905\n","\n","Candidate: 0.9999999999982823 \n","Score: 0.41836734693877553\n","\n","Candidate: 0.9999999999983324 \n","Score: 0.4184693877551021\n","\n","Candidate: 0.999999999998396 \n","Score: 0.4185714285714286\n","\n","Candidate: 0.9999999999984432 \n","Score: 0.4186734693877551\n","\n","Candidate: 0.9999999999984719 \n","Score: 0.41877551020408166\n","\n","Candidate: 0.9999999999984917 \n","Score: 0.4188775510204082\n","\n","Candidate: 0.9999999999984983 \n","Score: 0.4189795918367347\n","\n","Candidate: 0.9999999999985003 \n","Score: 0.4189795918367347\n","\n","Candidate: 0.9999999999985096 \n","Score: 0.4192857142857144\n","\n","Candidate: 0.9999999999985363 \n","Score: 0.41938775510204085\n","\n","Candidate: 0.9999999999985794 \n","Score: 0.41948979591836744\n","\n","Candidate: 0.9999999999986429 \n","Score: 0.4195918367346939\n","\n","Candidate: 0.9999999999986955 \n","Score: 0.41969387755102044\n","\n","Candidate: 0.9999999999987218 \n","Score: 0.419795918367347\n","\n","Candidate: 0.9999999999987392 \n","Score: 0.419795918367347\n","\n","Candidate: 0.999999999998745 \n","Score: 0.4198979591836735\n","\n","Candidate: 0.9999999999987632 \n","Score: 0.42000000000000004\n","\n","Candidate: 0.9999999999987973 \n","Score: 0.42010204081632657\n","\n","Candidate: 0.9999999999988198 \n","Score: 0.4202040816326531\n","\n","Candidate: 0.9999999999988338 \n","Score: 0.42040816326530617\n","\n","Candidate: 0.9999999999988431 \n","Score: 0.42051020408163275\n","\n","Candidate: 0.9999999999988485 \n","Score: 0.42061224489795923\n","\n","Candidate: 0.9999999999988601 \n","Score: 0.4207142857142858\n","\n","Candidate: 0.9999999999988827 \n","Score: 0.4208163265306123\n","\n","Candidate: 0.9999999999988989 \n","Score: 0.4208163265306123\n","\n","Candidate: 0.9999999999989329 \n","Score: 0.4209183673469388\n","\n","Candidate: 0.9999999999989697 \n","Score: 0.42102040816326536\n","\n","Candidate: 0.9999999999989921 \n","Score: 0.42102040816326536\n","\n","Candidate: 0.9999999999990163 \n","Score: 0.42102040816326536\n","\n","Candidate: 0.9999999999990228 \n","Score: 0.42112244897959195\n","\n","Candidate: 0.9999999999990437 \n","Score: 0.4212244897959184\n","\n","Candidate: 0.9999999999990674 \n","Score: 0.42132653061224495\n","\n","Candidate: 0.999999999999083 \n","Score: 0.42132653061224495\n","\n","Candidate: 0.999999999999098 \n","Score: 0.4214285714285715\n","\n","Candidate: 0.9999999999991053 \n","Score: 0.421530612244898\n","\n","Candidate: 0.9999999999991138 \n","Score: 0.42163265306122455\n","\n","Candidate: 0.9999999999991189 \n","Score: 0.421734693877551\n","\n","Candidate: 0.9999999999991341 \n","Score: 0.4218367346938776\n","\n","Candidate: 0.9999999999991516 \n","Score: 0.40663265306122454\n","\n","Candidate: 0.9999999999991726 \n","Score: 0.40673469387755107\n","\n","Candidate: 0.9999999999991984 \n","Score: 0.4068367346938776\n","\n","Candidate: 0.999999999999209 \n","Score: 0.4069387755102041\n","\n","Candidate: 0.9999999999992157 \n","Score: 0.40704081632653066\n","\n","Candidate: 0.9999999999992222 \n","Score: 0.40704081632653066\n","\n","Candidate: 0.99999999999923 \n","Score: 0.40714285714285714\n","\n","Candidate: 0.9999999999992353 \n","Score: 0.40724489795918367\n","\n","Candidate: 0.9999999999992399 \n","Score: 0.4073469387755102\n","\n","Candidate: 0.9999999999992601 \n","Score: 0.4074489795918368\n","\n","Candidate: 0.9999999999992832 \n","Score: 0.40755102040816327\n","\n","Candidate: 0.9999999999993066 \n","Score: 0.40765306122448985\n","\n","Candidate: 0.9999999999993238 \n","Score: 0.4077551020408164\n","\n","Candidate: 0.9999999999993336 \n","Score: 0.4078571428571429\n","\n","Candidate: 0.9999999999993443 \n","Score: 0.4078571428571429\n","\n","Candidate: 0.9999999999993466 \n","Score: 0.4079591836734694\n","\n","Candidate: 0.9999999999993547 \n","Score: 0.408061224489796\n","\n","Candidate: 0.9999999999993657 \n","Score: 0.40816326530612246\n","\n","Candidate: 0.9999999999993723 \n","Score: 0.408265306122449\n","\n","Candidate: 0.9999999999993816 \n","Score: 0.4083673469387755\n","\n","Candidate: 0.9999999999993902 \n","Score: 0.4086734693877551\n","\n","Candidate: 0.9999999999993958 \n","Score: 0.40877551020408165\n","\n","Candidate: 0.9999999999994009 \n","Score: 0.4088775510204082\n","\n","Candidate: 0.9999999999994054 \n","Score: 0.4088775510204082\n","\n","Candidate: 0.9999999999994154 \n","Score: 0.4089795918367347\n","\n","Candidate: 0.999999999999442 \n","Score: 0.4089795918367347\n","\n","Candidate: 0.9999999999994647 \n","Score: 0.4090816326530612\n","\n","Candidate: 0.99999999999948 \n","Score: 0.4091836734693878\n","\n","Candidate: 0.9999999999994936 \n","Score: 0.40928571428571425\n","\n","Candidate: 0.9999999999994964 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.9999999999994973 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.9999999999995053 \n","Score: 0.4094897959183673\n","\n","Candidate: 0.9999999999995146 \n","Score: 0.4095918367346939\n","\n","Candidate: 0.999999999999529 \n","Score: 0.40969387755102044\n","\n","Candidate: 0.999999999999557 \n","Score: 0.40979591836734697\n","\n","Candidate: 0.9999999999995759 \n","Score: 0.4098979591836735\n","\n","Candidate: 0.9999999999995831 \n","Score: 0.41000000000000003\n","\n","Candidate: 0.9999999999995874 \n","Score: 0.4101020408163265\n","\n","Candidate: 0.9999999999995892 \n","Score: 0.4102040816326531\n","\n","Candidate: 0.9999999999995922 \n","Score: 0.41030612244897957\n","\n","Candidate: 0.9999999999995975 \n","Score: 0.41030612244897957\n","\n","Candidate: 0.9999999999996123 \n","Score: 0.41040816326530616\n","\n","Candidate: 0.9999999999996236 \n","Score: 0.41051020408163263\n","\n","Candidate: 0.9999999999996245 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9999999999996259 \n","Score: 0.4108163265306123\n","\n","Candidate: 0.9999999999996311 \n","Score: 0.41091836734693876\n","\n","Candidate: 0.9999999999996363 \n","Score: 0.41102040816326535\n","\n","Candidate: 0.9999999999996374 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.999999999999643 \n","Score: 0.4112244897959183\n","\n","Candidate: 0.9999999999996517 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999999996563 \n","Score: 0.41142857142857137\n","\n","Candidate: 0.9999999999996575 \n","Score: 0.41153061224489795\n","\n","Candidate: 0.9999999999996597 \n","Score: 0.41153061224489795\n","\n","Candidate: 0.9999999999996629 \n","Score: 0.41163265306122443\n","\n","Candidate: 0.9999999999996738 \n","Score: 0.411734693877551\n","\n","Candidate: 0.9999999999996851 \n","Score: 0.4118367346938775\n","\n","Candidate: 0.9999999999996875 \n","Score: 0.4119387755102041\n","\n","Candidate: 0.9999999999996898 \n","Score: 0.4119387755102041\n","\n","Candidate: 0.9999999999997068 \n","Score: 0.41204081632653056\n","\n","Candidate: 0.9999999999997231 \n","Score: 0.41214285714285714\n","\n","Candidate: 0.9999999999997303 \n","Score: 0.3998958333333333\n","\n","Candidate: 0.9999999999997371 \n","Score: 0.3999999999999999\n","\n","Candidate: 0.9999999999997385 \n","Score: 0.4001041666666666\n","\n","Candidate: 0.9999999999997418 \n","Score: 0.4002083333333333\n","\n","Candidate: 0.9999999999997464 \n","Score: 0.40031249999999996\n","\n","Candidate: 0.9999999999997482 \n","Score: 0.40041666666666664\n","\n","Candidate: 0.9999999999997489 \n","Score: 0.4005208333333333\n","\n","Candidate: 0.9999999999997504 \n","Score: 0.38666666666666666\n","\n","Candidate: 0.9999999999997524 \n","Score: 0.38739583333333333\n","\n","Candidate: 0.9999999999997544 \n","Score: 0.3875\n","\n","Candidate: 0.9999999999997589 \n","Score: 0.38760416666666664\n","\n","Candidate: 0.9999999999997629 \n","Score: 0.3877083333333333\n","\n","Candidate: 0.9999999999997722 \n","Score: 0.3878125\n","\n","Candidate: 0.9999999999997828 \n","Score: 0.3879166666666667\n","\n","Candidate: 0.9999999999997846 \n","Score: 0.38802083333333337\n","\n","Candidate: 0.9999999999997853 \n","Score: 0.38812500000000005\n","\n","Candidate: 0.9999999999997864 \n","Score: 0.3882291666666667\n","\n","Candidate: 0.999999999999788 \n","Score: 0.38833333333333336\n","\n","Candidate: 0.9999999999997925 \n","Score: 0.4040625\n","\n","Candidate: 0.9999999999997982 \n","Score: 0.40552083333333333\n","\n","Candidate: 0.9999999999998023 \n","Score: 0.405625\n","\n","Candidate: 0.9999999999998046 \n","Score: 0.40572916666666664\n","\n","Candidate: 0.9999999999998055 \n","Score: 0.4058333333333333\n","\n","Candidate: 0.9999999999998084 \n","Score: 0.4061458333333333\n","\n","Candidate: 0.9999999999998161 \n","Score: 0.40625\n","\n","Candidate: 0.9999999999998264 \n","Score: 0.40625\n","\n","Candidate: 0.9999999999998308 \n","Score: 0.3936170212765957\n","\n","Candidate: 0.9999999999998354 \n","Score: 0.3937234042553191\n","\n","Candidate: 0.9999999999998427 \n","Score: 0.3938297872340425\n","\n","Candidate: 0.9999999999998459 \n","Score: 0.3939361702127659\n","\n","Candidate: 0.9999999999998485 \n","Score: 0.39414893617021274\n","\n","Candidate: 0.9999999999998508 \n","Score: 0.39425531914893613\n","\n","Candidate: 0.9999999999998526 \n","Score: 0.39436170212765953\n","\n","Candidate: 0.9999999999998547 \n","Score: 0.3944680851063829\n","\n","Candidate: 0.9999999999998558 \n","Score: 0.3945744680851063\n","\n","Candidate: 0.9999999999998581 \n","Score: 0.3946808510638297\n","\n","Candidate: 0.999999999999862 \n","Score: 0.3947872340425531\n","\n","Candidate: 0.9999999999998643 \n","Score: 0.39489361702127657\n","\n","Candidate: 0.9999999999998658 \n","Score: 0.39499999999999996\n","\n","Candidate: 0.9999999999998681 \n","Score: 0.39510638297872336\n","\n","Candidate: 0.9999999999998698 \n","Score: 0.39521276595744675\n","\n","Candidate: 0.9999999999998752 \n","Score: 0.39531914893617015\n","\n","Candidate: 0.9999999999998823 \n","Score: 0.3954255319148936\n","\n","Candidate: 0.9999999999998848 \n","Score: 0.39869565217391306\n","\n","Candidate: 0.9999999999998855 \n","Score: 0.398804347826087\n","\n","Candidate: 0.9999999999998872 \n","Score: 0.3989130434782609\n","\n","Candidate: 0.9999999999998883 \n","Score: 0.3990217391304348\n","\n","Candidate: 0.9999999999998893 \n","Score: 0.3991304347826087\n","\n","Candidate: 0.9999999999998909 \n","Score: 0.40444444444444444\n","\n","Candidate: 0.9999999999998919 \n","Score: 0.40455555555555556\n","\n","Candidate: 0.9999999999998939 \n","Score: 0.4046666666666666\n","\n","Candidate: 0.999999999999897 \n","Score: 0.4047777777777778\n","\n","Candidate: 0.9999999999998992 \n","Score: 0.40488888888888885\n","\n","Candidate: 0.9999999999998999 \n","Score: 0.4051111111111111\n","\n","Candidate: 0.9999999999999019 \n","Score: 0.40522222222222215\n","\n","Candidate: 0.9999999999999047 \n","Score: 0.40522222222222215\n","\n","Candidate: 0.9999999999999094 \n","Score: 0.4053333333333333\n","\n","Candidate: 0.9999999999999134 \n","Score: 0.4054444444444444\n","\n","Candidate: 0.9999999999999151 \n","Score: 0.40555555555555556\n","\n","Candidate: 0.9999999999999165 \n","Score: 0.4056666666666666\n","\n","Candidate: 0.9999999999999172 \n","Score: 0.4057777777777778\n","\n","Candidate: 0.9999999999999187 \n","Score: 0.40588888888888885\n","\n","Candidate: 0.9999999999999221 \n","Score: 0.40599999999999997\n","\n","Candidate: 0.9999999999999256 \n","Score: 0.4061111111111111\n","\n","Candidate: 0.9999999999999288 \n","Score: 0.40622222222222215\n","\n","Candidate: 0.9999999999999314 \n","Score: 0.40633333333333327\n","\n","Candidate: 0.999999999999932 \n","Score: 0.3897777777777778\n","\n","Candidate: 0.9999999999999329 \n","Score: 0.38988888888888895\n","\n","Candidate: 0.9999999999999354 \n","Score: 0.39\n","\n","Candidate: 0.9999999999999375 \n","Score: 0.39022222222222225\n","\n","Candidate: 0.9999999999999382 \n","Score: 0.3904444444444445\n","\n","Candidate: 0.9999999999999392 \n","Score: 0.39363636363636356\n","\n","Candidate: 0.9999999999999399 \n","Score: 0.39374999999999993\n","\n","Candidate: 0.99999999999994 \n","Score: 0.39374999999999993\n","\n","Candidate: 0.9999999999999406 \n","Score: 0.3939772727272727\n","\n","Candidate: 0.9999999999999414 \n","Score: 0.39409090909090905\n","\n","Candidate: 0.9999999999999433 \n","Score: 0.3942045454545454\n","\n","Candidate: 0.9999999999999465 \n","Score: 0.3943181818181818\n","\n","Candidate: 0.9999999999999483 \n","Score: 0.39443181818181816\n","\n","Candidate: 0.9999999999999503 \n","Score: 0.39454545454545453\n","\n","Candidate: 0.9999999999999529 \n","Score: 0.3946590909090909\n","\n","Candidate: 0.9999999999999543 \n","Score: 0.3947727272727273\n","\n","Candidate: 0.9999999999999551 \n","Score: 0.398139534883721\n","\n","Candidate: 0.9999999999999565 \n","Score: 0.3982558139534884\n","\n","Candidate: 0.9999999999999576 \n","Score: 0.3983720930232559\n","\n","Candidate: 0.9999999999999578 \n","Score: 0.3984883720930233\n","\n","Candidate: 0.9999999999999581 \n","Score: 0.39860465116279076\n","\n","Candidate: 0.9999999999999587 \n","Score: 0.39872093023255817\n","\n","Candidate: 0.9999999999999595 \n","Score: 0.39883720930232563\n","\n","Candidate: 0.9999999999999607 \n","Score: 0.3990697674418605\n","\n","Candidate: 0.9999999999999614 \n","Score: 0.3990697674418605\n","\n","Candidate: 0.9999999999999618 \n","Score: 0.3993023255813954\n","\n","Candidate: 0.9999999999999638 \n","Score: 0.3994186046511628\n","\n","Candidate: 0.9999999999999656 \n","Score: 0.39953488372093027\n","\n","Candidate: 0.999999999999966 \n","Score: 0.3998837209302326\n","\n","Candidate: 0.9999999999999665 \n","Score: 0.4\n","\n","Candidate: 0.9999999999999669 \n","Score: 0.4001162790697675\n","\n","Candidate: 0.9999999999999679 \n","Score: 0.4002325581395349\n","\n","Candidate: 0.9999999999999687 \n","Score: 0.4002325581395349\n","\n","Candidate: 0.9999999999999689 \n","Score: 0.4004651162790698\n","\n","Candidate: 0.9999999999999702 \n","Score: 0.40058139534883724\n","\n","Candidate: 0.9999999999999718 \n","Score: 0.40069767441860465\n","\n","Candidate: 0.9999999999999734 \n","Score: 0.4008139534883721\n","\n","Candidate: 0.9999999999999746 \n","Score: 0.4009302325581396\n","\n","Candidate: 0.9999999999999747 \n","Score: 0.4009302325581396\n","\n","Candidate: 0.9999999999999754 \n","Score: 0.40139534883720934\n","\n","Candidate: 0.9999999999999762 \n","Score: 0.4015116279069768\n","\n","Candidate: 0.9999999999999771 \n","Score: 0.4016279069767442\n","\n","Candidate: 0.9999999999999778 \n","Score: 0.4016279069767442\n","\n","Candidate: 0.9999999999999786 \n","Score: 0.40186046511627915\n","\n","Candidate: 0.9999999999999796 \n","Score: 0.40197674418604656\n","\n","Candidate: 0.99999999999998 \n","Score: 0.402093023255814\n","\n","Candidate: 0.9999999999999802 \n","Score: 0.402093023255814\n","\n","Candidate: 0.9999999999999805 \n","Score: 0.4023255813953489\n","\n","Candidate: 0.9999999999999809 \n","Score: 0.4024418604651163\n","\n","Candidate: 0.9999999999999813 \n","Score: 0.40255813953488373\n","\n","Candidate: 0.9999999999999821 \n","Score: 0.40267441860465125\n","\n","Candidate: 0.9999999999999829 \n","Score: 0.40279069767441866\n","\n","Candidate: 0.9999999999999835 \n","Score: 0.4029069767441861\n","\n","Candidate: 0.9999999999999838 \n","Score: 0.403139534883721\n","\n","Candidate: 0.9999999999999842 \n","Score: 0.4032558139534884\n","\n","Candidate: 0.9999999999999848 \n","Score: 0.40348837209302335\n","\n","Candidate: 0.9999999999999851 \n","Score: 0.40360465116279076\n","\n","Candidate: 0.9999999999999856 \n","Score: 0.4037209302325583\n","\n","Candidate: 0.9999999999999861 \n","Score: 0.4038372093023257\n","\n","Candidate: 0.9999999999999862 \n","Score: 0.4038372093023257\n","\n","Candidate: 0.9999999999999866 \n","Score: 0.4098809523809524\n","\n","Candidate: 0.9999999999999869 \n","Score: 0.41000000000000003\n","\n","Candidate: 0.9999999999999876 \n","Score: 0.4101190476190476\n","\n","Candidate: 0.9999999999999882 \n","Score: 0.4102380952380953\n","\n","Candidate: 0.9999999999999887 \n","Score: 0.41035714285714286\n","\n","Candidate: 0.9999999999999891 \n","Score: 0.4105952380952381\n","\n","Candidate: 0.9999999999999896 \n","Score: 0.4107142857142858\n","\n","Candidate: 0.9999999999999898 \n","Score: 0.410952380952381\n","\n","Candidate: 0.99999999999999 \n","Score: 0.41130952380952385\n","\n","Candidate: 0.9999999999999902 \n","Score: 0.4114285714285715\n","\n","Candidate: 0.9999999999999905 \n","Score: 0.4114285714285715\n","\n","Candidate: 0.9999999999999908 \n","Score: 0.41166666666666674\n","\n","Candidate: 0.9999999999999911 \n","Score: 0.4117857142857143\n","\n","Candidate: 0.9999999999999913 \n","Score: 0.3974390243902439\n","\n","Candidate: 0.9999999999999917 \n","Score: 0.3975609756097561\n","\n","Candidate: 0.9999999999999918 \n","Score: 0.3975609756097561\n","\n","Candidate: 0.999999999999992 \n","Score: 0.3978048780487805\n","\n","Candidate: 0.9999999999999925 \n","Score: 0.3981707317073171\n","\n","Candidate: 0.9999999999999928 \n","Score: 0.3982926829268293\n","\n","Candidate: 0.9999999999999931 \n","Score: 0.3984146341463415\n","\n","Candidate: 0.9999999999999933 \n","Score: 0.3985365853658537\n","\n","Candidate: 0.9999999999999936 \n","Score: 0.39878048780487807\n","\n","Candidate: 0.9999999999999938 \n","Score: 0.3989024390243903\n","\n","Candidate: 0.9999999999999941 \n","Score: 0.39902439024390246\n","\n","Candidate: 0.9999999999999947 \n","Score: 0.40325000000000005\n","\n","Candidate: 0.9999999999999951 \n","Score: 0.40337500000000004\n","\n","Candidate: 0.9999999999999952 \n","Score: 0.403625\n","\n","Candidate: 0.9999999999999953 \n","Score: 0.403625\n","\n","Candidate: 0.9999999999999956 \n","Score: 0.4076923076923077\n","\n","Candidate: 0.9999999999999958 \n","Score: 0.4078205128205129\n","\n","Candidate: 0.999999999999996 \n","Score: 0.4083333333333334\n","\n","Candidate: 0.9999999999999962 \n","Score: 0.4092307692307693\n","\n","Candidate: 0.9999999999999964 \n","Score: 0.4094871794871795\n","\n","Candidate: 0.9999999999999967 \n","Score: 0.40961538461538466\n","\n","Candidate: 0.9999999999999969 \n","Score: 0.4098717948717949\n","\n","Candidate: 0.9999999999999971 \n","Score: 0.4098717948717949\n","\n","Candidate: 0.9999999999999973 \n","Score: 0.41051282051282056\n","\n","Candidate: 0.9999999999999976 \n","Score: 0.4151315789473685\n","\n","Candidate: 0.9999999999999978 \n","Score: 0.41552631578947374\n","\n","Candidate: 0.9999999999999979 \n","Score: 0.41565789473684217\n","\n","Candidate: 0.999999999999998 \n","Score: 0.41565789473684217\n","\n","Candidate: 0.9999999999999982 \n","Score: 0.41605263157894745\n","\n","Candidate: 0.9999999999999984 \n","Score: 0.41671052631578953\n","\n","Candidate: 0.9999999999999987 \n","Score: 0.4218918918918919\n","\n","Candidate: 0.9999999999999989 \n","Score: 0.4239189189189189\n","\n","Candidate: 0.9999999999999991 \n","Score: 0.4344285714285715\n","\n","Candidate: 0.9999999999999993 \n","Score: 0.4411764705882353\n","\n","Candidate: 0.9999999999999996 \n","Score: 0.4425\n","\n","Candidate: 0.9999999999999998 \n","Score: 0.4518181818181818\n","\n","Candidate: 1.0 \n","Score: 0.4465625\n","\n"]}]},{"cell_type":"code","source":["# aim is to minimise cost function -- find index in array where this is the case\n","lowest_cf_score = np.min(np.array(cost_function_values))\n","index_best_th = np.argmin(np.array(cost_function_values))"],"metadata":{"id":"P2IsLZXQ77oZ","executionInfo":{"status":"ok","timestamp":1651225176692,"user_tz":-60,"elapsed":372,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":147,"outputs":[]},{"cell_type":"code","source":["lowest_cf_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iZ3ba0jhY0I","executionInfo":{"status":"ok","timestamp":1651225177098,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"9dac930d-97ca-4732-e999-2f210edf905b"},"execution_count":148,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2652040816326531"]},"metadata":{},"execution_count":148}]},{"cell_type":"code","source":["index_best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBS0v3GAh77m","executionInfo":{"status":"ok","timestamp":1651225179240,"user_tz":-60,"elapsed":354,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"cab49a8a-afc1-43a5-c852-d5cdadaf0c38"},"execution_count":149,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":149}]},{"cell_type":"code","source":["best_th = list(threshold_candidates)[index_best_th]\n","best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmy0bv8N8YvW","executionInfo":{"status":"ok","timestamp":1651225179607,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"b54113ff-2b8f-4af8-f3c6-0300fa0b1efc"},"execution_count":150,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.45141065830721"]},"metadata":{},"execution_count":150}]},{"cell_type":"markdown","source":["#### Testing with best threshold"],"metadata":{"id":"ypFTpLSAir09"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions excluding the current test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # count inconclusive results\n","  inconc_count = 0\n","  \n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    for i in range(len(predictions)):\n","\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","    \n","      if(c >= best_th ): # best confidence threshold from cost function\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","\n","        earliness.append(time_index/timestamps[-1])\n","\n","        if(pred == 1.0):\n","          print(f\"TTP: {time_to_result + 30}s\")\n","\n","        break\n","\n","      if(i == len(predictions)-1):\n","        print(\"Inconclusive\")\n","        inconc_count += 1\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","  print(f\"Average Earliness: {sum(earliness)/len(earliness)}\")\n","  print(f\"Total Inconclusive: {inconc_count}/{sample_idx}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfPwqWWHiqnY","executionInfo":{"status":"ok","timestamp":1651225235677,"user_tz":-60,"elapsed":3321,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2d0de72c-8955-42db-8c03-17377f8567ed"},"execution_count":151,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 50.0s\n","\n","Sample exp_86_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample exp_165_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_35_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_28_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample exp_40_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 52s\n","\n","Sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 50.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 50.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 51.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 50.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 53.0s\n","\n","Sample rv1y_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample rv1y_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 50.0s\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 52.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 58.0s\n","\n","Sample b1\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 49.0s\n","\n","Sample b5\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 50s\n","\n","Sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 52s\n","\n","Sample exp_165_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_35_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_28_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 57s\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 60s\n","\n","Sample exp_40_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 52s\n","\n","Sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_27_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 53s\n","\n","Sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_97_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_64_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample yap\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample yap1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample yap1n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 49.0s\n","\n","Sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 50.0s\n","\n","Sample arv7\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 50.0s\n","\n","Accuracy: 0.6530612244897959\n","Sensitivity/Recall: 0.7142857142857143\n","Specificity: 0.5714285714285714\n","Precision: 0.6896551724137931\n","F1 Score: 0.7017543859649122\n","Average Earliness: 0.02000000000000001\n","Total Inconclusive: 0/49\n"]}]},{"cell_type":"markdown","source":["#### Testing with different alpha values"],"metadata":{"id":"w43_TkUVitvi"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"pJXWD05RjB-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"NSkTWcddjB-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981439090,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"f742fd4d-fa2c-4f24-c18f-ffde40f1d377","id":"KWOXfxRKjB-i"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"NXrd_74JjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"wcE9LintjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"qb9FWSPgjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are mad of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"bM7ILJSwjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981450827,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"23bf8873-4159-42ca-fc01-82fcb7e27198","id":"36WDfG-TjB-l"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1184"]},"metadata":{},"execution_count":497}]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  acc = []\n","  ear = []\n","\n","  for i in range(0,100,5):\n","\n","    # alpha\n","    alpha = i/100\n","\n","    print(f\"Alpha: {alpha}\")\n","\n","    # array to hold cost function value for each candidate\n","    cost_function_values = []\n","\n","    # create nN predictions using each dataset as the test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # evaluate every candidate\n","    for th in threshold_candidates:\n","\n","      # print(f\"Candidate: {th} \")\n","\n","      # array to hold earliness values for the samples \n","      earliness = []  \n","\n","      # dict to hold predictions vs true values for the samples  \n","      final_classifications = {}\n","\n","      # sample index\n","      sample_idx = 0\n","\n","      for key, value in all_samples.items():\n","        test_sample_name = key\n","        test_sample = value\n","  \n","        # get KNN predicition for the sample\n","        predictions = sample_predictions[sample_idx]\n","\n","        for i in range(len(predictions)):\n","\n","          # get the confidence for that prediction \n","          c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","          if(c >= th): # check if confidence is above confidence threshold\n","\n","            time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","            time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","            # predicted class for the sample is given by the prediction which led to the gien confidence value\n","            pred = predictions[i]\n","\n","            # update final outcomes dict\n","            final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","            # add to earliness array\n","            earliness.append(time_index/timestamps[-1])\n","\n","            break\n","        sample_idx += 1\n","\n","      # get avg accuracy and avg earliness for this threshold\n","      if(len(final_classifications) > 0):\n","        avg_accuracy = accuracy(final_classifications)\n","        avg_earliness = sum(earliness)/len(earliness)\n","\n","        # compute value of cost function and add to array \n","        cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","        cost_function_values.append(cf_score)\n","\n","    index_best_th = np.argmin(np.array(cost_function_values))    \n","    best_th = list(threshold_candidates)[index_best_th]\n","\n","###########################################################################################################\n","\n","    ## teating with best th\n","    final_classifications = {}\n","    earliness = []\n","\n","    # create nN predictions excluding the current test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    # count inconclusive results\n","    inconc_count = 0\n","    \n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      \n","        if(c >= best_th): # best confidence threshold from cost function\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          pred = predictions[i]\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","          earliness.append(time_index/timestamps[-1])\n","          break\n","\n","        if(i == len(predictions)-1):\n","          inconc_count += 1\n","      \n","      sample_idx += 1\n","\n","    print(f\"Avg Accuracy: {accuracy(final_classifications)}\")\n","    print(f\"Avg Earliness: {sum(earliness)/len(earliness)}\")\n","    print(\"\")\n","    acc.append(accuracy(final_classifications))\n","    ear.append(sum(earliness)/len(earliness))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"V6Fhz4hsiui6","executionInfo":{"status":"error","timestamp":1650981574100,"user_tz":-60,"elapsed":121427,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"5e8c4f9a-49b2-44fb-eed4-3494af98bb4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Alpha: 0.0\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.05\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.1\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.15\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-498-89cc9171be6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# create nN predictions excluding the current test sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0msample_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_predictions_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# create multipliers for every classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-66-ab459af536aa>\u001b[0m in \u001b[0;36mgenerate_predictions_table\u001b[0;34m(positives, negatives, timestamps)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_sample_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-100-5619c2d01103>\u001b[0m in \u001b[0;36mget_training_data_knn\u001b[0;34m(positive_samples, negative_samples, timestamp, test_samples)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m## truncate sample to length t = timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpos_subsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Average Output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## append subsample of length t to training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m             \u001b[0;31m# shortcut if the key is in columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3424\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3425\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4538\u001b[0m         \"\"\"\n\u001b[1;32m   4539\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = acc\n","y = ear\n","axes.set_xlabel(\"Accuracy\")\n","axes.set_ylabel(\"Earliness\")\n","axes.plot(x,y, '-o')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"R0a7Bbrabp6R","executionInfo":{"status":"ok","timestamp":1650975154308,"user_tz":-60,"elapsed":485,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"ecaa763d-1bfa-4fdc-9a86-c2e35604c565"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f4beae35050>]"]},"metadata":{},"execution_count":347},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"simepEdKIiL0"},"source":["### Github Commands"]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"YdlGDV3AzZ1L","executionInfo":{"status":"ok","timestamp":1651225335811,"user_tz":-60,"elapsed":385,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"4d90ee9f-94fc-4c17-f323-3a2dcffacca0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":152,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itbAqo9qGukN","outputId":"8c7dd349-8f22-4199-ac4b-d472f9233b7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project\n"]}],"source":["username = \"adityag16\"\n","git_token = \"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\"\n","repository = \"/content/drive/MyDrive/Final-Year-Project\"\n","%cd {repository}\n","!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNInxPqdG7nx"},"outputs":[],"source":["!git add 'Early Time Series Classification - Average Ouput.ipynb' 'Best Performances.docx'\n","!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1tS6nonHF9u"},"outputs":[],"source":["!git config --global user.email \"aditya.gupta18@imperial.ac.uk\"\n","!git config --global user.name \"adityag16\"\n","\n","!git commit -m \"Testing KNN and Confidence with drift removal -- confidence still not working\"\n","!git push origin main"]},{"cell_type":"code","source":[""],"metadata":{"id":"8KO_iVTj0cIP"},"execution_count":null,"outputs":[]}]}
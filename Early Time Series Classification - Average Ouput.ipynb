{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Early Time Series Classification - Average Ouput.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1WYaF_HRa3IGG6auTN3SvWNlJMYRlk-43","authorship_tag":"ABX9TyM+8bw+T/hIa2SDBhXokP2z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Connect Drive"],"metadata":{"id":"XVaAULW6qhh1"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10446,"status":"ok","timestamp":1651148761676,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"_DdiqzlkZMhe","outputId":"b97be8a8-4189-4042-cca0-7e0d364a6bcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"markdown","metadata":{"id":"ttpluWU4tHLq"},"source":["### Package Imports"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Z_3NHgGwZIsI","executionInfo":{"status":"ok","timestamp":1651148772267,"user_tz":-60,"elapsed":4098,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.signal import savgol_filter\n","from collections import Counter\n","import copy\n","from collections import defaultdict"]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from scipy.spatial import distance\n","from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances"],"metadata":{"id":"5vMvjgqYCd2d","executionInfo":{"status":"ok","timestamp":1651148772269,"user_tz":-60,"elapsed":16,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### GPU Device"],"metadata":{"id":"6cosBM9Jd74f"}},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kElpooT1fLzz","executionInfo":{"status":"ok","timestamp":1651148772269,"user_tz":-60,"elapsed":16,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"5b05ea77-5336-48c1-dc40-e13768380f46"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-a7cf58f4-156b-2711-7f8b-91f43befeb4b)\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1651148774869,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"bLu_lZGKu9dp","outputId":"c15a368a-24a5-449c-9d0b-104303318bbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["gpu = tf.test.gpu_device_name()\n","print(gpu)"]},{"cell_type":"markdown","metadata":{"id":"ihJkU1v2STVo"},"source":["### Pre-Processing Helper Functions"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"W1YMbu9bSW5m","executionInfo":{"status":"ok","timestamp":1651148774869,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vref(X, v_thresh=70):\n","    '''\n","    Identifies active pixels by checking if one of the first 10 derivatives d(i) is > v_thresh\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_thresh : int, optional\n","        Minimum value of the derivative d(i)=X(i+1)-X(i) in mV. Default is 70\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if, during the first 10 samples,\n","        one of the derivatives is > v_thresh. The derivatives are calculated as d(i) = X(i+1)-X(i)\n","    '''\n","    return (np.diff(X[:10, :], axis=0) > v_thresh).any(axis=0)  # check if one of the first 10 derivatives is >v_thresh"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"XjXkAhKwSgFB","executionInfo":{"status":"ok","timestamp":1651148774870,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vrange(X, v_range=(100, 900)):\n","    '''\n","    Identifies active pixels by checking that all the values are in v_range\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_range : (int, int), optional\n","        tuple containing the minimum and maximum allowable voltage in mV. Default is (100, 900)\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if the value is always in v_range\n","    '''\n","    return (X < v_range[1]).all(axis=0) & (X > v_range[0]).all(axis=0)  # for each pixel, check if all the values are\n","    # within the given range\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"G5a7Uqi9Skg_","executionInfo":{"status":"ok","timestamp":1651148774870,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_derivative(X, vthresh=5):\n","    \"\"\" Identifies active pixels by checking that the absolute value of the derivative is always below vthresh\n","    Parameters\n","    ----------\n","    X : ndarray\n","        input 2D array of shape TxNM\n","    vthresh : int\n","        threshold for active pixels. Default is 5\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if all the derivatives are below vthresh\n","    \"\"\"\n","    x_diff = np.abs(np.diff(X, axis=0))\n","    return (x_diff < vthresh).all(axis=0)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"XUOV5CRYflUO","executionInfo":{"status":"ok","timestamp":1651148774870,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # set pixel values to 0/nan\n","  for idx, col in enumerate(df.columns):\n","    if(not active[idx]):\n","      df.loc[:, col] = 0\n","\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_drop(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"DhuoGbbPutKZ","executionInfo":{"status":"ok","timestamp":1651148774870,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ZZJkYzPiVvd6","executionInfo":{"status":"ok","timestamp":1651148774871,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels_deriv(df, v_thresh_deriv=5): \n","  active = filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # for idx, col in enumerate(df.columns):\n","  #   if(not active[idx]):\n","  #     df.loc[:, col] = 0\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_range(df, v_range=(100, 900)):\n","  active = filter_by_vrange(df.values, v_range)\n","\n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"imVXR8eVUrby","executionInfo":{"status":"ok","timestamp":1651148774871,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def reshape_data(df, rows, cols):\n","  X = df.values #pandas.DataFrame.values: Return a Numpy representation of the DataFrame.\n","  X = X.reshape(-1, rows, cols, order='F') #or C. different reshaping row by row or column by column but this works\n","  return X"],"metadata":{"id":"RTF9Vh78MZSB","executionInfo":{"status":"ok","timestamp":1651148774871,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def filter_chemical_pixels(df, arr_rows, arr_cols):\n","  X = reshape_data(df, arr_rows, arr_cols) # reshape data to T x 78 x 56\n","  X_mean = np.mean(X, axis=0) # get mean to have 78 x 56 shape\n","  X_mean[1::3, 1::3] = np.nan # set temperature pixels to nan\n","  X_mean = X_mean.flatten('F') # restore shape to 4068 \n","\n","  active_chemical = ~(np.isnan(X_mean)) # get bool array of all chemical pixels\n","\n","  # drop pixels \n","  df = df.loc[: , active_chemical]\n","  return df\n"],"metadata":{"id":"D9Xt8X4zL7hc","executionInfo":{"status":"ok","timestamp":1651148774872,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"id":"o82EQTYe9euH","executionInfo":{"status":"ok","timestamp":1651148775318,"user_tz":-60,"elapsed":452,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def time_to_index(times, time_vect):\n","    '''\n","    Returns index of the times closest to the desired ones time_vect\n","    Arguments\n","    ---------\n","    times : list\n","        list of integers containing the desired times\n","    time_vect : nparray\n","        array of the times at which the values are sampled\n","    Returns\n","    -------\n","    list\n","        for each element in the input list times, return an element in the output list\n","        with the index of the sample closest to the desired time\n","    '''\n","    indices = []\n","    for time in times:  # for each time in the input list\n","        indices.append( np.argmin(np.abs(time_vect - time)) )\n","        # find index of the sampled time (in time_vect) closest to the desired one (time)\n","    return indices\n","\n","\n","def find_loading_time(time_vect, X, bounds=(600, 900), viz=False):  # for v2\n","    ''' Finds loading and settling time for the data of v2 chip\n","    Parameters\n","    ----------\n","    time_vect : ndarray\n","        1D array with dimension T containing the sampling times\n","    X : ndarray\n","        2D array with dimension TxNM containing the sampled data\n","    bounds : list, optional\n","        tuple containing the minimum and maximum times (in ms) where the loading time has to be searched.\n","        Default is (600, 900)\n","    viz : bool, optional\n","        if viz=True, show the plot. Default is False\n","    Returns\n","    -------\n","    tuple\n","        - settled_index : index at which the settling occurs\n","        - settled_time : time at which the settling occurs\n","    '''\n","\n","    search_start, search_end = time_to_index(bounds, time_vect)  # for each time in bounds, find the index\n","    # of the sample (in time_vect) that is closest to the desired one (in bounds)\n","    X_mean = np.mean(X, axis=1)  # for each sample, calculate the mean of all pixels\n","    X_mean_diff = np.diff(X_mean)  # find the derivative\n","\n","    loading_index = np.argmax(X_mean_diff[search_start:search_end]) + search_start + 1  # find the index\n","    # where the derivative is max in the specified interval\n","    loading_index = loading_index  # add settling time\n","    settled_index = loading_index + 10  # add settling time\n","    settled_time = time_vect[settled_index]  # find the time that index corresponds to\n","\n","    if viz:  # if viz is true, plot the following\n","        fig, ax = plt.subplots(3, 1)\n","        fig.suptitle('Finding Loading Time...')\n","\n","        ax[0].set(title='Active Chemical Pixels, ACP')\n","        ax[0].plot(time_vect, X)  # plot the active chemical pixels\n","\n","        ax[1].set(title='Mean(ACP)')\n","        ax[1].plot(time_vect, X_mean)  # plot the average of the pixels\n","        ax[1].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[1].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[1].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        ax[2].set(title='Diff(Mean(ACP))')\n","        ax[2].plot(time_vect[1:], X_mean_diff)  # plot the derivative of the mean\n","        ax[2].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[2].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[2].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        plt.tight_layout()\n","        plt.show()\n","    return settled_index, settled_time"]},{"cell_type":"code","execution_count":170,"metadata":{"id":"9m8OqTUtQVb0","executionInfo":{"status":"ok","timestamp":1651150419566,"user_tz":-60,"elapsed":545,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def preprocess_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","  \n","  df = filter_chemical_pixels(df, 78, 56) # filter all chemical pixels\n","  \n","  df = filter_active_pixels_drop(df=df, v_thresh_deriv=deriv_thresh, v_range=(100,900))\n","\n","  settle_idx, settle_time = find_loading_time(df.index, df, bounds=(600, 900), viz=False) # find settling point\n","  df = df.iloc[settle_idx + 10:, :] # use only the data after the settling time + 30s to allow reaction to settle\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise don't\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +200 added on to see impact on graph after pre-processing\n","  \n","  # for col in df.columns:\n","  #   df[col] = savgol_filter(df[col],101, 3)\n","\n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  # df['Average Output'] = normalise_data(df['Average Output']) # normalise data using mix-max scaling\n","\n","   \n","  return df"]},{"cell_type":"code","source":["def preprocess_partial_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","\n","  df = filter_active_pixels_range(df=df, v_range=(100,900)) # filter by range incase of any saturation\n","  \n","  df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh) # filter pixels by deriv\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise dont\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +250 added on to see impact on graph after pre-processing\n","  \n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  # df['Average Output'] = normalise_data(df['Average Output']) # normalise data using mix-max scaling\n","    \n","  return df"],"metadata":{"id":"JsSdU8xPZX4U","executionInfo":{"status":"ok","timestamp":1651150419829,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":171,"outputs":[]},{"cell_type":"code","source":["def normalise_data(series):\n","  return (series - series.min()) / (series.max() - series.min())"],"metadata":{"id":"M6wMMfHZEADc","executionInfo":{"status":"ok","timestamp":1651150422966,"user_tz":-60,"elapsed":1123,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":172,"outputs":[]},{"cell_type":"markdown","source":["### Data Loading Helper Functions"],"metadata":{"id":"Dvvp28miEMsF"}},{"cell_type":"code","source":["def load_partial_covid_exp(filepath):\n","\n","  bot_filepath = filepath[:-4] + \"_bot.csv\"\n","  top_filepath = filepath[:-4] + \"_top.csv\"\n","\n","  ## load in 2 sheets\n","  df_neg = pd.read_csv(top_filepath, header=0, index_col=0)\n","  df_pos = pd.read_csv(bot_filepath, header=0, index_col=0)\n","\n","  return df_pos, df_neg"],"metadata":{"id":"vL28HCTcZUUG","executionInfo":{"status":"ok","timestamp":1651150422968,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":173,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation Metric Helper Functions"],"metadata":{"id":"PaNIFO5iSa9C"}},{"cell_type":"code","source":["def accuracy(classifications):\n","  total = len(classifications)\n","  total_correct = 0\n","  for i in classifications.values():\n","    if(i[0] == i[1]):\n","      total_correct +=1\n","\n","  accuracy = (total_correct/total)\n","\n","  return accuracy"],"metadata":{"id":"U2zoSqPJLatm","executionInfo":{"status":"ok","timestamp":1651150423972,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":174,"outputs":[]},{"cell_type":"code","source":["def sensitivity(classifications):\n","  true_pos = 0\n","  false_neg = 0\n","\n","  for i in classifications.values():\n","\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","\n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 1 and predicted == 0):\n","      false_neg += 1\n","\n","  sensitivity = (true_pos/(true_pos + false_neg))\n","\n","  return sensitivity"],"metadata":{"id":"lzSAF5WsTIuF","executionInfo":{"status":"ok","timestamp":1651150423975,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":175,"outputs":[]},{"cell_type":"code","source":["def specificity(classifications):\n","  true_neg = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 0 and predicted == 0):\n","      true_neg += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  specificity = (true_neg/(true_neg + false_pos))\n","\n","  return specificity"],"metadata":{"id":"WP_kdiXMYeU1","executionInfo":{"status":"ok","timestamp":1651150424486,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":176,"outputs":[]},{"cell_type":"code","source":["def precision(classifications):\n","  true_pos = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  precision = (true_pos/(true_pos + false_pos))\n","\n","  return precision"],"metadata":{"id":"w7-_ZPDDaxRp","executionInfo":{"status":"ok","timestamp":1651150424487,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":177,"outputs":[]},{"cell_type":"code","source":["def f1(classifications):\n","  numerator = 2*precision(classifications)*sensitivity(classifications)\n","  denominator = precision(classifications) + sensitivity(classifications)\n","  return numerator/denominator"],"metadata":{"id":"qkFpU-UJbV1R","executionInfo":{"status":"ok","timestamp":1651150424738,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":178,"outputs":[]},{"cell_type":"markdown","source":["### Array Dims"],"metadata":{"id":"W9kgS_-Cx1nm"}},{"cell_type":"code","source":["arr_rows = 78\n","arr_cols = 56"],"metadata":{"id":"whsJZh4Zx0xs","executionInfo":{"status":"ok","timestamp":1651148781690,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["### Load Data"],"metadata":{"id":"KCr7gvB_tf5-"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"AvJiLnQ8tiKx"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  avg_data_g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_data_export.csv\"\n","  avg_g1 = pd.read_csv(avg_data_g1_file, header=0)\n","\n","  ## Gamma 2\n","  avg_data_g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_data_export.csv\"\n","  avg_g2 = pd.read_csv(avg_data_g2_file, header=0)\n","\n","  ## Gamma 3\n","  avg_data_g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_data_export.csv\"\n","  avg_g3 = pd.read_csv(avg_data_g3_file, header=0)\n","  \n","  ## Gamma 5 \n","  avg_data_g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_data_export.csv\"\n","  avg_g5 = pd.read_csv(avg_data_g5_file, header=0)\n","\n","  ## 22RV1.ap1\n","  avg_data_22rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_data_export.csv\"\n","  avg_22rv1_ap1 = pd.read_csv(avg_data_22rv1_ap1_file, header=0)\n","\n","  ## 22RV1.ap2\n","  avg_data_22rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_data_export.csv\"\n","  avg_22rv1_ap2 = pd.read_csv(avg_data_22rv1_ap2_file, header=0)\n","\n","  ## 22RV1y.p1\n","  avg_data_22rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_data_export.csv\"\n","  avg_22rv1y_p1 = pd.read_csv(avg_data_22rv1y_p1_file, header=0)\n","\n","  ## 22RV1y.p3\n","  avg_data_22rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_data_export.csv\"\n","  avg_22rv1y_p3 = pd.read_csv(avg_data_22rv1y_p3_file, header=0)\n","\n","  ## 22RV1y.p4\n","  avg_data_22rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_data_export.csv\"\n","  avg_22rv1y_p4 = pd.read_csv(avg_data_22rv1y_p4_file, header=0)\n","\n","  ## ARV7.p1\n","  avg_data_arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_data_export.csv\"\n","  avg_arv7_p1 = pd.read_csv(avg_data_arv7_p1_file, header=0).iloc[1:, :].reset_index(drop=True) # row 0 was NAN\n","\n","  ## ARV7.p3\n","  avg_data_arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_data_export.csv\"\n","  avg_arv7_p3 = pd.read_csv(avg_data_arv7_p3_file, header=0)\n","\n","  ## ARV7.p4\n","  avg_data_arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_data_export.csv\"\n","  avg_arv7_p4 = pd.read_csv(avg_data_arv7_p4_file, header=0)\n","\n","  ## Beta 1\n","  avg_data_b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_data_export.csv\"\n","  avg_b1 = pd.read_csv(avg_data_b1_file, header=0)\n","\n","  ## Beta 2\n","  avg_data_b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_data_export.csv\"\n","  avg_b2 = pd.read_csv(avg_data_b2_file, header=0)\n","\n","  ## Beta 5\n","  avg_data_b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_data_export.csv\"\n","  avg_b5 = pd.read_csv(avg_data_b5_file, header=0)\n","  "],"metadata":{"id":"Ekqd_pB0tuTS","executionInfo":{"status":"ok","timestamp":1651150431286,"user_tz":-60,"elapsed":350,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":179,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_vsChem_export.csv\"\n","  g1 = pd.read_csv(g1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g1.index = avg_g1[\"Time Elapsed\"]\n","\n","  ## Gamma 2\n","  g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_vsChem_export.csv\"\n","  g2 = pd.read_csv(g2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g2.index = avg_g2[\"Time Elapsed\"]\n","\n","  ## Gamma 3\n","  g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_vsChem_export.csv\"\n","  g3 = pd.read_csv(g3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g3.index = avg_g3[\"Time Elapsed\"]\n","\n","  ## Gamma 5\n","  g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_vsChem_export.csv\"\n","  g5 = pd.read_csv(g5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g5.index = avg_g5[\"Time Elapsed\"]\n","\n","  ## 22RV1.ap1\n","  rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_vsChem_export.csv\"\n","  rv1_ap1 = pd.read_csv(rv1_ap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap1.index = avg_22rv1_ap1['Time Elapsed']\n","\n","  ## 22RV1.ap2\n","  rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_vsChem_export.csv\"\n","  rv1_ap2 = pd.read_csv(rv1_ap2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap2.index = avg_22rv1_ap2['Time Elapsed']\n","\n","  ## 22RV1y.p1\n","  rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_vsChem_export.csv\"\n","  rv1y_p1 = pd.read_csv(rv1y_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p1.index = avg_22rv1y_p1['Time Elapsed']\n","\n","  ## 22RV1y.p3\n","  rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_vsChem_export.csv\"\n","  rv1y_p3 = pd.read_csv(rv1y_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p3.index = avg_22rv1y_p3['Time Elapsed']\n","\n","  ## 22RV1y.p4\n","  rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_vsChem_export.csv\"\n","  rv1y_p4 = pd.read_csv(rv1y_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p4.index = avg_22rv1y_p4['Time Elapsed']\n","\n","  ## ARV7.p1 \n","  arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_vsChem_export.csv\"\n","  arv7_p1 = pd.read_csv(arv7_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)] \n","  arv7_p1.index = avg_arv7_p1[\"Time Elapsed\"]\n","\n","  ## ARV7.p3 \n","  arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_vsChem_export.csv\"\n","  arv7_p3 = pd.read_csv(arv7_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p3.index = avg_arv7_p3[\"Time Elapsed\"]\n","\n","  ## ARV7.p4 \n","  arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_vsChem_export.csv\"\n","  arv7_p4 = pd.read_csv(arv7_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p4.index = avg_arv7_p4[\"Time Elapsed\"]\n","\n","  ## Beta 1\n","  b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_vsChem_export.csv\"\n","  b1 = pd.read_csv(b1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b1.index = avg_b1[\"Time Elapsed\"]\n","\n","  ## Beta 2\n","  b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_vsChem_export.csv\"\n","  b2 = pd.read_csv(b2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b2.index = avg_b2[\"Time Elapsed\"]\n","\n","  ## Beta 5\n","  b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_vsChem_export.csv\"\n","  b5 = pd.read_csv(b5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b5.index = avg_b5[\"Time Elapsed\"]"],"metadata":{"id":"vZRah5zpxXp6","executionInfo":{"status":"ok","timestamp":1651150442039,"user_tz":-60,"elapsed":10269,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":180,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"7qOF9VBstkbe"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):  \n","  ## ARV7.n1\n","  avg_data_arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_data_export.csv\"\n","  avg_arv7 = pd.read_csv(avg_data_arv7_file, header=0)\n","\n","  ## Yap.n2\n","  avg_data_yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_data_export.csv\"\n","  avg_yap = pd.read_csv(avg_data_yap_file, header=0)\n","\n","  ## Yap1.n2\n","  avg_data_yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_data_export.csv\"\n","  avg_yap1 = pd.read_csv(avg_data_yap1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## Yap1.n1.1 \n","  avg_data_yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_data_export.csv\"\n","  avg_yap1n1 = pd.read_csv(avg_data_yap1n1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## ARV7.n2\n","  avg_data_arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_data_export.csv\"\n","  avg_arv72 = pd.read_csv(avg_data_arv72_file, header=0)\n","\n","  ## ARV7.n3\n","  avg_data_arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_data_export.csv\"\n","  avg_arv73 = pd.read_csv(avg_data_arv73_file, header=0)\n","\n","  ## DU145a.p1\n","  avg_data_du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_data_export.csv\"\n","  avg_du145a_p1 = pd.read_csv(avg_data_du145a_p1_file, header=0)\n","\n","  ## DU145a.p2\n","  avg_data_du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_data_export.csv\"\n","  avg_du145a_p2 = pd.read_csv(avg_data_du145a_p2_file, header=0)\n","\n","  ## DU145a.p3\n","  avg_data_du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_data_export.csv\"\n","  avg_du145a_p3 = pd.read_csv(avg_data_du145a_p3_file, header=0)\n","\n","  ## DU145y.n1\n","  avg_data_du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_data_export.csv\"\n","  avg_du145y_n1 = pd.read_csv(avg_data_du145y_n1_file, header=0)"],"metadata":{"id":"mlU83yKsuSHV","executionInfo":{"status":"ok","timestamp":1651150442040,"user_tz":-60,"elapsed":13,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":181,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):   \n","  ## ARV7.n1 \n","  arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_vsChem_export.csv\"\n","  arv7 = pd.read_csv(arv7_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7.index = avg_arv7[\"Time Elapsed\"]\n","\n","  ## Yap.n2\n","  yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_vsChem_export.csv\"\n","  yap = pd.read_csv(yap_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap.index = avg_yap[\"Time Elapsed\"]\n","\n","  ## Yap1.n2\n","  yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_vsChem_export.csv\"\n","  yap1 = pd.read_csv(yap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1.index = avg_yap1[\"Time Elapsed\"]\n","\n","  ## Yap1.n1.1\n","  yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_vsChem_export.csv\"\n","  yap1n1 = pd.read_csv(yap1n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1n1.index = avg_yap1n1[\"Time Elapsed\"]\n","\n","  ## ARV7.n2\n","  arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_vsChem_export.csv\"\n","  arv72 = pd.read_csv(arv72_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv72.index = avg_arv72[\"Time Elapsed\"]\n","\n","  ## ARV7.n3\n","  arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_vsChem_export.csv\"\n","  arv73 = pd.read_csv(arv73_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv73.index = avg_arv73[\"Time Elapsed\"]\n","\n","  ## DU145a.p1\n","  du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_vsChem_export.csv\"\n","  du145a_p1 = pd.read_csv(du145a_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p1.index = avg_du145a_p1[\"Time Elapsed\"]\n","\n","  ## DU145a.p2\n","  du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_vsChem_export.csv\"\n","  du145a_p2 = pd.read_csv(du145a_p2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p2.index = avg_du145a_p2[\"Time Elapsed\"]\n","\n","  ## DU145a.p3\n","  du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_vsChem_export.csv\"\n","  du145a_p3 = pd.read_csv(du145a_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p3.index = avg_du145a_p3[\"Time Elapsed\"]\n","\n","  ## DU145y.n1\n","  du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_vsChem_export.csv\"\n","  du145y_n1 = pd.read_csv(du145y_n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145y_n1.index = avg_du145y_n1[\"Time Elapsed\"]"],"metadata":{"id":"W3_XExOjypwI","executionInfo":{"status":"ok","timestamp":1651150448530,"user_tz":-60,"elapsed":6502,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":182,"outputs":[]},{"cell_type":"markdown","source":["#### Partial Covid Data"],"metadata":{"id":"yjXPLEfmRUJH"}},{"cell_type":"code","source":["## 150520_2_118\n","avg_118_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_2_118/exp_summary_118.csv\"\n","exp_118_pos, exp_118_neg = load_partial_covid_exp(avg_118_file)\n","\n","## 150520_4_2_86\n","avg_86_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_4_2_86/exp_summary_86.csv\"\n","exp_86_pos, exp_86_neg = load_partial_covid_exp(avg_86_file)\n","\n","## 150520_5_129\n","avg_129_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_5_129/exp_summary_129.csv\"\n","exp_129_pos, exp_129_neg = load_partial_covid_exp(avg_129_file)\n","\n","## 180520_4_165\n","avg_165_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_4_165/exp_summary_165.csv\"\n","exp_165_pos, exp_165_neg = load_partial_covid_exp(avg_165_file)\n","\n","## 180520_6_35\n","avg_35_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_6_35/exp_summary_35.csv\"\n","exp_35_pos, exp_35_neg = load_partial_covid_exp(avg_35_file)\n","\n","## 190520_1_28\n","avg_28_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_1_28/exp_summary_28.csv\"\n","exp_28_pos, exp_28_neg = load_partial_covid_exp(avg_28_file) \n","\n","## 190520_2_14\n","avg_14_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_2_14/exp_summary_14.csv\"\n","exp_14_pos, exp_14_neg = load_partial_covid_exp(avg_14_file)\n","\n","## 210520_2_40\n","avg_40_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_2_40/exp_summary_40.csv\"\n","exp_40_pos, exp_40_neg = load_partial_covid_exp(avg_40_file)\n","\n","## 210520_3_88\n","avg_88_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_3_88/exp_summary_88.csv\"\n","exp_88_pos, exp_88_neg = load_partial_covid_exp(avg_88_file)\n","\n","## 210520_6_27\n","avg_27_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_6_27/exp_summary_27.csv\"\n","exp_27_pos, exp_27_neg = load_partial_covid_exp(avg_27_file)\n","\n","## 250520_1_134\n","avg_134_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_1_134/exp_summary_134.csv\"\n","exp_134_pos, exp_134_neg = load_partial_covid_exp(avg_134_file)\n","\n","## 250520_2_97\n","avg_97_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_2_97/exp_summary_97.csv\"\n","exp_97_pos, exp_97_neg = load_partial_covid_exp(avg_97_file)\n","\n","## 250520_6_2D1\n","avg_2d1_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_6_2D1/exp_summary_2D1.csv\"\n","exp_2d1_pos, exp_2d1_neg = load_partial_covid_exp(avg_2d1_file)\n","\n","## 250520_7_64\n","avg_64_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_7_64/exp_summary_64.csv\"\n","exp_64_pos, exp_64_neg = load_partial_covid_exp(avg_64_file)"],"metadata":{"id":"ORRtMFfEZBwV","executionInfo":{"status":"ok","timestamp":1651150452434,"user_tz":-60,"elapsed":3920,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":183,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"7XgnkewwwPki"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"CTcUwvRiwUmJ"}},{"cell_type":"code","source":["g1 = preprocess_data(g1, 500)\n","g2 = preprocess_data(g2, 500)\n","g3 = preprocess_data(g3, 500)\n","g5 = preprocess_data(g5, 500)\n","rv1_ap1 = preprocess_data(rv1_ap1, 500)\n","rv1_ap2 = preprocess_data(rv1_ap2, 500)\n","rv1y_p1 = preprocess_data(rv1y_p1, 500)\n","rv1y_p3 = preprocess_data(rv1y_p3, 500)\n","rv1y_p4 = preprocess_data(rv1y_p4, 500)\n","arv7_p1 = preprocess_data(arv7_p1, 500)\n","arv7_p3 = preprocess_data(arv7_p3, 500)\n","arv7_p4 = preprocess_data(arv7_p4, 500)\n","b1 = preprocess_data(b1, 500)\n","b2 = preprocess_data(b2, 500)\n","b5 = preprocess_data(b5, 500)"],"metadata":{"id":"1-WlDoK49D2Y","executionInfo":{"status":"ok","timestamp":1651150460213,"user_tz":-60,"elapsed":1712,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":184,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"1WaPBFGuwYN4"}},{"cell_type":"code","source":["arv7 = preprocess_data(arv7, 500)\n","yap = preprocess_data(yap, 500)\n","yap1 = preprocess_data(yap1, 500)\n","yap1n1 = preprocess_data(yap1n1, 500)\n","arv72 = preprocess_data(arv72, 500)\n","arv73 = preprocess_data(arv73, 500)\n","du145y_n1 = preprocess_data(du145y_n1, 500)\n","du145a_p1 = preprocess_data(du145a_p1, 500)\n","du145a_p2 = preprocess_data(du145a_p2, 500)\n","du145a_p3 = preprocess_data(du145a_p3, 500)"],"metadata":{"id":"gazhgzLT9HLV","executionInfo":{"status":"ok","timestamp":1651150462859,"user_tz":-60,"elapsed":1281,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":185,"outputs":[]},{"cell_type":"markdown","source":["#### Covid Partial Data"],"metadata":{"id":"nUwBPNQNjQ7w"}},{"cell_type":"code","source":["exp_118_pos = preprocess_partial_data(exp_118_pos, 500)\n","exp_86_pos = preprocess_partial_data(exp_86_pos, 500)\n","exp_129_pos = preprocess_partial_data(exp_129_pos, 500)\n","exp_165_pos = preprocess_partial_data(exp_165_pos, 500)\n","exp_35_pos = preprocess_partial_data(exp_35_pos, 500)\n","exp_28_pos = preprocess_partial_data(exp_28_pos, 500)\n","exp_14_pos = preprocess_partial_data(exp_14_pos, 500)\n","exp_40_pos = preprocess_partial_data(exp_40_pos, 500)\n","exp_88_pos = preprocess_partial_data(exp_88_pos, 500)\n","exp_27_pos = preprocess_partial_data(exp_27_pos, 500)\n","exp_134_pos = preprocess_partial_data(exp_134_pos, 500)\n","exp_97_pos = preprocess_partial_data(exp_97_pos, 500)\n","exp_2d1_pos = preprocess_partial_data(exp_2d1_pos, 500)\n","exp_64_pos = preprocess_partial_data(exp_64_pos, 500)"],"metadata":{"id":"HQBQ_1YF9Oqj","executionInfo":{"status":"ok","timestamp":1651150464586,"user_tz":-60,"elapsed":1157,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":186,"outputs":[]},{"cell_type":"code","source":["exp_118_neg = preprocess_partial_data(exp_118_neg, 500)\n","exp_86_neg = preprocess_partial_data(exp_86_neg, 500)\n","exp_129_neg = preprocess_partial_data(exp_129_neg, 500)\n","exp_165_neg = preprocess_partial_data(exp_165_neg, 500)\n","exp_35_neg = preprocess_partial_data(exp_35_neg, 500)\n","exp_28_neg = preprocess_partial_data(exp_28_neg, 500)\n","exp_14_neg = preprocess_partial_data(exp_14_neg, 500)\n","exp_40_neg = preprocess_partial_data(exp_40_neg, 500)\n","exp_88_neg = preprocess_partial_data(exp_88_neg, 500)\n","exp_27_neg = preprocess_partial_data(exp_27_neg, 500)\n","exp_134_neg = preprocess_partial_data(exp_134_neg, 500)\n","exp_97_neg = preprocess_partial_data(exp_97_neg, 500)\n","exp_2d1_neg = preprocess_partial_data(exp_2d1_neg, 500)\n","exp_64_neg = preprocess_partial_data(exp_64_neg, 500)"],"metadata":{"id":"sYsOnsAW9Rob","executionInfo":{"status":"ok","timestamp":1651150466253,"user_tz":-60,"elapsed":1669,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":187,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - Neural Network Ensemble"],"metadata":{"id":"cco-BOwij9af"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"j5qgb5mx3rOW"}},{"cell_type":"code","source":["def get_training_data(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"OIYXEisg2WX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_test_data(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"xH5J1l0cgIHI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"d6Qyl80Wzy-r"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,\n","             \"arv7_p3\":arv7_p3,\n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7,  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3}"],"metadata":{"id":"d-bA8RfjcM35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Model Specs"],"metadata":{"id":"rxkmk6GHqC7g"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_classifiers = 50\n","\n","timestep = int(number_of_samples/number_of_classifiers)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]\n","\n","batch_size = 3\n","epochs = 10\n","loss_function = 'binary_crossentropy'\n","optimiser = 'adam'"],"metadata":{"id":"eztwFZUaloVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBcYHOw_BU4E","executionInfo":{"status":"ok","timestamp":1650888347765,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"62652afd-35c9-48f8-c037-b58efe79e12c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Creating Ensemble"],"metadata":{"id":"qG3eDbNkqG9A"}},{"cell_type":"code","source":["def create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples):\n","\n","  neural_nets = [0]*number_of_classifiers\n","\n","  for i in range(number_of_classifiers):\n","\n","    # print(f\"============================================== Neural Network {i} ============================================\")\n","\n","    ## make model \n","    neural_nets[i] = Sequential()\n","    neural_nets[i].add(Dense(16, activation='relu', input_dim = timestamps[i]))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(1, activation='sigmoid'))\n","\n","    ## compile model \n","    neural_nets[i].compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])\n","\n","    ## model summary\n","    # neural_nets[i].summary()\n","\n","    ## training data\n","    training_data, training_label = get_training_data(positive_samples=positives, negative_samples=negatives, timestamp=timestamps[i], test_samples=[test_samples])\n","\n","    ## train model\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n","    neural_nets[i].fit(training_data, training_label,  batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[callback], verbose=0)\n","\n","    # print(\"\\n\\n\")\n","\n","  return neural_nets"],"metadata":{"id":"GVVPVw4-ndtu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Evaluating Ensemble"],"metadata":{"id":"fGH97jNBfzdu"}},{"cell_type":"code","source":["def get_prediction(ensemble, timestamps, test_sample):\n","  predictions = []\n","\n","  for i in range(number_of_classifiers):\n","    test_data = get_test_data(test_sample, timestamps[i])\n","    prediction = ensemble[i].predict(test_data)\n","    predictions.append(prediction[0][0])\n","\n","  predictions = [int(i >= 0.5) for i in predictions]\n","  classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","\n","  return classification"],"metadata":{"id":"HslDzCxe1PaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with tule label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"TCTzCBpU0S8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  final_classifications = {}\n","\n","  ## use ensemble to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Testing sample: {test_sample_name}...\")\n","\n","    en = create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_sample_name)\n","    classification = get_prediction(en, timestamps, test_sample)\n","    \n","    \n","    final_classifications[key] = (classification, true_label_dict[key])\n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"HlIwk3By0Zqi","colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"status":"error","timestamp":1650888354674,"user_tz":-60,"elapsed":6919,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2e248431-2ec4-4c7b-e50c-96b007673ba4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample: exp_118_pos...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'sequential_1/dense_7/BiasAdd/ReadVariableOp/resource' has no attr named '_class'.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-5086e332c720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing sample: {test_sample_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0men\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-83e0a485fc39>\u001b[0m in \u001b[0;36mcreate_ensemble\u001b[0;34m(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m## train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mneural_nets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# print(\"\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    530\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m    531\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_compute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    673\u001b[0m           \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m           \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m               var.op.name):\n\u001b[1;32m    716\u001b[0m             update_op = distribution.extended.update(\n\u001b[0;32m--> 717\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False)\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_cross_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m               \u001b[0;31m# In cross-replica context, extended.update returns a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n\u001b[0;32m-> 2633\u001b[0;31m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[0m\u001b[1;32m   2634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2509\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3101\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3102\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3108\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3109\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2509\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2628\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2629\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3701\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3702\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3709\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3710\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    174\u001b[0m           \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m           \u001b[0;34m'Please pass these args as kwargs instead.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1447\u001b[0m                              \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m                              \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m                              use_nesterov=use_nesterov, name=name)\n\u001b[0m\u001b[1;32m   1450\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0mResourceApplyAdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_ops.ResourceApplyAdam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_apply_adam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[1;32m   1655\u001b[0m                            \"building a function.\")\n\u001b[0;32m-> 1656\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;31m# Large EagerTensors and resources are captured with Placeholder ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m       placeholder = _create_substitute_placeholder(\n\u001b[0;32m--> 765\u001b[0;31m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0m\u001b[1;32m    766\u001b[0m       \u001b[0;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0;31m# This attribute would be propogated into the arg_attr of the FunctionDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     placeholder = graph_placeholder(\n\u001b[0;32m-> 1306\u001b[0;31m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   1307\u001b[0m   \u001b[0mhandle_data_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       attrs=attrs, name=name)\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3785\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3872\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcolocation_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3874\u001b[0;31m           \u001b[0mall_colocation_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3876\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocation_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \u001b[0mdefault_colocation_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc:@%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m       \u001b[0mclass_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m       \u001b[0;31m# This op has no explicit colocation group, so it is itself its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["final_classifications"],"metadata":{"id":"4AuD_rrC2yYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"mhkc8Lnr9-c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"WCjSN-dLz9Mq"}},{"cell_type":"code","source":["# ## checking the timestap where majority of classifiers agree\n","\n","# from collections import defaultdict\n","\n","# def get_timestamp(timestamps, predictions):\n","\n","#   ## create dict to hold count of predictions\n","#   label_counters = defaultdict(int)\n","\n","#   ## add entries to dict\n","#   for index, pred in enumerate(predictions):\n","#     label_counters[pred] += 1\n","\n","#     ## if label count == half of total possible predictions then majority is achieved\n","#     if(label_counters[pred] == int(len(predictions)/2)+1):\n","#       return timestamps[index], index\n","  \n","#   return -1, -1\n"],"metadata":{"id":"3r69Gbpd99So"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Timestamp where majority aggement is reached: {timestamp_final}\")\n","# print(f\"Index of final time stamp in array : {pred_index}\")"],"metadata":{"id":"ghvOJ4Ot_fRB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Save Ensemble"],"metadata":{"id":"PppLDxSdv5Uk"}},{"cell_type":"code","source":["# !pwd"],"metadata":{"id":"jAJAZJtKv816"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G1Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G2Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G3Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G5Test"],"metadata":{"id":"UgtDxJjmxHQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/ARV7Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAPTest/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1N1Test/"],"metadata":{"id":"bwBDVrvMRsO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for i in range(number_of_classifiers):\n","#   filename = f\"ensemble-model-{i}.h5\"\n","#   neural_nets[i].save(filename)\n","\n","#   print(f\"Saved {filename}\")"],"metadata":{"id":"ZGXuLcuXx99S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - KNN Ensemble"],"metadata":{"id":"GvAKajynLNa9"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"H8ueQFk24bbg"}},{"cell_type":"code","source":["def get_training_data_knn(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"x4q6d44BLwpQ","executionInfo":{"status":"ok","timestamp":1651150472288,"user_tz":-60,"elapsed":362,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":188,"outputs":[]},{"cell_type":"code","source":["def get_test_data_knn(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"GZOfy-0GQuGA","executionInfo":{"status":"ok","timestamp":1651150472288,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":189,"outputs":[]},{"cell_type":"code","source":["def get_time_index(timestamps, predictions):\n","\n","  ## create dict to hold count of predictions\n","  label_counters = defaultdict(int)\n","\n","  ## add entries to dict\n","  for index, pred in enumerate(predictions):\n","    label_counters[pred] += 1\n","\n","    ## if label count == half of total possible predictions then majority is achieved\n","    if(label_counters[pred] == int(len(predictions)/2)+1):\n","      return timestamps[index]\n","  \n","  return -1"],"metadata":{"id":"2hib6StpHWbU","executionInfo":{"status":"ok","timestamp":1651150473416,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":190,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"FOMhNuiKNGAw"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","            #  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"-prfZYD_VgMB","executionInfo":{"status":"ok","timestamp":1651153375844,"user_tz":-60,"elapsed":316,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":470,"outputs":[]},{"cell_type":"markdown","source":["#### Timestamps"],"metadata":{"id":"Ry9pqKjnNKiI"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"3cDeyMc3M_bN","executionInfo":{"status":"ok","timestamp":1651153376663,"user_tz":-60,"elapsed":1,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":471,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIjHUplVOmH3","executionInfo":{"status":"ok","timestamp":1651153377993,"user_tz":-60,"elapsed":10,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8359f189-3f4b-4838-d8fe-e592603bf656"},"execution_count":472,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Model"],"metadata":{"id":"DJBWoo1SNMy3"}},{"cell_type":"code","source":["def KNN(k, test_sample, train_data, train_labels, distance_metric):\n","  test = np.tile(test_sample, (len(train_data),1)) # repeat test sample and stack vertically\n","  \n","  distances = None\n","\n","  if(distance_metric.lower() == 'manhattan' or distance_metric.lower() == 'cityblock'):\n","    distances = manhattan_distances(test, train_data).diagonal() # get pair wise manhattan distance for every row\n","  elif(distance_metric.lower() == 'euclidean'):\n","    distances = euclidean_distances(test, train_data).diagonal() # get pair wise euclidean distance for every row \n","  elif(distance_metric.lower() == 'cosine'):\n","    distances = cosine_distances(test, train_data).diagonal() # get pair wise cosine distance for every row \n","\n","  min_indexes = np.argsort(distances)[:k] # get k smallest indexes\n","\n","  knn_labels = list(train_labels[min_indexes]) # get k predictions\n","  final_pred = max(set(knn_labels), key=knn_labels.count)\n","\n","  return final_pred"],"metadata":{"id":"sGJZphgaLeL0","executionInfo":{"status":"ok","timestamp":1651153379019,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":473,"outputs":[]},{"cell_type":"markdown","source":["#### Model Predictions"],"metadata":{"id":"0C0XQKFHFtFV"}},{"cell_type":"markdown","source":["##### Held-out Test Set"],"metadata":{"id":"Vf8LAE4Qbxls"}},{"cell_type":"code","source":["# test_samples = {\"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \"exp_27_neg\":exp_27_neg,\"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg,\n","#                 \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \"g1\":g1, \"exp_86_pos\":exp_86_pos, \"rv1_ap1\":rv1_ap1,\"b5\":b5, \"exp_28_pos\":exp_28_pos}\n","# test_sample_keys = keys = list(test_samples.keys())\n","# test_labels = list(np.concatenate((np.ones(7),np.zeros(7))))\n","# test_label_dict = dict(zip(test_sample_keys, test_labels))"],"metadata":{"id":"AxaTjkExYX9r","executionInfo":{"status":"ok","timestamp":1651140631972,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["# import time\n","# with tf.device(gpu):\n","\n","#   final_classifications = {}\n","\n","#   ## use KNN to evaluate the prediction for each of the samples individually\n","#   for key, value in test_samples.items():\n","#     test_sample_name = key\n","#     test_sample = value\n","\n","#     predictions = []\n","#     for t in timestamps:\n","#       train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=test_sample_keys)\n","#       test_data = get_test_data_knn(test_sample, t)\n","#       pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","#       predictions.append(pred)\n","    \n","#     print(f\"Testing sample {test_sample_name}\")\n","\n","#     time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","#     time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","#     classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","#     final_classifications[key] = (classification, true_label_dict[key])\n","  \n","#     print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","#     if(classification == 1.0):\n","#       print(f\"TTP: {time_to_result}s\")\n","\n","#     print(\"\")"],"metadata":{"id":"PVYWffD2Z5q6","executionInfo":{"status":"ok","timestamp":1651140632573,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["# print(f\"Accuracy: {accuracy(final_classifications)}\")\n","# print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","# print(f\"Specificity: {specificity(final_classifications)}\")\n","# print(f\"Precision: {precision(final_classifications)}\")\n","# print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"uV2qejqoblws","executionInfo":{"status":"ok","timestamp":1651140632860,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":["##### Cross Validation"],"metadata":{"id":"DuKAj66EbskM"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             #\"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"RGVdwT8rxS23","executionInfo":{"status":"ok","timestamp":1651153386876,"user_tz":-60,"elapsed":248,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":474,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"SUDmHpF-GigC","executionInfo":{"status":"ok","timestamp":1651153387225,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":475,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(9, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    print(f\"Testing sample {test_sample_name}\")\n","    time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","    time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","    classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","    final_classifications[key] = (classification, true_label_dict[key])\n","  \n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","    if(classification == 1.0):\n","      print(f\"TTP: {time_to_result}s\")\n","\n","    print(\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rptrj0arSjSR","executionInfo":{"status":"ok","timestamp":1651153395622,"user_tz":-60,"elapsed":7165,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"38629f28-6420-4f44-beae-c0d68005c769"},"execution_count":476,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample exp_118_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_86_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 785.0s\n","\n","Testing sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 798.0s\n","\n","Testing sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 646.0s\n","\n","Testing sample exp_35_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_28_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 628.0s\n","\n","Testing sample exp_40_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1136.0s\n","\n","Testing sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 600.0s\n","\n","Testing sample exp_134_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_97_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 583.0s\n","\n","Testing sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 630.0s\n","\n","Testing sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 572.0s\n","\n","Testing sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 605.0s\n","\n","Testing sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 599.0s\n","\n","Testing sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 575.0s\n","\n","Testing sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 746.0s\n","\n","Testing sample rv1_ap2\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 660.0s\n","\n","Testing sample rv1y_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 748.0s\n","\n","Testing sample rv1y_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 655.0s\n","\n","Testing sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 599.0s\n","\n","Testing sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 999.0s\n","\n","Testing sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 600.0s\n","\n","Testing sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 575.0s\n","\n","Testing sample b5\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 678s\n","\n","Testing sample exp_129_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_165_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_35_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 662s\n","\n","Testing sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 661s\n","\n","Testing sample exp_40_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_97_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_2d1_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 672s\n","\n","Testing sample exp_64_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 576.0s\n","\n","Testing sample yap1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample yap1n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 573.0s\n","\n","Testing sample arv72\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 604.0s\n","\n","Testing sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 597.0s\n","\n","Testing sample arv7\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 599.0s\n","\n"]}]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SilNigCLya5","executionInfo":{"status":"ok","timestamp":1651153395622,"user_tz":-60,"elapsed":17,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8aa6b632-51ca-4901-9c93-05b290a029c9"},"execution_count":477,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6530612244897959\n","Sensitivity/Recall: 0.7142857142857143\n","Specificity: 0.5714285714285714\n","Precision: 0.6896551724137931\n","F1 Score: 0.7017543859649122\n"]}]},{"cell_type":"markdown","source":["#### Elbow Plot"],"metadata":{"id":"DgvFMAGtSbpy"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"i1xQt-8FxVXG","executionInfo":{"status":"ok","timestamp":1651152781515,"user_tz":-60,"elapsed":253,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":467,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  accuracies = []\n","  for k in range(1,30):\n","    final_classifications = {}\n","\n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = []\n","      for t in timestamps:\n","        train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","        test_data = get_test_data_knn(test_sample, t)\n","        pred = KNN(k, test_data, train_data, train_labels, 'cosine')\n","        predictions.append(pred)\n","      \n","      time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","      \n","      classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","      final_classifications[key] = (classification, true_label_dict[key])\n","\n","    acc = accuracy(final_classifications)\n","    accuracies.append(acc)\n","    print(f\"K: {k} \\t Accuracy: {acc}\")\n","    # print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"WwBbkDraFWF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651152910533,"user_tz":-60,"elapsed":128783,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"24efc2d6-ca91-4059-f41d-70233d5df061"},"execution_count":468,"outputs":[{"output_type":"stream","name":"stdout","text":["K: 1 \t Accuracy: 0.5192307692307693\n","K: 2 \t Accuracy: 0.5\n","K: 3 \t Accuracy: 0.4807692307692308\n","K: 4 \t Accuracy: 0.5192307692307693\n","K: 5 \t Accuracy: 0.5769230769230769\n","K: 6 \t Accuracy: 0.5576923076923077\n","K: 7 \t Accuracy: 0.5769230769230769\n","K: 8 \t Accuracy: 0.5384615384615384\n","K: 9 \t Accuracy: 0.5769230769230769\n","K: 10 \t Accuracy: 0.5384615384615384\n","K: 11 \t Accuracy: 0.5576923076923077\n","K: 12 \t Accuracy: 0.5384615384615384\n","K: 13 \t Accuracy: 0.5769230769230769\n","K: 14 \t Accuracy: 0.5384615384615384\n","K: 15 \t Accuracy: 0.5576923076923077\n","K: 16 \t Accuracy: 0.5192307692307693\n","K: 17 \t Accuracy: 0.5576923076923077\n","K: 18 \t Accuracy: 0.5\n","K: 19 \t Accuracy: 0.5\n","K: 20 \t Accuracy: 0.5\n","K: 21 \t Accuracy: 0.5576923076923077\n","K: 22 \t Accuracy: 0.5192307692307693\n","K: 23 \t Accuracy: 0.5384615384615384\n","K: 24 \t Accuracy: 0.5\n","K: 25 \t Accuracy: 0.5576923076923077\n","K: 26 \t Accuracy: 0.5576923076923077\n","K: 27 \t Accuracy: 0.5\n","K: 28 \t Accuracy: 0.5576923076923077\n","K: 29 \t Accuracy: 0.5192307692307693\n"]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = np.arange(1,30)\n","y = accuracies\n","axes.set_xlabel(\"K\")\n","axes.set_ylabel(\"Accuracy (%)\")\n","axes.plot(x,y)"],"metadata":{"id":"P8t0E1pS9YNL","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"ok","timestamp":1651152911030,"user_tz":-60,"elapsed":510,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"431e0e05-422e-402b-a827-90cec7f28884"},"execution_count":469,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f9c597ea050>]"]},"metadata":{},"execution_count":469},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Confidence "],"metadata":{"id":"qXrQKuQm8ery"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"oZRyLyYo7k36"}},{"cell_type":"code","source":["def get_rH_00(true_vals, classifier_outputs):\n","  correct_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 0)):\n","      correct_pred_0 += 1\n","\n","  return correct_pred_0/total_pred_0\n","\n","\n","def get_rH_01(true_vals, classifier_outputs):\n","  wrong_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 0)):\n","      wrong_pred_1 += 1\n","    \n","  return wrong_pred_1/total_pred_1\n","\n","def get_rH_10(true_vals, classifier_outputs):\n","  wrong_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 1)):\n","      wrong_pred_0 += 1\n","  \n","  return wrong_pred_0/total_pred_0\n","\n","def get_rH_11(true_vals, classifier_outputs):\n","  correct_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 1)):\n","      correct_pred_1 += 1\n","\n","  return correct_pred_1/total_pred_1"],"metadata":{"id":"6IQ6mN5uJ6z1","executionInfo":{"status":"ok","timestamp":1651152147789,"user_tz":-60,"elapsed":256,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":371,"outputs":[]},{"cell_type":"code","source":["def get_confidence_multipliers(sample_predictions, true_labels):\n","\n","  sample_predictions = np.asarray(sample_predictions) # array of all predictions made by every classifer for all samples\n","\n","  #2d array of all possible multipliers for each classifier\n","  multipliers_final = []\n","\n","  # generate 4 multipliers for each classifier\n","  for classifier in range(len(sample_predictions[0])):\n","    classifier_output = sample_predictions[:, classifier]\n","\n","    rH_00 = get_rH_00(true_labels, classifier_output)\n","    rH_01 = get_rH_01(true_labels, classifier_output)\n","    rH_10 = get_rH_10(true_labels, classifier_output)\n","    rH_11 = get_rH_11(true_labels, classifier_output)\n","    multipliers_classfier = [rH_00, rH_01, rH_10, rH_11] \n","\n","    # add multipliers to 2d array\n","    multipliers_final.append(multipliers_classfier)\n","\n","  return multipliers_final"],"metadata":{"id":"5r-wTh3nlga0","executionInfo":{"status":"ok","timestamp":1651152150165,"user_tz":-60,"elapsed":261,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":372,"outputs":[]},{"cell_type":"code","source":["def get_confidence(preds, multipliers):\n","  \n","  # initialise variable\n","  confidence = 1\n","\n","  # the prediction for which the confidence is being calculated -- predication at time t by classifier Ht (most recent prediction)\n","  pred_t = preds[-1]\n","\n","  for idx , pred in enumerate(preds):\n","    # prediction at time k made by classifier Hk\n","    pred_k = pred\n","\n","    # array of multipliers for Hk \n","    multiplier_k = multipliers[idx]\n","\n","    if(pred_t == 0 and pred_k == 0):\n","        confidence*=(1-multiplier_k[0])\n","    elif(pred_t == 0 and pred_k == 1):\n","        confidence*=(1-multiplier_k[1])\n","    elif(pred_t == 1 and pred_k == 0):\n","        confidence*=(1-multiplier_k[2])  \n","    elif(pred_t == 1 and pred_k == 1):\n","        confidence*=(1-multiplier_k[3])\n","        \n","        \n","\n","  confidence = 1 - confidence\n","\n","  return confidence\n","  "],"metadata":{"id":"8SmPp5iDzHQJ","executionInfo":{"status":"ok","timestamp":1651152152754,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":373,"outputs":[]},{"cell_type":"code","source":["def generate_predictions_table(positives, negatives, timestamps):\n","\n","  sample_predictions = []\n","\n","  true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(9, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    sample_predictions.append(predictions)\n","\n","  return sample_predictions, true_labels"],"metadata":{"id":"Qfe-e7-84_Zc","executionInfo":{"status":"ok","timestamp":1651153889530,"user_tz":-60,"elapsed":422,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":478,"outputs":[]},{"cell_type":"markdown","source":["#### Random Threshold Testing"],"metadata":{"id":"bwcY82bSq0t6"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651152412246,"user_tz":-60,"elapsed":233,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"bZnftjyQxXcw"},"execution_count":419,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651152310659,"user_tz":-60,"elapsed":12,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"asGaVch58nEo"},"execution_count":397,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651152310660,"user_tz":-60,"elapsed":12,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"61d1c6b9-b999-4ef6-f8ae-0094a3e6aa44","id":"YF_lFeGo8nE2"},"execution_count":398,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"68OVHXKmw-Hg","executionInfo":{"status":"ok","timestamp":1651152311203,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":399,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","  \n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","      if(c >= 0.9869661240808167): # 99% confidence threshold\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","        if(pred == 1.0):\n","          print(f\"Earliness:  {time_index/timestamps[-1]}\")\n","          print(f\"TTP: {time_to_result+30}s\")\n","          ttps.append(time_to_result+30) # 30 second delay from reaction start when preprocessing\n","          earliness.append(time_index/timestamps[-1])\n","        break\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxnI-jcElWhV","executionInfo":{"status":"ok","timestamp":1651152316780,"user_tz":-60,"elapsed":3949,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"4f90aab8-9a31-47a5-d27c-36b9d756f2e6"},"execution_count":400,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_86_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_129_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 161.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 165.0s\n","\n","Sample exp_28_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 163.0s\n","\n","Sample exp_40_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 140.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 140.0s\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 183s\n","\n","Sample exp_97_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 158.0s\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 137.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 161.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 163.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 167.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 164.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 163.0s\n","\n","Sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 179.0s\n","\n","Sample rv1y_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 159.0s\n","\n","Sample rv1y_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 164.0s\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 166.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.14\n","TTP: 257.0s\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 157.0s\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 161.0s\n","\n","Sample b5\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_118_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 162s\n","\n","Sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.16\n","TTP: 213s\n","\n","Sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.14\n","TTP: 182s\n","\n","Sample exp_165_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.14\n","TTP: 188s\n","\n","Sample exp_35_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.14\n","TTP: 192s\n","\n","Sample exp_28_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 172s\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 174s\n","\n","Sample exp_40_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 166s\n","\n","Sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_97_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 159s\n","\n","Sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 162s\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 168.0s\n","\n","Sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 166.0s\n","\n","Sample yap1n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 159.0s\n","\n","Sample arv72\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 157.0s\n","\n","Sample arv73\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 160.0s\n","\n","Sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 165.0s\n","\n","Sample arv7\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 166.0s\n","\n","Accuracy: 0.4897959183673469\n","Sensitivity/Recall: 0.7142857142857143\n","Specificity: 0.19047619047619047\n","Precision: 0.5405405405405406\n","F1 Score: 0.6153846153846154\n"]}]},{"cell_type":"markdown","source":["#### Learning best threshold"],"metadata":{"id":"KPuLuWoixCSR"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651153899247,"user_tz":-60,"elapsed":276,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"HAfi2bU4phQC"},"execution_count":479,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651153900256,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"ps-swVLHphQD"},"execution_count":480,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651153901096,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"bb40ed97-1936-46a0-9da3-74173a85105f","id":"z-c4frksphQD"},"execution_count":481,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651153901468,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"r0eTLRQophQD"},"execution_count":482,"outputs":[]},{"cell_type":"markdown","source":["##### Generating candidates"],"metadata":{"id":"ErEA8XSGqh8a"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"_m7lA1HIer-y","executionInfo":{"status":"ok","timestamp":1651153907540,"user_tz":-60,"elapsed":4349,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":483,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"yVEuBQRb1BpE","executionInfo":{"status":"ok","timestamp":1651153907541,"user_tz":-60,"elapsed":13,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":484,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are the set of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"rI2uBt6fxLlF","executionInfo":{"status":"ok","timestamp":1651153907542,"user_tz":-60,"elapsed":10,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":485,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTV9vJPW5zUg","executionInfo":{"status":"ok","timestamp":1651153907542,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"7b682fb3-dbed-425c-dd72-f08558801de7"},"execution_count":486,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1126"]},"metadata":{},"execution_count":486}]},{"cell_type":"markdown","source":["##### Evaluating candidates"],"metadata":{"id":"872Hxw3fqlfv"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # array to hold cost function value for each candidate\n","  cost_function_values = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # alpha\n","  alpha = 0.75\n","\n","  # evaluate every candidate\n","  for th in threshold_candidates:\n","\n","    print(f\"Candidate: {th} \")\n","\n","    # array to hold earliness values for the samples \n","    earliness = []  \n","\n","    # dict to hold predictions vs true values for the samples  \n","    final_classifications = {}\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      # get KNN predicition for the sample\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","        \n","        # get the confidence for that prediction \n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","        if(c >= th): # check if confidence is at or above confidence threshold\n","\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          # predicted class for the sample is given by the prediction which led to the gien confidence value\n","          pred = predictions[i]\n","\n","          # update final outcomes dict\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","          # add to earliness array\n","          earliness.append(time_index/timestamps[-1])\n","\n","          break\n","\n","      sample_idx += 1\n","\n","    # get avg accuracy and avg earliness for this threshold\n","    if(len(final_classifications) > 0):\n","      avg_accuracy = accuracy(final_classifications)\n","      avg_earliness = sum(earliness)/len(earliness)\n","\n","      # compute value of cost function and add to array \n","      cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","      cost_function_values.append(cf_score)\n","      print(f\"Score: {cf_score}\")\n","      print(\"\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKc1S0R6ebff","executionInfo":{"status":"ok","timestamp":1651153935745,"user_tz":-60,"elapsed":27047,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"61429de2-4e6a-4f99-d7cf-0df551de87d7"},"execution_count":487,"outputs":[{"output_type":"stream","name":"stdout","text":["Candidate: 0.493859649122807 \n","Score: 0.34367346938775517\n","\n","Candidate: 0.6096491228070176 \n","Score: 0.39265306122448984\n","\n","Candidate: 0.6563157894736842 \n","Score: 0.3943877551020409\n","\n","Candidate: 0.7142105263157894 \n","Score: 0.3946938775510205\n","\n","Candidate: 0.770877192982456 \n","Score: 0.3805102040816326\n","\n","Candidate: 0.7824521072796935 \n","Score: 0.3502040816326531\n","\n","Candidate: 0.7986590038314176 \n","Score: 0.3502040816326531\n","\n","Candidate: 0.8084996975196612 \n","Score: 0.353061224489796\n","\n","Candidate: 0.8432779561636186 \n","Score: 0.35326530612244905\n","\n","Candidate: 0.8766261808367072 \n","Score: 0.3542857142857143\n","\n","Candidate: 0.8932678004888959 \n","Score: 0.35438775510204085\n","\n","Candidate: 0.9097311072970302 \n","Score: 0.3570408163265307\n","\n","Candidate: 0.9110264348654442 \n","Score: 0.35724489795918374\n","\n","Candidate: 0.9138343831180384 \n","Score: 0.3574489795918368\n","\n","Candidate: 0.9186171310629515 \n","Score: 0.3574489795918368\n","\n","Candidate: 0.9209937203093468 \n","Score: 0.358061224489796\n","\n","Candidate: 0.9220796931600256 \n","Score: 0.34377551020408165\n","\n","Candidate: 0.9275810029957008 \n","Score: 0.3438775510204082\n","\n","Candidate: 0.9356334949683379 \n","Score: 0.3438775510204082\n","\n","Candidate: 0.941365349713807 \n","Score: 0.3438775510204082\n","\n","Candidate: 0.9510082990116479 \n","Score: 0.34408163265306124\n","\n","Candidate: 0.9587480728494253 \n","Score: 0.36030612244897964\n","\n","Candidate: 0.9605507423314619 \n","Score: 0.36040816326530617\n","\n","Candidate: 0.9624509210822865 \n","Score: 0.4091836734693878\n","\n","Candidate: 0.9649834525461727 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.9673463577808619 \n","Score: 0.41010204081632656\n","\n","Candidate: 0.9687134433147658 \n","Score: 0.41040816326530616\n","\n","Candidate: 0.9699551182620029 \n","Score: 0.41040816326530616\n","\n","Candidate: 0.9713466260439678 \n","Score: 0.4106122448979592\n","\n","Candidate: 0.97261589376781 \n","Score: 0.4106122448979592\n","\n","Candidate: 0.9728793854706633 \n","Score: 0.4106122448979592\n","\n","Candidate: 0.9742472354366185 \n","Score: 0.41071428571428575\n","\n","Candidate: 0.9756999812859162 \n","Score: 0.41132653061224494\n","\n","Candidate: 0.9759601051396718 \n","Score: 0.41163265306122454\n","\n","Candidate: 0.9763012357439602 \n","Score: 0.4117346938775511\n","\n","Candidate: 0.9776550063461562 \n","Score: 0.4118367346938776\n","\n","Candidate: 0.9798557514176804 \n","Score: 0.4118367346938776\n","\n","Candidate: 0.9815122760965174 \n","Score: 0.41214285714285714\n","\n","Candidate: 0.9821200510855683 \n","Score: 0.41214285714285714\n","\n","Candidate: 0.9823478492943888 \n","Score: 0.39897959183673465\n","\n","Candidate: 0.9825997185438027 \n","Score: 0.3991836734693877\n","\n","Candidate: 0.9827686862589979 \n","Score: 0.3993877551020408\n","\n","Candidate: 0.983386067121168 \n","Score: 0.3993877551020408\n","\n","Candidate: 0.9842763253837175 \n","Score: 0.41479591836734697\n","\n","Candidate: 0.9846300980961527 \n","Score: 0.41540816326530616\n","\n","Candidate: 0.9848338503122887 \n","Score: 0.41602040816326535\n","\n","Candidate: 0.9858425343472583 \n","Score: 0.4161224489795919\n","\n","Candidate: 0.9870490884731926 \n","Score: 0.4161224489795919\n","\n","Candidate: 0.987770292135612 \n","Score: 0.4162244897959184\n","\n","Candidate: 0.9884451725603234 \n","Score: 0.416530612244898\n","\n","Candidate: 0.9887623644604713 \n","Score: 0.416530612244898\n","\n","Candidate: 0.9889047383409841 \n","Score: 0.41663265306122454\n","\n","Candidate: 0.9890639326229853 \n","Score: 0.4321428571428571\n","\n","Candidate: 0.9891674491244875 \n","Score: 0.43224489795918364\n","\n","Candidate: 0.9897136550112506 \n","Score: 0.43224489795918364\n","\n","Candidate: 0.9907084799049162 \n","Score: 0.43224489795918364\n","\n","Candidate: 0.9913336287498793 \n","Score: 0.41755102040816333\n","\n","Candidate: 0.9919100196270048 \n","Score: 0.41765306122448986\n","\n","Candidate: 0.9925417489861253 \n","Score: 0.41765306122448986\n","\n","Candidate: 0.9927344937085354 \n","Score: 0.41765306122448986\n","\n","Candidate: 0.9928813204551834 \n","Score: 0.40459183673469384\n","\n","Candidate: 0.9931006921112988 \n","Score: 0.4047959183673469\n","\n","Candidate: 0.9933972414630419 \n","Score: 0.4051020408163265\n","\n","Candidate: 0.9936579955636217 \n","Score: 0.40520408163265303\n","\n","Candidate: 0.9937393520667719 \n","Score: 0.40561224489795916\n","\n","Candidate: 0.9937986063341171 \n","Score: 0.4057142857142857\n","\n","Candidate: 0.9939509381338743 \n","Score: 0.4057142857142857\n","\n","Candidate: 0.9941716635232436 \n","Score: 0.4057142857142857\n","\n","Candidate: 0.9944693539160151 \n","Score: 0.4214285714285715\n","\n","Candidate: 0.9947623112107666 \n","Score: 0.4214285714285715\n","\n","Candidate: 0.9949434026405157 \n","Score: 0.42153061224489796\n","\n","Candidate: 0.9950294919957866 \n","Score: 0.42153061224489796\n","\n","Candidate: 0.9951896590726638 \n","Score: 0.4216326530612245\n","\n","Candidate: 0.9953789861179889 \n","Score: 0.4216326530612245\n","\n","Candidate: 0.9955006294671864 \n","Score: 0.421734693877551\n","\n","Candidate: 0.9956971099705862 \n","Score: 0.42183673469387756\n","\n","Candidate: 0.9958731565475616 \n","Score: 0.4223469387755102\n","\n","Candidate: 0.996019639477355 \n","Score: 0.4071428571428571\n","\n","Candidate: 0.9962498725729665 \n","Score: 0.4229591836734694\n","\n","Candidate: 0.996387334740813 \n","Score: 0.42306122448979594\n","\n","Candidate: 0.9964579251495447 \n","Score: 0.42316326530612247\n","\n","Candidate: 0.9966446977926908 \n","Score: 0.42316326530612247\n","\n","Candidate: 0.996798742271899 \n","Score: 0.42346938775510207\n","\n","Candidate: 0.9968339715704098 \n","Score: 0.4235714285714286\n","\n","Candidate: 0.9968855776991428 \n","Score: 0.41020408163265304\n","\n","Candidate: 0.9969358243902522 \n","Score: 0.4104081632653061\n","\n","Candidate: 0.9969800464497116 \n","Score: 0.41051020408163263\n","\n","Candidate: 0.9970469553971986 \n","Score: 0.41061224489795917\n","\n","Candidate: 0.9971194943494639 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9972123937294216 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9972957577960514 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9973889869427395 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9975336142201672 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9976910449897454 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9977731771623863 \n","Score: 0.4112244897959183\n","\n","Candidate: 0.9978108412553174 \n","Score: 0.41132653061224483\n","\n","Candidate: 0.9979204005133493 \n","Score: 0.41142857142857137\n","\n","Candidate: 0.9980137276576371 \n","Score: 0.41153061224489795\n","\n","Candidate: 0.9980294219956098 \n","Score: 0.41204081632653056\n","\n","Candidate: 0.998047219729867 \n","Score: 0.4123469387755102\n","\n","Candidate: 0.9981720349336549 \n","Score: 0.41244897959183674\n","\n","Candidate: 0.9983176877412313 \n","Score: 0.41255102040816327\n","\n","Candidate: 0.9983873643999254 \n","Score: 0.41255102040816327\n","\n","Candidate: 0.9984290184251712 \n","Score: 0.4126530612244898\n","\n","Candidate: 0.9984523003480994 \n","Score: 0.41295918367346934\n","\n","Candidate: 0.9985106559691073 \n","Score: 0.41326530612244894\n","\n","Candidate: 0.9985544657672717 \n","Score: 0.41336734693877547\n","\n","Candidate: 0.9985608961683681 \n","Score: 0.413469387755102\n","\n","Candidate: 0.9985759260878018 \n","Score: 0.40010204081632655\n","\n","Candidate: 0.9985962741894501 \n","Score: 0.38489795918367353\n","\n","Candidate: 0.9986096168104815 \n","Score: 0.3851020408163266\n","\n","Candidate: 0.9986315038441873 \n","Score: 0.3852040816326531\n","\n","Candidate: 0.9986525217794922 \n","Score: 0.38530612244897966\n","\n","Candidate: 0.9986960561324019 \n","Score: 0.38530612244897966\n","\n","Candidate: 0.9987452544401141 \n","Score: 0.38530612244897966\n","\n","Candidate: 0.9987729144069222 \n","Score: 0.4013265306122449\n","\n","Candidate: 0.9988673243592108 \n","Score: 0.4014285714285714\n","\n","Candidate: 0.9989470767634878 \n","Score: 0.4014285714285714\n","\n","Candidate: 0.9989666031367748 \n","Score: 0.40153061224489794\n","\n","Candidate: 0.998999957199131 \n","Score: 0.4016326530612245\n","\n","Candidate: 0.9990405917253271 \n","Score: 0.401734693877551\n","\n","Candidate: 0.9990782419900226 \n","Score: 0.40224489795918367\n","\n","Candidate: 0.9990995115607508 \n","Score: 0.4023469387755102\n","\n","Candidate: 0.999112372604485 \n","Score: 0.3726530612244898\n","\n","Candidate: 0.9991526881294527 \n","Score: 0.37275510204081636\n","\n","Candidate: 0.9992031152458465 \n","Score: 0.3575510204081633\n","\n","Candidate: 0.9992471482581938 \n","Score: 0.3577551020408163\n","\n","Candidate: 0.9992793992800909 \n","Score: 0.3580612244897959\n","\n","Candidate: 0.9992985781032466 \n","Score: 0.3581632653061224\n","\n","Candidate: 0.9993287128826123 \n","Score: 0.35826530612244895\n","\n","Candidate: 0.999353681557636 \n","Score: 0.3583673469387755\n","\n","Candidate: 0.9993727730548869 \n","Score: 0.358469387755102\n","\n","Candidate: 0.9993832412150149 \n","Score: 0.35857142857142854\n","\n","Candidate: 0.9993928105386342 \n","Score: 0.34489795918367344\n","\n","Candidate: 0.9994015311536263 \n","Score: 0.34489795918367344\n","\n","Candidate: 0.9994113951292705 \n","Score: 0.3451020408163265\n","\n","Candidate: 0.9994240134004694 \n","Score: 0.330204081632653\n","\n","Candidate: 0.9994468324369841 \n","Score: 0.34571428571428564\n","\n","Candidate: 0.9994846853645813 \n","Score: 0.3460204081632653\n","\n","Candidate: 0.9995045067122296 \n","Score: 0.3460204081632653\n","\n","Candidate: 0.9995109945025554 \n","Score: 0.34612244897959177\n","\n","Candidate: 0.9995377561714076 \n","Score: 0.3462244897959183\n","\n","Candidate: 0.9995618262299208 \n","Score: 0.33142857142857135\n","\n","Candidate: 0.9995714102281991 \n","Score: 0.3315306122448979\n","\n","Candidate: 0.9995948832168862 \n","Score: 0.3316326530612244\n","\n","Candidate: 0.9996140763831789 \n","Score: 0.33173469387755095\n","\n","Candidate: 0.999619588259065 \n","Score: 0.3318367346938775\n","\n","Candidate: 0.9996272458901969 \n","Score: 0.331938775510204\n","\n","Candidate: 0.9996383622616891 \n","Score: 0.3321428571428571\n","\n","Candidate: 0.9996516301050655 \n","Score: 0.3321428571428571\n","\n","Candidate: 0.9996680099993056 \n","Score: 0.33244897959183667\n","\n","Candidate: 0.9996841001800527 \n","Score: 0.3325510204081632\n","\n","Candidate: 0.9996920374021594 \n","Score: 0.33265306122448973\n","\n","Candidate: 0.9996967225146731 \n","Score: 0.33275510204081626\n","\n","Candidate: 0.9997093375898852 \n","Score: 0.3328571428571428\n","\n","Candidate: 0.9997243056116825 \n","Score: 0.33295918367346933\n","\n","Candidate: 0.9997548622018757 \n","Score: 0.33306122448979586\n","\n","Candidate: 0.9997797290053625 \n","Score: 0.3331632653061224\n","\n","Candidate: 0.9997833194132058 \n","Score: 0.33459183673469384\n","\n","Candidate: 0.9997915226176415 \n","Score: 0.3347959183673469\n","\n","Candidate: 0.9998030223297191 \n","Score: 0.33489795918367343\n","\n","Candidate: 0.9998140418404229 \n","Score: 0.33520408163265303\n","\n","Candidate: 0.9998228846244603 \n","Score: 0.33561224489795916\n","\n","Candidate: 0.9998357153602591 \n","Score: 0.33571428571428574\n","\n","Candidate: 0.9998464836368659 \n","Score: 0.3358163265306122\n","\n","Candidate: 0.9998491040514946 \n","Score: 0.3360204081632653\n","\n","Candidate: 0.9998510770658267 \n","Score: 0.33612244897959187\n","\n","Candidate: 0.9998560917079613 \n","Score: 0.33612244897959187\n","\n","Candidate: 0.9998603300767368 \n","Score: 0.3364285714285714\n","\n","Candidate: 0.9998621701368496 \n","Score: 0.33653061224489794\n","\n","Candidate: 0.9998641386639517 \n","Score: 0.3366326530612245\n","\n","Candidate: 0.9998652723561059 \n","Score: 0.336734693877551\n","\n","Candidate: 0.9998662719872751 \n","Score: 0.336734693877551\n","\n","Candidate: 0.9998690740882801 \n","Score: 0.33683673469387754\n","\n","Candidate: 0.9998719831450698 \n","Score: 0.33693877551020407\n","\n","Candidate: 0.999874761824317 \n","Score: 0.3370408163265306\n","\n","Candidate: 0.999880315478188 \n","Score: 0.3218367346938776\n","\n","Candidate: 0.999886478781281 \n","Score: 0.3219387755102041\n","\n","Candidate: 0.9998896712565366 \n","Score: 0.32204081632653064\n","\n","Candidate: 0.9998920759585305 \n","Score: 0.3221428571428572\n","\n","Candidate: 0.9999064432347604 \n","Score: 0.3222448979591837\n","\n","Candidate: 0.9999192339686329 \n","Score: 0.32234693877551024\n","\n","Candidate: 0.9999205504515087 \n","Score: 0.3237755102040817\n","\n","Candidate: 0.9999259089979005 \n","Score: 0.3241836734693878\n","\n","Candidate: 0.9999311646656183 \n","Score: 0.3244897959183674\n","\n","Candidate: 0.9999344070197653 \n","Score: 0.32459183673469394\n","\n","Candidate: 0.99993808019 \n","Score: 0.32469387755102047\n","\n","Candidate: 0.9999403936443476 \n","Score: 0.3251020408163266\n","\n","Candidate: 0.9999416862954588 \n","Score: 0.32520408163265313\n","\n","Candidate: 0.9999425248725831 \n","Score: 0.32520408163265313\n","\n","Candidate: 0.9999438751489309 \n","Score: 0.3253061224489796\n","\n","Candidate: 0.9999469489926875 \n","Score: 0.3254081632653062\n","\n","Candidate: 0.9999493069195408 \n","Score: 0.32551020408163267\n","\n","Candidate: 0.9999497072853054 \n","Score: 0.32571428571428573\n","\n","Candidate: 0.9999501841767824 \n","Score: 0.3258163265306123\n","\n","Candidate: 0.9999506863842555 \n","Score: 0.3259183673469388\n","\n","Candidate: 0.9999509673694862 \n","Score: 0.3259183673469388\n","\n","Candidate: 0.9999519082861714 \n","Score: 0.3260204081632654\n","\n","Candidate: 0.9999529714860056 \n","Score: 0.32612244897959186\n","\n","Candidate: 0.9999544327450027 \n","Score: 0.3264285714285715\n","\n","Candidate: 0.9999566412011838 \n","Score: 0.326530612244898\n","\n","Candidate: 0.9999586983451323 \n","Score: 0.3266326530612245\n","\n","Candidate: 0.9999598628460893 \n","Score: 0.32673469387755105\n","\n","Candidate: 0.999960504894066 \n","Score: 0.32673469387755105\n","\n","Candidate: 0.999961191611066 \n","Score: 0.3268367346938776\n","\n","Candidate: 0.9999621595937603 \n","Score: 0.3269387755102041\n","\n","Candidate: 0.999964759538967 \n","Score: 0.32704081632653065\n","\n","Candidate: 0.9999665980756669 \n","Score: 0.3120408163265307\n","\n","Candidate: 0.9999685023721396 \n","Score: 0.3120408163265307\n","\n","Candidate: 0.9999703857884987 \n","Score: 0.31214285714285717\n","\n","Candidate: 0.9999708684988865 \n","Score: 0.3135714285714286\n","\n","Candidate: 0.9999728332992301 \n","Score: 0.31367346938775514\n","\n","Candidate: 0.9999746218077591 \n","Score: 0.31397959183673474\n","\n","Candidate: 0.9999752201401532 \n","Score: 0.31397959183673474\n","\n","Candidate: 0.9999761665672131 \n","Score: 0.31397959183673474\n","\n","Candidate: 0.9999768056319897 \n","Score: 0.3140816326530612\n","\n","Candidate: 0.9999771277116933 \n","Score: 0.3140816326530612\n","\n","Candidate: 0.9999779274443041 \n","Score: 0.3141836734693878\n","\n","Candidate: 0.9999787611094735 \n","Score: 0.3142857142857143\n","\n","Candidate: 0.9999792705418564 \n","Score: 0.31438775510204087\n","\n","Candidate: 0.9999796228420454 \n","Score: 0.31448979591836734\n","\n","Candidate: 0.9999798116128502 \n","Score: 0.31459183673469393\n","\n","Candidate: 0.9999805863887052 \n","Score: 0.3303061224489796\n","\n","Candidate: 0.9999814695406208 \n","Score: 0.33040816326530614\n","\n","Candidate: 0.9999816333409662 \n","Score: 0.3305102040816327\n","\n","Candidate: 0.9999817511977185 \n","Score: 0.33061224489795915\n","\n","Candidate: 0.9999820664645016 \n","Score: 0.33071428571428574\n","\n","Candidate: 0.9999823247880044 \n","Score: 0.3308163265306122\n","\n","Candidate: 0.9999827506433123 \n","Score: 0.3308163265306122\n","\n","Candidate: 0.9999831582625791 \n","Score: 0.3308163265306122\n","\n","Candidate: 0.9999834031642595 \n","Score: 0.3310204081632653\n","\n","Candidate: 0.9999840101897735 \n","Score: 0.3311224489795918\n","\n","Candidate: 0.9999848109150009 \n","Score: 0.3314285714285714\n","\n","Candidate: 0.99998523931657 \n","Score: 0.33153061224489794\n","\n","Candidate: 0.9999854902122025 \n","Score: 0.33163265306122447\n","\n","Candidate: 0.9999857979626936 \n","Score: 0.331734693877551\n","\n","Candidate: 0.9999864568302296 \n","Score: 0.33183673469387753\n","\n","Candidate: 0.999987073902882 \n","Score: 0.33183673469387753\n","\n","Candidate: 0.9999873865312534 \n","Score: 0.33193877551020406\n","\n","Candidate: 0.9999882696494393 \n","Score: 0.3320408163265306\n","\n","Candidate: 0.999988894670687 \n","Score: 0.33214285714285713\n","\n","Candidate: 0.9999890756870824 \n","Score: 0.3336734693877551\n","\n","Candidate: 0.9999893246169012 \n","Score: 0.3337755102040816\n","\n","Candidate: 0.99998976478693 \n","Score: 0.3337755102040816\n","\n","Candidate: 0.9999902526572402 \n","Score: 0.33387755102040817\n","\n","Candidate: 0.9999907883278993 \n","Score: 0.3341836734693877\n","\n","Candidate: 0.9999912341515946 \n","Score: 0.3344897959183673\n","\n","Candidate: 0.9999916020117251 \n","Score: 0.33459183673469384\n","\n","Candidate: 0.999992035011084 \n","Score: 0.33469387755102037\n","\n","Candidate: 0.9999921503154385 \n","Score: 0.3347959183673469\n","\n","Candidate: 0.9999921750461747 \n","Score: 0.33489795918367343\n","\n","Candidate: 0.9999923071587455 \n","Score: 0.33499999999999996\n","\n","Candidate: 0.9999924572556903 \n","Score: 0.3351020408163265\n","\n","Candidate: 0.9999925712698883 \n","Score: 0.33520408163265303\n","\n","Candidate: 0.9999927388843635 \n","Score: 0.3354081632653061\n","\n","Candidate: 0.9999928892326344 \n","Score: 0.3355102040816326\n","\n","Candidate: 0.9999929698489634 \n","Score: 0.33561224489795916\n","\n","Candidate: 0.9999930510777328 \n","Score: 0.3357142857142857\n","\n","Candidate: 0.9999931247560512 \n","Score: 0.3358163265306122\n","\n","Candidate: 0.999993158752673 \n","Score: 0.3358163265306122\n","\n","Candidate: 0.9999931843209295 \n","Score: 0.3361224489795918\n","\n","Candidate: 0.9999933174851001 \n","Score: 0.33622448979591835\n","\n","Candidate: 0.9999934879394836 \n","Score: 0.33622448979591835\n","\n","Candidate: 0.999993613866957 \n","Score: 0.3363265306122449\n","\n","Candidate: 0.9999937552794398 \n","Score: 0.3364285714285714\n","\n","Candidate: 0.9999938636523965 \n","Score: 0.3365306122448979\n","\n","Candidate: 0.999994133621682 \n","Score: 0.3366326530612245\n","\n","Candidate: 0.999994414370436 \n","Score: 0.336734693877551\n","\n","Candidate: 0.9999945377849664 \n","Score: 0.33683673469387754\n","\n","Candidate: 0.9999946260665633 \n","Score: 0.336938775510204\n","\n","Candidate: 0.9999948042098659 \n","Score: 0.3370408163265306\n","\n","Candidate: 0.9999954227561181 \n","Score: 0.3370408163265306\n","\n","Candidate: 0.9999959647118624 \n","Score: 0.3370408163265306\n","\n","Candidate: 0.9999960784844703 \n","Score: 0.3371428571428571\n","\n","Candidate: 0.9999961430221023 \n","Score: 0.3371428571428571\n","\n","Candidate: 0.9999961825430487 \n","Score: 0.33724489795918366\n","\n","Candidate: 0.9999962447674346 \n","Score: 0.3385714285714286\n","\n","Candidate: 0.999996386250329 \n","Score: 0.3386734693877551\n","\n","Candidate: 0.9999965855487245 \n","Score: 0.3389795918367347\n","\n","Candidate: 0.9999968505927697 \n","Score: 0.3392857142857143\n","\n","Candidate: 0.9999970305171213 \n","Score: 0.33938775510204083\n","\n","Candidate: 0.9999970955537454 \n","Score: 0.33959183673469395\n","\n","Candidate: 0.9999971782281546 \n","Score: 0.3396938775510205\n","\n","Candidate: 0.999997246093452 \n","Score: 0.339795918367347\n","\n","Candidate: 0.9999972857293238 \n","Score: 0.34010204081632656\n","\n","Candidate: 0.999997317674196 \n","Score: 0.34020408163265314\n","\n","Candidate: 0.9999973630878922 \n","Score: 0.34020408163265314\n","\n","Candidate: 0.9999974034046375 \n","Score: 0.3403061224489796\n","\n","Candidate: 0.99999743161774 \n","Score: 0.3404081632653062\n","\n","Candidate: 0.9999974546644448 \n","Score: 0.3404081632653062\n","\n","Candidate: 0.9999974682662726 \n","Score: 0.34051020408163274\n","\n","Candidate: 0.999997501784561 \n","Score: 0.34061224489795927\n","\n","Candidate: 0.9999975503453372 \n","Score: 0.3407142857142858\n","\n","Candidate: 0.999997582886689 \n","Score: 0.34081632653061233\n","\n","Candidate: 0.9999976113079707 \n","Score: 0.34091836734693887\n","\n","Candidate: 0.9999976454239807 \n","Score: 0.3410204081632654\n","\n","Candidate: 0.999997688843158 \n","Score: 0.3411224489795919\n","\n","Candidate: 0.9999977301735102 \n","Score: 0.34122448979591846\n","\n","Candidate: 0.999997786118717 \n","Score: 0.341326530612245\n","\n","Candidate: 0.9999978354845291 \n","Score: 0.3414285714285715\n","\n","Candidate: 0.9999978665520131 \n","Score: 0.34153061224489806\n","\n","Candidate: 0.9999979251851243 \n","Score: 0.3416326530612246\n","\n","Candidate: 0.9999979943368429 \n","Score: 0.3417346938775511\n","\n","Candidate: 0.9999980349537829 \n","Score: 0.34183673469387765\n","\n","Candidate: 0.9999980698798758 \n","Score: 0.34183673469387765\n","\n","Candidate: 0.9999981295976668 \n","Score: 0.34193877551020413\n","\n","Candidate: 0.9999981678790502 \n","Score: 0.3420408163265307\n","\n","Candidate: 0.999998287613088 \n","Score: 0.3420408163265307\n","\n","Candidate: 0.9999984436574443 \n","Score: 0.3420408163265307\n","\n","Candidate: 0.9999985024299325 \n","Score: 0.3420408163265307\n","\n","Candidate: 0.9999985924472259 \n","Score: 0.3421428571428572\n","\n","Candidate: 0.9999986727978247 \n","Score: 0.3421428571428572\n","\n","Candidate: 0.999998719965364 \n","Score: 0.3424489795918368\n","\n","Candidate: 0.9999987649403981 \n","Score: 0.3425510204081633\n","\n","Candidate: 0.999998785071817 \n","Score: 0.34387755102040823\n","\n","Candidate: 0.9999988494904711 \n","Score: 0.34397959183673477\n","\n","Candidate: 0.9999989108326546 \n","Score: 0.34418367346938783\n","\n","Candidate: 0.9999989283559266 \n","Score: 0.34428571428571436\n","\n","Candidate: 0.9999989472676447 \n","Score: 0.34459183673469396\n","\n","Candidate: 0.999998969580422 \n","Score: 0.34459183673469396\n","\n","Candidate: 0.9999989920437109 \n","Score: 0.34489795918367355\n","\n","Candidate: 0.9999990191418173 \n","Score: 0.34489795918367355\n","\n","Candidate: 0.9999990304850153 \n","Score: 0.3450000000000001\n","\n","Candidate: 0.9999990516968876 \n","Score: 0.3451020408163266\n","\n","Candidate: 0.9999990775086002 \n","Score: 0.34520408163265315\n","\n","Candidate: 0.9999990918442665 \n","Score: 0.3453061224489796\n","\n","Candidate: 0.9999991142328515 \n","Score: 0.3454081632653062\n","\n","Candidate: 0.9999991314839718 \n","Score: 0.3455102040816327\n","\n","Candidate: 0.9999991448203278 \n","Score: 0.3455102040816327\n","\n","Candidate: 0.9999991550852443 \n","Score: 0.3456122448979593\n","\n","Candidate: 0.9999991673813167 \n","Score: 0.34571428571428575\n","\n","Candidate: 0.9999991845371858 \n","Score: 0.34602040816326535\n","\n","Candidate: 0.9999992028366231 \n","Score: 0.3461224489795919\n","\n","Candidate: 0.9999992179927524 \n","Score: 0.3462244897959184\n","\n","Candidate: 0.9999992271878728 \n","Score: 0.34632653061224494\n","\n","Candidate: 0.99999923353044 \n","Score: 0.3464285714285715\n","\n","Candidate: 0.9999992358631815 \n","Score: 0.346530612244898\n","\n","Candidate: 0.999999240558147 \n","Score: 0.346530612244898\n","\n","Candidate: 0.9999992522727864 \n","Score: 0.34663265306122454\n","\n","Candidate: 0.9999992895561204 \n","Score: 0.34673469387755107\n","\n","Candidate: 0.9999993287363638 \n","Score: 0.3468367346938776\n","\n","Candidate: 0.9999993511089785 \n","Score: 0.34693877551020413\n","\n","Candidate: 0.9999993690067874 \n","Score: 0.34704081632653067\n","\n","Candidate: 0.9999993765551909 \n","Score: 0.3471428571428572\n","\n","Candidate: 0.9999993813005364 \n","Score: 0.3471428571428572\n","\n","Candidate: 0.9999993948698334 \n","Score: 0.34724489795918373\n","\n","Candidate: 0.9999994239563188 \n","Score: 0.34734693877551026\n","\n","Candidate: 0.9999994892852226 \n","Score: 0.3476530612244898\n","\n","Candidate: 0.999999541403223 \n","Score: 0.34785714285714286\n","\n","Candidate: 0.9999995528162757 \n","Score: 0.34795918367346945\n","\n","Candidate: 0.999999563531849 \n","Score: 0.34795918367346945\n","\n","Candidate: 0.9999995803015987 \n","Score: 0.34826530612244905\n","\n","Candidate: 0.9999995942250688 \n","Score: 0.3483673469387756\n","\n","Candidate: 0.999999598148701 \n","Score: 0.3483673469387756\n","\n","Candidate: 0.9999996004218935 \n","Score: 0.3484693877551021\n","\n","Candidate: 0.9999996054295759 \n","Score: 0.34979591836734697\n","\n","Candidate: 0.9999996110793808 \n","Score: 0.3498979591836735\n","\n","Candidate: 0.9999996133975306 \n","Score: 0.35000000000000003\n","\n","Candidate: 0.9999996289427986 \n","Score: 0.35000000000000003\n","\n","Candidate: 0.9999996450923406 \n","Score: 0.35010204081632657\n","\n","Candidate: 0.9999996504078908 \n","Score: 0.35010204081632657\n","\n","Candidate: 0.9999996545905052 \n","Score: 0.3504081632653061\n","\n","Candidate: 0.9999996570695568 \n","Score: 0.3504081632653061\n","\n","Candidate: 0.9999996676815167 \n","Score: 0.3505102040816327\n","\n","Candidate: 0.999999681243537 \n","Score: 0.35061224489795917\n","\n","Candidate: 0.9999996950228964 \n","Score: 0.3507142857142857\n","\n","Candidate: 0.9999997064683729 \n","Score: 0.3507142857142857\n","\n","Candidate: 0.9999997118979422 \n","Score: 0.3509183673469388\n","\n","Candidate: 0.9999997160466797 \n","Score: 0.3510204081632653\n","\n","Candidate: 0.9999997223305226 \n","Score: 0.3511224489795919\n","\n","Candidate: 0.9999997292520082 \n","Score: 0.35122448979591836\n","\n","Candidate: 0.9999997380017729 \n","Score: 0.3513265306122449\n","\n","Candidate: 0.9999997462876791 \n","Score: 0.3514285714285714\n","\n","Candidate: 0.9999997499426772 \n","Score: 0.35153061224489796\n","\n","Candidate: 0.999999751923428 \n","Score: 0.3516326530612245\n","\n","Candidate: 0.9999997535435136 \n","Score: 0.351734693877551\n","\n","Candidate: 0.9999997561481817 \n","Score: 0.35183673469387755\n","\n","Candidate: 0.9999997575492409 \n","Score: 0.3519387755102041\n","\n","Candidate: 0.9999997589252768 \n","Score: 0.3519387755102041\n","\n","Candidate: 0.9999997640396285 \n","Score: 0.3520408163265306\n","\n","Candidate: 0.9999997758204159 \n","Score: 0.35214285714285715\n","\n","Candidate: 0.9999997922612178 \n","Score: 0.35244897959183674\n","\n","Candidate: 0.9999998011117388 \n","Score: 0.3525510204081633\n","\n","Candidate: 0.999999804288177 \n","Score: 0.3525510204081633\n","\n","Candidate: 0.9999998133500729 \n","Score: 0.3526530612244898\n","\n","Candidate: 0.9999998216568089 \n","Score: 0.35285714285714287\n","\n","Candidate: 0.9999998281796708 \n","Score: 0.35295918367346935\n","\n","Candidate: 0.9999998333742606 \n","Score: 0.353265306122449\n","\n","Candidate: 0.9999998378113775 \n","Score: 0.353265306122449\n","\n","Candidate: 0.9999998421986378 \n","Score: 0.35336734693877553\n","\n","Candidate: 0.9999998456719269 \n","Score: 0.35336734693877553\n","\n","Candidate: 0.9999998490691526 \n","Score: 0.35346938775510206\n","\n","Candidate: 0.9999998521777991 \n","Score: 0.35346938775510206\n","\n","Candidate: 0.9999998546988704 \n","Score: 0.35357142857142854\n","\n","Candidate: 0.9999998552014915 \n","Score: 0.35489795918367345\n","\n","Candidate: 0.9999998571012543 \n","Score: 0.35489795918367345\n","\n","Candidate: 0.9999998589670355 \n","Score: 0.35489795918367345\n","\n","Candidate: 0.9999998602755231 \n","Score: 0.355\n","\n","Candidate: 0.9999998644605332 \n","Score: 0.3551020408163265\n","\n","Candidate: 0.9999998708925093 \n","Score: 0.35520408163265305\n","\n","Candidate: 0.999999879524416 \n","Score: 0.35551020408163264\n","\n","Candidate: 0.9999998853575331 \n","Score: 0.35551020408163264\n","\n","Candidate: 0.9999998889961577 \n","Score: 0.3556122448979592\n","\n","Candidate: 0.9999998946667809 \n","Score: 0.35571428571428565\n","\n","Candidate: 0.9999998982708977 \n","Score: 0.35581632653061224\n","\n","Candidate: 0.9999998999994467 \n","Score: 0.3559183673469387\n","\n","Candidate: 0.9999999029824416 \n","Score: 0.3560204081632653\n","\n","Candidate: 0.9999999053851499 \n","Score: 0.35612244897959183\n","\n","Candidate: 0.9999999056920419 \n","Score: 0.35622448979591836\n","\n","Candidate: 0.9999999058423888 \n","Score: 0.35622448979591836\n","\n","Candidate: 0.9999999067125309 \n","Score: 0.35622448979591836\n","\n","Candidate: 0.9999999077027777 \n","Score: 0.35632653061224484\n","\n","Candidate: 0.9999999081025437 \n","Score: 0.35632653061224484\n","\n","Candidate: 0.9999999090809262 \n","Score: 0.35642857142857143\n","\n","Candidate: 0.9999999103794595 \n","Score: 0.3565306122448979\n","\n","Candidate: 0.9999999116953702 \n","Score: 0.3566326530612245\n","\n","Candidate: 0.9999999136471039 \n","Score: 0.37275510204081624\n","\n","Candidate: 0.9999999150626007 \n","Score: 0.3728571428571428\n","\n","Candidate: 0.9999999155301728 \n","Score: 0.3729591836734693\n","\n","Candidate: 0.9999999169860276 \n","Score: 0.3732653061224489\n","\n","Candidate: 0.9999999229144355 \n","Score: 0.3733673469387755\n","\n","Candidate: 0.9999999286906792 \n","Score: 0.37346938775510197\n","\n","Candidate: 0.9999999298457476 \n","Score: 0.3736734693877551\n","\n","Candidate: 0.999999930761851 \n","Score: 0.3737755102040816\n","\n","Candidate: 0.9999999319078259 \n","Score: 0.3738775510204081\n","\n","Candidate: 0.999999933528391 \n","Score: 0.3738775510204081\n","\n","Candidate: 0.9999999365270936 \n","Score: 0.3741836734693877\n","\n","Candidate: 0.9999999386328036 \n","Score: 0.3742857142857142\n","\n","Candidate: 0.9999999399272037 \n","Score: 0.3742857142857142\n","\n","Candidate: 0.9999999408977627 \n","Score: 0.3742857142857142\n","\n","Candidate: 0.9999999413046705 \n","Score: 0.3743877551020408\n","\n","Candidate: 0.9999999419483301 \n","Score: 0.3743877551020408\n","\n","Candidate: 0.9999999422624215 \n","Score: 0.3743877551020408\n","\n","Candidate: 0.9999999441974159 \n","Score: 0.3744897959183673\n","\n","Candidate: 0.9999999472902074 \n","Score: 0.3745918367346939\n","\n","Candidate: 0.9999999485377356 \n","Score: 0.3746938775510204\n","\n","Candidate: 0.9999999486933542 \n","Score: 0.37479591836734694\n","\n","Candidate: 0.9999999488041522 \n","Score: 0.37479591836734694\n","\n","Candidate: 0.9999999495531551 \n","Score: 0.3616326530612245\n","\n","Candidate: 0.999999952955588 \n","Score: 0.36173469387755103\n","\n","Candidate: 0.9999999576916594 \n","Score: 0.3620408163265306\n","\n","Candidate: 0.9999999598413847 \n","Score: 0.36214285714285716\n","\n","Candidate: 0.9999999604528 \n","Score: 0.36214285714285716\n","\n","Candidate: 0.9999999612226991 \n","Score: 0.36214285714285716\n","\n","Candidate: 0.9999999623733783 \n","Score: 0.36214285714285716\n","\n","Candidate: 0.9999999633330642 \n","Score: 0.3622448979591837\n","\n","Candidate: 0.999999963572366 \n","Score: 0.3623469387755102\n","\n","Candidate: 0.9999999638820714 \n","Score: 0.36244897959183675\n","\n","Candidate: 0.9999999644921476 \n","Score: 0.3625510204081633\n","\n","Candidate: 0.9999999656935198 \n","Score: 0.3626530612244898\n","\n","Candidate: 0.999999966805389 \n","Score: 0.36275510204081635\n","\n","Candidate: 0.9999999672256096 \n","Score: 0.36275510204081635\n","\n","Candidate: 0.999999967455415 \n","Score: 0.36306122448979594\n","\n","Candidate: 0.999999967910915 \n","Score: 0.3631632653061225\n","\n","Candidate: 0.9999999682837402 \n","Score: 0.363265306122449\n","\n","Candidate: 0.999999968487832 \n","Score: 0.3793877551020408\n","\n","Candidate: 0.9999999688801766 \n","Score: 0.37948979591836735\n","\n","Candidate: 0.999999970470856 \n","Score: 0.3795918367346939\n","\n","Candidate: 0.9999999720204518 \n","Score: 0.3796938775510204\n","\n","Candidate: 0.9999999724110495 \n","Score: 0.3796938775510204\n","\n","Candidate: 0.9999999726039746 \n","Score: 0.37979591836734694\n","\n","Candidate: 0.9999999726986617 \n","Score: 0.38\n","\n","Candidate: 0.9999999728099469 \n","Score: 0.38010204081632654\n","\n","Candidate: 0.9999999731396297 \n","Score: 0.38020408163265307\n","\n","Candidate: 0.9999999737268046 \n","Score: 0.38030612244897954\n","\n","Candidate: 0.9999999742674095 \n","Score: 0.38040816326530613\n","\n","Candidate: 0.9999999745554315 \n","Score: 0.3805102040816326\n","\n","Candidate: 0.9999999749631028 \n","Score: 0.38081632653061226\n","\n","Candidate: 0.9999999755399649 \n","Score: 0.3809183673469388\n","\n","Candidate: 0.9999999758929541 \n","Score: 0.3809183673469388\n","\n","Candidate: 0.9999999761793107 \n","Score: 0.3810204081632653\n","\n","Candidate: 0.9999999766613001 \n","Score: 0.3810204081632653\n","\n","Candidate: 0.9999999769944081 \n","Score: 0.3810204081632653\n","\n","Candidate: 0.99999997804051 \n","Score: 0.38112244897959185\n","\n","Candidate: 0.9999999795017473 \n","Score: 0.3812244897959184\n","\n","Candidate: 0.9999999803606603 \n","Score: 0.3813265306122449\n","\n","Candidate: 0.999999981670217 \n","Score: 0.3815306122448979\n","\n","Candidate: 0.9999999827240524 \n","Score: 0.3815306122448979\n","\n","Candidate: 0.9999999829057494 \n","Score: 0.3816326530612245\n","\n","Candidate: 0.999999983184385 \n","Score: 0.38285714285714284\n","\n","Candidate: 0.9999999835778289 \n","Score: 0.38295918367346937\n","\n","Candidate: 0.9999999838820381 \n","Score: 0.3830612244897959\n","\n","Candidate: 0.9999999841365587 \n","Score: 0.3830612244897959\n","\n","Candidate: 0.9999999847247909 \n","Score: 0.3830612244897959\n","\n","Candidate: 0.9999999854644346 \n","Score: 0.3689795918367347\n","\n","Candidate: 0.9999999860100972 \n","Score: 0.36908163265306126\n","\n","Candidate: 0.9999999864428826 \n","Score: 0.36908163265306126\n","\n","Candidate: 0.999999986923158 \n","Score: 0.36918367346938774\n","\n","Candidate: 0.9999999872641707 \n","Score: 0.36918367346938774\n","\n","Candidate: 0.9999999875340441 \n","Score: 0.3848979591836734\n","\n","Candidate: 0.9999999878601633 \n","Score: 0.385\n","\n","Candidate: 0.9999999881210919 \n","Score: 0.3851020408163265\n","\n","Candidate: 0.9999999883277508 \n","Score: 0.385204081632653\n","\n","Candidate: 0.9999999883608389 \n","Score: 0.38530612244897955\n","\n","Candidate: 0.9999999885265882 \n","Score: 0.3854081632653061\n","\n","Candidate: 0.999999988733556 \n","Score: 0.3854081632653061\n","\n","Candidate: 0.9999999889433351 \n","Score: 0.3855102040816326\n","\n","Candidate: 0.999999989150504 \n","Score: 0.3856122448979592\n","\n","Candidate: 0.9999999892956883 \n","Score: 0.3857142857142857\n","\n","Candidate: 0.9999999893804263 \n","Score: 0.38591836734693874\n","\n","Candidate: 0.9999999894033963 \n","Score: 0.38602040816326527\n","\n","Candidate: 0.9999999894714269 \n","Score: 0.3861224489795918\n","\n","Candidate: 0.9999999895870035 \n","Score: 0.38622448979591834\n","\n","Candidate: 0.9999999896680214 \n","Score: 0.38632653061224487\n","\n","Candidate: 0.9999999898734044 \n","Score: 0.38632653061224487\n","\n","Candidate: 0.9999999900799164 \n","Score: 0.3864285714285714\n","\n","Candidate: 0.9999999901196186 \n","Score: 0.3864285714285714\n","\n","Candidate: 0.9999999902367646 \n","Score: 0.386734693877551\n","\n","Candidate: 0.9999999904593396 \n","Score: 0.386734693877551\n","\n","Candidate: 0.9999999906232775 \n","Score: 0.3868367346938775\n","\n","Candidate: 0.9999999907850392 \n","Score: 0.38693877551020406\n","\n","Candidate: 0.9999999909893152 \n","Score: 0.3870408163265306\n","\n","Candidate: 0.9999999911054095 \n","Score: 0.3871428571428571\n","\n","Candidate: 0.9999999913146038 \n","Score: 0.38724489795918365\n","\n","Candidate: 0.9999999916244959 \n","Score: 0.3873469387755102\n","\n","Candidate: 0.9999999918052831 \n","Score: 0.38744897959183666\n","\n","Candidate: 0.9999999920284572 \n","Score: 0.38755102040816325\n","\n","Candidate: 0.999999992316256 \n","Score: 0.3876530612244897\n","\n","Candidate: 0.999999992552042 \n","Score: 0.3876530612244897\n","\n","Candidate: 0.9999999930734841 \n","Score: 0.3877551020408163\n","\n","Candidate: 0.9999999935104104 \n","Score: 0.3877551020408163\n","\n","Candidate: 0.9999999937302386 \n","Score: 0.3877551020408163\n","\n","Candidate: 0.9999999940652996 \n","Score: 0.3877551020408163\n","\n","Candidate: 0.9999999942559434 \n","Score: 0.3878571428571428\n","\n","Candidate: 0.9999999943019164 \n","Score: 0.3879591836734693\n","\n","Candidate: 0.9999999943800384 \n","Score: 0.38918367346938776\n","\n","Candidate: 0.9999999944592263 \n","Score: 0.3892857142857143\n","\n","Candidate: 0.9999999944739828 \n","Score: 0.3893877551020408\n","\n","Candidate: 0.9999999947615275 \n","Score: 0.38948979591836735\n","\n","Candidate: 0.9999999950575681 \n","Score: 0.3896938775510204\n","\n","Candidate: 0.9999999950688837 \n","Score: 0.3896938775510204\n","\n","Candidate: 0.9999999952161378 \n","Score: 0.3898979591836735\n","\n","Candidate: 0.9999999954448875 \n","Score: 0.3898979591836735\n","\n","Candidate: 0.9999999955307062 \n","Score: 0.39\n","\n","Candidate: 0.9999999956145116 \n","Score: 0.39010204081632655\n","\n","Candidate: 0.9999999957463666 \n","Score: 0.39010204081632655\n","\n","Candidate: 0.9999999958321868 \n","Score: 0.39010204081632655\n","\n","Candidate: 0.9999999959198259 \n","Score: 0.3903061224489796\n","\n","Candidate: 0.9999999959737051 \n","Score: 0.39040816326530614\n","\n","Candidate: 0.9999999960414914 \n","Score: 0.3905102040816327\n","\n","Candidate: 0.9999999961368023 \n","Score: 0.3906122448979592\n","\n","Candidate: 0.9999999962053495 \n","Score: 0.3909183673469388\n","\n","Candidate: 0.9999999962501427 \n","Score: 0.39102040816326533\n","\n","Candidate: 0.999999996311733 \n","Score: 0.39112244897959186\n","\n","Candidate: 0.9999999963784969 \n","Score: 0.3912244897959184\n","\n","Candidate: 0.9999999963974344 \n","Score: 0.3913265306122449\n","\n","Candidate: 0.9999999964066526 \n","Score: 0.39142857142857146\n","\n","Candidate: 0.9999999964348987 \n","Score: 0.391530612244898\n","\n","Candidate: 0.999999996485469 \n","Score: 0.3916326530612245\n","\n","Candidate: 0.9999999965177262 \n","Score: 0.39173469387755105\n","\n","Candidate: 0.999999996529568 \n","Score: 0.3918367346938776\n","\n","Candidate: 0.9999999966193446 \n","Score: 0.3919387755102041\n","\n","Candidate: 0.9999999967502582 \n","Score: 0.3919387755102041\n","\n","Candidate: 0.9999999968121411 \n","Score: 0.39204081632653065\n","\n","Candidate: 0.9999999968919436 \n","Score: 0.3921428571428572\n","\n","Candidate: 0.9999999969537103 \n","Score: 0.3921428571428572\n","\n","Candidate: 0.9999999969585134 \n","Score: 0.3921428571428572\n","\n","Candidate: 0.9999999969660768 \n","Score: 0.3922448979591837\n","\n","Candidate: 0.9999999970182579 \n","Score: 0.3923469387755102\n","\n","Candidate: 0.99999999710468 \n","Score: 0.3924489795918368\n","\n","Candidate: 0.9999999971524991 \n","Score: 0.39255102040816325\n","\n","Candidate: 0.9999999972081652 \n","Score: 0.39265306122448984\n","\n","Candidate: 0.9999999972907755 \n","Score: 0.3927551020408163\n","\n","Candidate: 0.9999999973451679 \n","Score: 0.3927551020408163\n","\n","Candidate: 0.9999999974993173 \n","Score: 0.3927551020408163\n","\n","Candidate: 0.9999999976386695 \n","Score: 0.39285714285714285\n","\n","Candidate: 0.9999999976898718 \n","Score: 0.39285714285714285\n","\n","Candidate: 0.9999999977894224 \n","Score: 0.3929591836734694\n","\n","Candidate: 0.999999997911755 \n","Score: 0.3930612244897959\n","\n","Candidate: 0.9999999980287799 \n","Score: 0.3930612244897959\n","\n","Candidate: 0.9999999981012759 \n","Score: 0.39326530612244903\n","\n","Candidate: 0.9999999981431933 \n","Score: 0.39326530612244903\n","\n","Candidate: 0.9999999981619085 \n","Score: 0.3933673469387755\n","\n","Candidate: 0.9999999981693093 \n","Score: 0.3945918367346939\n","\n","Candidate: 0.9999999981727854 \n","Score: 0.3945918367346939\n","\n","Candidate: 0.9999999981953455 \n","Score: 0.3946938775510204\n","\n","Candidate: 0.9999999982888954 \n","Score: 0.39479591836734695\n","\n","Candidate: 0.9999999983638753 \n","Score: 0.39479591836734695\n","\n","Candidate: 0.9999999983699375 \n","Score: 0.39479591836734695\n","\n","Candidate: 0.9999999983824037 \n","Score: 0.39479591836734695\n","\n","Candidate: 0.9999999984012664 \n","Score: 0.395\n","\n","Candidate: 0.9999999984222194 \n","Score: 0.3952040816326531\n","\n","Candidate: 0.9999999984717225 \n","Score: 0.3953061224489796\n","\n","Candidate: 0.9999999985286233 \n","Score: 0.3956122448979592\n","\n","Candidate: 0.9999999985529104 \n","Score: 0.3956122448979592\n","\n","Candidate: 0.9999999985692826 \n","Score: 0.3957142857142857\n","\n","Candidate: 0.9999999985844619 \n","Score: 0.3958163265306123\n","\n","Candidate: 0.9999999986186145 \n","Score: 0.39591836734693875\n","\n","Candidate: 0.9999999986511572 \n","Score: 0.39602040816326534\n","\n","Candidate: 0.9999999986768189 \n","Score: 0.39602040816326534\n","\n","Candidate: 0.9999999987030441 \n","Score: 0.3961224489795918\n","\n","Candidate: 0.9999999987249106 \n","Score: 0.39622448979591834\n","\n","Candidate: 0.9999999987499708 \n","Score: 0.3963265306122449\n","\n","Candidate: 0.9999999987614213 \n","Score: 0.3963265306122449\n","\n","Candidate: 0.999999998779707 \n","Score: 0.3964285714285714\n","\n","Candidate: 0.9999999988062123 \n","Score: 0.39653061224489794\n","\n","Candidate: 0.9999999988209323 \n","Score: 0.39653061224489794\n","\n","Candidate: 0.9999999988282056 \n","Score: 0.39663265306122447\n","\n","Candidate: 0.999999998837882 \n","Score: 0.396734693877551\n","\n","Candidate: 0.9999999988408557 \n","Score: 0.39683673469387754\n","\n","Candidate: 0.9999999988499673 \n","Score: 0.39693877551020407\n","\n","Candidate: 0.9999999988662803 \n","Score: 0.3970408163265306\n","\n","Candidate: 0.9999999988902705 \n","Score: 0.39714285714285713\n","\n","Candidate: 0.9999999989139323 \n","Score: 0.39714285714285713\n","\n","Candidate: 0.9999999989433075 \n","Score: 0.39714285714285713\n","\n","Candidate: 0.9999999989929877 \n","Score: 0.39724489795918366\n","\n","Candidate: 0.9999999990266738 \n","Score: 0.3973469387755102\n","\n","Candidate: 0.9999999990365456 \n","Score: 0.3974489795918367\n","\n","Candidate: 0.9999999990469843 \n","Score: 0.39755102040816326\n","\n","Candidate: 0.9999999990644528 \n","Score: 0.3976530612244898\n","\n","Candidate: 0.9999999990765334 \n","Score: 0.3977551020408163\n","\n","Candidate: 0.9999999990814513 \n","Score: 0.39785714285714285\n","\n","Candidate: 0.9999999990994082 \n","Score: 0.3979591836734694\n","\n","Candidate: 0.999999999117706 \n","Score: 0.3980612244897959\n","\n","Candidate: 0.9999999991223172 \n","Score: 0.3980612244897959\n","\n","Candidate: 0.9999999991244297 \n","Score: 0.3980612244897959\n","\n","Candidate: 0.9999999991267523 \n","Score: 0.3980612244897959\n","\n","Candidate: 0.9999999991359665 \n","Score: 0.3980612244897959\n","\n","Candidate: 0.999999999165164 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999991959105 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999992139637 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999992374554 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999992690947 \n","Score: 0.3983673469387755\n","\n","Candidate: 0.9999999992949796 \n","Score: 0.3985714285714286\n","\n","Candidate: 0.9999999993187649 \n","Score: 0.3986734693877551\n","\n","Candidate: 0.9999999993352384 \n","Score: 0.3986734693877551\n","\n","Candidate: 0.9999999993510553 \n","Score: 0.3989795918367347\n","\n","Candidate: 0.999999999368596 \n","Score: 0.3989795918367347\n","\n","Candidate: 0.9999999993860509 \n","Score: 0.39908163265306124\n","\n","Candidate: 0.9999999994021957 \n","Score: 0.39918367346938777\n","\n","Candidate: 0.9999999994051982 \n","Score: 0.39918367346938777\n","\n","Candidate: 0.9999999994070672 \n","Score: 0.3992857142857143\n","\n","Candidate: 0.9999999994113059 \n","Score: 0.4005102040816326\n","\n","Candidate: 0.9999999994169233 \n","Score: 0.4005102040816326\n","\n","Candidate: 0.9999999994223494 \n","Score: 0.4006122448979592\n","\n","Candidate: 0.9999999994386612 \n","Score: 0.40071428571428575\n","\n","Candidate: 0.9999999994641898 \n","Score: 0.4008163265306123\n","\n","Candidate: 0.9999999994815996 \n","Score: 0.40091836734693875\n","\n","Candidate: 0.9999999995058926 \n","Score: 0.4011224489795919\n","\n","Candidate: 0.9999999995250098 \n","Score: 0.4011224489795919\n","\n","Candidate: 0.999999999527289 \n","Score: 0.4012244897959184\n","\n","Candidate: 0.9999999995300758 \n","Score: 0.4012244897959184\n","\n","Candidate: 0.9999999995327338 \n","Score: 0.4012244897959184\n","\n","Candidate: 0.999999999541183 \n","Score: 0.40132653061224494\n","\n","Candidate: 0.9999999995483201 \n","Score: 0.40132653061224494\n","\n","Candidate: 0.9999999995584589 \n","Score: 0.40132653061224494\n","\n","Candidate: 0.999999999574462 \n","Score: 0.40142857142857147\n","\n","Candidate: 0.9999999995879671 \n","Score: 0.401530612244898\n","\n","Candidate: 0.999999999596404 \n","Score: 0.40163265306122453\n","\n","Candidate: 0.999999999601112 \n","Score: 0.40163265306122453\n","\n","Candidate: 0.9999999996073714 \n","Score: 0.40173469387755106\n","\n","Candidate: 0.9999999996125633 \n","Score: 0.4018367346938776\n","\n","Candidate: 0.9999999996168107 \n","Score: 0.40204081632653066\n","\n","Candidate: 0.9999999996201878 \n","Score: 0.40204081632653066\n","\n","Candidate: 0.9999999996228877 \n","Score: 0.40214285714285714\n","\n","Candidate: 0.9999999996251232 \n","Score: 0.4022448979591837\n","\n","Candidate: 0.9999999996260824 \n","Score: 0.4023469387755102\n","\n","Candidate: 0.9999999996290216 \n","Score: 0.4024489795918368\n","\n","Candidate: 0.9999999996342839 \n","Score: 0.40255102040816326\n","\n","Candidate: 0.9999999996397249 \n","Score: 0.40265306122448985\n","\n","Candidate: 0.9999999996445078 \n","Score: 0.40265306122448985\n","\n","Candidate: 0.9999999996503959 \n","Score: 0.40265306122448985\n","\n","Candidate: 0.9999999996571673 \n","Score: 0.40265306122448985\n","\n","Candidate: 0.9999999996630531 \n","Score: 0.40265306122448985\n","\n","Candidate: 0.9999999996724518 \n","Score: 0.4027551020408163\n","\n","Candidate: 0.9999999996797957 \n","Score: 0.4029591836734694\n","\n","Candidate: 0.9999999996825013 \n","Score: 0.4029591836734694\n","\n","Candidate: 0.9999999996854463 \n","Score: 0.403061224489796\n","\n","Candidate: 0.9999999996905725 \n","Score: 0.40316326530612245\n","\n","Candidate: 0.9999999996945172 \n","Score: 0.40326530612244904\n","\n","Candidate: 0.9999999996982893 \n","Score: 0.4033673469387755\n","\n","Candidate: 0.9999999997021862 \n","Score: 0.4036734693877551\n","\n","Candidate: 0.999999999703694 \n","Score: 0.40377551020408164\n","\n","Candidate: 0.9999999997094866 \n","Score: 0.4038775510204082\n","\n","Candidate: 0.9999999997158722 \n","Score: 0.4039795918367347\n","\n","Candidate: 0.9999999997187047 \n","Score: 0.40408163265306124\n","\n","Candidate: 0.9999999997248834 \n","Score: 0.40408163265306124\n","\n","Candidate: 0.9999999997416973 \n","Score: 0.40418367346938777\n","\n","Candidate: 0.9999999997550182 \n","Score: 0.4042857142857143\n","\n","Candidate: 0.9999999997595501 \n","Score: 0.4042857142857143\n","\n","Candidate: 0.9999999997634172 \n","Score: 0.40438775510204084\n","\n","Candidate: 0.9999999997690722 \n","Score: 0.40448979591836737\n","\n","Candidate: 0.9999999997741601 \n","Score: 0.40448979591836737\n","\n","Candidate: 0.9999999997839135 \n","Score: 0.40448979591836737\n","\n","Candidate: 0.9999999997943734 \n","Score: 0.40448979591836737\n","\n","Candidate: 0.9999999997956941 \n","Score: 0.4045918367346939\n","\n","Candidate: 0.9999999997974542 \n","Score: 0.4045918367346939\n","\n","Candidate: 0.9999999998036059 \n","Score: 0.4045918367346939\n","\n","Candidate: 0.9999999998087314 \n","Score: 0.40469387755102043\n","\n","Candidate: 0.9999999998118491 \n","Score: 0.40591836734693876\n","\n","Candidate: 0.999999999814899 \n","Score: 0.4060204081632653\n","\n","Candidate: 0.9999999998163955 \n","Score: 0.4060204081632653\n","\n","Candidate: 0.9999999998176357 \n","Score: 0.40622448979591835\n","\n","Candidate: 0.999999999825993 \n","Score: 0.40622448979591835\n","\n","Candidate: 0.9999999998343929 \n","Score: 0.40622448979591835\n","\n","Candidate: 0.999999999834773 \n","Score: 0.4064285714285714\n","\n","Candidate: 0.9999999998366 \n","Score: 0.4064285714285714\n","\n","Candidate: 0.9999999998416842 \n","Score: 0.40653061224489795\n","\n","Candidate: 0.9999999998456839 \n","Score: 0.4066326530612245\n","\n","Candidate: 0.9999999998469562 \n","Score: 0.4066326530612245\n","\n","Candidate: 0.9999999998481455 \n","Score: 0.40683673469387754\n","\n","Candidate: 0.9999999998491874 \n","Score: 0.40683673469387754\n","\n","Candidate: 0.9999999998498499 \n","Score: 0.40683673469387754\n","\n","Candidate: 0.999999999850793 \n","Score: 0.4069387755102041\n","\n","Candidate: 0.9999999998552158 \n","Score: 0.40704081632653066\n","\n","Candidate: 0.9999999998590319 \n","Score: 0.4073469387755102\n","\n","Candidate: 0.9999999998620737 \n","Score: 0.40744897959183674\n","\n","Candidate: 0.9999999998654167 \n","Score: 0.40755102040816327\n","\n","Candidate: 0.9999999998661138 \n","Score: 0.40755102040816327\n","\n","Candidate: 0.9999999998677833 \n","Score: 0.40765306122448985\n","\n","Candidate: 0.9999999998707101 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.9999999998731754 \n","Score: 0.4078571428571429\n","\n","Candidate: 0.999999999874599 \n","Score: 0.4079591836734694\n","\n","Candidate: 0.9999999998765887 \n","Score: 0.408061224489796\n","\n","Candidate: 0.9999999998785231 \n","Score: 0.408061224489796\n","\n","Candidate: 0.9999999998790721 \n","Score: 0.40816326530612246\n","\n","Candidate: 0.9999999998793814 \n","Score: 0.40826530612244905\n","\n","Candidate: 0.9999999998803295 \n","Score: 0.4083673469387755\n","\n","Candidate: 0.999999999882027 \n","Score: 0.40846938775510205\n","\n","Candidate: 0.9999999998830109 \n","Score: 0.4085714285714286\n","\n","Candidate: 0.9999999998857878 \n","Score: 0.4086734693877552\n","\n","Candidate: 0.9999999998895871 \n","Score: 0.4087755102040817\n","\n","Candidate: 0.9999999998909739 \n","Score: 0.4087755102040817\n","\n","Candidate: 0.9999999998917438 \n","Score: 0.4087755102040817\n","\n","Candidate: 0.999999999895212 \n","Score: 0.40887755102040824\n","\n","Candidate: 0.9999999998998036 \n","Score: 0.40897959183673477\n","\n","Candidate: 0.9999999999022097 \n","Score: 0.4090816326530613\n","\n","Candidate: 0.9999999999028891 \n","Score: 0.4091836734693878\n","\n","Candidate: 0.9999999999034916 \n","Score: 0.4091836734693878\n","\n","Candidate: 0.9999999999044173 \n","Score: 0.40928571428571436\n","\n","Candidate: 0.9999999999052426 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.9999999999066709 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.9999999999077143 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.9999999999089844 \n","Score: 0.4094897959183674\n","\n","Candidate: 0.9999999999107365 \n","Score: 0.4094897959183674\n","\n","Candidate: 0.9999999999138 \n","Score: 0.4094897959183674\n","\n","Candidate: 0.9999999999168998 \n","Score: 0.4095918367346939\n","\n","Candidate: 0.9999999999214353 \n","Score: 0.4095918367346939\n","\n","Candidate: 0.9999999999266498 \n","Score: 0.40979591836734697\n","\n","Candidate: 0.9999999999304755 \n","Score: 0.40979591836734697\n","\n","Candidate: 0.9999999999334058 \n","Score: 0.40979591836734697\n","\n","Candidate: 0.9999999999352345 \n","Score: 0.40989795918367355\n","\n","Candidate: 0.9999999999368707 \n","Score: 0.41000000000000003\n","\n","Candidate: 0.9999999999373912 \n","Score: 0.41000000000000003\n","\n","Candidate: 0.9999999999379383 \n","Score: 0.4102040816326531\n","\n","Candidate: 0.9999999999383005 \n","Score: 0.4103061224489796\n","\n","Candidate: 0.9999999999384979 \n","Score: 0.411734693877551\n","\n","Candidate: 0.9999999999389478 \n","Score: 0.411734693877551\n","\n","Candidate: 0.9999999999397561 \n","Score: 0.41183673469387755\n","\n","Candidate: 0.9999999999407065 \n","Score: 0.4119387755102041\n","\n","Candidate: 0.9999999999417206 \n","Score: 0.4119387755102041\n","\n","Candidate: 0.9999999999437361 \n","Score: 0.4122448979591837\n","\n","Candidate: 0.9999999999454385 \n","Score: 0.4123469387755102\n","\n","Candidate: 0.999999999946116 \n","Score: 0.41244897959183674\n","\n","Candidate: 0.9999999999471405 \n","Score: 0.4126530612244898\n","\n","Candidate: 0.9999999999496175 \n","Score: 0.41275510204081634\n","\n","Candidate: 0.9999999999519034 \n","Score: 0.41285714285714287\n","\n","Candidate: 0.9999999999532768 \n","Score: 0.4129591836734694\n","\n","Candidate: 0.9999999999548628 \n","Score: 0.4130612244897959\n","\n","Candidate: 0.9999999999558972 \n","Score: 0.4130612244897959\n","\n","Candidate: 0.9999999999571245 \n","Score: 0.41316326530612246\n","\n","Candidate: 0.9999999999580902 \n","Score: 0.41326530612244894\n","\n","Candidate: 0.9999999999588856 \n","Score: 0.4133673469387755\n","\n","Candidate: 0.9999999999598133 \n","Score: 0.413469387755102\n","\n","Candidate: 0.99999999996022 \n","Score: 0.413469387755102\n","\n","Candidate: 0.9999999999605788 \n","Score: 0.4135714285714286\n","\n","Candidate: 0.9999999999609175 \n","Score: 0.41367346938775507\n","\n","Candidate: 0.9999999999610136 \n","Score: 0.41367346938775507\n","\n","Candidate: 0.9999999999610908 \n","Score: 0.41377551020408165\n","\n","Candidate: 0.999999999961267 \n","Score: 0.41387755102040813\n","\n","Candidate: 0.9999999999615691 \n","Score: 0.41387755102040813\n","\n","Candidate: 0.9999999999619442 \n","Score: 0.41397959183673466\n","\n","Candidate: 0.9999999999630594 \n","Score: 0.4140816326530612\n","\n","Candidate: 0.9999999999646052 \n","Score: 0.4140816326530612\n","\n","Candidate: 0.999999999965518 \n","Score: 0.4307142857142857\n","\n","Candidate: 0.9999999999658573 \n","Score: 0.43081632653061225\n","\n","Candidate: 0.9999999999665368 \n","Score: 0.4309183673469388\n","\n","Candidate: 0.9999999999676785 \n","Score: 0.4310204081632653\n","\n","Candidate: 0.9999999999687614 \n","Score: 0.43112244897959184\n","\n","Candidate: 0.9999999999693723 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.9999999999698628 \n","Score: 0.43142857142857144\n","\n","Candidate: 0.9999999999703905 \n","Score: 0.43153061224489797\n","\n","Candidate: 0.9999999999708692 \n","Score: 0.43153061224489797\n","\n","Candidate: 0.9999999999718411 \n","Score: 0.43163265306122445\n","\n","Candidate: 0.9999999999725524 \n","Score: 0.43173469387755103\n","\n","Candidate: 0.9999999999729641 \n","Score: 0.43173469387755103\n","\n","Candidate: 0.9999999999739027 \n","Score: 0.43173469387755103\n","\n","Candidate: 0.9999999999748497 \n","Score: 0.4319387755102041\n","\n","Candidate: 0.9999999999757674 \n","Score: 0.4320408163265306\n","\n","Candidate: 0.9999999999763549 \n","Score: 0.43214285714285716\n","\n","Candidate: 0.999999999976983 \n","Score: 0.4324489795918367\n","\n","Candidate: 0.9999999999780985 \n","Score: 0.4325510204081633\n","\n","Candidate: 0.9999999999793212 \n","Score: 0.43265306122448977\n","\n","Candidate: 0.9999999999800969 \n","Score: 0.43275510204081635\n","\n","Candidate: 0.9999999999802992 \n","Score: 0.43387755102040815\n","\n","Candidate: 0.9999999999805674 \n","Score: 0.4339795918367346\n","\n","Candidate: 0.9999999999806896 \n","Score: 0.4339795918367346\n","\n","Candidate: 0.9999999999810081 \n","Score: 0.4340816326530612\n","\n","Candidate: 0.9999999999820182 \n","Score: 0.4341836734693877\n","\n","Candidate: 0.9999999999827518 \n","Score: 0.4342857142857143\n","\n","Candidate: 0.9999999999828992 \n","Score: 0.43448979591836734\n","\n","Candidate: 0.9999999999831259 \n","Score: 0.43448979591836734\n","\n","Candidate: 0.9999999999838067 \n","Score: 0.4345918367346938\n","\n","Candidate: 0.9999999999849949 \n","Score: 0.4346938775510204\n","\n","Candidate: 0.9999999999857717 \n","Score: 0.4347959183673469\n","\n","Candidate: 0.9999999999859615 \n","Score: 0.43489795918367347\n","\n","Candidate: 0.9999999999860865 \n","Score: 0.43499999999999994\n","\n","Candidate: 0.9999999999862942 \n","Score: 0.43499999999999994\n","\n","Candidate: 0.9999999999866604 \n","Score: 0.43510204081632653\n","\n","Candidate: 0.9999999999870489 \n","Score: 0.43510204081632653\n","\n","Candidate: 0.9999999999872842 \n","Score: 0.43510204081632653\n","\n","Candidate: 0.9999999999874164 \n","Score: 0.435204081632653\n","\n","Candidate: 0.9999999999874487 \n","Score: 0.43530612244897954\n","\n","Candidate: 0.9999999999874679 \n","Score: 0.43540816326530607\n","\n","Candidate: 0.9999999999874972 \n","Score: 0.4355102040816326\n","\n","Candidate: 0.9999999999875766 \n","Score: 0.43571428571428567\n","\n","Candidate: 0.9999999999876479 \n","Score: 0.4358163265306122\n","\n","Candidate: 0.9999999999877272 \n","Score: 0.43591836734693873\n","\n","Candidate: 0.9999999999879157 \n","Score: 0.43602040816326526\n","\n","Candidate: 0.999999999988145 \n","Score: 0.43612244897959174\n","\n","Candidate: 0.9999999999888267 \n","Score: 0.4362244897959183\n","\n","Candidate: 0.9999999999894834 \n","Score: 0.43632653061224486\n","\n","Candidate: 0.9999999999896116 \n","Score: 0.4365306122448979\n","\n","Candidate: 0.9999999999896834 \n","Score: 0.4365306122448979\n","\n","Candidate: 0.9999999999897373 \n","Score: 0.43663265306122445\n","\n","Candidate: 0.9999999999898015 \n","Score: 0.436734693877551\n","\n","Candidate: 0.9999999999899686 \n","Score: 0.4368367346938775\n","\n","Candidate: 0.9999999999902089 \n","Score: 0.43693877551020405\n","\n","Candidate: 0.9999999999903673 \n","Score: 0.43724489795918364\n","\n","Candidate: 0.9999999999906232 \n","Score: 0.4373469387755101\n","\n","Candidate: 0.9999999999910403 \n","Score: 0.4374489795918367\n","\n","Candidate: 0.999999999991541 \n","Score: 0.4375510204081632\n","\n","Candidate: 0.9999999999919236 \n","Score: 0.43765306122448977\n","\n","Candidate: 0.9999999999921806 \n","Score: 0.43775510204081625\n","\n","Candidate: 0.9999999999924218 \n","Score: 0.43785714285714283\n","\n","Candidate: 0.9999999999927704 \n","Score: 0.4379591836734693\n","\n","Candidate: 0.999999999993097 \n","Score: 0.4379591836734693\n","\n","Candidate: 0.9999999999933535 \n","Score: 0.43806122448979584\n","\n","Candidate: 0.9999999999935797 \n","Score: 0.4381632653061224\n","\n","Candidate: 0.9999999999936677 \n","Score: 0.4392857142857142\n","\n","Candidate: 0.9999999999937585 \n","Score: 0.4392857142857142\n","\n","Candidate: 0.9999999999938226 \n","Score: 0.43938775510204076\n","\n","Candidate: 0.9999999999940694 \n","Score: 0.43938775510204076\n","\n","Candidate: 0.9999999999943572 \n","Score: 0.4394897959183673\n","\n","Candidate: 0.9999999999945023 \n","Score: 0.43969387755102035\n","\n","Candidate: 0.9999999999946023 \n","Score: 0.4397959183673469\n","\n","Candidate: 0.9999999999947202 \n","Score: 0.4397959183673469\n","\n","Candidate: 0.9999999999948423 \n","Score: 0.4398979591836734\n","\n","Candidate: 0.9999999999949254 \n","Score: 0.4401020408163265\n","\n","Candidate: 0.9999999999949996 \n","Score: 0.440204081632653\n","\n","Candidate: 0.9999999999952502 \n","Score: 0.44030612244897954\n","\n","Candidate: 0.9999999999954929 \n","Score: 0.4404081632653061\n","\n","Candidate: 0.9999999999955269 \n","Score: 0.44051020408163255\n","\n","Candidate: 0.9999999999955382 \n","Score: 0.44061224489795914\n","\n","Candidate: 0.9999999999955809 \n","Score: 0.4407142857142856\n","\n","Candidate: 0.9999999999956555 \n","Score: 0.4408163265306122\n","\n","Candidate: 0.9999999999957158 \n","Score: 0.4267346938775509\n","\n","Candidate: 0.9999999999957909 \n","Score: 0.426938775510204\n","\n","Candidate: 0.9999999999958762 \n","Score: 0.4270408163265305\n","\n","Candidate: 0.9999999999959284 \n","Score: 0.4270408163265305\n","\n","Candidate: 0.9999999999959825 \n","Score: 0.42714285714285705\n","\n","Candidate: 0.9999999999960288 \n","Score: 0.4272448979591836\n","\n","Candidate: 0.9999999999960544 \n","Score: 0.4275510204081632\n","\n","Candidate: 0.9999999999961506 \n","Score: 0.4276530612244897\n","\n","Candidate: 0.9999999999962441 \n","Score: 0.42775510204081624\n","\n","Candidate: 0.9999999999962969 \n","Score: 0.4278571428571427\n","\n","Candidate: 0.999999999996353 \n","Score: 0.4279591836734693\n","\n","Candidate: 0.9999999999963909 \n","Score: 0.4280612244897958\n","\n","Candidate: 0.9999999999965732 \n","Score: 0.42816326530612236\n","\n","Candidate: 0.9999999999967317 \n","Score: 0.42826530612244884\n","\n","Candidate: 0.9999999999967686 \n","Score: 0.42836734693877543\n","\n","Candidate: 0.9999999999968371 \n","Score: 0.4284693877551019\n","\n","Candidate: 0.9999999999968718 \n","Score: 0.4284693877551019\n","\n","Candidate: 0.999999999996889 \n","Score: 0.4285714285714285\n","\n","Candidate: 0.9999999999969119 \n","Score: 0.42867346938775497\n","\n","Candidate: 0.9999999999969489 \n","Score: 0.42867346938775497\n","\n","Candidate: 0.9999999999969987 \n","Score: 0.42877551020408156\n","\n","Candidate: 0.9999999999970433 \n","Score: 0.42887755102040803\n","\n","Candidate: 0.9999999999971275 \n","Score: 0.42887755102040803\n","\n","Candidate: 0.9999999999972548 \n","Score: 0.4289795918367346\n","\n","Candidate: 0.9999999999974786 \n","Score: 0.4289795918367346\n","\n","Candidate: 0.9999999999976449 \n","Score: 0.4290816326530611\n","\n","Candidate: 0.9999999999976862 \n","Score: 0.4291836734693877\n","\n","Candidate: 0.9999999999977218 \n","Score: 0.42928571428571416\n","\n","Candidate: 0.9999999999977318 \n","Score: 0.43051020408163254\n","\n","Candidate: 0.999999999997764 \n","Score: 0.43061224489795913\n","\n","Candidate: 0.9999999999978504 \n","Score: 0.4307142857142856\n","\n","Candidate: 0.9999999999979692 \n","Score: 0.43091836734693867\n","\n","Candidate: 0.9999999999980427 \n","Score: 0.43112244897959173\n","\n","Candidate: 0.9999999999981186 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.9999999999981963 \n","Score: 0.4313265306122448\n","\n","Candidate: 0.9999999999982336 \n","Score: 0.43142857142857133\n","\n","Candidate: 0.9999999999982782 \n","Score: 0.4316326530612244\n","\n","Candidate: 0.999999999998308 \n","Score: 0.4317346938775509\n","\n","Candidate: 0.9999999999983322 \n","Score: 0.4317346938775509\n","\n","Candidate: 0.9999999999983653 \n","Score: 0.4317346938775509\n","\n","Candidate: 0.9999999999983855 \n","Score: 0.4320408163265305\n","\n","Candidate: 0.9999999999984168 \n","Score: 0.43214285714285705\n","\n","Candidate: 0.9999999999984502 \n","Score: 0.43224489795918364\n","\n","Candidate: 0.9999999999984603 \n","Score: 0.4323469387755101\n","\n","Candidate: 0.9999999999984657 \n","Score: 0.4324489795918367\n","\n","Candidate: 0.9999999999985005 \n","Score: 0.4325510204081632\n","\n","Candidate: 0.9999999999985341 \n","Score: 0.4325510204081632\n","\n","Candidate: 0.9999999999985447 \n","Score: 0.4326530612244897\n","\n","Candidate: 0.9999999999985593 \n","Score: 0.43275510204081624\n","\n","Candidate: 0.9999999999985685 \n","Score: 0.4499999999999999\n","\n","Candidate: 0.9999999999985769 \n","Score: 0.45010204081632643\n","\n","Candidate: 0.9999999999985829 \n","Score: 0.45020408163265296\n","\n","Candidate: 0.9999999999985949 \n","Score: 0.4503061224489795\n","\n","Candidate: 0.999999999998633 \n","Score: 0.450408163265306\n","\n","Candidate: 0.9999999999986819 \n","Score: 0.45051020408163256\n","\n","Candidate: 0.9999999999987048 \n","Score: 0.4506122448979591\n","\n","Candidate: 0.9999999999987141 \n","Score: 0.4506122448979591\n","\n","Candidate: 0.9999999999987305 \n","Score: 0.4507142857142856\n","\n","Candidate: 0.9999999999987434 \n","Score: 0.4507142857142856\n","\n","Candidate: 0.9999999999988061 \n","Score: 0.45081632653061215\n","\n","Candidate: 0.9999999999988838 \n","Score: 0.4509183673469387\n","\n","Candidate: 0.9999999999989089 \n","Score: 0.4510204081632652\n","\n","Candidate: 0.9999999999989422 \n","Score: 0.45112244897959175\n","\n","Candidate: 0.9999999999989699 \n","Score: 0.45275510204081626\n","\n","Candidate: 0.999999999998976 \n","Score: 0.45285714285714274\n","\n","Candidate: 0.9999999999989984 \n","Score: 0.4529591836734693\n","\n","Candidate: 0.9999999999990535 \n","Score: 0.4530612244897958\n","\n","Candidate: 0.9999999999990943 \n","Score: 0.45326530612244886\n","\n","Candidate: 0.9999999999991065 \n","Score: 0.45336734693877545\n","\n","Candidate: 0.9999999999991169 \n","Score: 0.45336734693877545\n","\n","Candidate: 0.9999999999991616 \n","Score: 0.45336734693877545\n","\n","Candidate: 0.9999999999992089 \n","Score: 0.4534693877551019\n","\n","Candidate: 0.9999999999992144 \n","Score: 0.4535714285714285\n","\n","Candidate: 0.9999999999992272 \n","Score: 0.4545918367346938\n","\n","Candidate: 0.9999999999992399 \n","Score: 0.4546938775510203\n","\n","Candidate: 0.9999999999992514 \n","Score: 0.4548979591836734\n","\n","Candidate: 0.9999999999992788 \n","Score: 0.45499999999999985\n","\n","Candidate: 0.9999999999993027 \n","Score: 0.45530612244897944\n","\n","Candidate: 0.9999999999993134 \n","Score: 0.455408163265306\n","\n","Candidate: 0.9999999999993191 \n","Score: 0.4555102040816325\n","\n","Candidate: 0.999999999999327 \n","Score: 0.45571428571428557\n","\n","Candidate: 0.9999999999993481 \n","Score: 0.4558163265306121\n","\n","Candidate: 0.9999999999993726 \n","Score: 0.4559183673469386\n","\n","Candidate: 0.9999999999993829 \n","Score: 0.45602040816326517\n","\n","Candidate: 0.9999999999994009 \n","Score: 0.4561224489795917\n","\n","Candidate: 0.9999999999994262 \n","Score: 0.45622448979591823\n","\n","Candidate: 0.9999999999994355 \n","Score: 0.45632653061224476\n","\n","Candidate: 0.9999999999994403 \n","Score: 0.4564285714285713\n","\n","Candidate: 0.9999999999994442 \n","Score: 0.4565306122448978\n","\n","Candidate: 0.9999999999994529 \n","Score: 0.45663265306122436\n","\n","Candidate: 0.9999999999994622 \n","Score: 0.4567346938775509\n","\n","Candidate: 0.9999999999994879 \n","Score: 0.4568367346938774\n","\n","Candidate: 0.9999999999995144 \n","Score: 0.4569387755102039\n","\n","Candidate: 0.9999999999995175 \n","Score: 0.4570408163265305\n","\n","Candidate: 0.9999999999995213 \n","Score: 0.45714285714285696\n","\n","Candidate: 0.9999999999995322 \n","Score: 0.4572448979591835\n","\n","Candidate: 0.999999999999541 \n","Score: 0.45734693877551\n","\n","Candidate: 0.9999999999995421 \n","Score: 0.458673469387755\n","\n","Candidate: 0.9999999999995497 \n","Score: 0.458673469387755\n","\n","Candidate: 0.9999999999995579 \n","Score: 0.4587755102040815\n","\n","Candidate: 0.9999999999995615 \n","Score: 0.4587755102040815\n","\n","Candidate: 0.9999999999995716 \n","Score: 0.4587755102040815\n","\n","Candidate: 0.9999999999995883 \n","Score: 0.45887755102040806\n","\n","Candidate: 0.9999999999996012 \n","Score: 0.4589795918367346\n","\n","Candidate: 0.9999999999996069 \n","Score: 0.4591836734693876\n","\n","Candidate: 0.9999999999996151 \n","Score: 0.4592857142857142\n","\n","Candidate: 0.9999999999996378 \n","Score: 0.45938775510204066\n","\n","Candidate: 0.9999999999996544 \n","Score: 0.45948979591836725\n","\n","Candidate: 0.9999999999996567 \n","Score: 0.4595918367346937\n","\n","Candidate: 0.9999999999996627 \n","Score: 0.4596938775510203\n","\n","Candidate: 0.9999999999996683 \n","Score: 0.4597959183673468\n","\n","Candidate: 0.9999999999996745 \n","Score: 0.45999999999999985\n","\n","Candidate: 0.9999999999996865 \n","Score: 0.46010204081632644\n","\n","Candidate: 0.9999999999997021 \n","Score: 0.460408163265306\n","\n","Candidate: 0.9999999999997108 \n","Score: 0.4605102040816325\n","\n","Candidate: 0.999999999999712 \n","Score: 0.46061224489795904\n","\n","Candidate: 0.9999999999997167 \n","Score: 0.4616326530612244\n","\n","Candidate: 0.9999999999997218 \n","Score: 0.46173469387755095\n","\n","Candidate: 0.999999999999735 \n","Score: 0.4618367346938775\n","\n","Candidate: 0.9999999999997473 \n","Score: 0.461938775510204\n","\n","Candidate: 0.9999999999997486 \n","Score: 0.46204081632653055\n","\n","Candidate: 0.9999999999997503 \n","Score: 0.4621428571428571\n","\n","Candidate: 0.9999999999997544 \n","Score: 0.46234693877551014\n","\n","Candidate: 0.9999999999997647 \n","Score: 0.46244897959183673\n","\n","Candidate: 0.9999999999997726 \n","Score: 0.46244897959183673\n","\n","Candidate: 0.9999999999997806 \n","Score: 0.4625510204081632\n","\n","Candidate: 0.9999999999997917 \n","Score: 0.4625510204081632\n","\n","Candidate: 0.9999999999997998 \n","Score: 0.46265306122448974\n","\n","Candidate: 0.9999999999998053 \n","Score: 0.46275510204081627\n","\n","Candidate: 0.9999999999998106 \n","Score: 0.46285714285714286\n","\n","Candidate: 0.9999999999998153 \n","Score: 0.4629591836734694\n","\n","Candidate: 0.9999999999998167 \n","Score: 0.4630612244897959\n","\n","Candidate: 0.999999999999819 \n","Score: 0.46316326530612245\n","\n","Candidate: 0.9999999999998224 \n","Score: 0.463265306122449\n","\n","Candidate: 0.9999999999998243 \n","Score: 0.4633673469387755\n","\n","Candidate: 0.9999999999998266 \n","Score: 0.46346938775510205\n","\n","Candidate: 0.9999999999998302 \n","Score: 0.4636734693877551\n","\n","Candidate: 0.9999999999998328 \n","Score: 0.46377551020408164\n","\n","Candidate: 0.9999999999998339 \n","Score: 0.4638775510204082\n","\n","Candidate: 0.9999999999998375 \n","Score: 0.4639795918367347\n","\n","Candidate: 0.9999999999998446 \n","Score: 0.46408163265306124\n","\n","Candidate: 0.9999999999998528 \n","Score: 0.46408163265306124\n","\n","Candidate: 0.9999999999998578 \n","Score: 0.4643877551020409\n","\n","Candidate: 0.9999999999998597 \n","Score: 0.46448979591836737\n","\n","Candidate: 0.9999999999998608 \n","Score: 0.46459183673469395\n","\n","Candidate: 0.9999999999998624 \n","Score: 0.46469387755102043\n","\n","Candidate: 0.9999999999998654 \n","Score: 0.464795918367347\n","\n","Candidate: 0.9999999999998705 \n","Score: 0.46510204081632656\n","\n","Candidate: 0.9999999999998745 \n","Score: 0.46520408163265314\n","\n","Candidate: 0.9999999999998772 \n","Score: 0.4653061224489797\n","\n","Candidate: 0.9999999999998845 \n","Score: 0.4654081632653062\n","\n","Candidate: 0.9999999999998899 \n","Score: 0.4654081632653062\n","\n","Candidate: 0.9999999999998901 \n","Score: 0.4654081632653062\n","\n","Candidate: 0.9999999999998925 \n","Score: 0.46561224489795927\n","\n","Candidate: 0.9999999999998961 \n","Score: 0.46571428571428586\n","\n","Candidate: 0.9999999999998987 \n","Score: 0.46581632653061233\n","\n","Candidate: 0.999999999999901 \n","Score: 0.46591836734693887\n","\n","Candidate: 0.9999999999999071 \n","Score: 0.4660204081632654\n","\n","Candidate: 0.9999999999999135 \n","Score: 0.46612244897959193\n","\n","Candidate: 0.9999999999999147 \n","Score: 0.46622448979591846\n","\n","Candidate: 0.9999999999999155 \n","Score: 0.4672448979591837\n","\n","Candidate: 0.9999999999999163 \n","Score: 0.46734693877551026\n","\n","Candidate: 0.9999999999999167 \n","Score: 0.4674489795918368\n","\n","Candidate: 0.9999999999999192 \n","Score: 0.4675510204081633\n","\n","Candidate: 0.9999999999999232 \n","Score: 0.46765306122448985\n","\n","Candidate: 0.9999999999999257 \n","Score: 0.4683673469387756\n","\n","Candidate: 0.9999999999999296 \n","Score: 0.46857142857142864\n","\n","Candidate: 0.9999999999999354 \n","Score: 0.46867346938775517\n","\n","Candidate: 0.9999999999999385 \n","Score: 0.4688775510204082\n","\n","Candidate: 0.9999999999999394 \n","Score: 0.46897959183673477\n","\n","Candidate: 0.9999999999999396 \n","Score: 0.46897959183673477\n","\n","Candidate: 0.9999999999999407 \n","Score: 0.45802083333333343\n","\n","Candidate: 0.9999999999999419 \n","Score: 0.458125\n","\n","Candidate: 0.9999999999999437 \n","Score: 0.45843750000000005\n","\n","Candidate: 0.9999999999999459 \n","Score: 0.45854166666666674\n","\n","Candidate: 0.9999999999999468 \n","Score: 0.4586458333333334\n","\n","Candidate: 0.9999999999999472 \n","Score: 0.45875\n","\n","Candidate: 0.9999999999999474 \n","Score: 0.4588541666666667\n","\n","Candidate: 0.9999999999999476 \n","Score: 0.45895833333333336\n","\n","Candidate: 0.9999999999999489 \n","Score: 0.4591666666666667\n","\n","Candidate: 0.9999999999999505 \n","Score: 0.4592708333333334\n","\n","Candidate: 0.9999999999999514 \n","Score: 0.459375\n","\n","Candidate: 0.9999999999999525 \n","Score: 0.45947916666666666\n","\n","Candidate: 0.9999999999999535 \n","Score: 0.45958333333333334\n","\n","Candidate: 0.9999999999999558 \n","Score: 0.4596875\n","\n","Candidate: 0.9999999999999578 \n","Score: 0.4597916666666667\n","\n","Candidate: 0.9999999999999583 \n","Score: 0.4598958333333334\n","\n","Candidate: 0.9999999999999585 \n","Score: 0.4600000000000001\n","\n","Candidate: 0.9999999999999593 \n","Score: 0.46010416666666676\n","\n","Candidate: 0.9999999999999598 \n","Score: 0.46020833333333333\n","\n","Candidate: 0.9999999999999603 \n","Score: 0.4603125\n","\n","Candidate: 0.999999999999962 \n","Score: 0.4604166666666667\n","\n","Candidate: 0.9999999999999656 \n","Score: 0.4605208333333334\n","\n","Candidate: 0.999999999999968 \n","Score: 0.46062500000000006\n","\n","Candidate: 0.9999999999999705 \n","Score: 0.46072916666666675\n","\n","Candidate: 0.9999999999999725 \n","Score: 0.46083333333333343\n","\n","Candidate: 0.9999999999999728 \n","Score: 0.4609375\n","\n","Candidate: 0.9999999999999732 \n","Score: 0.46114583333333337\n","\n","Candidate: 0.9999999999999741 \n","Score: 0.46125000000000005\n","\n","Candidate: 0.9999999999999747 \n","Score: 0.46125000000000005\n","\n","Candidate: 0.9999999999999749 \n","Score: 0.4627083333333334\n","\n","Candidate: 0.9999999999999751 \n","Score: 0.46281250000000007\n","\n","Candidate: 0.9999999999999758 \n","Score: 0.46291666666666675\n","\n","Candidate: 0.9999999999999767 \n","Score: 0.46302083333333344\n","\n","Candidate: 0.9999999999999777 \n","Score: 0.4631250000000001\n","\n","Candidate: 0.9999999999999785 \n","Score: 0.4633333333333334\n","\n","Candidate: 0.9999999999999789 \n","Score: 0.46343750000000006\n","\n","Candidate: 0.9999999999999791 \n","Score: 0.46343750000000006\n","\n","Candidate: 0.9999999999999796 \n","Score: 0.4636458333333334\n","\n","Candidate: 0.99999999999998 \n","Score: 0.4636458333333334\n","\n","Candidate: 0.9999999999999811 \n","Score: 0.4639583333333335\n","\n","Candidate: 0.9999999999999825 \n","Score: 0.46406250000000004\n","\n","Candidate: 0.9999999999999836 \n","Score: 0.4641666666666667\n","\n","Candidate: 0.9999999999999845 \n","Score: 0.4642708333333334\n","\n","Candidate: 0.9999999999999848 \n","Score: 0.4643750000000001\n","\n","Candidate: 0.9999999999999851 \n","Score: 0.4643750000000001\n","\n","Candidate: 0.9999999999999853 \n","Score: 0.46458333333333335\n","\n","Candidate: 0.9999999999999857 \n","Score: 0.46468750000000003\n","\n","Candidate: 0.9999999999999861 \n","Score: 0.4647916666666667\n","\n","Candidate: 0.9999999999999862 \n","Score: 0.4647916666666667\n","\n","Candidate: 0.9999999999999865 \n","Score: 0.4650000000000001\n","\n","Candidate: 0.9999999999999871 \n","Score: 0.46510416666666676\n","\n","Candidate: 0.9999999999999876 \n","Score: 0.4653125\n","\n","Candidate: 0.9999999999999877 \n","Score: 0.4654166666666667\n","\n","Candidate: 0.9999999999999879 \n","Score: 0.4655208333333334\n","\n","Candidate: 0.9999999999999882 \n","Score: 0.46562500000000007\n","\n","Candidate: 0.9999999999999887 \n","Score: 0.46572916666666675\n","\n","Candidate: 0.9999999999999889 \n","Score: 0.46583333333333343\n","\n","Candidate: 0.9999999999999891 \n","Score: 0.4660416666666667\n","\n","Candidate: 0.9999999999999895 \n","Score: 0.46625000000000005\n","\n","Candidate: 0.99999999999999 \n","Score: 0.4665625000000001\n","\n","Candidate: 0.9999999999999905 \n","Score: 0.46677083333333347\n","\n","Candidate: 0.9999999999999911 \n","Score: 0.46687500000000004\n","\n","Candidate: 0.9999999999999917 \n","Score: 0.4669791666666667\n","\n","Candidate: 0.9999999999999922 \n","Score: 0.4670833333333334\n","\n","Candidate: 0.9999999999999925 \n","Score: 0.4670833333333334\n","\n","Candidate: 0.9999999999999927 \n","Score: 0.4682291666666667\n","\n","Candidate: 0.999999999999993 \n","Score: 0.4683333333333334\n","\n","Candidate: 0.9999999999999933 \n","Score: 0.46843750000000006\n","\n","Candidate: 0.9999999999999936 \n","Score: 0.46163043478260873\n","\n","Candidate: 0.9999999999999938 \n","Score: 0.4619565217391305\n","\n","Candidate: 0.999999999999994 \n","Score: 0.46206521739130435\n","\n","Candidate: 0.9999999999999942 \n","Score: 0.4622826086956522\n","\n","Candidate: 0.9999999999999944 \n","Score: 0.4625\n","\n","Candidate: 0.9999999999999947 \n","Score: 0.46260869565217394\n","\n","Candidate: 0.9999999999999948 \n","Score: 0.46271739130434786\n","\n","Candidate: 0.9999999999999951 \n","Score: 0.4628260869565218\n","\n","Candidate: 0.9999999999999953 \n","Score: 0.46304347826086956\n","\n","Candidate: 0.9999999999999956 \n","Score: 0.46336956521739137\n","\n","Candidate: 0.9999999999999958 \n","Score: 0.4639130434782609\n","\n","Candidate: 0.999999999999996 \n","Score: 0.46413043478260874\n","\n","Candidate: 0.9999999999999961 \n","Score: 0.46423913043478265\n","\n","Candidate: 0.9999999999999962 \n","Score: 0.46423913043478265\n","\n","Candidate: 0.9999999999999964 \n","Score: 0.4647826086956522\n","\n","Candidate: 0.9999999999999967 \n","Score: 0.465\n","\n","Candidate: 0.9999999999999969 \n","Score: 0.46510869565217394\n","\n","Candidate: 0.9999999999999971 \n","Score: 0.4655434782608696\n","\n","Candidate: 0.9999999999999974 \n","Score: 0.44967391304347826\n","\n","Candidate: 0.9999999999999978 \n","Score: 0.4498913043478261\n","\n","Candidate: 0.999999999999998 \n","Score: 0.45163043478260867\n","\n","Candidate: 0.9999999999999982 \n","Score: 0.45217391304347826\n","\n","Candidate: 0.9999999999999984 \n","Score: 0.4527173913043478\n","\n","Candidate: 0.9999999999999987 \n","Score: 0.4532608695652174\n","\n","Candidate: 0.9999999999999988 \n","Score: 0.45391304347826084\n","\n","Candidate: 0.9999999999999989 \n","Score: 0.45391304347826084\n","\n","Candidate: 0.9999999999999991 \n","Score: 0.4552173913043478\n","\n","Candidate: 0.9999999999999993 \n","Score: 0.4605555555555555\n","\n","Candidate: 0.9999999999999996 \n","Score: 0.4697727272727272\n","\n","Candidate: 0.9999999999999998 \n","Score: 0.4647619047619047\n","\n","Candidate: 1.0 \n","Score: 0.46587499999999993\n","\n"]}]},{"cell_type":"code","source":["# aim is to minimise cost function -- find index in array where this is the case\n","lowest_cf_score = np.min(np.array(cost_function_values))\n","index_best_th = np.argmin(np.array(cost_function_values))"],"metadata":{"id":"P2IsLZXQ77oZ","executionInfo":{"status":"ok","timestamp":1651153935745,"user_tz":-60,"elapsed":12,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":488,"outputs":[]},{"cell_type":"code","source":["lowest_cf_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iZ3ba0jhY0I","executionInfo":{"status":"ok","timestamp":1651153936104,"user_tz":-60,"elapsed":370,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"d74f26f4-ff6a-4940-f545-5e46f8af19cc"},"execution_count":489,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3120408163265307"]},"metadata":{},"execution_count":489}]},{"cell_type":"code","source":["index_best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBS0v3GAh77m","executionInfo":{"status":"ok","timestamp":1651153936105,"user_tz":-60,"elapsed":10,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8c704b10-0e84-41e6-ecd9-d3ab890b0a66"},"execution_count":490,"outputs":[{"output_type":"execute_result","data":{"text/plain":["207"]},"metadata":{},"execution_count":490}]},{"cell_type":"code","source":["best_th = list(threshold_candidates)[index_best_th]\n","best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmy0bv8N8YvW","executionInfo":{"status":"ok","timestamp":1651153936141,"user_tz":-60,"elapsed":42,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"707e5d5d-7e9e-4554-b703-e3fe51a8c209"},"execution_count":491,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9999665980756669"]},"metadata":{},"execution_count":491}]},{"cell_type":"markdown","source":["#### Testing with best threshold"],"metadata":{"id":"ypFTpLSAir09"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions excluding the current test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # count inconclusive results\n","  inconc_count = 0\n","  \n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    for i in range(len(predictions)):\n","\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","    \n","      if(c >= best_th ): # best confidence threshold from cost function\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","\n","        earliness.append(time_index/timestamps[-1])\n","\n","        if(pred == 1.0):\n","          print(f\"TTP: {time_to_result + 30}s\")\n","\n","        break\n","\n","      if(i == len(predictions)-1):\n","        print(\"Inconclusive\")\n","        inconc_count += 1\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","  print(f\"Average Earliness: {sum(earliness)/len(earliness)}\")\n","  print(f\"Total Inconclusive: {inconc_count}/{sample_idx}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfPwqWWHiqnY","executionInfo":{"status":"ok","timestamp":1651153944123,"user_tz":-60,"elapsed":4360,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"1852d2a7-8c88-4599-ae82-8cc12d19307d"},"execution_count":492,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_86_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 298.0s\n","\n","Sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 286.0s\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 341.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 325.0s\n","\n","Sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 345.0s\n","\n","Sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 298.0s\n","\n","Sample exp_40_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 301.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 297.0s\n","\n","Sample exp_134_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_97_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 289.0s\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 290.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 293.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 298.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 306.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 296.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 315.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 298.0s\n","\n","Sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 330.0s\n","\n","Sample rv1y_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 358.0s\n","\n","Sample rv1y_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 300.0s\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 305.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 425.0s\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 286.0s\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 294.0s\n","\n","Sample b5\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 325s\n","\n","Sample exp_129_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_165_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_35_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 306s\n","\n","Sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 309s\n","\n","Sample exp_40_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_97_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_2d1_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 290s\n","\n","Sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 293s\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 300.0s\n","\n","Sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 305.0s\n","\n","Sample yap1n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 292.0s\n","\n","Sample arv72\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 288.0s\n","\n","Sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 304.0s\n","\n","Sample arv7\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 305.0s\n","\n","Accuracy: 0.673469387755102\n","Sensitivity/Recall: 0.8214285714285714\n","Specificity: 0.47619047619047616\n","Precision: 0.6764705882352942\n","F1 Score: 0.7419354838709677\n","Average Earliness: 0.26857142857142874\n","Total Inconclusive: 0/49\n"]}]},{"cell_type":"markdown","source":["#### Testing with different alpha values"],"metadata":{"id":"w43_TkUVitvi"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651149640811,"user_tz":-60,"elapsed":432,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"pJXWD05RjB-g"},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"NSkTWcddjB-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981439090,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"f742fd4d-fa2c-4f24-c18f-ffde40f1d377","id":"KWOXfxRKjB-i"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"NXrd_74JjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"wcE9LintjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"qb9FWSPgjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are mad of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"bM7ILJSwjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981450827,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"23bf8873-4159-42ca-fc01-82fcb7e27198","id":"36WDfG-TjB-l"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1184"]},"metadata":{},"execution_count":497}]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  acc = []\n","  ear = []\n","\n","  for i in range(0,100,5):\n","\n","    # alpha\n","    alpha = i/100\n","\n","    print(f\"Alpha: {alpha}\")\n","\n","    # array to hold cost function value for each candidate\n","    cost_function_values = []\n","\n","    # create nN predictions using each dataset as the test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # evaluate every candidate\n","    for th in threshold_candidates:\n","\n","      # print(f\"Candidate: {th} \")\n","\n","      # array to hold earliness values for the samples \n","      earliness = []  \n","\n","      # dict to hold predictions vs true values for the samples  \n","      final_classifications = {}\n","\n","      # sample index\n","      sample_idx = 0\n","\n","      for key, value in all_samples.items():\n","        test_sample_name = key\n","        test_sample = value\n","  \n","        # get KNN predicition for the sample\n","        predictions = sample_predictions[sample_idx]\n","\n","        for i in range(len(predictions)):\n","\n","          # get the confidence for that prediction \n","          c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","          if(c >= th): # check if confidence is above confidence threshold\n","\n","            time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","            time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","            # predicted class for the sample is given by the prediction which led to the gien confidence value\n","            pred = predictions[i]\n","\n","            # update final outcomes dict\n","            final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","            # add to earliness array\n","            earliness.append(time_index/timestamps[-1])\n","\n","            break\n","        sample_idx += 1\n","\n","      # get avg accuracy and avg earliness for this threshold\n","      if(len(final_classifications) > 0):\n","        avg_accuracy = accuracy(final_classifications)\n","        avg_earliness = sum(earliness)/len(earliness)\n","\n","        # compute value of cost function and add to array \n","        cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","        cost_function_values.append(cf_score)\n","\n","    index_best_th = np.argmin(np.array(cost_function_values))    \n","    best_th = list(threshold_candidates)[index_best_th]\n","\n","###########################################################################################################\n","\n","    ## teating with best th\n","    final_classifications = {}\n","    earliness = []\n","\n","    # create nN predictions excluding the current test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    # count inconclusive results\n","    inconc_count = 0\n","    \n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      \n","        if(c >= best_th): # best confidence threshold from cost function\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          pred = predictions[i]\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","          earliness.append(time_index/timestamps[-1])\n","          break\n","\n","        if(i == len(predictions)-1):\n","          inconc_count += 1\n","      \n","      sample_idx += 1\n","\n","    print(f\"Avg Accuracy: {accuracy(final_classifications)}\")\n","    print(f\"Avg Earliness: {sum(earliness)/len(earliness)}\")\n","    print(\"\")\n","    acc.append(accuracy(final_classifications))\n","    ear.append(sum(earliness)/len(earliness))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"V6Fhz4hsiui6","executionInfo":{"status":"error","timestamp":1650981574100,"user_tz":-60,"elapsed":121427,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"5e8c4f9a-49b2-44fb-eed4-3494af98bb4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Alpha: 0.0\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.05\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.1\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.15\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-498-89cc9171be6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# create nN predictions excluding the current test sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0msample_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_predictions_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# create multipliers for every classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-66-ab459af536aa>\u001b[0m in \u001b[0;36mgenerate_predictions_table\u001b[0;34m(positives, negatives, timestamps)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_sample_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-100-5619c2d01103>\u001b[0m in \u001b[0;36mget_training_data_knn\u001b[0;34m(positive_samples, negative_samples, timestamp, test_samples)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m## truncate sample to length t = timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpos_subsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Average Output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## append subsample of length t to training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m             \u001b[0;31m# shortcut if the key is in columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3424\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3425\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4538\u001b[0m         \"\"\"\n\u001b[1;32m   4539\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = acc\n","y = ear\n","axes.set_xlabel(\"Accuracy\")\n","axes.set_ylabel(\"Earliness\")\n","axes.plot(x,y, '-o')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"R0a7Bbrabp6R","executionInfo":{"status":"ok","timestamp":1650975154308,"user_tz":-60,"elapsed":485,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"ecaa763d-1bfa-4fdc-9a86-c2e35604c565"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f4beae35050>]"]},"metadata":{},"execution_count":347},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"simepEdKIiL0"},"source":["### Github Commands"]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"YdlGDV3AzZ1L","executionInfo":{"status":"ok","timestamp":1651154122180,"user_tz":-60,"elapsed":245,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"262f3514-72ba-4d8c-d6a9-db20af750e8b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":493,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itbAqo9qGukN","outputId":"8b7cde65-3b40-406d-b58f-70d2a4fc00da"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project\n"]}],"source":["username = \"adityag16\"\n","git_token = \"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\"\n","repository = \"/content/drive/MyDrive/Final-Year-Project\"\n","%cd {repository}\n","!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNInxPqdG7nx"},"outputs":[],"source":["!git add 'Early Time Series Classification - Average Ouput.ipynb' 'Best Performances.docx'\n","!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1tS6nonHF9u"},"outputs":[],"source":["!git config --global user.email \"aditya.gupta18@imperial.ac.uk\"\n","!git config --global user.name \"adityag16\"\n","\n","!git commit -m \"Remove normalisation + remove 3 negatives that are very anomalous\"\n","!git push origin main"]},{"cell_type":"code","source":[""],"metadata":{"id":"8KO_iVTj0cIP"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Early Time Series Classification - Average Ouput.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1WYaF_HRa3IGG6auTN3SvWNlJMYRlk-43","authorship_tag":"ABX9TyNyXpnaDo+mlLefxvtbRAyO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Connect Drive"],"metadata":{"id":"XVaAULW6qhh1"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11093,"status":"ok","timestamp":1651139795448,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"_DdiqzlkZMhe","outputId":"e16b92cc-d80a-47b9-834a-ab419adab45c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"markdown","metadata":{"id":"ttpluWU4tHLq"},"source":["### Package Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Z_3NHgGwZIsI","executionInfo":{"status":"ok","timestamp":1651139802251,"user_tz":-60,"elapsed":6807,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.signal import savgol_filter\n","from collections import Counter\n","import copy\n","from collections import defaultdict"]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from scipy.spatial import distance\n","from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances"],"metadata":{"id":"5vMvjgqYCd2d","executionInfo":{"status":"ok","timestamp":1651139802577,"user_tz":-60,"elapsed":332,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### GPU Device"],"metadata":{"id":"6cosBM9Jd74f"}},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kElpooT1fLzz","executionInfo":{"status":"ok","timestamp":1651139808432,"user_tz":-60,"elapsed":5867,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"1c435ce7-e9c6-48f9-b50d-d3a8acd91676"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-9880cc6b-0f02-2a6a-77fd-ef32240c42b6)\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1651139808433,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"bLu_lZGKu9dp","outputId":"cfc4cc4b-f9a4-427c-cde8-c66992b9bbf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["gpu = tf.test.gpu_device_name()\n","print(gpu)"]},{"cell_type":"markdown","metadata":{"id":"ihJkU1v2STVo"},"source":["### Pre-Processing Helper Functions"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"W1YMbu9bSW5m","executionInfo":{"status":"ok","timestamp":1651139808433,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vref(X, v_thresh=70):\n","    '''\n","    Identifies active pixels by checking if one of the first 10 derivatives d(i) is > v_thresh\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_thresh : int, optional\n","        Minimum value of the derivative d(i)=X(i+1)-X(i) in mV. Default is 70\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if, during the first 10 samples,\n","        one of the derivatives is > v_thresh. The derivatives are calculated as d(i) = X(i+1)-X(i)\n","    '''\n","    return (np.diff(X[:10, :], axis=0) > v_thresh).any(axis=0)  # check if one of the first 10 derivatives is >v_thresh"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"XjXkAhKwSgFB","executionInfo":{"status":"ok","timestamp":1651139808433,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vrange(X, v_range=(100, 900)):\n","    '''\n","    Identifies active pixels by checking that all the values are in v_range\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_range : (int, int), optional\n","        tuple containing the minimum and maximum allowable voltage in mV. Default is (100, 900)\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if the value is always in v_range\n","    '''\n","    return (X < v_range[1]).all(axis=0) & (X > v_range[0]).all(axis=0)  # for each pixel, check if all the values are\n","    # within the given range\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"G5a7Uqi9Skg_","executionInfo":{"status":"ok","timestamp":1651139808434,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_derivative(X, vthresh=5):\n","    \"\"\" Identifies active pixels by checking that the absolute value of the derivative is always below vthresh\n","    Parameters\n","    ----------\n","    X : ndarray\n","        input 2D array of shape TxNM\n","    vthresh : int\n","        threshold for active pixels. Default is 5\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if all the derivatives are below vthresh\n","    \"\"\"\n","    x_diff = np.abs(np.diff(X, axis=0))\n","    return (x_diff < vthresh).all(axis=0)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XUOV5CRYflUO","executionInfo":{"status":"ok","timestamp":1651139808434,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # set pixel values to 0/nan\n","  for idx, col in enumerate(df.columns):\n","    if(not active[idx]):\n","      df.loc[:, col] = 0\n","\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_drop(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"DhuoGbbPutKZ","executionInfo":{"status":"ok","timestamp":1651139808435,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"ZZJkYzPiVvd6","executionInfo":{"status":"ok","timestamp":1651139808435,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels_deriv(df, v_thresh_deriv=5): \n","  active = filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # for idx, col in enumerate(df.columns):\n","  #   if(not active[idx]):\n","  #     df.loc[:, col] = 0\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_range(df, v_range=(100, 900)):\n","  active = filter_by_vrange(df.values, v_range)\n","\n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"imVXR8eVUrby","executionInfo":{"status":"ok","timestamp":1651139808435,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def reshape_data(df, rows, cols):\n","  X = df.values #pandas.DataFrame.values: Return a Numpy representation of the DataFrame.\n","  X = X.reshape(-1, rows, cols, order='F') #or C. different reshaping row by row or column by column but this works\n","  return X"],"metadata":{"id":"RTF9Vh78MZSB","executionInfo":{"status":"ok","timestamp":1651139809264,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def filter_chemical_pixels(df, arr_rows, arr_cols):\n","  X = reshape_data(df, arr_rows, arr_cols) # reshape data to T x 78 x 56\n","  X_mean = np.mean(X, axis=0) # get mean to have 78 x 56 shape\n","  X_mean[1::3, 1::3] = np.nan # set temperature pixels to nan\n","  X_mean = X_mean.flatten('F') # restore shape to 4068 \n","\n","  active_chemical = ~(np.isnan(X_mean)) # get bool array of all chemical pixels\n","\n","  # drop pixels \n","  df = df.loc[: , active_chemical]\n","  return df\n"],"metadata":{"id":"D9Xt8X4zL7hc","executionInfo":{"status":"ok","timestamp":1651139809265,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"o82EQTYe9euH","executionInfo":{"status":"ok","timestamp":1651139809265,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def time_to_index(times, time_vect):\n","    '''\n","    Returns index of the times closest to the desired ones time_vect\n","    Arguments\n","    ---------\n","    times : list\n","        list of integers containing the desired times\n","    time_vect : nparray\n","        array of the times at which the values are sampled\n","    Returns\n","    -------\n","    list\n","        for each element in the input list times, return an element in the output list\n","        with the index of the sample closest to the desired time\n","    '''\n","    indices = []\n","    for time in times:  # for each time in the input list\n","        indices.append( np.argmin(np.abs(time_vect - time)) )\n","        # find index of the sampled time (in time_vect) closest to the desired one (time)\n","    return indices\n","\n","\n","def find_loading_time(time_vect, X, bounds=(600, 900), viz=False):  # for v2\n","    ''' Finds loading and settling time for the data of v2 chip\n","    Parameters\n","    ----------\n","    time_vect : ndarray\n","        1D array with dimension T containing the sampling times\n","    X : ndarray\n","        2D array with dimension TxNM containing the sampled data\n","    bounds : list, optional\n","        tuple containing the minimum and maximum times (in ms) where the loading time has to be searched.\n","        Default is (600, 900)\n","    viz : bool, optional\n","        if viz=True, show the plot. Default is False\n","    Returns\n","    -------\n","    tuple\n","        - settled_index : index at which the settling occurs\n","        - settled_time : time at which the settling occurs\n","    '''\n","\n","    search_start, search_end = time_to_index(bounds, time_vect)  # for each time in bounds, find the index\n","    # of the sample (in time_vect) that is closest to the desired one (in bounds)\n","    X_mean = np.mean(X, axis=1)  # for each sample, calculate the mean of all pixels\n","    X_mean_diff = np.diff(X_mean)  # find the derivative\n","\n","    loading_index = np.argmax(X_mean_diff[search_start:search_end]) + search_start + 1  # find the index\n","    # where the derivative is max in the specified interval\n","    loading_index = loading_index  # add settling time\n","    settled_index = loading_index + 10  # add settling time\n","    settled_time = time_vect[settled_index]  # find the time that index corresponds to\n","\n","    if viz:  # if viz is true, plot the following\n","        fig, ax = plt.subplots(3, 1)\n","        fig.suptitle('Finding Loading Time...')\n","\n","        ax[0].set(title='Active Chemical Pixels, ACP')\n","        ax[0].plot(time_vect, X)  # plot the active chemical pixels\n","\n","        ax[1].set(title='Mean(ACP)')\n","        ax[1].plot(time_vect, X_mean)  # plot the average of the pixels\n","        ax[1].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[1].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[1].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        ax[2].set(title='Diff(Mean(ACP))')\n","        ax[2].plot(time_vect[1:], X_mean_diff)  # plot the derivative of the mean\n","        ax[2].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[2].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[2].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        plt.tight_layout()\n","        plt.show()\n","    return settled_index, settled_time"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"9m8OqTUtQVb0","executionInfo":{"status":"ok","timestamp":1651139809616,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def preprocess_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","  \n","  df = filter_chemical_pixels(df, 78, 56) # filter all chemical pixels\n","  \n","  df = filter_active_pixels_drop(df=df, v_thresh_deriv=deriv_thresh, v_range=(100,900))\n","\n","  settle_idx, settle_time = find_loading_time(df.index, df, bounds=(600, 900), viz=False) # find settling point\n","  df = df.iloc[settle_idx + 10:, :] # use only the data after the settling time + 30s to allow reaction to settle\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise don't\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +200 added on to see impact on graph after pre-processing\n","  \n","  # for col in df.columns:\n","  #   df[col] = savgol_filter(df[col],101, 3)\n","\n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  df['Average Output'] = normalise_data(df['Average Output']) # normalise data using mix-max scaling\n","\n","   \n","  return df"]},{"cell_type":"code","source":["def preprocess_partial_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","\n","  df = filter_active_pixels_range(df=df, v_range=(100,900)) # filter by range incase of any saturation\n","  \n","  df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh) # filter pixels by deriv\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise dont\n","\n","  df = df.iloc[:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +250 added on to see impact on graph after pre-processing\n","  \n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  df['Average Output'] = normalise_data(df['Average Output']) # normalise data using mix-max scaling\n","    \n","  return df"],"metadata":{"id":"JsSdU8xPZX4U","executionInfo":{"status":"ok","timestamp":1651139810435,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def normalise_data(series):\n","  return (series - series.min()) / (series.max() - series.min())"],"metadata":{"id":"M6wMMfHZEADc","executionInfo":{"status":"ok","timestamp":1651139811428,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### Data Loading Helper Functions"],"metadata":{"id":"Dvvp28miEMsF"}},{"cell_type":"code","source":["def load_partial_covid_exp(filepath):\n","\n","  bot_filepath = filepath[:-4] + \"_bot.csv\"\n","  top_filepath = filepath[:-4] + \"_top.csv\"\n","\n","  ## load in 2 sheets\n","  df_neg = pd.read_csv(top_filepath, header=0, index_col=0)\n","  df_pos = pd.read_csv(bot_filepath, header=0, index_col=0)\n","\n","  return df_pos, df_neg"],"metadata":{"id":"vL28HCTcZUUG","executionInfo":{"status":"ok","timestamp":1651139813433,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation Metric Helper Functions"],"metadata":{"id":"PaNIFO5iSa9C"}},{"cell_type":"code","source":["def accuracy(classifications):\n","  total = len(classifications)\n","  total_correct = 0\n","  for i in classifications.values():\n","    if(i[0] == i[1]):\n","      total_correct +=1\n","\n","  accuracy = (total_correct/total)\n","\n","  return accuracy"],"metadata":{"id":"U2zoSqPJLatm","executionInfo":{"status":"ok","timestamp":1651139817324,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def sensitivity(classifications):\n","  true_pos = 0\n","  false_neg = 0\n","\n","  for i in classifications.values():\n","\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","\n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 1 and predicted == 0):\n","      false_neg += 1\n","\n","  sensitivity = (true_pos/(true_pos + false_neg))\n","\n","  return sensitivity"],"metadata":{"id":"lzSAF5WsTIuF","executionInfo":{"status":"ok","timestamp":1651139817646,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def specificity(classifications):\n","  true_neg = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 0 and predicted == 0):\n","      true_neg += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  specificity = (true_neg/(true_neg + false_pos))\n","\n","  return specificity"],"metadata":{"id":"WP_kdiXMYeU1","executionInfo":{"status":"ok","timestamp":1651139818979,"user_tz":-60,"elapsed":12,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def precision(classifications):\n","  true_pos = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  precision = (true_pos/(true_pos + false_pos))\n","\n","  return precision"],"metadata":{"id":"w7-_ZPDDaxRp","executionInfo":{"status":"ok","timestamp":1651139819611,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def f1(classifications):\n","  numerator = 2*precision(classifications)*sensitivity(classifications)\n","  denominator = precision(classifications) + sensitivity(classifications)\n","  return numerator/denominator"],"metadata":{"id":"qkFpU-UJbV1R","executionInfo":{"status":"ok","timestamp":1651139821412,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["### Array Dims"],"metadata":{"id":"W9kgS_-Cx1nm"}},{"cell_type":"code","source":["arr_rows = 78\n","arr_cols = 56"],"metadata":{"id":"whsJZh4Zx0xs","executionInfo":{"status":"ok","timestamp":1651139825455,"user_tz":-60,"elapsed":285,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["### Load Data"],"metadata":{"id":"KCr7gvB_tf5-"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"AvJiLnQ8tiKx"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  avg_data_g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_data_export.csv\"\n","  avg_g1 = pd.read_csv(avg_data_g1_file, header=0)\n","\n","  ## Gamma 2\n","  avg_data_g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_data_export.csv\"\n","  avg_g2 = pd.read_csv(avg_data_g2_file, header=0)\n","\n","  ## Gamma 3\n","  avg_data_g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_data_export.csv\"\n","  avg_g3 = pd.read_csv(avg_data_g3_file, header=0)\n","  \n","  ## Gamma 5 \n","  avg_data_g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_data_export.csv\"\n","  avg_g5 = pd.read_csv(avg_data_g5_file, header=0)\n","\n","  ## 22RV1.ap1\n","  avg_data_22rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_data_export.csv\"\n","  avg_22rv1_ap1 = pd.read_csv(avg_data_22rv1_ap1_file, header=0)\n","\n","  ## 22RV1.ap2\n","  avg_data_22rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_data_export.csv\"\n","  avg_22rv1_ap2 = pd.read_csv(avg_data_22rv1_ap2_file, header=0)\n","\n","  ## 22RV1y.p1\n","  avg_data_22rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_data_export.csv\"\n","  avg_22rv1y_p1 = pd.read_csv(avg_data_22rv1y_p1_file, header=0)\n","\n","  ## 22RV1y.p3\n","  avg_data_22rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_data_export.csv\"\n","  avg_22rv1y_p3 = pd.read_csv(avg_data_22rv1y_p3_file, header=0)\n","\n","  ## 22RV1y.p4\n","  avg_data_22rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_data_export.csv\"\n","  avg_22rv1y_p4 = pd.read_csv(avg_data_22rv1y_p4_file, header=0)\n","\n","  ## ARV7.p1\n","  avg_data_arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_data_export.csv\"\n","  avg_arv7_p1 = pd.read_csv(avg_data_arv7_p1_file, header=0).iloc[1:, :].reset_index(drop=True) # row 0 was NAN\n","\n","  ## ARV7.p3\n","  avg_data_arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_data_export.csv\"\n","  avg_arv7_p3 = pd.read_csv(avg_data_arv7_p3_file, header=0)\n","\n","  ## ARV7.p4\n","  avg_data_arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_data_export.csv\"\n","  avg_arv7_p4 = pd.read_csv(avg_data_arv7_p4_file, header=0)\n","\n","  ## Beta 1\n","  avg_data_b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_data_export.csv\"\n","  avg_b1 = pd.read_csv(avg_data_b1_file, header=0)\n","\n","  ## Beta 2\n","  avg_data_b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_data_export.csv\"\n","  avg_b2 = pd.read_csv(avg_data_b2_file, header=0)\n","\n","  ## Beta 5\n","  avg_data_b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_data_export.csv\"\n","  avg_b5 = pd.read_csv(avg_data_b5_file, header=0)\n","  "],"metadata":{"id":"Ekqd_pB0tuTS","executionInfo":{"status":"ok","timestamp":1651139833129,"user_tz":-60,"elapsed":5626,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_vsChem_export.csv\"\n","  g1 = pd.read_csv(g1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g1.index = avg_g1[\"Time Elapsed\"]\n","\n","  ## Gamma 2\n","  g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_vsChem_export.csv\"\n","  g2 = pd.read_csv(g2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g2.index = avg_g2[\"Time Elapsed\"]\n","\n","  ## Gamma 3\n","  g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_vsChem_export.csv\"\n","  g3 = pd.read_csv(g3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g3.index = avg_g3[\"Time Elapsed\"]\n","\n","  ## Gamma 5\n","  g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_vsChem_export.csv\"\n","  g5 = pd.read_csv(g5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g5.index = avg_g5[\"Time Elapsed\"]\n","\n","  ## 22RV1.ap1\n","  rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_vsChem_export.csv\"\n","  rv1_ap1 = pd.read_csv(rv1_ap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap1.index = avg_22rv1_ap1['Time Elapsed']\n","\n","  ## 22RV1.ap2\n","  rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_vsChem_export.csv\"\n","  rv1_ap2 = pd.read_csv(rv1_ap2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap2.index = avg_22rv1_ap2['Time Elapsed']\n","\n","  ## 22RV1y.p1\n","  rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_vsChem_export.csv\"\n","  rv1y_p1 = pd.read_csv(rv1y_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p1.index = avg_22rv1y_p1['Time Elapsed']\n","\n","  ## 22RV1y.p3\n","  rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_vsChem_export.csv\"\n","  rv1y_p3 = pd.read_csv(rv1y_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p3.index = avg_22rv1y_p3['Time Elapsed']\n","\n","  ## 22RV1y.p4\n","  rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_vsChem_export.csv\"\n","  rv1y_p4 = pd.read_csv(rv1y_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p4.index = avg_22rv1y_p4['Time Elapsed']\n","\n","  ## ARV7.p1 \n","  arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_vsChem_export.csv\"\n","  arv7_p1 = pd.read_csv(arv7_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)] \n","  arv7_p1.index = avg_arv7_p1[\"Time Elapsed\"]\n","\n","  ## ARV7.p3 \n","  arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_vsChem_export.csv\"\n","  arv7_p3 = pd.read_csv(arv7_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p3.index = avg_arv7_p3[\"Time Elapsed\"]\n","\n","  ## ARV7.p4 \n","  arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_vsChem_export.csv\"\n","  arv7_p4 = pd.read_csv(arv7_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p4.index = avg_arv7_p4[\"Time Elapsed\"]\n","\n","  ## Beta 1\n","  b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_vsChem_export.csv\"\n","  b1 = pd.read_csv(b1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b1.index = avg_b1[\"Time Elapsed\"]\n","\n","  ## Beta 2\n","  b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_vsChem_export.csv\"\n","  b2 = pd.read_csv(b2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b2.index = avg_b2[\"Time Elapsed\"]\n","\n","  ## Beta 5\n","  b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_vsChem_export.csv\"\n","  b5 = pd.read_csv(b5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b5.index = avg_b5[\"Time Elapsed\"]"],"metadata":{"id":"vZRah5zpxXp6","executionInfo":{"status":"ok","timestamp":1651139855921,"user_tz":-60,"elapsed":22802,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"7qOF9VBstkbe"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):  \n","  ## ARV7.n1\n","  avg_data_arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_data_export.csv\"\n","  avg_arv7 = pd.read_csv(avg_data_arv7_file, header=0)\n","\n","  ## Yap.n2\n","  avg_data_yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_data_export.csv\"\n","  avg_yap = pd.read_csv(avg_data_yap_file, header=0)\n","\n","  ## Yap1.n2\n","  avg_data_yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_data_export.csv\"\n","  avg_yap1 = pd.read_csv(avg_data_yap1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## Yap1.n1.1 \n","  avg_data_yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_data_export.csv\"\n","  avg_yap1n1 = pd.read_csv(avg_data_yap1n1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## ARV7.n2\n","  avg_data_arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_data_export.csv\"\n","  avg_arv72 = pd.read_csv(avg_data_arv72_file, header=0)\n","\n","  ## ARV7.n3\n","  avg_data_arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_data_export.csv\"\n","  avg_arv73 = pd.read_csv(avg_data_arv73_file, header=0)\n","\n","  ## DU145a.p1\n","  avg_data_du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_data_export.csv\"\n","  avg_du145a_p1 = pd.read_csv(avg_data_du145a_p1_file, header=0)\n","\n","  ## DU145a.p2\n","  avg_data_du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_data_export.csv\"\n","  avg_du145a_p2 = pd.read_csv(avg_data_du145a_p2_file, header=0)\n","\n","  ## DU145a.p3\n","  avg_data_du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_data_export.csv\"\n","  avg_du145a_p3 = pd.read_csv(avg_data_du145a_p3_file, header=0)\n","\n","  ## DU145y.n1\n","  avg_data_du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_data_export.csv\"\n","  avg_du145y_n1 = pd.read_csv(avg_data_du145y_n1_file, header=0)"],"metadata":{"id":"mlU83yKsuSHV","executionInfo":{"status":"ok","timestamp":1651139859017,"user_tz":-60,"elapsed":3108,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):   \n","  ## ARV7.n1 \n","  arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_vsChem_export.csv\"\n","  arv7 = pd.read_csv(arv7_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7.index = avg_arv7[\"Time Elapsed\"]\n","\n","  ## Yap.n2\n","  yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_vsChem_export.csv\"\n","  yap = pd.read_csv(yap_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap.index = avg_yap[\"Time Elapsed\"]\n","\n","  ## Yap1.n2\n","  yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_vsChem_export.csv\"\n","  yap1 = pd.read_csv(yap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1.index = avg_yap1[\"Time Elapsed\"]\n","\n","  ## Yap1.n1.1\n","  yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_vsChem_export.csv\"\n","  yap1n1 = pd.read_csv(yap1n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1n1.index = avg_yap1n1[\"Time Elapsed\"]\n","\n","  ## ARV7.n2\n","  arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_vsChem_export.csv\"\n","  arv72 = pd.read_csv(arv72_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv72.index = avg_arv72[\"Time Elapsed\"]\n","\n","  ## ARV7.n3\n","  arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_vsChem_export.csv\"\n","  arv73 = pd.read_csv(arv73_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv73.index = avg_arv73[\"Time Elapsed\"]\n","\n","  ## DU145a.p1\n","  du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_vsChem_export.csv\"\n","  du145a_p1 = pd.read_csv(du145a_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p1.index = avg_du145a_p1[\"Time Elapsed\"]\n","\n","  ## DU145a.p2\n","  du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_vsChem_export.csv\"\n","  du145a_p2 = pd.read_csv(du145a_p2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p2.index = avg_du145a_p2[\"Time Elapsed\"]\n","\n","  ## DU145a.p3\n","  du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_vsChem_export.csv\"\n","  du145a_p3 = pd.read_csv(du145a_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p3.index = avg_du145a_p3[\"Time Elapsed\"]\n","\n","  ## DU145y.n1\n","  du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_vsChem_export.csv\"\n","  du145y_n1 = pd.read_csv(du145y_n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145y_n1.index = avg_du145y_n1[\"Time Elapsed\"]"],"metadata":{"id":"W3_XExOjypwI","executionInfo":{"status":"ok","timestamp":1651139868929,"user_tz":-60,"elapsed":9915,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["#### Partial Covid Data"],"metadata":{"id":"yjXPLEfmRUJH"}},{"cell_type":"code","source":["## 150520_2_118\n","avg_118_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_2_118/exp_summary_118.csv\"\n","exp_118_pos, exp_118_neg = load_partial_covid_exp(avg_118_file)\n","\n","## 150520_4_2_86\n","avg_86_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_4_2_86/exp_summary_86.csv\"\n","exp_86_pos, exp_86_neg = load_partial_covid_exp(avg_86_file)\n","\n","## 150520_5_129\n","avg_129_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_5_129/exp_summary_129.csv\"\n","exp_129_pos, exp_129_neg = load_partial_covid_exp(avg_129_file)\n","\n","## 180520_4_165\n","avg_165_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_4_165/exp_summary_165.csv\"\n","exp_165_pos, exp_165_neg = load_partial_covid_exp(avg_165_file)\n","\n","## 180520_6_35\n","avg_35_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_6_35/exp_summary_35.csv\"\n","exp_35_pos, exp_35_neg = load_partial_covid_exp(avg_35_file)\n","\n","## 190520_1_28\n","avg_28_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_1_28/exp_summary_28.csv\"\n","exp_28_pos, exp_28_neg = load_partial_covid_exp(avg_28_file) \n","\n","## 190520_2_14\n","avg_14_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_2_14/exp_summary_14.csv\"\n","exp_14_pos, exp_14_neg = load_partial_covid_exp(avg_14_file)\n","\n","## 210520_2_40\n","avg_40_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_2_40/exp_summary_40.csv\"\n","exp_40_pos, exp_40_neg = load_partial_covid_exp(avg_40_file)\n","\n","## 210520_3_88\n","avg_88_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_3_88/exp_summary_88.csv\"\n","exp_88_pos, exp_88_neg = load_partial_covid_exp(avg_88_file)\n","\n","## 210520_6_27\n","avg_27_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_6_27/exp_summary_27.csv\"\n","exp_27_pos, exp_27_neg = load_partial_covid_exp(avg_27_file)\n","\n","## 250520_1_134\n","avg_134_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_1_134/exp_summary_134.csv\"\n","exp_134_pos, exp_134_neg = load_partial_covid_exp(avg_134_file)\n","\n","## 250520_2_97\n","avg_97_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_2_97/exp_summary_97.csv\"\n","exp_97_pos, exp_97_neg = load_partial_covid_exp(avg_97_file)\n","\n","## 250520_6_2D1\n","avg_2d1_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_6_2D1/exp_summary_2D1.csv\"\n","exp_2d1_pos, exp_2d1_neg = load_partial_covid_exp(avg_2d1_file)\n","\n","## 250520_7_64\n","avg_64_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_7_64/exp_summary_64.csv\"\n","exp_64_pos, exp_64_neg = load_partial_covid_exp(avg_64_file)"],"metadata":{"id":"ORRtMFfEZBwV","executionInfo":{"status":"ok","timestamp":1651139883683,"user_tz":-60,"elapsed":14772,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"7XgnkewwwPki"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"CTcUwvRiwUmJ"}},{"cell_type":"code","source":["g1 = preprocess_data(g1, 500)\n","g2 = preprocess_data(g2, 500)\n","g3 = preprocess_data(g3, 500)\n","g5 = preprocess_data(g5, 500)\n","rv1_ap1 = preprocess_data(rv1_ap1, 500)\n","rv1_ap2 = preprocess_data(rv1_ap2, 500)\n","rv1y_p1 = preprocess_data(rv1y_p1, 500)\n","rv1y_p3 = preprocess_data(rv1y_p3, 500)\n","rv1y_p4 = preprocess_data(rv1y_p4, 500)\n","arv7_p1 = preprocess_data(arv7_p1, 500)\n","arv7_p3 = preprocess_data(arv7_p3, 500)\n","arv7_p4 = preprocess_data(arv7_p4, 500)\n","b1 = preprocess_data(b1, 500)\n","b2 = preprocess_data(b2, 500)\n","b5 = preprocess_data(b5, 500)"],"metadata":{"id":"1-WlDoK49D2Y","executionInfo":{"status":"ok","timestamp":1651139884989,"user_tz":-60,"elapsed":1311,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"1WaPBFGuwYN4"}},{"cell_type":"code","source":["arv7 = preprocess_data(arv7, 500)\n","yap = preprocess_data(yap, 500)\n","yap1 = preprocess_data(yap1, 500)\n","yap1n1 = preprocess_data(yap1n1, 500)\n","arv72 = preprocess_data(arv72, 500)\n","arv73 = preprocess_data(arv73, 500)\n","du145y_n1 = preprocess_data(du145y_n1, 500)\n","du145a_p1 = preprocess_data(du145a_p1, 500)\n","du145a_p2 = preprocess_data(du145a_p2, 500)\n","du145a_p3 = preprocess_data(du145a_p3, 500)"],"metadata":{"id":"gazhgzLT9HLV","executionInfo":{"status":"ok","timestamp":1651139885789,"user_tz":-60,"elapsed":802,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["#### Covid Partial Data"],"metadata":{"id":"nUwBPNQNjQ7w"}},{"cell_type":"code","source":["exp_118_pos = preprocess_partial_data(exp_118_pos, 500)\n","exp_86_pos = preprocess_partial_data(exp_86_pos, 500)\n","exp_129_pos = preprocess_partial_data(exp_129_pos, 500)\n","exp_165_pos = preprocess_partial_data(exp_165_pos, 500)\n","exp_35_pos = preprocess_partial_data(exp_35_pos, 500)\n","exp_28_pos = preprocess_partial_data(exp_28_pos, 500)\n","exp_14_pos = preprocess_partial_data(exp_14_pos, 500)\n","exp_40_pos = preprocess_partial_data(exp_40_pos, 500)\n","exp_88_pos = preprocess_partial_data(exp_88_pos, 500)\n","exp_27_pos = preprocess_partial_data(exp_27_pos, 500)\n","exp_134_pos = preprocess_partial_data(exp_134_pos, 500)\n","exp_97_pos = preprocess_partial_data(exp_97_pos, 500)\n","exp_2d1_pos = preprocess_partial_data(exp_2d1_pos, 500)\n","exp_64_pos = preprocess_partial_data(exp_64_pos, 500)"],"metadata":{"id":"HQBQ_1YF9Oqj","executionInfo":{"status":"ok","timestamp":1651139887169,"user_tz":-60,"elapsed":1384,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["exp_118_neg = preprocess_partial_data(exp_118_neg, 500)\n","exp_86_neg = preprocess_partial_data(exp_86_neg, 500)\n","exp_129_neg = preprocess_partial_data(exp_129_neg, 500)\n","exp_165_neg = preprocess_partial_data(exp_165_neg, 500)\n","exp_35_neg = preprocess_partial_data(exp_35_neg, 500)\n","exp_28_neg = preprocess_partial_data(exp_28_neg, 500)\n","exp_14_neg = preprocess_partial_data(exp_14_neg, 500)\n","exp_40_neg = preprocess_partial_data(exp_40_neg, 500)\n","exp_88_neg = preprocess_partial_data(exp_88_neg, 500)\n","exp_27_neg = preprocess_partial_data(exp_27_neg, 500)\n","exp_134_neg = preprocess_partial_data(exp_134_neg, 500)\n","exp_97_neg = preprocess_partial_data(exp_97_neg, 500)\n","exp_2d1_neg = preprocess_partial_data(exp_2d1_neg, 500)\n","exp_64_neg = preprocess_partial_data(exp_64_neg, 500)"],"metadata":{"id":"sYsOnsAW9Rob","executionInfo":{"status":"ok","timestamp":1651139888448,"user_tz":-60,"elapsed":1284,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - Neural Network Ensemble"],"metadata":{"id":"cco-BOwij9af"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"j5qgb5mx3rOW"}},{"cell_type":"code","source":["def get_training_data(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"OIYXEisg2WX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_test_data(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"xH5J1l0cgIHI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"d6Qyl80Wzy-r"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,\n","             \"arv7_p3\":arv7_p3,\n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7,  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3}"],"metadata":{"id":"d-bA8RfjcM35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Model Specs"],"metadata":{"id":"rxkmk6GHqC7g"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_classifiers = 50\n","\n","timestep = int(number_of_samples/number_of_classifiers)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]\n","\n","batch_size = 3\n","epochs = 10\n","loss_function = 'binary_crossentropy'\n","optimiser = 'adam'"],"metadata":{"id":"eztwFZUaloVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBcYHOw_BU4E","executionInfo":{"status":"ok","timestamp":1650888347765,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"62652afd-35c9-48f8-c037-b58efe79e12c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Creating Ensemble"],"metadata":{"id":"qG3eDbNkqG9A"}},{"cell_type":"code","source":["def create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples):\n","\n","  neural_nets = [0]*number_of_classifiers\n","\n","  for i in range(number_of_classifiers):\n","\n","    # print(f\"============================================== Neural Network {i} ============================================\")\n","\n","    ## make model \n","    neural_nets[i] = Sequential()\n","    neural_nets[i].add(Dense(16, activation='relu', input_dim = timestamps[i]))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(1, activation='sigmoid'))\n","\n","    ## compile model \n","    neural_nets[i].compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])\n","\n","    ## model summary\n","    # neural_nets[i].summary()\n","\n","    ## training data\n","    training_data, training_label = get_training_data(positive_samples=positives, negative_samples=negatives, timestamp=timestamps[i], test_samples=[test_samples])\n","\n","    ## train model\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n","    neural_nets[i].fit(training_data, training_label,  batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[callback], verbose=0)\n","\n","    # print(\"\\n\\n\")\n","\n","  return neural_nets"],"metadata":{"id":"GVVPVw4-ndtu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Evaluating Ensemble"],"metadata":{"id":"fGH97jNBfzdu"}},{"cell_type":"code","source":["def get_prediction(ensemble, timestamps, test_sample):\n","  predictions = []\n","\n","  for i in range(number_of_classifiers):\n","    test_data = get_test_data(test_sample, timestamps[i])\n","    prediction = ensemble[i].predict(test_data)\n","    predictions.append(prediction[0][0])\n","\n","  predictions = [int(i >= 0.5) for i in predictions]\n","  classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","\n","  return classification"],"metadata":{"id":"HslDzCxe1PaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with tule label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"TCTzCBpU0S8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  final_classifications = {}\n","\n","  ## use ensemble to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Testing sample: {test_sample_name}...\")\n","\n","    en = create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_sample_name)\n","    classification = get_prediction(en, timestamps, test_sample)\n","    \n","    \n","    final_classifications[key] = (classification, true_label_dict[key])\n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"HlIwk3By0Zqi","colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"status":"error","timestamp":1650888354674,"user_tz":-60,"elapsed":6919,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2e248431-2ec4-4c7b-e50c-96b007673ba4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample: exp_118_pos...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'sequential_1/dense_7/BiasAdd/ReadVariableOp/resource' has no attr named '_class'.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-5086e332c720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing sample: {test_sample_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0men\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-83e0a485fc39>\u001b[0m in \u001b[0;36mcreate_ensemble\u001b[0;34m(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m## train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mneural_nets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# print(\"\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    530\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m    531\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_compute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    673\u001b[0m           \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m           \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m               var.op.name):\n\u001b[1;32m    716\u001b[0m             update_op = distribution.extended.update(\n\u001b[0;32m--> 717\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False)\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_cross_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m               \u001b[0;31m# In cross-replica context, extended.update returns a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n\u001b[0;32m-> 2633\u001b[0;31m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[0m\u001b[1;32m   2634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2509\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3101\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3102\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3108\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3109\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2509\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2628\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2629\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3701\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3702\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3709\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3710\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    174\u001b[0m           \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m           \u001b[0;34m'Please pass these args as kwargs instead.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1447\u001b[0m                              \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m                              \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m                              use_nesterov=use_nesterov, name=name)\n\u001b[0m\u001b[1;32m   1450\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0mResourceApplyAdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_ops.ResourceApplyAdam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_apply_adam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[1;32m   1655\u001b[0m                            \"building a function.\")\n\u001b[0;32m-> 1656\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;31m# Large EagerTensors and resources are captured with Placeholder ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m       placeholder = _create_substitute_placeholder(\n\u001b[0;32m--> 765\u001b[0;31m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0m\u001b[1;32m    766\u001b[0m       \u001b[0;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0;31m# This attribute would be propogated into the arg_attr of the FunctionDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     placeholder = graph_placeholder(\n\u001b[0;32m-> 1306\u001b[0;31m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   1307\u001b[0m   \u001b[0mhandle_data_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       attrs=attrs, name=name)\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3785\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3872\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcolocation_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3874\u001b[0;31m           \u001b[0mall_colocation_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3876\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocation_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \u001b[0mdefault_colocation_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc:@%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m       \u001b[0mclass_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m       \u001b[0;31m# This op has no explicit colocation group, so it is itself its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["final_classifications"],"metadata":{"id":"4AuD_rrC2yYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"mhkc8Lnr9-c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"WCjSN-dLz9Mq"}},{"cell_type":"code","source":["# ## checking the timestap where majority of classifiers agree\n","\n","# from collections import defaultdict\n","\n","# def get_timestamp(timestamps, predictions):\n","\n","#   ## create dict to hold count of predictions\n","#   label_counters = defaultdict(int)\n","\n","#   ## add entries to dict\n","#   for index, pred in enumerate(predictions):\n","#     label_counters[pred] += 1\n","\n","#     ## if label count == half of total possible predictions then majority is achieved\n","#     if(label_counters[pred] == int(len(predictions)/2)+1):\n","#       return timestamps[index], index\n","  \n","#   return -1, -1\n"],"metadata":{"id":"3r69Gbpd99So"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Timestamp where majority aggement is reached: {timestamp_final}\")\n","# print(f\"Index of final time stamp in array : {pred_index}\")"],"metadata":{"id":"ghvOJ4Ot_fRB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Save Ensemble"],"metadata":{"id":"PppLDxSdv5Uk"}},{"cell_type":"code","source":["# !pwd"],"metadata":{"id":"jAJAZJtKv816"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G1Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G2Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G3Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G5Test"],"metadata":{"id":"UgtDxJjmxHQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/ARV7Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAPTest/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1N1Test/"],"metadata":{"id":"bwBDVrvMRsO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for i in range(number_of_classifiers):\n","#   filename = f\"ensemble-model-{i}.h5\"\n","#   neural_nets[i].save(filename)\n","\n","#   print(f\"Saved {filename}\")"],"metadata":{"id":"ZGXuLcuXx99S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - KNN Ensemble"],"metadata":{"id":"GvAKajynLNa9"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"H8ueQFk24bbg"}},{"cell_type":"code","source":["def get_training_data_knn(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"x4q6d44BLwpQ","executionInfo":{"status":"ok","timestamp":1651139894734,"user_tz":-60,"elapsed":221,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def get_test_data_knn(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"GZOfy-0GQuGA","executionInfo":{"status":"ok","timestamp":1651139896711,"user_tz":-60,"elapsed":221,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def get_time_index(timestamps, predictions):\n","\n","  ## create dict to hold count of predictions\n","  label_counters = defaultdict(int)\n","\n","  ## add entries to dict\n","  for index, pred in enumerate(predictions):\n","    label_counters[pred] += 1\n","\n","    ## if label count == half of total possible predictions then majority is achieved\n","    if(label_counters[pred] == int(len(predictions)/2)+1):\n","      return timestamps[index]\n","  \n","  return -1"],"metadata":{"id":"2hib6StpHWbU","executionInfo":{"status":"ok","timestamp":1651139898711,"user_tz":-60,"elapsed":300,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"FOMhNuiKNGAw"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"-prfZYD_VgMB","executionInfo":{"status":"ok","timestamp":1651139900811,"user_tz":-60,"elapsed":224,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["#### Timestamps"],"metadata":{"id":"Ry9pqKjnNKiI"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"3cDeyMc3M_bN","executionInfo":{"status":"ok","timestamp":1651140630848,"user_tz":-60,"elapsed":490,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIjHUplVOmH3","executionInfo":{"status":"ok","timestamp":1651140631691,"user_tz":-60,"elapsed":12,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"d41bee3a-b240-4fac-e28d-6a35eff9aa4f"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Model"],"metadata":{"id":"DJBWoo1SNMy3"}},{"cell_type":"code","source":["def KNN(k, test_sample, train_data, train_labels, distance_metric):\n","  test = np.tile(test_sample, (len(train_data),1)) # repeat test sample and stack vertically\n","  \n","  distances = None\n","\n","  if(distance_metric.lower() == 'manhattan' or distance_metric.lower() == 'cityblock'):\n","    distances = manhattan_distances(test, train_data).diagonal() # get pair wise manhattan distance for every row\n","  elif(distance_metric.lower() == 'euclidean'):\n","    distances = euclidean_distances(test, train_data).diagonal() # get pair wise euclidean distance for every row \n","  elif(distance_metric.lower() == 'cosine'):\n","    distances = cosine_distances(test, train_data).diagonal() # get pair wise cosine distance for every row \n","\n","  min_indexes = np.argsort(distances)[:k] # get k smallest indexes\n","\n","  knn_labels = list(train_labels[min_indexes]) # get k predictions\n","  final_pred = max(set(knn_labels), key=knn_labels.count)\n","\n","  return final_pred"],"metadata":{"id":"sGJZphgaLeL0","executionInfo":{"status":"ok","timestamp":1651140631970,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":["#### Model Predictions"],"metadata":{"id":"0C0XQKFHFtFV"}},{"cell_type":"markdown","source":["##### Held-out Test Set"],"metadata":{"id":"Vf8LAE4Qbxls"}},{"cell_type":"code","source":["# test_samples = {\"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \"exp_27_neg\":exp_27_neg,\"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg,\n","#                 \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \"g1\":g1, \"exp_86_pos\":exp_86_pos, \"rv1_ap1\":rv1_ap1,\"b5\":b5, \"exp_28_pos\":exp_28_pos}\n","# test_sample_keys = keys = list(test_samples.keys())\n","# test_labels = list(np.concatenate((np.ones(7),np.zeros(7))))\n","# test_label_dict = dict(zip(test_sample_keys, test_labels))"],"metadata":{"id":"AxaTjkExYX9r","executionInfo":{"status":"ok","timestamp":1651140631972,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["# import time\n","# with tf.device(gpu):\n","\n","#   final_classifications = {}\n","\n","#   ## use KNN to evaluate the prediction for each of the samples individually\n","#   for key, value in test_samples.items():\n","#     test_sample_name = key\n","#     test_sample = value\n","\n","#     predictions = []\n","#     for t in timestamps:\n","#       train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=test_sample_keys)\n","#       test_data = get_test_data_knn(test_sample, t)\n","#       pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","#       predictions.append(pred)\n","    \n","#     print(f\"Testing sample {test_sample_name}\")\n","\n","#     time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","#     time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","#     classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","#     final_classifications[key] = (classification, true_label_dict[key])\n","  \n","#     print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","#     if(classification == 1.0):\n","#       print(f\"TTP: {time_to_result}s\")\n","\n","#     print(\"\")"],"metadata":{"id":"PVYWffD2Z5q6","executionInfo":{"status":"ok","timestamp":1651140632573,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["# print(f\"Accuracy: {accuracy(final_classifications)}\")\n","# print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","# print(f\"Specificity: {specificity(final_classifications)}\")\n","# print(f\"Precision: {precision(final_classifications)}\")\n","# print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"uV2qejqoblws","executionInfo":{"status":"ok","timestamp":1651140632860,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":["##### Cross Validation"],"metadata":{"id":"DuKAj66EbskM"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"RGVdwT8rxS23","executionInfo":{"status":"ok","timestamp":1651140633931,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"SUDmHpF-GigC","executionInfo":{"status":"ok","timestamp":1651140635403,"user_tz":-60,"elapsed":229,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    print(f\"Testing sample {test_sample_name}\")\n","    print(predictions)\n","    time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","    time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","    classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","    final_classifications[key] = (classification, true_label_dict[key])\n","  \n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","    if(classification == 1.0):\n","      print(f\"TTP: {time_to_result}s\")\n","\n","    print(\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rptrj0arSjSR","executionInfo":{"status":"ok","timestamp":1651140642058,"user_tz":-60,"elapsed":3856,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"4ef19ed5-89a7-4b38-b64b-97bb8cc272c6"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample exp_118_pos\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_86_pos\n","[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 628.0s\n","\n","Testing sample exp_129_pos\n","[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_165_pos\n","[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 734.0s\n","\n","Testing sample exp_35_pos\n","[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1065.0s\n","\n","Testing sample exp_28_pos\n","[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_14_pos\n","[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_40_pos\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_88_pos\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 591.0s\n","\n","Testing sample exp_27_pos\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_134_pos\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 577s\n","\n","Testing sample exp_97_pos\n","[0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_2d1_pos\n","[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_64_pos\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample g1\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 572.0s\n","\n","Testing sample g2\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 582.0s\n","\n","Testing sample g3\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 599.0s\n","\n","Testing sample g5\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 575.0s\n","\n","Testing sample rv1_ap1\n","[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 614.0s\n","\n","Testing sample rv1_ap2\n","[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample arv7_p3\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 660.0s\n","\n","Testing sample rv1y_p3\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 835.0s\n","\n","Testing sample rv1y_p4\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample arv7_p1\n","[0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 645.0s\n","\n","Testing sample arv7_p4\n","[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 999.0s\n","\n","Testing sample b1\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 557.0s\n","\n","Testing sample b2\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 575.0s\n","\n","Testing sample b5\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 570.0s\n","\n","Testing sample exp_118_neg\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_86_neg\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_129_neg\n","[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_165_neg\n","[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_35_neg\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_28_neg\n","[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_14_neg\n","[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_40_neg\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 975s\n","\n","Testing sample exp_88_neg\n","[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_27_neg\n","[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_134_neg\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_97_neg\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_2d1_neg\n","[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_64_neg\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 567s\n","\n","Testing sample yap\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 576.0s\n","\n","Testing sample yap1\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample yap1n1\n","[1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 684.0s\n","\n","Testing sample arv72\n","[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv73\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample du145y_n1\n","[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv7\n","[1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample du145a_p1\n","[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 806.0s\n","\n","Testing sample du145a_p2\n","[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample du145a_p3\n","[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n"]}]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SilNigCLya5","executionInfo":{"status":"ok","timestamp":1651139941399,"user_tz":-60,"elapsed":230,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"c7853e9d-3cbb-41c0-fb61-cacfd344fcde"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6923076923076923\n","Sensitivity/Recall: 0.6071428571428571\n","Specificity: 0.7916666666666666\n","Precision: 0.7727272727272727\n","F1 Score: 0.68\n"]}]},{"cell_type":"markdown","source":["#### Elbow Plot"],"metadata":{"id":"DgvFMAGtSbpy"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"i1xQt-8FxVXG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  accuracies = []\n","  for k in range(1,30):\n","    final_classifications = {}\n","\n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = []\n","      for t in timestamps:\n","        train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","        test_data = get_test_data_knn(test_sample, t)\n","        pred = KNN(k, test_data, train_data, train_labels, 'cosine')\n","        predictions.append(pred)\n","      \n","      time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","      \n","      classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","      final_classifications[key] = (classification, true_label_dict[key])\n","\n","    acc = accuracy(final_classifications)\n","    accuracies.append(acc)\n","    print(f\"K: {k} \\t Accuracy: {acc}\")\n","    # print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"WwBbkDraFWF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650966514202,"user_tz":-60,"elapsed":88053,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"f0062b80-f45a-46b6-d744-babae2744155"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["K: 1 \t Accuracy: 0.6530612244897959\n","K: 2 \t Accuracy: 0.673469387755102\n","K: 3 \t Accuracy: 0.7142857142857143\n","K: 4 \t Accuracy: 0.6530612244897959\n","K: 5 \t Accuracy: 0.6326530612244898\n","K: 6 \t Accuracy: 0.6122448979591837\n","K: 7 \t Accuracy: 0.6122448979591837\n","K: 8 \t Accuracy: 0.5714285714285714\n","K: 9 \t Accuracy: 0.5714285714285714\n","K: 10 \t Accuracy: 0.5510204081632653\n","K: 11 \t Accuracy: 0.5306122448979592\n","K: 12 \t Accuracy: 0.5510204081632653\n","K: 13 \t Accuracy: 0.5102040816326531\n","K: 14 \t Accuracy: 0.5102040816326531\n","K: 15 \t Accuracy: 0.4489795918367347\n","K: 16 \t Accuracy: 0.4897959183673469\n","K: 17 \t Accuracy: 0.4897959183673469\n","K: 18 \t Accuracy: 0.5306122448979592\n","K: 19 \t Accuracy: 0.4489795918367347\n","K: 20 \t Accuracy: 0.5306122448979592\n","K: 21 \t Accuracy: 0.40816326530612246\n","K: 22 \t Accuracy: 0.46938775510204084\n","K: 23 \t Accuracy: 0.3877551020408163\n","K: 24 \t Accuracy: 0.46938775510204084\n","K: 25 \t Accuracy: 0.30612244897959184\n","K: 26 \t Accuracy: 0.3469387755102041\n","K: 27 \t Accuracy: 0.40816326530612246\n","K: 28 \t Accuracy: 0.46938775510204084\n","K: 29 \t Accuracy: 0.4489795918367347\n"]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = np.arange(1,30)\n","y = accuracies\n","axes.set_xlabel(\"K\")\n","axes.set_ylabel(\"Accuracy (%)\")\n","axes.plot(x,y)"],"metadata":{"id":"P8t0E1pS9YNL","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"ok","timestamp":1650966556872,"user_tz":-60,"elapsed":386,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"874fb5d2-17bc-472e-8d54-ac175e67c839"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f4bee3e3ad0>]"]},"metadata":{},"execution_count":162},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Confidence "],"metadata":{"id":"qXrQKuQm8ery"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"oZRyLyYo7k36"}},{"cell_type":"code","source":["def get_rH_00(true_vals, classifier_outputs):\n","  correct_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 0)):\n","      correct_pred_0 += 1\n","\n","  return correct_pred_0/total_pred_0\n","\n","\n","def get_rH_01(true_vals, classifier_outputs):\n","  wrong_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 0)):\n","      wrong_pred_1 += 1\n","    \n","  return wrong_pred_1/total_pred_1\n","\n","def get_rH_10(true_vals, classifier_outputs):\n","  wrong_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 1)):\n","      wrong_pred_0 += 1\n","  \n","  return wrong_pred_0/total_pred_0\n","\n","def get_rH_11(true_vals, classifier_outputs):\n","  correct_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 1)):\n","      correct_pred_1 += 1\n","\n","  return correct_pred_1/total_pred_1"],"metadata":{"id":"6IQ6mN5uJ6z1","executionInfo":{"status":"ok","timestamp":1651139952199,"user_tz":-60,"elapsed":224,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["def get_confidence_multipliers(sample_predictions, true_labels):\n","\n","  sample_predictions = np.asarray(sample_predictions) # array of all predictions made by every classifer for all samples\n","\n","  #2d array of all possible multipliers for each classifier\n","  multipliers_final = []\n","\n","  # generate 4 multipliers for each classifier\n","  for classifier in range(len(sample_predictions[0])):\n","    classifier_output = sample_predictions[:, classifier]\n","\n","    rH_00 = get_rH_00(true_labels, classifier_output)\n","    rH_01 = get_rH_01(true_labels, classifier_output)\n","    rH_10 = get_rH_10(true_labels, classifier_output)\n","    rH_11 = get_rH_11(true_labels, classifier_output)\n","    multipliers_classfier = [rH_00, rH_01, rH_10, rH_11] \n","\n","    # add multipliers to 2d array\n","    multipliers_final.append(multipliers_classfier)\n","\n","  return multipliers_final"],"metadata":{"id":"5r-wTh3nlga0","executionInfo":{"status":"ok","timestamp":1651139954390,"user_tz":-60,"elapsed":214,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["def get_confidence(preds, multipliers):\n","  \n","  # initialise variable\n","  confidence = 1\n","\n","  # the prediction for which the confidence is being calculated -- predication at time t by classifier Ht (most recent prediction)\n","  pred_t = preds[-1]\n","\n","  for idx , pred in enumerate(preds):\n","    # prediction at time k made by classifier Hk\n","    pred_k = pred\n","\n","    # array of multipliers for Hk \n","    multiplier_k = multipliers[idx]\n","\n","    if(pred_t == 0 and pred_k == 0):\n","        confidence*=(1-multiplier_k[0])\n","    elif(pred_t == 0 and pred_k == 1):\n","        confidence*=(1-multiplier_k[1])\n","    elif(pred_t == 1 and pred_k == 0):\n","        confidence*=(1-multiplier_k[2])  \n","    elif(pred_t == 1 and pred_k == 1):\n","        confidence*=(1-multiplier_k[3])\n","        \n","        \n","\n","  confidence = 1 - confidence\n","\n","  return confidence\n","  "],"metadata":{"id":"8SmPp5iDzHQJ","executionInfo":{"status":"ok","timestamp":1651139955664,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["def generate_predictions_table(positives, negatives, timestamps):\n","\n","  sample_predictions = []\n","\n","  true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    sample_predictions.append(predictions)\n","\n","  return sample_predictions, true_labels"],"metadata":{"id":"Qfe-e7-84_Zc","executionInfo":{"status":"ok","timestamp":1651140450030,"user_tz":-60,"elapsed":216,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":["#### Random Threshold Testing"],"metadata":{"id":"bwcY82bSq0t6"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651140451349,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"bZnftjyQxXcw"},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651140647840,"user_tz":-60,"elapsed":232,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"asGaVch58nEo"},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651140648081,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2b30472b-1ccc-49b8-dcea-3c2d91e69f71","id":"YF_lFeGo8nE2"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"68OVHXKmw-Hg","executionInfo":{"status":"ok","timestamp":1651140648759,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","  \n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","      if(c >= 0.99 ): # 99% confidence threshold\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","        if(pred == 1.0):\n","          print(f\"Earliness:  {time_index/timestamps[-1]}\")\n","          print(f\"TTP: {time_to_result+30}s\")\n","          ttps.append(time_to_result+30) # 30 second delay from reaction start when preprocessing\n","          earliness.append(time_index/timestamps[-1])\n","        break\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxnI-jcElWhV","executionInfo":{"status":"ok","timestamp":1651142147523,"user_tz":-60,"elapsed":3955,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"dcf86108-4a78-4b10-ba73-6c74a441ea60"},"execution_count":192,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_86_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 163.0s\n","\n","Sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 156.0s\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 161.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 165.0s\n","\n","Sample exp_28_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_14_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_40_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 164.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 162.0s\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 183s\n","\n","Sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 157.0s\n","\n","Sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 158.0s\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 159.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 161.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 163.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 167.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 164.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 161.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 140.0s\n","\n","Sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 179.0s\n","\n","Sample rv1y_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample rv1y_p4\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 166.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 191.0s\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 157.0s\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 161.0s\n","\n","Sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 160.0s\n","\n","Sample exp_118_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 162s\n","\n","Sample exp_86_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_129_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_165_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_35_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 169s\n","\n","Sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_14_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_40_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_97_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 162s\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 168.0s\n","\n","Sample yap1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample yap1n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 159.0s\n","\n","Sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145y_n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv7\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 166.0s\n","\n","Sample du145a_p1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145a_p2\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145a_p3\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Accuracy: 0.7692307692307693\n","Sensitivity/Recall: 0.7857142857142857\n","Specificity: 0.75\n","Precision: 0.7857142857142857\n","F1 Score: 0.7857142857142857\n"]}]},{"cell_type":"markdown","source":["#### Learning best threshold"],"metadata":{"id":"KPuLuWoixCSR"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651141560967,"user_tz":-60,"elapsed":317,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"HAfi2bU4phQC"},"execution_count":173,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651141561193,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"ps-swVLHphQD"},"execution_count":174,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651141561629,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"5092659e-f8b2-4357-bb88-677187322052","id":"z-c4frksphQD"},"execution_count":175,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651141561848,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"r0eTLRQophQD"},"execution_count":176,"outputs":[]},{"cell_type":"markdown","source":["##### Generating candidates"],"metadata":{"id":"ErEA8XSGqh8a"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"_m7lA1HIer-y","executionInfo":{"status":"ok","timestamp":1651141569046,"user_tz":-60,"elapsed":4966,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":177,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"yVEuBQRb1BpE","executionInfo":{"status":"ok","timestamp":1651141569047,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":178,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are the set of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"rI2uBt6fxLlF","executionInfo":{"status":"ok","timestamp":1651141569047,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":179,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTV9vJPW5zUg","executionInfo":{"status":"ok","timestamp":1651141569047,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"9e24617e-2e3b-46d8-92dc-788bc11bd614"},"execution_count":180,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1184"]},"metadata":{},"execution_count":180}]},{"cell_type":"markdown","source":["##### Evaluating candidates"],"metadata":{"id":"872Hxw3fqlfv"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # array to hold cost function value for each candidate\n","  cost_function_values = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # alpha\n","  alpha = 0.5\n","\n","  # evaluate every candidate\n","  for th in threshold_candidates:\n","\n","    print(f\"Candidate: {th} \")\n","\n","    # array to hold earliness values for the samples \n","    earliness = []  \n","\n","    # dict to hold predictions vs true values for the samples  \n","    final_classifications = {}\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      # get KNN predicition for the sample\n","      predictions = sample_predictions[sample_idx]\n","      confidences = []\n","      for i in range(len(predictions)):\n","        \n","        # get the confidence for that prediction \n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","        \n","        if(c >= th): # check if confidence is at or above confidence threshold\n","\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          # predicted class for the sample is given by the prediction which led to the gien confidence value\n","          pred = predictions[i]\n","\n","          # update final outcomes dict\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","          # add to earliness array\n","          earliness.append(time_index/timestamps[-1])\n","\n","          break\n","\n","      sample_idx += 1\n","\n","    # get avg accuracy and avg earliness for this threshold\n","    if(len(final_classifications) > 0):\n","      avg_accuracy = accuracy(final_classifications)\n","      avg_earliness = sum(earliness)/len(earliness)\n","\n","      # compute value of cost function and add to array \n","      cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","      cost_function_values.append(cf_score)\n","      print(f\"Score: {cf_score}\")\n","      print(\"\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKc1S0R6ebff","executionInfo":{"status":"ok","timestamp":1651141592505,"user_tz":-60,"elapsed":23462,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"d0f43d11-f7d3-4459-bd03-6bd365b13bc5"},"execution_count":181,"outputs":[{"output_type":"stream","name":"stdout","text":["Candidate: 0.4370314842578711 \n","Score: 0.2740384615384615\n","\n","Candidate: 0.5765242378810594 \n","Score: 0.27\n","\n","Candidate: 0.7043978010994502 \n","Score: 0.2832692307692308\n","\n","Candidate: 0.7491789819376026 \n","Score: 0.3034615384615385\n","\n","Candidate: 0.7700227267318721 \n","Score: 0.3080769230769231\n","\n","Candidate: 0.7814009661835748 \n","Score: 0.2823076923076923\n","\n","Candidate: 0.8004658385093167 \n","Score: 0.2823076923076923\n","\n","Candidate: 0.8219967397253753 \n","Score: 0.3026923076923077\n","\n","Candidate: 0.846988276215195 \n","Score: 0.2840384615384616\n","\n","Candidate: 0.8691502463054188 \n","Score: 0.269423076923077\n","\n","Candidate: 0.8829377225648636 \n","Score: 0.26980769230769236\n","\n","Candidate: 0.8964530892448512 \n","Score: 0.25307692307692314\n","\n","Candidate: 0.8986979194128378 \n","Score: 0.24384615384615388\n","\n","Candidate: 0.9010093167701863 \n","Score: 0.23461538461538461\n","\n","Candidate: 0.9095354169265113 \n","Score: 0.2351923076923077\n","\n","Candidate: 0.9238328628554993 \n","Score: 0.2353846153846154\n","\n","Candidate: 0.9371863497175629 \n","Score: 0.23557692307692307\n","\n","Candidate: 0.944402605766109 \n","Score: 0.22057692307692306\n","\n","Candidate: 0.9447607478094568 \n","Score: 0.22096153846153846\n","\n","Candidate: 0.9502758660584989 \n","Score: 0.22134615384615383\n","\n","Candidate: 0.956719308560122 \n","Score: 0.22134615384615383\n","\n","Candidate: 0.9580039525691699 \n","Score: 0.22153846153846152\n","\n","Candidate: 0.9609166236067026 \n","Score: 0.21249999999999997\n","\n","Candidate: 0.9637585812356979 \n","Score: 0.20500000000000002\n","\n","Candidate: 0.9652169529270453 \n","Score: 0.20519230769230767\n","\n","Candidate: 0.9682346082579434 \n","Score: 0.20557692307692307\n","\n","Candidate: 0.9705460621801051 \n","Score: 0.20576923076923076\n","\n","Candidate: 0.9728678423945922 \n","Score: 0.20596153846153847\n","\n","Candidate: 0.9751113407642529 \n","Score: 0.2163461538461538\n","\n","Candidate: 0.9760243739837136 \n","Score: 0.2165384615384615\n","\n","Candidate: 0.9785500636007047 \n","Score: 0.21692307692307689\n","\n","Candidate: 0.9807155062642703 \n","Score: 0.21730769230769229\n","\n","Candidate: 0.9809177442528736 \n","Score: 0.1826923076923077\n","\n","Candidate: 0.9815727018175971 \n","Score: 0.1830769230769231\n","\n","Candidate: 0.9822028747139588 \n","Score: 0.1830769230769231\n","\n","Candidate: 0.9838640473905662 \n","Score: 0.1830769230769231\n","\n","Candidate: 0.9854488078541375 \n","Score: 0.1830769230769231\n","\n","Candidate: 0.9855638586956521 \n","Score: 0.1832692307692308\n","\n","Candidate: 0.9857958695917803 \n","Score: 0.17403846153846156\n","\n","Candidate: 0.9864438666114157 \n","Score: 0.17423076923076924\n","\n","Candidate: 0.9876332930141112 \n","Score: 0.17423076923076924\n","\n","Candidate: 0.9883778079038438 \n","Score: 0.17423076923076924\n","\n","Candidate: 0.9884589165430726 \n","Score: 0.17423076923076924\n","\n","Candidate: 0.988701107937193 \n","Score: 0.17461538461538462\n","\n","Candidate: 0.9889468916924318 \n","Score: 0.17480769230769233\n","\n","Candidate: 0.9890054912683368 \n","Score: 0.17557692307692307\n","\n","Candidate: 0.9891138341778358 \n","Score: 0.1757692307692308\n","\n","Candidate: 0.9900368278032037 \n","Score: 0.17615384615384616\n","\n","Candidate: 0.9909396453089245 \n","Score: 0.17807692307692308\n","\n","Candidate: 0.9911357027078567 \n","Score: 0.17826923076923074\n","\n","Candidate: 0.9918901165405811 \n","Score: 0.17865384615384614\n","\n","Candidate: 0.9926365155450263 \n","Score: 0.18846153846153846\n","\n","Candidate: 0.9932899606939951 \n","Score: 0.18865384615384617\n","\n","Candidate: 0.9938351755198831 \n","Score: 0.18865384615384617\n","\n","Candidate: 0.993869211671089 \n","Score: 0.18865384615384617\n","\n","Candidate: 0.9938848714376161 \n","Score: 0.18865384615384617\n","\n","Candidate: 0.9940060934959284 \n","Score: 0.19865384615384618\n","\n","Candidate: 0.9945357000012006 \n","Score: 0.19903846153846155\n","\n","Candidate: 0.9950368128978315 \n","Score: 0.19903846153846155\n","\n","Candidate: 0.995138628796807 \n","Score: 0.18961538461538463\n","\n","Candidate: 0.99516343432639 \n","Score: 0.19\n","\n","Candidate: 0.9952396775580725 \n","Score: 0.19\n","\n","Candidate: 0.9954645108520563 \n","Score: 0.1901923076923077\n","\n","Candidate: 0.995751002269148 \n","Score: 0.19038461538461537\n","\n","Candidate: 0.9959109451970444 \n","Score: 0.19365384615384612\n","\n","Candidate: 0.995946016407119 \n","Score: 0.18461538461538457\n","\n","Candidate: 0.996131753592256 \n","Score: 0.18480769230769226\n","\n","Candidate: 0.9963156305641439 \n","Score: 0.18499999999999994\n","\n","Candidate: 0.9966045219561355 \n","Score: 0.18576923076923074\n","\n","Candidate: 0.9969065411490683 \n","Score: 0.18634615384615383\n","\n","Candidate: 0.9969448474908345 \n","Score: 0.1865384615384615\n","\n","Candidate: 0.9969798817696416 \n","Score: 0.1980769230769231\n","\n","Candidate: 0.9971217105263158 \n","Score: 0.19826923076923078\n","\n","Candidate: 0.9973886925780531 \n","Score: 0.19846153846153847\n","\n","Candidate: 0.9975610159558379 \n","Score: 0.19884615384615384\n","\n","Candidate: 0.9976218502423063 \n","Score: 0.19903846153846155\n","\n","Candidate: 0.9976672501809648 \n","Score: 0.20923076923076928\n","\n","Candidate: 0.9977261257763975 \n","Score: 0.2196153846153846\n","\n","Candidate: 0.9977822043874318 \n","Score: 0.21980769230769232\n","\n","Candidate: 0.9977965557101325 \n","Score: 0.21999999999999997\n","\n","Candidate: 0.9979087769625854 \n","Score: 0.21999999999999997\n","\n","Candidate: 0.9980227181543293 \n","Score: 0.21999999999999997\n","\n","Candidate: 0.998032591017541 \n","Score: 0.2201923076923077\n","\n","Candidate: 0.9980686339622273 \n","Score: 0.22057692307692306\n","\n","Candidate: 0.9981152078847602 \n","Score: 0.22057692307692306\n","\n","Candidate: 0.9982400220067174 \n","Score: 0.22096153846153846\n","\n","Candidate: 0.9983626681959944 \n","Score: 0.22115384615384615\n","\n","Candidate: 0.9983817254118686 \n","Score: 0.22134615384615383\n","\n","Candidate: 0.9983878114421301 \n","Score: 0.22173076923076923\n","\n","Candidate: 0.9984664761499925 \n","Score: 0.22173076923076923\n","\n","Candidate: 0.9986144658398388 \n","Score: 0.22192307692307692\n","\n","Candidate: 0.9987037572080233 \n","Score: 0.22192307692307692\n","\n","Candidate: 0.9987246413491268 \n","Score: 0.2221153846153846\n","\n","Candidate: 0.9987362271033815 \n","Score: 0.22288461538461538\n","\n","Candidate: 0.9988185127790112 \n","Score: 0.22288461538461538\n","\n","Candidate: 0.998919881306046 \n","Score: 0.22288461538461538\n","\n","Candidate: 0.9989484921542988 \n","Score: 0.22307692307692306\n","\n","Candidate: 0.998954574458722 \n","Score: 0.23461538461538461\n","\n","Candidate: 0.9989863228490188 \n","Score: 0.2348076923076923\n","\n","Candidate: 0.9990186268472907 \n","Score: 0.2376923076923077\n","\n","Candidate: 0.9990598566875413 \n","Score: 0.2378846153846154\n","\n","Candidate: 0.9991305218271701 \n","Score: 0.2378846153846154\n","\n","Candidate: 0.9991701723151583 \n","Score: 0.23807692307692307\n","\n","Candidate: 0.9991785942175673 \n","Score: 0.2382692307692308\n","\n","Candidate: 0.9991836926369249 \n","Score: 0.23846153846153845\n","\n","Candidate: 0.9991869933180115 \n","Score: 0.23865384615384616\n","\n","Candidate: 0.9992255328844148 \n","Score: 0.23865384615384616\n","\n","Candidate: 0.9992618458915703 \n","Score: 0.23884615384615382\n","\n","Candidate: 0.9992642888768393 \n","Score: 0.23903846153846153\n","\n","Candidate: 0.9992778855554062 \n","Score: 0.23903846153846153\n","\n","Candidate: 0.9992926695692396 \n","Score: 0.23923076923076925\n","\n","Candidate: 0.9993084278380298 \n","Score: 0.23923076923076925\n","\n","Candidate: 0.9993372192859151 \n","Score: 0.23961538461538462\n","\n","Candidate: 0.9993803482578886 \n","Score: 0.23961538461538462\n","\n","Candidate: 0.9994115392473302 \n","Score: 0.24\n","\n","Candidate: 0.9994285924677324 \n","Score: 0.2401923076923077\n","\n","Candidate: 0.9994425930350814 \n","Score: 0.24057692307692308\n","\n","Candidate: 0.9994445220085237 \n","Score: 0.24076923076923074\n","\n","Candidate: 0.9994529597615124 \n","Score: 0.2313461538461538\n","\n","Candidate: 0.9994856101501457 \n","Score: 0.23153846153846153\n","\n","Candidate: 0.9995229720473453 \n","Score: 0.2317307692307692\n","\n","Candidate: 0.999537685553187 \n","Score: 0.2317307692307692\n","\n","Candidate: 0.9995408708856857 \n","Score: 0.2319230769230769\n","\n","Candidate: 0.999546676221654 \n","Score: 0.23269230769230764\n","\n","Candidate: 0.9995566881002296 \n","Score: 0.23307692307692304\n","\n","Candidate: 0.9995643980052223 \n","Score: 0.23307692307692304\n","\n","Candidate: 0.99957330695403 \n","Score: 0.23307692307692304\n","\n","Candidate: 0.9995887254857789 \n","Score: 0.23307692307692304\n","\n","Candidate: 0.9996097274069935 \n","Score: 0.24326923076923077\n","\n","Candidate: 0.9996236468051399 \n","Score: 0.2448076923076923\n","\n","Candidate: 0.9996411786724358 \n","Score: 0.245\n","\n","Candidate: 0.9996782475620801 \n","Score: 0.245\n","\n","Candidate: 0.9996998826332635 \n","Score: 0.24519230769230768\n","\n","Candidate: 0.9997083603023238 \n","Score: 0.24519230769230768\n","\n","Candidate: 0.9997207522883296 \n","Score: 0.2453846153846154\n","\n","Candidate: 0.9997261980725225 \n","Score: 0.24557692307692308\n","\n","Candidate: 0.999730297574001 \n","Score: 0.24576923076923077\n","\n","Candidate: 0.9997334819452313 \n","Score: 0.24576923076923077\n","\n","Candidate: 0.9997354755265329 \n","Score: 0.24865384615384611\n","\n","Candidate: 0.9997371801449123 \n","Score: 0.24884615384615383\n","\n","Candidate: 0.9997465369203933 \n","Score: 0.2490384615384615\n","\n","Candidate: 0.9997603874165881 \n","Score: 0.2494230769230769\n","\n","Candidate: 0.9997683902873717 \n","Score: 0.2494230769230769\n","\n","Candidate: 0.9997746383524999 \n","Score: 0.24961538461538457\n","\n","Candidate: 0.9997794106550866 \n","Score: 0.24961538461538457\n","\n","Candidate: 0.9997823734327647 \n","Score: 0.2407692307692307\n","\n","Candidate: 0.9997912638486497 \n","Score: 0.24096153846153842\n","\n","Candidate: 0.9998001603985702 \n","Score: 0.24134615384615382\n","\n","Candidate: 0.9998105044080348 \n","Score: 0.2415384615384615\n","\n","Candidate: 0.9998199067258482 \n","Score: 0.2415384615384615\n","\n","Candidate: 0.9998213364755795 \n","Score: 0.2417307692307692\n","\n","Candidate: 0.9998251858365632 \n","Score: 0.24192307692307688\n","\n","Candidate: 0.9998287724271062 \n","Score: 0.24192307692307688\n","\n","Candidate: 0.9998299521798835 \n","Score: 0.24211538461538457\n","\n","Candidate: 0.9998313111591157 \n","Score: 0.24288461538461537\n","\n","Candidate: 0.9998363946288995 \n","Score: 0.24288461538461537\n","\n","Candidate: 0.9998453376424136 \n","Score: 0.24326923076923074\n","\n","Candidate: 0.9998549997898556 \n","Score: 0.24346153846153845\n","\n","Candidate: 0.999859799230975 \n","Score: 0.24365384615384614\n","\n","Candidate: 0.9998606099278295 \n","Score: 0.2359615384615385\n","\n","Candidate: 0.9998621730045256 \n","Score: 0.2361538461538462\n","\n","Candidate: 0.9998711255436912 \n","Score: 0.23634615384615387\n","\n","Candidate: 0.9998810778866666 \n","Score: 0.23730769230769236\n","\n","Candidate: 0.9998858545658877 \n","Score: 0.23730769230769236\n","\n","Candidate: 0.9998888454197272 \n","Score: 0.23750000000000004\n","\n","Candidate: 0.999893766318773 \n","Score: 0.23750000000000004\n","\n","Candidate: 0.999904078112946 \n","Score: 0.23750000000000004\n","\n","Candidate: 0.9999106876329011 \n","Score: 0.23788461538461542\n","\n","Candidate: 0.9999120949101259 \n","Score: 0.23807692307692313\n","\n","Candidate: 0.9999125789798319 \n","Score: 0.24807692307692308\n","\n","Candidate: 0.9999144810186 \n","Score: 0.24826923076923077\n","\n","Candidate: 0.999917407058637 \n","Score: 0.24846153846153846\n","\n","Candidate: 0.9999196727055972 \n","Score: 0.24865384615384617\n","\n","Candidate: 0.9999209173143355 \n","Score: 0.24865384615384617\n","\n","Candidate: 0.999921713822576 \n","Score: 0.25153846153846154\n","\n","Candidate: 0.9999228816186284 \n","Score: 0.25173076923076926\n","\n","Candidate: 0.9999240493295045 \n","Score: 0.25173076923076926\n","\n","Candidate: 0.9999250394266876 \n","Score: 0.25173076923076926\n","\n","Candidate: 0.9999257038919279 \n","Score: 0.25211538461538463\n","\n","Candidate: 0.999926876864723 \n","Score: 0.25211538461538463\n","\n","Candidate: 0.9999302406394617 \n","Score: 0.25230769230769234\n","\n","Candidate: 0.9999363784990747 \n","Score: 0.25230769230769234\n","\n","Candidate: 0.999940287930589 \n","Score: 0.2525\n","\n","Candidate: 0.9999407932811823 \n","Score: 0.2525\n","\n","Candidate: 0.9999418119207559 \n","Score: 0.2526923076923077\n","\n","Candidate: 0.9999428276721853 \n","Score: 0.25288461538461543\n","\n","Candidate: 0.9999432003610988 \n","Score: 0.2530769230769231\n","\n","Candidate: 0.9999433173932946 \n","Score: 0.2532692307692308\n","\n","Candidate: 0.9999443021326279 \n","Score: 0.25403846153846155\n","\n","Candidate: 0.9999478135363614 \n","Score: 0.25423076923076926\n","\n","Candidate: 0.999950950096619 \n","Score: 0.25423076923076926\n","\n","Candidate: 0.9999520881022554 \n","Score: 0.2544230769230769\n","\n","Candidate: 0.999953000613953 \n","Score: 0.25480769230769235\n","\n","Candidate: 0.9999535366426099 \n","Score: 0.2561538461538462\n","\n","Candidate: 0.9999543290645376 \n","Score: 0.25634615384615383\n","\n","Candidate: 0.9999552458632233 \n","Score: 0.2661538461538462\n","\n","Candidate: 0.9999585763809526 \n","Score: 0.2663461538461539\n","\n","Candidate: 0.9999619999968481 \n","Score: 0.2663461538461539\n","\n","Candidate: 0.9999627101669518 \n","Score: 0.2663461538461539\n","\n","Candidate: 0.9999635893928879 \n","Score: 0.2665384615384616\n","\n","Candidate: 0.9999650403225935 \n","Score: 0.26673076923076927\n","\n","Candidate: 0.9999661333293455 \n","Score: 0.26673076923076927\n","\n","Candidate: 0.9999667652368291 \n","Score: 0.26673076923076927\n","\n","Candidate: 0.9999683077206989 \n","Score: 0.26692307692307693\n","\n","Candidate: 0.9999696644629767 \n","Score: 0.26711538461538464\n","\n","Candidate: 0.9999698320255672 \n","Score: 0.26750000000000007\n","\n","Candidate: 0.9999698674285147 \n","Score: 0.26769230769230773\n","\n","Candidate: 0.9999704392763644 \n","Score: 0.2678846153846154\n","\n","Candidate: 0.9999726633151287 \n","Score: 0.2678846153846154\n","\n","Candidate: 0.9999746926182802 \n","Score: 0.2678846153846154\n","\n","Candidate: 0.999975107940674 \n","Score: 0.2678846153846154\n","\n","Candidate: 0.9999758406646226 \n","Score: 0.2682692307692308\n","\n","Candidate: 0.9999767125190042 \n","Score: 0.26846153846153853\n","\n","Candidate: 0.9999770034424784 \n","Score: 0.2686538461538462\n","\n","Candidate: 0.9999775133903392 \n","Score: 0.2686538461538462\n","\n","Candidate: 0.9999780798703213 \n","Score: 0.2715384615384616\n","\n","Candidate: 0.9999784068532159 \n","Score: 0.2717307692307693\n","\n","Candidate: 0.9999786181819836 \n","Score: 0.2717307692307693\n","\n","Candidate: 0.9999788496851438 \n","Score: 0.271923076923077\n","\n","Candidate: 0.9999791896823536 \n","Score: 0.271923076923077\n","\n","Candidate: 0.999979450605192 \n","Score: 0.271923076923077\n","\n","Candidate: 0.9999798309887113 \n","Score: 0.271923076923077\n","\n","Candidate: 0.9999801314102842 \n","Score: 0.27211538461538465\n","\n","Candidate: 0.9999802562796114 \n","Score: 0.27211538461538465\n","\n","Candidate: 0.9999810811947044 \n","Score: 0.27230769230769236\n","\n","Candidate: 0.9999818615658542 \n","Score: 0.2725000000000001\n","\n","Candidate: 0.9999819577647824 \n","Score: 0.2732692307692308\n","\n","Candidate: 0.9999826306377975 \n","Score: 0.27346153846153853\n","\n","Candidate: 0.9999833824346565 \n","Score: 0.2736538461538462\n","\n","Candidate: 0.9999842867566477 \n","Score: 0.2738461538461539\n","\n","Candidate: 0.9999851259091388 \n","Score: 0.27519230769230774\n","\n","Candidate: 0.999985208054301 \n","Score: 0.27519230769230774\n","\n","Candidate: 0.9999855008717964 \n","Score: 0.27538461538461545\n","\n","Candidate: 0.9999859447096207 \n","Score: 0.2755769230769231\n","\n","Candidate: 0.999986334501379 \n","Score: 0.2755769230769231\n","\n","Candidate: 0.999986664708606 \n","Score: 0.2755769230769231\n","\n","Candidate: 0.9999871687525558 \n","Score: 0.2759615384615385\n","\n","Candidate: 0.9999877663041976 \n","Score: 0.2761538461538462\n","\n","Candidate: 0.9999880499174518 \n","Score: 0.2761538461538462\n","\n","Candidate: 0.9999883620294395 \n","Score: 0.27634615384615385\n","\n","Candidate: 0.9999886431641758 \n","Score: 0.27653846153846157\n","\n","Candidate: 0.9999887671004112 \n","Score: 0.2767307692307692\n","\n","Candidate: 0.9999892329644298 \n","Score: 0.27692307692307694\n","\n","Candidate: 0.9999898109519334 \n","Score: 0.27692307692307694\n","\n","Candidate: 0.9999900587602912 \n","Score: 0.2771153846153846\n","\n","Candidate: 0.9999902382432619 \n","Score: 0.2771153846153846\n","\n","Candidate: 0.9999903987863203 \n","Score: 0.27749999999999997\n","\n","Candidate: 0.9999906293533267 \n","Score: 0.27749999999999997\n","\n","Candidate: 0.999991082797052 \n","Score: 0.27749999999999997\n","\n","Candidate: 0.999991416898333 \n","Score: 0.27749999999999997\n","\n","Candidate: 0.9999915329488505 \n","Score: 0.2776923076923077\n","\n","Candidate: 0.9999917459440587 \n","Score: 0.2778846153846154\n","\n","Candidate: 0.9999919548487017 \n","Score: 0.2684615384615384\n","\n","Candidate: 0.99999203310972 \n","Score: 0.26865384615384613\n","\n","Candidate: 0.9999920635975157 \n","Score: 0.2690384615384615\n","\n","Candidate: 0.9999923476054544 \n","Score: 0.2690384615384615\n","\n","Candidate: 0.9999926650667984 \n","Score: 0.2692307692307692\n","\n","Candidate: 0.9999927113146974 \n","Score: 0.2692307692307692\n","\n","Candidate: 0.9999929482954538 \n","Score: 0.2694230769230769\n","\n","Candidate: 0.9999933678215807 \n","Score: 0.2696153846153846\n","\n","Candidate: 0.9999935968253395 \n","Score: 0.2696153846153846\n","\n","Candidate: 0.9999936603780493 \n","Score: 0.2696153846153846\n","\n","Candidate: 0.9999936961459626 \n","Score: 0.2696153846153846\n","\n","Candidate: 0.9999937213112573 \n","Score: 0.2698076923076923\n","\n","Candidate: 0.999993783608148 \n","Score: 0.27057692307692305\n","\n","Candidate: 0.9999939200711047 \n","Score: 0.27057692307692305\n","\n","Candidate: 0.9999941837162607 \n","Score: 0.27057692307692305\n","\n","Candidate: 0.9999944942692944 \n","Score: 0.27076923076923076\n","\n","Candidate: 0.999994666105278 \n","Score: 0.27076923076923076\n","\n","Candidate: 0.999994739168877 \n","Score: 0.27365384615384614\n","\n","Candidate: 0.9999947989822511 \n","Score: 0.27384615384615385\n","\n","Candidate: 0.999994853289643 \n","Score: 0.2751923076923076\n","\n","Candidate: 0.9999949876716241 \n","Score: 0.27538461538461534\n","\n","Candidate: 0.9999951413077941 \n","Score: 0.27538461538461534\n","\n","Candidate: 0.9999952937527207 \n","Score: 0.27538461538461534\n","\n","Candidate: 0.9999954179781698 \n","Score: 0.27557692307692305\n","\n","Candidate: 0.9999955327590668 \n","Score: 0.27557692307692305\n","\n","Candidate: 0.9999956484174315 \n","Score: 0.2757692307692307\n","\n","Candidate: 0.9999956922346873 \n","Score: 0.28557692307692306\n","\n","Candidate: 0.9999957392449835 \n","Score: 0.2857692307692307\n","\n","Candidate: 0.9999957811561668 \n","Score: 0.28596153846153843\n","\n","Candidate: 0.9999958440104972 \n","Score: 0.28596153846153843\n","\n","Candidate: 0.9999958920341036 \n","Score: 0.28596153846153843\n","\n","Candidate: 0.9999959706591788 \n","Score: 0.2861538461538461\n","\n","Candidate: 0.9999961037549442 \n","Score: 0.2863461538461538\n","\n","Candidate: 0.9999961677120356 \n","Score: 0.2863461538461538\n","\n","Candidate: 0.9999964156158418 \n","Score: 0.2865384615384615\n","\n","Candidate: 0.9999966673172949 \n","Score: 0.2869230769230769\n","\n","Candidate: 0.9999966867064051 \n","Score: 0.2869230769230769\n","\n","Candidate: 0.9999967596112298 \n","Score: 0.2869230769230769\n","\n","Candidate: 0.9999969205006134 \n","Score: 0.28730769230769226\n","\n","Candidate: 0.9999970294854598 \n","Score: 0.2875\n","\n","Candidate: 0.999997053885501 \n","Score: 0.2876923076923077\n","\n","Candidate: 0.9999971188862069 \n","Score: 0.2876923076923077\n","\n","Candidate: 0.999997186517952 \n","Score: 0.2876923076923077\n","\n","Candidate: 0.9999972139705595 \n","Score: 0.28788461538461535\n","\n","Candidate: 0.999997231512866 \n","Score: 0.288076923076923\n","\n","Candidate: 0.9999972437077724 \n","Score: 0.2882692307692307\n","\n","Candidate: 0.9999972686068397 \n","Score: 0.28865384615384615\n","\n","Candidate: 0.9999972928286716 \n","Score: 0.28865384615384615\n","\n","Candidate: 0.9999973558663249 \n","Score: 0.28865384615384615\n","\n","Candidate: 0.9999975047923952 \n","Score: 0.2888461538461538\n","\n","Candidate: 0.9999976333407155 \n","Score: 0.28903846153846147\n","\n","Candidate: 0.9999976745597249 \n","Score: 0.2892307692307692\n","\n","Candidate: 0.99999768863431 \n","Score: 0.29000000000000004\n","\n","Candidate: 0.9999977013926218 \n","Score: 0.29000000000000004\n","\n","Candidate: 0.9999977161464804 \n","Score: 0.2901923076923077\n","\n","Candidate: 0.9999977321685911 \n","Score: 0.2901923076923077\n","\n","Candidate: 0.9999977488370677 \n","Score: 0.2903846153846154\n","\n","Candidate: 0.9999978292539469 \n","Score: 0.2903846153846154\n","\n","Candidate: 0.9999979347320864 \n","Score: 0.2903846153846154\n","\n","Candidate: 0.9999980277392728 \n","Score: 0.2903846153846154\n","\n","Candidate: 0.9999980938109788 \n","Score: 0.2917307692307693\n","\n","Candidate: 0.9999981269782908 \n","Score: 0.291923076923077\n","\n","Candidate: 0.9999981702757059 \n","Score: 0.291923076923077\n","\n","Candidate: 0.9999982069070803 \n","Score: 0.291923076923077\n","\n","Candidate: 0.9999982988997347 \n","Score: 0.291923076923077\n","\n","Candidate: 0.9999983805600281 \n","Score: 0.29211538461538467\n","\n","Candidate: 0.9999983894890252 \n","Score: 0.29211538461538467\n","\n","Candidate: 0.9999984363114712 \n","Score: 0.2923076923076924\n","\n","Candidate: 0.9999985090118009 \n","Score: 0.2925000000000001\n","\n","Candidate: 0.9999985768116355 \n","Score: 0.29269230769230775\n","\n","Candidate: 0.9999986213617054 \n","Score: 0.29269230769230775\n","\n","Candidate: 0.99999863608082 \n","Score: 0.30673076923076925\n","\n","Candidate: 0.9999986581304203 \n","Score: 0.3069230769230769\n","\n","Candidate: 0.9999986838970918 \n","Score: 0.3069230769230769\n","\n","Candidate: 0.999998703998024 \n","Score: 0.3069230769230769\n","\n","Candidate: 0.9999987204742501 \n","Score: 0.30711538461538457\n","\n","Candidate: 0.9999987457151993 \n","Score: 0.30711538461538457\n","\n","Candidate: 0.9999988071445802 \n","Score: 0.3075\n","\n","Candidate: 0.9999988558607393 \n","Score: 0.3075\n","\n","Candidate: 0.99999886852837 \n","Score: 0.3076923076923077\n","\n","Candidate: 0.999998903092187 \n","Score: 0.3078846153846154\n","\n","Candidate: 0.999998933693784 \n","Score: 0.3080769230769231\n","\n","Candidate: 0.9999989454172893 \n","Score: 0.3082692307692308\n","\n","Candidate: 0.9999989634468772 \n","Score: 0.30846153846153845\n","\n","Candidate: 0.999998978177308 \n","Score: 0.30865384615384617\n","\n","Candidate: 0.9999989855592288 \n","Score: 0.3090384615384616\n","\n","Candidate: 0.9999990066582942 \n","Score: 0.3090384615384616\n","\n","Candidate: 0.999999032819248 \n","Score: 0.3090384615384616\n","\n","Candidate: 0.9999990534007279 \n","Score: 0.3092307692307693\n","\n","Candidate: 0.9999990905972591 \n","Score: 0.3092307692307693\n","\n","Candidate: 0.9999991179364474 \n","Score: 0.30942307692307697\n","\n","Candidate: 0.9999991292555517 \n","Score: 0.3205769230769231\n","\n","Candidate: 0.99999914324717 \n","Score: 0.3205769230769231\n","\n","Candidate: 0.9999991530192247 \n","Score: 0.3205769230769231\n","\n","Candidate: 0.999999167391703 \n","Score: 0.3205769230769231\n","\n","Candidate: 0.9999991921034157 \n","Score: 0.3209615384615385\n","\n","Candidate: 0.9999992155580921 \n","Score: 0.3209615384615385\n","\n","Candidate: 0.9999992250659465 \n","Score: 0.32115384615384623\n","\n","Candidate: 0.9999992279643279 \n","Score: 0.3213461538461539\n","\n","Candidate: 0.9999992318165993 \n","Score: 0.32153846153846155\n","\n","Candidate: 0.9999992429424276 \n","Score: 0.32153846153846155\n","\n","Candidate: 0.9999992621128329 \n","Score: 0.32153846153846155\n","\n","Candidate: 0.999999276962785 \n","Score: 0.32288461538461544\n","\n","Candidate: 0.9999992850541171 \n","Score: 0.32307692307692315\n","\n","Candidate: 0.9999993231895915 \n","Score: 0.32307692307692315\n","\n","Candidate: 0.9999993617146057 \n","Score: 0.32326923076923086\n","\n","Candidate: 0.9999993715268404 \n","Score: 0.3234615384615385\n","\n","Candidate: 0.9999993838236974 \n","Score: 0.3236538461538462\n","\n","Candidate: 0.9999993944569865 \n","Score: 0.3236538461538462\n","\n","Candidate: 0.9999994014264983 \n","Score: 0.3238461538461539\n","\n","Candidate: 0.9999994140610153 \n","Score: 0.3240384615384616\n","\n","Candidate: 0.9999994528614156 \n","Score: 0.32423076923076927\n","\n","Candidate: 0.9999994851055611 \n","Score: 0.32423076923076927\n","\n","Candidate: 0.9999994956610874 \n","Score: 0.32423076923076927\n","\n","Candidate: 0.9999995169417859 \n","Score: 0.3244230769230769\n","\n","Candidate: 0.9999995356640634 \n","Score: 0.32480769230769235\n","\n","Candidate: 0.9999995490083948 \n","Score: 0.32480769230769235\n","\n","Candidate: 0.9999995616145925 \n","Score: 0.32480769230769235\n","\n","Candidate: 0.9999995701746394 \n","Score: 0.32480769230769235\n","\n","Candidate: 0.9999995903401707 \n","Score: 0.325\n","\n","Candidate: 0.9999996066913874 \n","Score: 0.3251923076923077\n","\n","Candidate: 0.9999996094138108 \n","Score: 0.3253846153846154\n","\n","Candidate: 0.9999996127814239 \n","Score: 0.3255769230769231\n","\n","Candidate: 0.9999996197286576 \n","Score: 0.32596153846153847\n","\n","Candidate: 0.999999628097307 \n","Score: 0.32596153846153847\n","\n","Candidate: 0.99999963279099 \n","Score: 0.3286538461538462\n","\n","Candidate: 0.9999996372015771 \n","Score: 0.3288461538461539\n","\n","Candidate: 0.9999996421971362 \n","Score: 0.32903846153846156\n","\n","Candidate: 0.9999996471743877 \n","Score: 0.3292307692307692\n","\n","Candidate: 0.9999996549800876 \n","Score: 0.3292307692307692\n","\n","Candidate: 0.9999996627832695 \n","Score: 0.32942307692307693\n","\n","Candidate: 0.9999996654241697 \n","Score: 0.32961538461538464\n","\n","Candidate: 0.9999996733517266 \n","Score: 0.33019230769230773\n","\n","Candidate: 0.9999996819109357 \n","Score: 0.3303846153846154\n","\n","Candidate: 0.9999996857302784 \n","Score: 0.3303846153846154\n","\n","Candidate: 0.9999996910743287 \n","Score: 0.3303846153846154\n","\n","Candidate: 0.9999996993868722 \n","Score: 0.3303846153846154\n","\n","Candidate: 0.9999997058060213 \n","Score: 0.3303846153846154\n","\n","Candidate: 0.9999997076975415 \n","Score: 0.3303846153846154\n","\n","Candidate: 0.9999997121830874 \n","Score: 0.3303846153846154\n","\n","Candidate: 0.9999997164043444 \n","Score: 0.3303846153846154\n","\n","Candidate: 0.9999997188295286 \n","Score: 0.3303846153846154\n","\n","Candidate: 0.9999997222506727 \n","Score: 0.3305769230769231\n","\n","Candidate: 0.9999997241099752 \n","Score: 0.3307692307692308\n","\n","Candidate: 0.9999997257445047 \n","Score: 0.3321153846153846\n","\n","Candidate: 0.9999997347594722 \n","Score: 0.3323076923076923\n","\n","Candidate: 0.9999997503325282 \n","Score: 0.3323076923076923\n","\n","Candidate: 0.9999997640117759 \n","Score: 0.3323076923076923\n","\n","Candidate: 0.9999997733494967 \n","Score: 0.3323076923076923\n","\n","Candidate: 0.9999997776122843 \n","Score: 0.3325\n","\n","Candidate: 0.9999997781889225 \n","Score: 0.3325\n","\n","Candidate: 0.9999997788827486 \n","Score: 0.33288461538461533\n","\n","Candidate: 0.9999997804081152 \n","Score: 0.33307692307692305\n","\n","Candidate: 0.9999997853824196 \n","Score: 0.33326923076923076\n","\n","Candidate: 0.9999997901717737 \n","Score: 0.33326923076923076\n","\n","Candidate: 0.9999997913639087 \n","Score: 0.3334615384615384\n","\n","Candidate: 0.9999997986694653 \n","Score: 0.33365384615384613\n","\n","Candidate: 0.9999998109155449 \n","Score: 0.33365384615384613\n","\n","Candidate: 0.9999998167274149 \n","Score: 0.33365384615384613\n","\n","Candidate: 0.9999998194945994 \n","Score: 0.33365384615384613\n","\n","Candidate: 0.9999998222747064 \n","Score: 0.3340384615384615\n","\n","Candidate: 0.9999998260996354 \n","Score: 0.3342307692307692\n","\n","Candidate: 0.9999998308849134 \n","Score: 0.3342307692307692\n","\n","Candidate: 0.9999998322750393 \n","Score: 0.33442307692307693\n","\n","Candidate: 0.9999998334907667 \n","Score: 0.3346153846153846\n","\n","Candidate: 0.9999998384873796 \n","Score: 0.33480769230769225\n","\n","Candidate: 0.9999998459848931 \n","Score: 0.33499999999999996\n","\n","Candidate: 0.9999998510158601 \n","Score: 0.33499999999999996\n","\n","Candidate: 0.9999998529210943 \n","Score: 0.33499999999999996\n","\n","Candidate: 0.9999998539461334 \n","Score: 0.33538461538461534\n","\n","Candidate: 0.9999998553384485 \n","Score: 0.33557692307692305\n","\n","Candidate: 0.9999998563638433 \n","Score: 0.3357692307692307\n","\n","Candidate: 0.9999998618046391 \n","Score: 0.3359615384615384\n","\n","Candidate: 0.99999986879629 \n","Score: 0.3359615384615384\n","\n","Candidate: 0.9999998728361534 \n","Score: 0.3359615384615384\n","\n","Candidate: 0.9999998755329162 \n","Score: 0.3359615384615384\n","\n","Candidate: 0.9999998760830258 \n","Score: 0.33615384615384614\n","\n","Candidate: 0.9999998767402314 \n","Score: 0.33673076923076917\n","\n","Candidate: 0.9999998773540448 \n","Score: 0.3369230769230769\n","\n","Candidate: 0.9999998795327476 \n","Score: 0.3369230769230769\n","\n","Candidate: 0.9999998856632402 \n","Score: 0.3369230769230769\n","\n","Candidate: 0.9999998907941476 \n","Score: 0.33749999999999997\n","\n","Candidate: 0.9999998926006423 \n","Score: 0.33749999999999997\n","\n","Candidate: 0.9999998947567941 \n","Score: 0.33749999999999997\n","\n","Candidate: 0.9999998963086894 \n","Score: 0.33749999999999997\n","\n","Candidate: 0.9999998967109092 \n","Score: 0.3401923076923077\n","\n","Candidate: 0.9999998969493917 \n","Score: 0.3401923076923077\n","\n","Candidate: 0.9999998974199598 \n","Score: 0.3401923076923077\n","\n","Candidate: 0.9999998978537595 \n","Score: 0.34076923076923077\n","\n","Candidate: 0.9999998984238906 \n","Score: 0.35288461538461546\n","\n","Candidate: 0.9999999003130133 \n","Score: 0.3530769230769231\n","\n","Candidate: 0.9999999019353404 \n","Score: 0.3530769230769231\n","\n","Candidate: 0.9999999025514369 \n","Score: 0.3530769230769231\n","\n","Candidate: 0.9999999028875455 \n","Score: 0.3532692307692308\n","\n","Candidate: 0.9999999067432456 \n","Score: 0.3532692307692308\n","\n","Candidate: 0.999999914789544 \n","Score: 0.3534615384615385\n","\n","Candidate: 0.9999999205922989 \n","Score: 0.3536538461538462\n","\n","Candidate: 0.9999999224537164 \n","Score: 0.3536538461538462\n","\n","Candidate: 0.999999922776608 \n","Score: 0.35384615384615387\n","\n","Candidate: 0.9999999231587428 \n","Score: 0.3540384615384616\n","\n","Candidate: 0.9999999235827217 \n","Score: 0.3540384615384616\n","\n","Candidate: 0.9999999239482118 \n","Score: 0.3542307692307693\n","\n","Candidate: 0.9999999252451524 \n","Score: 0.3542307692307693\n","\n","Candidate: 0.9999999266837045 \n","Score: 0.3542307692307693\n","\n","Candidate: 0.9999999286436092 \n","Score: 0.34634615384615386\n","\n","Candidate: 0.9999999304105899 \n","Score: 0.34634615384615386\n","\n","Candidate: 0.9999999323285821 \n","Score: 0.34634615384615386\n","\n","Candidate: 0.9999999341758172 \n","Score: 0.3467307692307693\n","\n","Candidate: 0.9999999349843172 \n","Score: 0.34692307692307695\n","\n","Candidate: 0.999999936778069 \n","Score: 0.3471153846153846\n","\n","Candidate: 0.9999999385135889 \n","Score: 0.34750000000000003\n","\n","Candidate: 0.9999999403595807 \n","Score: 0.34750000000000003\n","\n","Candidate: 0.9999999416597645 \n","Score: 0.34769230769230774\n","\n","Candidate: 0.9999999421562312 \n","Score: 0.3478846153846154\n","\n","Candidate: 0.9999999434360439 \n","Score: 0.34807692307692306\n","\n","Candidate: 0.9999999450049273 \n","Score: 0.34807692307692306\n","\n","Candidate: 0.9999999458811044 \n","Score: 0.3484615384615385\n","\n","Candidate: 0.999999946546853 \n","Score: 0.3484615384615385\n","\n","Candidate: 0.9999999471684315 \n","Score: 0.3484615384615385\n","\n","Candidate: 0.9999999481260793 \n","Score: 0.3484615384615385\n","\n","Candidate: 0.9999999492920235 \n","Score: 0.3484615384615385\n","\n","Candidate: 0.9999999499248475 \n","Score: 0.3486538461538462\n","\n","Candidate: 0.9999999514988087 \n","Score: 0.34884615384615386\n","\n","Candidate: 0.9999999528905554 \n","Score: 0.3490384615384615\n","\n","Candidate: 0.9999999535220196 \n","Score: 0.34923076923076923\n","\n","Candidate: 0.9999999541048243 \n","Score: 0.34942307692307695\n","\n","Candidate: 0.9999999542049735 \n","Score: 0.35\n","\n","Candidate: 0.9999999543263924 \n","Score: 0.35\n","\n","Candidate: 0.9999999546072917 \n","Score: 0.35\n","\n","Candidate: 0.999999955519676 \n","Score: 0.35\n","\n","Candidate: 0.9999999565387194 \n","Score: 0.3501923076923077\n","\n","Candidate: 0.9999999568440179 \n","Score: 0.35038461538461535\n","\n","Candidate: 0.9999999578147909 \n","Score: 0.350576923076923\n","\n","Candidate: 0.9999999600569771 \n","Score: 0.3507692307692307\n","\n","Candidate: 0.9999999617619244 \n","Score: 0.3507692307692307\n","\n","Candidate: 0.9999999623792187 \n","Score: 0.35230769230769227\n","\n","Candidate: 0.9999999627398282 \n","Score: 0.3440384615384615\n","\n","Candidate: 0.9999999639873187 \n","Score: 0.3440384615384615\n","\n","Candidate: 0.9999999661478485 \n","Score: 0.3440384615384615\n","\n","Candidate: 0.9999999674238162 \n","Score: 0.34423076923076923\n","\n","Candidate: 0.9999999682550016 \n","Score: 0.34423076923076923\n","\n","Candidate: 0.9999999694370003 \n","Score: 0.34423076923076923\n","\n","Candidate: 0.9999999700563966 \n","Score: 0.3444230769230769\n","\n","Candidate: 0.9999999702181417 \n","Score: 0.3446153846153846\n","\n","Candidate: 0.9999999704456703 \n","Score: 0.34480769230769226\n","\n","Candidate: 0.9999999706087391 \n","Score: 0.34480769230769226\n","\n","Candidate: 0.9999999714485457 \n","Score: 0.345\n","\n","Candidate: 0.9999999726271056 \n","Score: 0.345\n","\n","Candidate: 0.9999999742153096 \n","Score: 0.3403846153846154\n","\n","Candidate: 0.999999975496919 \n","Score: 0.3403846153846154\n","\n","Candidate: 0.9999999757472772 \n","Score: 0.3407692307692308\n","\n","Candidate: 0.9999999759708247 \n","Score: 0.3409615384615385\n","\n","Candidate: 0.9999999764615997 \n","Score: 0.3409615384615385\n","\n","Candidate: 0.9999999769630887 \n","Score: 0.3409615384615385\n","\n","Candidate: 0.9999999770271297 \n","Score: 0.34115384615384614\n","\n","Candidate: 0.9999999771501102 \n","Score: 0.34134615384615385\n","\n","Candidate: 0.99999997731417 \n","Score: 0.34153846153846157\n","\n","Candidate: 0.9999999774524513 \n","Score: 0.34153846153846157\n","\n","Candidate: 0.9999999777179491 \n","Score: 0.34153846153846157\n","\n","Candidate: 0.999999978839579 \n","Score: 0.34153846153846157\n","\n","Candidate: 0.999999979811562 \n","Score: 0.3417307692307693\n","\n","Candidate: 0.9999999798693555 \n","Score: 0.34192307692307694\n","\n","Candidate: 0.9999999801073665 \n","Score: 0.3423076923076923\n","\n","Candidate: 0.9999999803451995 \n","Score: 0.3425\n","\n","Candidate: 0.9999999804969322 \n","Score: 0.3425\n","\n","Candidate: 0.9999999807176723 \n","Score: 0.34269230769230774\n","\n","Candidate: 0.9999999808391927 \n","Score: 0.34269230769230774\n","\n","Candidate: 0.9999999811487039 \n","Score: 0.3534615384615385\n","\n","Candidate: 0.9999999817252891 \n","Score: 0.3534615384615385\n","\n","Candidate: 0.999999982416149 \n","Score: 0.3534615384615385\n","\n","Candidate: 0.9999999833093809 \n","Score: 0.3536538461538462\n","\n","Candidate: 0.9999999839426194 \n","Score: 0.3540384615384616\n","\n","Candidate: 0.9999999841132085 \n","Score: 0.35423076923076924\n","\n","Candidate: 0.9999999844698342 \n","Score: 0.3548076923076923\n","\n","Candidate: 0.9999999850688025 \n","Score: 0.3671153846153847\n","\n","Candidate: 0.9999999854736192 \n","Score: 0.3671153846153847\n","\n","Candidate: 0.9999999859470148 \n","Score: 0.36730769230769234\n","\n","Candidate: 0.9999999865964304 \n","Score: 0.36730769230769234\n","\n","Candidate: 0.9999999869685741 \n","Score: 0.3682692307692308\n","\n","Candidate: 0.9999999873328105 \n","Score: 0.3682692307692308\n","\n","Candidate: 0.9999999876897074 \n","Score: 0.3684615384615385\n","\n","Candidate: 0.9999999877487855 \n","Score: 0.3686538461538462\n","\n","Candidate: 0.9999999877609702 \n","Score: 0.36115384615384616\n","\n","Candidate: 0.9999999878464538 \n","Score: 0.3613461538461539\n","\n","Candidate: 0.9999999879665081 \n","Score: 0.3615384615384616\n","\n","Candidate: 0.999999988061322 \n","Score: 0.36173076923076924\n","\n","Candidate: 0.999999988201643 \n","Score: 0.3619230769230769\n","\n","Candidate: 0.9999999883266371 \n","Score: 0.3621153846153846\n","\n","Candidate: 0.9999999884016973 \n","Score: 0.3621153846153846\n","\n","Candidate: 0.9999999885115218 \n","Score: 0.36230769230769233\n","\n","Candidate: 0.9999999887813471 \n","Score: 0.36230769230769233\n","\n","Candidate: 0.9999999891181873 \n","Score: 0.3625\n","\n","Candidate: 0.9999999892913667 \n","Score: 0.3625\n","\n","Candidate: 0.9999999894707021 \n","Score: 0.3626923076923077\n","\n","Candidate: 0.9999999898141865 \n","Score: 0.37403846153846154\n","\n","Candidate: 0.9999999900938378 \n","Score: 0.37403846153846154\n","\n","Candidate: 0.9999999903028771 \n","Score: 0.37403846153846154\n","\n","Candidate: 0.9999999905045521 \n","Score: 0.37423076923076926\n","\n","Candidate: 0.9999999906703005 \n","Score: 0.37423076923076926\n","\n","Candidate: 0.9999999907739854 \n","Score: 0.37423076923076926\n","\n","Candidate: 0.999999991061729 \n","Score: 0.37423076923076926\n","\n","Candidate: 0.999999991413453 \n","Score: 0.37442307692307697\n","\n","Candidate: 0.9999999915154538 \n","Score: 0.36576923076923074\n","\n","Candidate: 0.9999999915749935 \n","Score: 0.36615384615384616\n","\n","Candidate: 0.9999999917658691 \n","Score: 0.36615384615384616\n","\n","Candidate: 0.9999999919645779 \n","Score: 0.3663461538461538\n","\n","Candidate: 0.9999999920152115 \n","Score: 0.36653846153846154\n","\n","Candidate: 0.9999999920347907 \n","Score: 0.3667307692307692\n","\n","Candidate: 0.9999999921341762 \n","Score: 0.3669230769230769\n","\n","Candidate: 0.9999999923229341 \n","Score: 0.3671153846153846\n","\n","Candidate: 0.9999999925070646 \n","Score: 0.36730769230769234\n","\n","Candidate: 0.9999999927752787 \n","Score: 0.3675\n","\n","Candidate: 0.9999999929705423 \n","Score: 0.36999999999999994\n","\n","Candidate: 0.9999999930127133 \n","Score: 0.36999999999999994\n","\n","Candidate: 0.9999999932166797 \n","Score: 0.3703846153846153\n","\n","Candidate: 0.9999999934840269 \n","Score: 0.370576923076923\n","\n","Candidate: 0.9999999937275801 \n","Score: 0.370576923076923\n","\n","Candidate: 0.9999999938896955 \n","Score: 0.3707692307692307\n","\n","Candidate: 0.9999999940186305 \n","Score: 0.37249999999999994\n","\n","Candidate: 0.9999999943050382 \n","Score: 0.37249999999999994\n","\n","Candidate: 0.9999999945163873 \n","Score: 0.37249999999999994\n","\n","Candidate: 0.9999999945888326 \n","Score: 0.37269230769230766\n","\n","Candidate: 0.9999999946797102 \n","Score: 0.37288461538461537\n","\n","Candidate: 0.9999999948001035 \n","Score: 0.3730769230769231\n","\n","Candidate: 0.9999999948604604 \n","Score: 0.37326923076923074\n","\n","Candidate: 0.9999999949125247 \n","Score: 0.3734615384615384\n","\n","Candidate: 0.999999994987913 \n","Score: 0.37442307692307697\n","\n","Candidate: 0.9999999950660092 \n","Score: 0.3746153846153847\n","\n","Candidate: 0.9999999953570549 \n","Score: 0.3746153846153847\n","\n","Candidate: 0.9999999956842864 \n","Score: 0.3746153846153847\n","\n","Candidate: 0.999999995826857 \n","Score: 0.37500000000000006\n","\n","Candidate: 0.9999999959631736 \n","Score: 0.37500000000000006\n","\n","Candidate: 0.999999996086731 \n","Score: 0.3751923076923077\n","\n","Candidate: 0.9999999961933629 \n","Score: 0.3751923076923077\n","\n","Candidate: 0.9999999962831261 \n","Score: 0.3751923076923077\n","\n","Candidate: 0.9999999963129828 \n","Score: 0.3753846153846154\n","\n","Candidate: 0.9999999963277674 \n","Score: 0.37557692307692314\n","\n","Candidate: 0.999999996340986 \n","Score: 0.37576923076923086\n","\n","Candidate: 0.9999999963717257 \n","Score: 0.3759615384615385\n","\n","Candidate: 0.9999999964201995 \n","Score: 0.38576923076923086\n","\n","Candidate: 0.999999996445038 \n","Score: 0.3859615384615385\n","\n","Candidate: 0.9999999964636173 \n","Score: 0.3861538461538462\n","\n","Candidate: 0.9999999964858961 \n","Score: 0.3861538461538462\n","\n","Candidate: 0.9999999965266317 \n","Score: 0.3863461538461539\n","\n","Candidate: 0.9999999965676739 \n","Score: 0.3863461538461539\n","\n","Candidate: 0.9999999965959413 \n","Score: 0.3865384615384616\n","\n","Candidate: 0.9999999966266118 \n","Score: 0.3867307692307693\n","\n","Candidate: 0.9999999966531596 \n","Score: 0.3867307692307693\n","\n","Candidate: 0.9999999966770252 \n","Score: 0.38692307692307704\n","\n","Candidate: 0.9999999967148536 \n","Score: 0.38692307692307704\n","\n","Candidate: 0.9999999967537186 \n","Score: 0.3873076923076924\n","\n","Candidate: 0.9999999967816954 \n","Score: 0.38750000000000007\n","\n","Candidate: 0.9999999968588331 \n","Score: 0.3876923076923078\n","\n","Candidate: 0.9999999969860129 \n","Score: 0.3882692307692309\n","\n","Candidate: 0.9999999971825382 \n","Score: 0.3882692307692309\n","\n","Candidate: 0.9999999973157174 \n","Score: 0.3884615384615386\n","\n","Candidate: 0.9999999973392278 \n","Score: 0.38884615384615395\n","\n","Candidate: 0.9999999974019461 \n","Score: 0.38903846153846167\n","\n","Candidate: 0.9999999974540399 \n","Score: 0.3892307692307694\n","\n","Candidate: 0.9999999974662677 \n","Score: 0.38961538461538475\n","\n","Candidate: 0.9999999975073894 \n","Score: 0.3898076923076924\n","\n","Candidate: 0.9999999975523068 \n","Score: 0.3898076923076924\n","\n","Candidate: 0.9999999975889173 \n","Score: 0.3898076923076924\n","\n","Candidate: 0.9999999976561178 \n","Score: 0.3900000000000001\n","\n","Candidate: 0.99999999771066 \n","Score: 0.3815384615384616\n","\n","Candidate: 0.9999999978124132 \n","Score: 0.3817307692307693\n","\n","Candidate: 0.9999999979347223 \n","Score: 0.3826923076923078\n","\n","Candidate: 0.9999999979926797 \n","Score: 0.3828846153846155\n","\n","Candidate: 0.9999999980228025 \n","Score: 0.3828846153846155\n","\n","Candidate: 0.9999999980795378 \n","Score: 0.38538461538461555\n","\n","Candidate: 0.9999999981640739 \n","Score: 0.38538461538461555\n","\n","Candidate: 0.9999999982777454 \n","Score: 0.38538461538461555\n","\n","Candidate: 0.9999999983669441 \n","Score: 0.3855769230769232\n","\n","Candidate: 0.9999999983923653 \n","Score: 0.3855769230769232\n","\n","Candidate: 0.9999999984137009 \n","Score: 0.38576923076923086\n","\n","Candidate: 0.9999999984392555 \n","Score: 0.3859615384615386\n","\n","Candidate: 0.9999999984784568 \n","Score: 0.3859615384615386\n","\n","Candidate: 0.9999999984987096 \n","Score: 0.3861538461538463\n","\n","Candidate: 0.9999999985081351 \n","Score: 0.38634615384615395\n","\n","Candidate: 0.99999999852148 \n","Score: 0.3865384615384616\n","\n","Candidate: 0.9999999985308219 \n","Score: 0.3867307692307693\n","\n","Candidate: 0.9999999985463213 \n","Score: 0.38692307692307704\n","\n","Candidate: 0.9999999985664458 \n","Score: 0.38692307692307704\n","\n","Candidate: 0.9999999986030648 \n","Score: 0.3871153846153847\n","\n","Candidate: 0.9999999986381511 \n","Score: 0.3873076923076924\n","\n","Candidate: 0.9999999986841014 \n","Score: 0.3876923076923078\n","\n","Candidate: 0.999999998744795 \n","Score: 0.3876923076923078\n","\n","Candidate: 0.9999999987740873 \n","Score: 0.3876923076923078\n","\n","Candidate: 0.9999999987994598 \n","Score: 0.3878846153846155\n","\n","Candidate: 0.9999999988314485 \n","Score: 0.3882692307692308\n","\n","Candidate: 0.9999999988500341 \n","Score: 0.3884615384615385\n","\n","Candidate: 0.9999999988579147 \n","Score: 0.38865384615384624\n","\n","Candidate: 0.9999999988697776 \n","Score: 0.38884615384615395\n","\n","Candidate: 0.9999999988797775 \n","Score: 0.3890384615384616\n","\n","Candidate: 0.9999999988834029 \n","Score: 0.389423076923077\n","\n","Candidate: 0.9999999989082181 \n","Score: 0.3898076923076924\n","\n","Candidate: 0.9999999989355699 \n","Score: 0.3898076923076924\n","\n","Candidate: 0.9999999989542314 \n","Score: 0.3900000000000001\n","\n","Candidate: 0.9999999989945099 \n","Score: 0.3900000000000001\n","\n","Candidate: 0.9999999990228281 \n","Score: 0.3901923076923078\n","\n","Candidate: 0.9999999990289192 \n","Score: 0.3901923076923078\n","\n","Candidate: 0.9999999990545312 \n","Score: 0.3901923076923078\n","\n","Candidate: 0.9999999990829956 \n","Score: 0.39115384615384624\n","\n","Candidate: 0.9999999990894543 \n","Score: 0.3913461538461539\n","\n","Candidate: 0.9999999990936812 \n","Score: 0.3915384615384616\n","\n","Candidate: 0.9999999991008287 \n","Score: 0.3917307692307693\n","\n","Candidate: 0.9999999991043833 \n","Score: 0.391923076923077\n","\n","Candidate: 0.9999999991151123 \n","Score: 0.39211538461538464\n","\n","Candidate: 0.9999999991272247 \n","Score: 0.39211538461538464\n","\n","Candidate: 0.9999999991680807 \n","Score: 0.39230769230769236\n","\n","Candidate: 0.9999999992091722 \n","Score: 0.39230769230769236\n","\n","Candidate: 0.9999999992521114 \n","Score: 0.39230769230769236\n","\n","Candidate: 0.9999999993096327 \n","Score: 0.39250000000000007\n","\n","Candidate: 0.9999999993332206 \n","Score: 0.39250000000000007\n","\n","Candidate: 0.999999999347565 \n","Score: 0.39250000000000007\n","\n","Candidate: 0.9999999993562351 \n","Score: 0.3926923076923078\n","\n","Candidate: 0.999999999377174 \n","Score: 0.39288461538461544\n","\n","Candidate: 0.9999999993977947 \n","Score: 0.39307692307692316\n","\n","Candidate: 0.9999999994011708 \n","Score: 0.3932692307692308\n","\n","Candidate: 0.9999999994049411 \n","Score: 0.39365384615384624\n","\n","Candidate: 0.9999999994099633 \n","Score: 0.3938461538461539\n","\n","Candidate: 0.999999999430794 \n","Score: 0.39403846153846156\n","\n","Candidate: 0.9999999994560729 \n","Score: 0.3965384615384616\n","\n","Candidate: 0.999999999476835 \n","Score: 0.3967307692307693\n","\n","Candidate: 0.9999999994916362 \n","Score: 0.3967307692307693\n","\n","Candidate: 0.9999999994962857 \n","Score: 0.396923076923077\n","\n","Candidate: 0.9999999995040451 \n","Score: 0.396923076923077\n","\n","Candidate: 0.9999999995172799 \n","Score: 0.39730769230769236\n","\n","Candidate: 0.9999999995260598 \n","Score: 0.3975000000000001\n","\n","Candidate: 0.9999999995351159 \n","Score: 0.39788461538461545\n","\n","Candidate: 0.9999999995435851 \n","Score: 0.3980769230769231\n","\n","Candidate: 0.9999999995502415 \n","Score: 0.3982692307692308\n","\n","Candidate: 0.9999999995634234 \n","Score: 0.39846153846153853\n","\n","Candidate: 0.9999999995756594 \n","Score: 0.3986538461538462\n","\n","Candidate: 0.999999999582257 \n","Score: 0.3986538461538462\n","\n","Candidate: 0.9999999995855531 \n","Score: 0.3988461538461539\n","\n","Candidate: 0.9999999995894928 \n","Score: 0.39903846153846156\n","\n","Candidate: 0.9999999995934871 \n","Score: 0.39903846153846156\n","\n","Candidate: 0.9999999995959898 \n","Score: 0.3992307692307693\n","\n","Candidate: 0.9999999996015776 \n","Score: 0.399423076923077\n","\n","Candidate: 0.9999999996080969 \n","Score: 0.399423076923077\n","\n","Candidate: 0.9999999996117397 \n","Score: 0.40038461538461545\n","\n","Candidate: 0.999999999617369 \n","Score: 0.40038461538461545\n","\n","Candidate: 0.9999999996281737 \n","Score: 0.4005769230769231\n","\n","Candidate: 0.9999999996444069 \n","Score: 0.4007692307692308\n","\n","Candidate: 0.9999999996569635 \n","Score: 0.4007692307692308\n","\n","Candidate: 0.9999999996647738 \n","Score: 0.4009615384615385\n","\n","Candidate: 0.9999999996689788 \n","Score: 0.4013461538461539\n","\n","Candidate: 0.9999999996819812 \n","Score: 0.4013461538461539\n","\n","Candidate: 0.9999999996981903 \n","Score: 0.4013461538461539\n","\n","Candidate: 0.9999999997052702 \n","Score: 0.4015384615384616\n","\n","Candidate: 0.9999999997131828 \n","Score: 0.4015384615384616\n","\n","Candidate: 0.9999999997186843 \n","Score: 0.4015384615384616\n","\n","Candidate: 0.9999999997210471 \n","Score: 0.4017307692307693\n","\n","Candidate: 0.9999999997223075 \n","Score: 0.40192307692307694\n","\n","Candidate: 0.999999999723332 \n","Score: 0.40211538461538465\n","\n","Candidate: 0.9999999997359856 \n","Score: 0.40230769230769237\n","\n","Candidate: 0.9999999997485343 \n","Score: 0.40269230769230774\n","\n","Candidate: 0.9999999997525382 \n","Score: 0.4028846153846154\n","\n","Candidate: 0.9999999997569035 \n","Score: 0.4030769230769231\n","\n","Candidate: 0.99999999975843 \n","Score: 0.4030769230769231\n","\n","Candidate: 0.9999999997591179 \n","Score: 0.4032692307692308\n","\n","Candidate: 0.9999999997606833 \n","Score: 0.40346153846153854\n","\n","Candidate: 0.9999999997621914 \n","Score: 0.4036538461538462\n","\n","Candidate: 0.9999999997660713 \n","Score: 0.40384615384615385\n","\n","Candidate: 0.9999999997742477 \n","Score: 0.40403846153846157\n","\n","Candidate: 0.999999999782363 \n","Score: 0.40403846153846157\n","\n","Candidate: 0.999999999789156 \n","Score: 0.40403846153846157\n","\n","Candidate: 0.999999999801251 \n","Score: 0.40442307692307694\n","\n","Candidate: 0.9999999998104239 \n","Score: 0.40461538461538465\n","\n","Candidate: 0.9999999998129785 \n","Score: 0.405\n","\n","Candidate: 0.9999999998177371 \n","Score: 0.405\n","\n","Candidate: 0.9999999998214593 \n","Score: 0.40519230769230774\n","\n","Candidate: 0.9999999998248101 \n","Score: 0.40538461538461545\n","\n","Candidate: 0.9999999998278053 \n","Score: 0.4055769230769231\n","\n","Candidate: 0.9999999998299514 \n","Score: 0.4055769230769231\n","\n","Candidate: 0.9999999998334361 \n","Score: 0.4057692307692308\n","\n","Candidate: 0.9999999998356828 \n","Score: 0.39634615384615396\n","\n","Candidate: 0.9999999998360367 \n","Score: 0.3965384615384616\n","\n","Candidate: 0.9999999998400185 \n","Score: 0.3965384615384616\n","\n","Candidate: 0.9999999998445153 \n","Score: 0.3975000000000001\n","\n","Candidate: 0.9999999998466228 \n","Score: 0.3976923076923078\n","\n","Candidate: 0.9999999998480897 \n","Score: 0.3978846153846155\n","\n","Candidate: 0.9999999998497238 \n","Score: 0.39807692307692316\n","\n","Candidate: 0.9999999998512907 \n","Score: 0.3982692307692309\n","\n","Candidate: 0.9999999998529369 \n","Score: 0.4007692307692309\n","\n","Candidate: 0.9999999998561255 \n","Score: 0.4007692307692309\n","\n","Candidate: 0.9999999998595156 \n","Score: 0.40096153846153854\n","\n","Candidate: 0.9999999998643543 \n","Score: 0.40096153846153854\n","\n","Candidate: 0.9999999998694846 \n","Score: 0.4011538461538462\n","\n","Candidate: 0.9999999998765454 \n","Score: 0.4011538461538462\n","\n","Candidate: 0.999999999884239 \n","Score: 0.4011538461538462\n","\n","Candidate: 0.9999999998873073 \n","Score: 0.4013461538461539\n","\n","Candidate: 0.9999999998883276 \n","Score: 0.4013461538461539\n","\n","Candidate: 0.9999999998940341 \n","Score: 0.40153846153846157\n","\n","Candidate: 0.9999999998994307 \n","Score: 0.40192307692307694\n","\n","Candidate: 0.9999999998998678 \n","Score: 0.40211538461538465\n","\n","Candidate: 0.999999999900374 \n","Score: 0.4023076923076923\n","\n","Candidate: 0.9999999999009157 \n","Score: 0.40249999999999997\n","\n","Candidate: 0.9999999999012815 \n","Score: 0.4026923076923077\n","\n","Candidate: 0.9999999999019781 \n","Score: 0.4028846153846154\n","\n","Candidate: 0.9999999999029676 \n","Score: 0.4028846153846154\n","\n","Candidate: 0.9999999999038045 \n","Score: 0.40307692307692305\n","\n","Candidate: 0.999999999905073 \n","Score: 0.40307692307692305\n","\n","Candidate: 0.9999999999062497 \n","Score: 0.40326923076923077\n","\n","Candidate: 0.9999999999083333 \n","Score: 0.4034615384615384\n","\n","Candidate: 0.999999999910507 \n","Score: 0.4034615384615384\n","\n","Candidate: 0.9999999999109854 \n","Score: 0.40384615384615385\n","\n","Candidate: 0.9999999999118963 \n","Score: 0.4040384615384615\n","\n","Candidate: 0.9999999999147993 \n","Score: 0.4042307692307692\n","\n","Candidate: 0.9999999999177172 \n","Score: 0.4046153846153846\n","\n","Candidate: 0.9999999999190692 \n","Score: 0.4046153846153846\n","\n","Candidate: 0.9999999999216768 \n","Score: 0.4048076923076923\n","\n","Candidate: 0.9999999999238532 \n","Score: 0.4048076923076923\n","\n","Candidate: 0.9999999999241695 \n","Score: 0.40499999999999997\n","\n","Candidate: 0.9999999999260232 \n","Score: 0.40538461538461534\n","\n","Candidate: 0.9999999999285685 \n","Score: 0.40557692307692306\n","\n","Candidate: 0.999999999929888 \n","Score: 0.4057692307692307\n","\n","Candidate: 0.999999999930462 \n","Score: 0.4057692307692307\n","\n","Candidate: 0.9999999999315354 \n","Score: 0.4057692307692307\n","\n","Candidate: 0.9999999999344371 \n","Score: 0.408076923076923\n","\n","Candidate: 0.9999999999365423 \n","Score: 0.408076923076923\n","\n","Candidate: 0.999999999937115 \n","Score: 0.4082692307692307\n","\n","Candidate: 0.9999999999395603 \n","Score: 0.4107692307692307\n","\n","Candidate: 0.9999999999417293 \n","Score: 0.4109615384615384\n","\n","Candidate: 0.9999999999424949 \n","Score: 0.4109615384615384\n","\n","Candidate: 0.9999999999433618 \n","Score: 0.4111538461538461\n","\n","Candidate: 0.9999999999445397 \n","Score: 0.41134615384615375\n","\n","Candidate: 0.9999999999456051 \n","Score: 0.41134615384615375\n","\n","Candidate: 0.9999999999468052 \n","Score: 0.41153846153846146\n","\n","Candidate: 0.9999999999483471 \n","Score: 0.40211538461538454\n","\n","Candidate: 0.9999999999495514 \n","Score: 0.4023076923076922\n","\n","Candidate: 0.9999999999521805 \n","Score: 0.4023076923076922\n","\n","Candidate: 0.9999999999541523 \n","Score: 0.4023076923076922\n","\n","Candidate: 0.9999999999545691 \n","Score: 0.40480769230769226\n","\n","Candidate: 0.9999999999562843 \n","Score: 0.40499999999999997\n","\n","Candidate: 0.9999999999581501 \n","Score: 0.40499999999999997\n","\n","Candidate: 0.9999999999591196 \n","Score: 0.40499999999999997\n","\n","Candidate: 0.9999999999597129 \n","Score: 0.4053846153846154\n","\n","Candidate: 0.9999999999606239 \n","Score: 0.40557692307692306\n","\n","Candidate: 0.9999999999615875 \n","Score: 0.40576923076923077\n","\n","Candidate: 0.9999999999618292 \n","Score: 0.40596153846153843\n","\n","Candidate: 0.9999999999621267 \n","Score: 0.40615384615384614\n","\n","Candidate: 0.9999999999623429 \n","Score: 0.4063461538461538\n","\n","Candidate: 0.9999999999626581 \n","Score: 0.4065384615384615\n","\n","Candidate: 0.9999999999632342 \n","Score: 0.4067307692307692\n","\n","Candidate: 0.9999999999635251 \n","Score: 0.4067307692307692\n","\n","Candidate: 0.9999999999639142 \n","Score: 0.4069230769230769\n","\n","Candidate: 0.9999999999646756 \n","Score: 0.40711538461538455\n","\n","Candidate: 0.9999999999652295 \n","Score: 0.40730769230769226\n","\n","Candidate: 0.9999999999656255 \n","Score: 0.40730769230769226\n","\n","Candidate: 0.9999999999662172 \n","Score: 0.4074999999999999\n","\n","Candidate: 0.9999999999666904 \n","Score: 0.40769230769230763\n","\n","Candidate: 0.9999999999673468 \n","Score: 0.408076923076923\n","\n","Candidate: 0.9999999999681252 \n","Score: 0.408076923076923\n","\n","Candidate: 0.9999999999684039 \n","Score: 0.4082692307692307\n","\n","Candidate: 0.9999999999687462 \n","Score: 0.4086538461538461\n","\n","Candidate: 0.9999999999691566 \n","Score: 0.4088461538461538\n","\n","Candidate: 0.9999999999694491 \n","Score: 0.4088461538461538\n","\n","Candidate: 0.9999999999700018 \n","Score: 0.4088461538461538\n","\n","Candidate: 0.9999999999712713 \n","Score: 0.4090384615384615\n","\n","Candidate: 0.9999999999723548 \n","Score: 0.4090384615384615\n","\n","Candidate: 0.9999999999728715 \n","Score: 0.4094230769230769\n","\n","Candidate: 0.9999999999735724 \n","Score: 0.4096153846153846\n","\n","Candidate: 0.9999999999743716 \n","Score: 0.41038461538461535\n","\n","Candidate: 0.9999999999751972 \n","Score: 0.410576923076923\n","\n","Candidate: 0.9999999999759126 \n","Score: 0.410576923076923\n","\n","Candidate: 0.9999999999765501 \n","Score: 0.4107692307692307\n","\n","Candidate: 0.9999999999770535 \n","Score: 0.4107692307692307\n","\n","Candidate: 0.9999999999773257 \n","Score: 0.41096153846153843\n","\n","Candidate: 0.9999999999781135 \n","Score: 0.41115384615384615\n","\n","Candidate: 0.9999999999789827 \n","Score: 0.41115384615384615\n","\n","Candidate: 0.9999999999801088 \n","Score: 0.41115384615384615\n","\n","Candidate: 0.9999999999811935 \n","Score: 0.41134615384615386\n","\n","Candidate: 0.9999999999818874 \n","Score: 0.41134615384615386\n","\n","Candidate: 0.9999999999825034 \n","Score: 0.41134615384615386\n","\n","Candidate: 0.9999999999828737 \n","Score: 0.41134615384615386\n","\n","Candidate: 0.9999999999832361 \n","Score: 0.41173076923076923\n","\n","Candidate: 0.9999999999834434 \n","Score: 0.4119230769230769\n","\n","Candidate: 0.99999999998363 \n","Score: 0.41211538461538455\n","\n","Candidate: 0.9999999999837861 \n","Score: 0.42769230769230765\n","\n","Candidate: 0.9999999999841015 \n","Score: 0.42769230769230765\n","\n","Candidate: 0.9999999999843946 \n","Score: 0.4278846153846153\n","\n","Candidate: 0.9999999999845146 \n","Score: 0.428076923076923\n","\n","Candidate: 0.999999999984742 \n","Score: 0.4282692307692307\n","\n","Candidate: 0.9999999999850049 \n","Score: 0.4284615384615384\n","\n","Candidate: 0.9999999999851933 \n","Score: 0.41942307692307684\n","\n","Candidate: 0.9999999999853343 \n","Score: 0.41942307692307684\n","\n","Candidate: 0.9999999999854825 \n","Score: 0.41961538461538456\n","\n","Candidate: 0.9999999999857981 \n","Score: 0.4198076923076922\n","\n","Candidate: 0.9999999999860686 \n","Score: 0.41999999999999993\n","\n","Candidate: 0.9999999999863052 \n","Score: 0.4203846153846153\n","\n","Candidate: 0.9999999999864949 \n","Score: 0.42057692307692296\n","\n","Candidate: 0.9999999999868014 \n","Score: 0.4207692307692307\n","\n","Candidate: 0.9999999999871176 \n","Score: 0.42096153846153833\n","\n","Candidate: 0.9999999999872158 \n","Score: 0.42115384615384605\n","\n","Candidate: 0.999999999987293 \n","Score: 0.42115384615384605\n","\n","Candidate: 0.9999999999873515 \n","Score: 0.42134615384615376\n","\n","Candidate: 0.9999999999875879 \n","Score: 0.4215384615384614\n","\n","Candidate: 0.9999999999878131 \n","Score: 0.42173076923076913\n","\n","Candidate: 0.9999999999878477 \n","Score: 0.42192307692307685\n","\n","Candidate: 0.9999999999880964 \n","Score: 0.4223076923076922\n","\n","Candidate: 0.9999999999885207 \n","Score: 0.4223076923076922\n","\n","Candidate: 0.9999999999888073 \n","Score: 0.4224999999999999\n","\n","Candidate: 0.9999999999893515 \n","Score: 0.4226923076923076\n","\n","Candidate: 0.9999999999898468 \n","Score: 0.42288461538461525\n","\n","Candidate: 0.9999999999899349 \n","Score: 0.42288461538461525\n","\n","Candidate: 0.999999999990091 \n","Score: 0.42365384615384605\n","\n","Candidate: 0.9999999999903113 \n","Score: 0.4240384615384614\n","\n","Candidate: 0.9999999999904301 \n","Score: 0.4242307692307691\n","\n","Candidate: 0.9999999999904852 \n","Score: 0.4244230769230768\n","\n","Candidate: 0.9999999999908638 \n","Score: 0.42461538461538445\n","\n","Candidate: 0.9999999999915847 \n","Score: 0.42461538461538445\n","\n","Candidate: 0.9999999999920288 \n","Score: 0.42461538461538445\n","\n","Candidate: 0.9999999999921994 \n","Score: 0.42461538461538445\n","\n","Candidate: 0.9999999999923502 \n","Score: 0.42461538461538445\n","\n","Candidate: 0.9999999999926417 \n","Score: 0.42480769230769216\n","\n","Candidate: 0.9999999999929636 \n","Score: 0.42480769230769216\n","\n","Candidate: 0.9999999999931484 \n","Score: 0.4249999999999998\n","\n","Candidate: 0.999999999993312 \n","Score: 0.4251923076923076\n","\n","Candidate: 0.9999999999933555 \n","Score: 0.4253846153846153\n","\n","Candidate: 0.9999999999934438 \n","Score: 0.42557692307692296\n","\n","Candidate: 0.9999999999935552 \n","Score: 0.42596153846153834\n","\n","Candidate: 0.9999999999935945 \n","Score: 0.42596153846153834\n","\n","Candidate: 0.9999999999936466 \n","Score: 0.42615384615384605\n","\n","Candidate: 0.9999999999936858 \n","Score: 0.4263461538461537\n","\n","Candidate: 0.9999999999936938 \n","Score: 0.4265384615384614\n","\n","Candidate: 0.9999999999937768 \n","Score: 0.4267307692307691\n","\n","Candidate: 0.999999999993902 \n","Score: 0.42692307692307685\n","\n","Candidate: 0.9999999999940306 \n","Score: 0.42923076923076925\n","\n","Candidate: 0.9999999999941809 \n","Score: 0.42923076923076925\n","\n","Candidate: 0.9999999999943381 \n","Score: 0.4294230769230769\n","\n","Candidate: 0.9999999999945395 \n","Score: 0.4294230769230769\n","\n","Candidate: 0.9999999999946656 \n","Score: 0.4296153846153846\n","\n","Candidate: 0.9999999999948044 \n","Score: 0.43\n","\n","Candidate: 0.9999999999949611 \n","Score: 0.43019230769230765\n","\n","Candidate: 0.9999999999950155 \n","Score: 0.43038461538461537\n","\n","Candidate: 0.9999999999950491 \n","Score: 0.430576923076923\n","\n","Candidate: 0.9999999999950806 \n","Score: 0.4309615384615384\n","\n","Candidate: 0.9999999999951854 \n","Score: 0.4309615384615384\n","\n","Candidate: 0.9999999999953748 \n","Score: 0.4311538461538461\n","\n","Candidate: 0.9999999999956032 \n","Score: 0.43134615384615377\n","\n","Candidate: 0.9999999999957416 \n","Score: 0.4315384615384615\n","\n","Candidate: 0.9999999999957753 \n","Score: 0.4315384615384615\n","\n","Candidate: 0.9999999999958253 \n","Score: 0.4317307692307692\n","\n","Candidate: 0.9999999999958891 \n","Score: 0.43192307692307685\n","\n","Candidate: 0.9999999999959608 \n","Score: 0.4326923076923076\n","\n","Candidate: 0.9999999999960164 \n","Score: 0.4328846153846153\n","\n","Candidate: 0.9999999999961025 \n","Score: 0.433076923076923\n","\n","Candidate: 0.9999999999962407 \n","Score: 0.4332692307692307\n","\n","Candidate: 0.9999999999963374 \n","Score: 0.4332692307692307\n","\n","Candidate: 0.9999999999963688 \n","Score: 0.4334615384615384\n","\n","Candidate: 0.9999999999964597 \n","Score: 0.43384615384615377\n","\n","Candidate: 0.9999999999965822 \n","Score: 0.43384615384615377\n","\n","Candidate: 0.9999999999966197 \n","Score: 0.4340384615384615\n","\n","Candidate: 0.9999999999966327 \n","Score: 0.43423076923076914\n","\n","Candidate: 0.9999999999967094 \n","Score: 0.43423076923076914\n","\n","Candidate: 0.9999999999968268 \n","Score: 0.43423076923076914\n","\n","Candidate: 0.9999999999968949 \n","Score: 0.43442307692307686\n","\n","Candidate: 0.9999999999969512 \n","Score: 0.4346153846153845\n","\n","Candidate: 0.9999999999970226 \n","Score: 0.4346153846153845\n","\n","Candidate: 0.9999999999970666 \n","Score: 0.43480769230769223\n","\n","Candidate: 0.9999999999971879 \n","Score: 0.4349999999999999\n","\n","Candidate: 0.9999999999973037 \n","Score: 0.4351923076923076\n","\n","Candidate: 0.9999999999973304 \n","Score: 0.4351923076923076\n","\n","Candidate: 0.9999999999973588 \n","Score: 0.43538461538461537\n","\n","Candidate: 0.999999999997427 \n","Score: 0.43576923076923074\n","\n","Candidate: 0.9999999999974962 \n","Score: 0.4359615384615384\n","\n","Candidate: 0.999999999997532 \n","Score: 0.4361538461538461\n","\n","Candidate: 0.9999999999975611 \n","Score: 0.43634615384615383\n","\n","Candidate: 0.9999999999976527 \n","Score: 0.43634615384615383\n","\n","Candidate: 0.9999999999977577 \n","Score: 0.4365384615384615\n","\n","Candidate: 0.9999999999978013 \n","Score: 0.4365384615384615\n","\n","Candidate: 0.9999999999978529 \n","Score: 0.4369230769230769\n","\n","Candidate: 0.9999999999978744 \n","Score: 0.4371153846153846\n","\n","Candidate: 0.9999999999978783 \n","Score: 0.4373076923076923\n","\n","Candidate: 0.9999999999978895 \n","Score: 0.4376923076923077\n","\n","Candidate: 0.9999999999979012 \n","Score: 0.43788461538461537\n","\n","Candidate: 0.9999999999979261 \n","Score: 0.44019230769230766\n","\n","Candidate: 0.9999999999980232 \n","Score: 0.44019230769230766\n","\n","Candidate: 0.9999999999981223 \n","Score: 0.4403846153846153\n","\n","Candidate: 0.9999999999981812 \n","Score: 0.4403846153846153\n","\n","Candidate: 0.9999999999982345 \n","Score: 0.44057692307692303\n","\n","Candidate: 0.9999999999982951 \n","Score: 0.44134615384615383\n","\n","Candidate: 0.9999999999983633 \n","Score: 0.4415384615384615\n","\n","Candidate: 0.9999999999983915 \n","Score: 0.4417307692307692\n","\n","Candidate: 0.9999999999984159 \n","Score: 0.44192307692307686\n","\n","Candidate: 0.9999999999984431 \n","Score: 0.4421153846153846\n","\n","Candidate: 0.999999999998475 \n","Score: 0.4421153846153846\n","\n","Candidate: 0.9999999999985234 \n","Score: 0.4421153846153846\n","\n","Candidate: 0.9999999999985609 \n","Score: 0.44230769230769224\n","\n","Candidate: 0.9999999999985827 \n","Score: 0.44249999999999995\n","\n","Candidate: 0.9999999999985938 \n","Score: 0.44249999999999995\n","\n","Candidate: 0.9999999999986042 \n","Score: 0.44269230769230766\n","\n","Candidate: 0.99999999999862 \n","Score: 0.4428846153846153\n","\n","Candidate: 0.9999999999986493 \n","Score: 0.44307692307692303\n","\n","Candidate: 0.9999999999986724 \n","Score: 0.4432692307692307\n","\n","Candidate: 0.9999999999986985 \n","Score: 0.4434615384615384\n","\n","Candidate: 0.9999999999987328 \n","Score: 0.4434615384615384\n","\n","Candidate: 0.9999999999987449 \n","Score: 0.4438461538461538\n","\n","Candidate: 0.9999999999987601 \n","Score: 0.44403846153846144\n","\n","Candidate: 0.9999999999987979 \n","Score: 0.44423076923076915\n","\n","Candidate: 0.999999999998828 \n","Score: 0.44423076923076915\n","\n","Candidate: 0.9999999999988523 \n","Score: 0.44442307692307687\n","\n","Candidate: 0.9999999999988844 \n","Score: 0.4448076923076923\n","\n","Candidate: 0.9999999999989115 \n","Score: 0.445\n","\n","Candidate: 0.9999999999989289 \n","Score: 0.4451923076923077\n","\n","Candidate: 0.999999999998949 \n","Score: 0.44538461538461543\n","\n","Candidate: 0.9999999999989743 \n","Score: 0.44538461538461543\n","\n","Candidate: 0.9999999999989984 \n","Score: 0.4455769230769231\n","\n","Candidate: 0.9999999999990148 \n","Score: 0.4457692307692308\n","\n","Candidate: 0.9999999999990437 \n","Score: 0.4461538461538462\n","\n","Candidate: 0.9999999999990752 \n","Score: 0.46961538461538466\n","\n","Candidate: 0.9999999999990914 \n","Score: 0.48000000000000004\n","\n","Candidate: 0.999999999999106 \n","Score: 0.48019230769230775\n","\n","Candidate: 0.9999999999991201 \n","Score: 0.48038461538461547\n","\n","Candidate: 0.9999999999991352 \n","Score: 0.48038461538461547\n","\n","Candidate: 0.9999999999991562 \n","Score: 0.48038461538461547\n","\n","Candidate: 0.9999999999991809 \n","Score: 0.4805769230769232\n","\n","Candidate: 0.9999999999991881 \n","Score: 0.4813461538461539\n","\n","Candidate: 0.9999999999991929 \n","Score: 0.4813461538461539\n","\n","Candidate: 0.9999999999992187 \n","Score: 0.4815384615384616\n","\n","Candidate: 0.9999999999992644 \n","Score: 0.4817307692307693\n","\n","Candidate: 0.9999999999992952 \n","Score: 0.48192307692307695\n","\n","Candidate: 0.9999999999993039 \n","Score: 0.4842307692307693\n","\n","Candidate: 0.9999999999993165 \n","Score: 0.48442307692307696\n","\n","Candidate: 0.9999999999993294 \n","Score: 0.48461538461538467\n","\n","Candidate: 0.9999999999993349 \n","Score: 0.48480769230769233\n","\n","Candidate: 0.9999999999993594 \n","Score: 0.48500000000000004\n","\n","Candidate: 0.999999999999382 \n","Score: 0.4853846153846154\n","\n","Candidate: 0.9999999999993869 \n","Score: 0.4853846153846154\n","\n","Candidate: 0.9999999999994158 \n","Score: 0.48557692307692313\n","\n","Candidate: 0.9999999999994419 \n","Score: 0.48557692307692313\n","\n","Candidate: 0.9999999999994487 \n","Score: 0.4857692307692308\n","\n","Candidate: 0.9999999999994578 \n","Score: 0.4859615384615385\n","\n","Candidate: 0.9999999999994684 \n","Score: 0.48615384615384616\n","\n","Candidate: 0.9999999999994771 \n","Score: 0.48653846153846153\n","\n","Candidate: 0.9999999999994816 \n","Score: 0.48673076923076924\n","\n","Candidate: 0.9999999999994877 \n","Score: 0.48673076923076924\n","\n","Candidate: 0.999999999999495 \n","Score: 0.4869230769230769\n","\n","Candidate: 0.9999999999995004 \n","Score: 0.4871153846153847\n","\n","Candidate: 0.999999999999508 \n","Score: 0.4873076923076924\n","\n","Candidate: 0.9999999999995195 \n","Score: 0.48750000000000004\n","\n","Candidate: 0.9999999999995253 \n","Score: 0.48769230769230776\n","\n","Candidate: 0.999999999999539 \n","Score: 0.4878846153846154\n","\n","Candidate: 0.9999999999995554 \n","Score: 0.48807692307692313\n","\n","Candidate: 0.9999999999995598 \n","Score: 0.48134615384615387\n","\n","Candidate: 0.9999999999995621 \n","Score: 0.4815384615384616\n","\n","Candidate: 0.9999999999995649 \n","Score: 0.48192307692307695\n","\n","Candidate: 0.9999999999995739 \n","Score: 0.4821153846153846\n","\n","Candidate: 0.9999999999995867 \n","Score: 0.4825\n","\n","Candidate: 0.9999999999995928 \n","Score: 0.4825\n","\n","Candidate: 0.9999999999996156 \n","Score: 0.4826923076923077\n","\n","Candidate: 0.9999999999996385 \n","Score: 0.48288461538461536\n","\n","Candidate: 0.9999999999996494 \n","Score: 0.48365384615384616\n","\n","Candidate: 0.9999999999996598 \n","Score: 0.48365384615384616\n","\n","Candidate: 0.9999999999996706 \n","Score: 0.4838461538461538\n","\n","Candidate: 0.9999999999996837 \n","Score: 0.48403846153846153\n","\n","Candidate: 0.9999999999996878 \n","Score: 0.4842307692307692\n","\n","Candidate: 0.9999999999996971 \n","Score: 0.4842307692307692\n","\n","Candidate: 0.9999999999997065 \n","Score: 0.4844230769230769\n","\n","Candidate: 0.9999999999997082 \n","Score: 0.48461538461538456\n","\n","Candidate: 0.9999999999997176 \n","Score: 0.4848076923076923\n","\n","Candidate: 0.999999999999734 \n","Score: 0.48499999999999993\n","\n","Candidate: 0.999999999999743 \n","Score: 0.48499999999999993\n","\n","Candidate: 0.999999999999752 \n","Score: 0.48519230769230776\n","\n","Candidate: 0.9999999999997624 \n","Score: 0.48538461538461547\n","\n","Candidate: 0.9999999999997662 \n","Score: 0.48557692307692313\n","\n","Candidate: 0.9999999999997671 \n","Score: 0.4859615384615385\n","\n","Candidate: 0.999999999999769 \n","Score: 0.48826923076923073\n","\n","Candidate: 0.9999999999997711 \n","Score: 0.4884615384615385\n","\n","Candidate: 0.9999999999997746 \n","Score: 0.4884615384615385\n","\n","Candidate: 0.9999999999997791 \n","Score: 0.4886538461538461\n","\n","Candidate: 0.9999999999997806 \n","Score: 0.4888461538461539\n","\n","Candidate: 0.9999999999997824 \n","Score: 0.48903846153846153\n","\n","Candidate: 0.9999999999997873 \n","Score: 0.48903846153846153\n","\n","Candidate: 0.9999999999997923 \n","Score: 0.48923076923076925\n","\n","Candidate: 0.999999999999799 \n","Score: 0.4894230769230769\n","\n","Candidate: 0.9999999999998047 \n","Score: 0.4896153846153846\n","\n","Candidate: 0.9999999999998064 \n","Score: 0.4898076923076923\n","\n","Candidate: 0.9999999999998137 \n","Score: 0.49\n","\n","Candidate: 0.999999999999823 \n","Score: 0.49019230769230765\n","\n","Candidate: 0.999999999999827 \n","Score: 0.49038461538461536\n","\n","Candidate: 0.999999999999828 \n","Score: 0.490576923076923\n","\n","Candidate: 0.9999999999998289 \n","Score: 0.4909615384615384\n","\n","Candidate: 0.9999999999998332 \n","Score: 0.49115384615384605\n","\n","Candidate: 0.9999999999998386 \n","Score: 0.4915384615384615\n","\n","Candidate: 0.9999999999998418 \n","Score: 0.49173076923076914\n","\n","Candidate: 0.9999999999998446 \n","Score: 0.49192307692307685\n","\n","Candidate: 0.9999999999998516 \n","Score: 0.49211538461538457\n","\n","Candidate: 0.9999999999998577 \n","Score: 0.49211538461538457\n","\n","Candidate: 0.9999999999998592 \n","Score: 0.49288461538461537\n","\n","Candidate: 0.9999999999998621 \n","Score: 0.49326923076923074\n","\n","Candidate: 0.9999999999998652 \n","Score: 0.4934615384615384\n","\n","Candidate: 0.9999999999998666 \n","Score: 0.4936538461538461\n","\n","Candidate: 0.9999999999998714 \n","Score: 0.49384615384615377\n","\n","Candidate: 0.9999999999998769 \n","Score: 0.4940384615384615\n","\n","Candidate: 0.9999999999998785 \n","Score: 0.4940384615384615\n","\n","Candidate: 0.9999999999998807 \n","Score: 0.49423076923076914\n","\n","Candidate: 0.999999999999885 \n","Score: 0.49442307692307685\n","\n","Candidate: 0.9999999999998899 \n","Score: 0.4946153846153845\n","\n","Candidate: 0.9999999999998939 \n","Score: 0.4946153846153845\n","\n","Candidate: 0.9999999999998967 \n","Score: 0.4948076923076922\n","\n","Candidate: 0.9999999999999003 \n","Score: 0.49499999999999994\n","\n","Candidate: 0.9999999999999057 \n","Score: 0.4951923076923076\n","\n","Candidate: 0.999999999999909 \n","Score: 0.49557692307692297\n","\n","Candidate: 0.9999999999999103 \n","Score: 0.49557692307692297\n","\n","Candidate: 0.9999999999999112 \n","Score: 0.49557692307692297\n","\n","Candidate: 0.9999999999999118 \n","Score: 0.4957692307692307\n","\n","Candidate: 0.9999999999999134 \n","Score: 0.49596153846153834\n","\n","Candidate: 0.9999999999999156 \n","Score: 0.49615384615384606\n","\n","Candidate: 0.9999999999999194 \n","Score: 0.493076923076923\n","\n","Candidate: 0.999999999999923 \n","Score: 0.4932692307692307\n","\n","Candidate: 0.999999999999925 \n","Score: 0.4934615384615384\n","\n","Candidate: 0.9999999999999261 \n","Score: 0.4936538461538461\n","\n","Candidate: 0.9999999999999265 \n","Score: 0.4938461538461538\n","\n","Candidate: 0.9999999999999275 \n","Score: 0.4940384615384616\n","\n","Candidate: 0.9999999999999283 \n","Score: 0.4942307692307693\n","\n","Candidate: 0.999999999999929 \n","Score: 0.494423076923077\n","\n","Candidate: 0.9999999999999296 \n","Score: 0.4946153846153847\n","\n","Candidate: 0.9999999999999307 \n","Score: 0.4948076923076924\n","\n","Candidate: 0.9999999999999327 \n","Score: 0.4948076923076924\n","\n","Candidate: 0.9999999999999343 \n","Score: 0.49500000000000005\n","\n","Candidate: 0.9999999999999363 \n","Score: 0.49519230769230776\n","\n","Candidate: 0.9999999999999383 \n","Score: 0.4953846153846154\n","\n","Candidate: 0.9999999999999386 \n","Score: 0.4955769230769231\n","\n","Candidate: 0.9999999999999394 \n","Score: 0.4959615384615385\n","\n","Candidate: 0.9999999999999416 \n","Score: 0.4961538461538462\n","\n","Candidate: 0.9999999999999432 \n","Score: 0.4963461538461539\n","\n","Candidate: 0.9999999999999446 \n","Score: 0.49653846153846154\n","\n","Candidate: 0.9999999999999463 \n","Score: 0.49673076923076925\n","\n","Candidate: 0.9999999999999472 \n","Score: 0.4969230769230769\n","\n","Candidate: 0.9999999999999485 \n","Score: 0.4971153846153846\n","\n","Candidate: 0.9999999999999496 \n","Score: 0.4978846153846154\n","\n","Candidate: 0.99999999999995 \n","Score: 0.4980769230769231\n","\n","Candidate: 0.9999999999999505 \n","Score: 0.49846153846153846\n","\n","Candidate: 0.9999999999999525 \n","Score: 0.49865384615384617\n","\n","Candidate: 0.9999999999999544 \n","Score: 0.49884615384615383\n","\n","Candidate: 0.9999999999999548 \n","Score: 0.49884615384615383\n","\n","Candidate: 0.9999999999999551 \n","Score: 0.49884615384615383\n","\n","Candidate: 0.9999999999999563 \n","Score: 0.4992307692307692\n","\n","Candidate: 0.999999999999958 \n","Score: 0.4996153846153846\n","\n","Candidate: 0.9999999999999603 \n","Score: 0.49980769230769223\n","\n","Candidate: 0.9999999999999618 \n","Score: 0.49999999999999994\n","\n","Candidate: 0.9999999999999623 \n","Score: 0.49999999999999994\n","\n","Candidate: 0.9999999999999631 \n","Score: 0.5001923076923076\n","\n","Candidate: 0.9999999999999645 \n","Score: 0.5003846153846153\n","\n","Candidate: 0.9999999999999656 \n","Score: 0.5003846153846153\n","\n","Candidate: 0.9999999999999667 \n","Score: 0.500576923076923\n","\n","Candidate: 0.9999999999999685 \n","Score: 0.5126923076923076\n","\n","Candidate: 0.99999999999997 \n","Score: 0.5128846153846153\n","\n","Candidate: 0.9999999999999702 \n","Score: 0.513076923076923\n","\n","Candidate: 0.9999999999999705 \n","Score: 0.5132692307692306\n","\n","Candidate: 0.9999999999999707 \n","Score: 0.5134615384615383\n","\n","Candidate: 0.9999999999999709 \n","Score: 0.513653846153846\n","\n","Candidate: 0.9999999999999716 \n","Score: 0.5138461538461537\n","\n","Candidate: 0.9999999999999734 \n","Score: 0.5140384615384614\n","\n","Candidate: 0.9999999999999746 \n","Score: 0.5161538461538461\n","\n","Candidate: 0.9999999999999748 \n","Score: 0.5161538461538461\n","\n","Candidate: 0.9999999999999751 \n","Score: 0.516470588235294\n","\n","Candidate: 0.9999999999999756 \n","Score: 0.5166666666666666\n","\n","Candidate: 0.999999999999976 \n","Score: 0.5166666666666666\n","\n","Candidate: 0.9999999999999765 \n","Score: 0.5170588235294118\n","\n","Candidate: 0.9999999999999767 \n","Score: 0.5170588235294118\n","\n","Candidate: 0.9999999999999769 \n","Score: 0.5176470588235293\n","\n","Candidate: 0.9999999999999772 \n","Score: 0.5178431372549019\n","\n","Candidate: 0.9999999999999784 \n","Score: 0.5180392156862745\n","\n","Candidate: 0.9999999999999796 \n","Score: 0.5182352941176471\n","\n","Candidate: 0.9999999999999801 \n","Score: 0.5184313725490196\n","\n","Candidate: 0.9999999999999806 \n","Score: 0.5184313725490196\n","\n","Candidate: 0.9999999999999807 \n","Score: 0.5184313725490196\n","\n","Candidate: 0.9999999999999809 \n","Score: 0.5194117647058824\n","\n","Candidate: 0.9999999999999811 \n","Score: 0.5196078431372548\n","\n","Candidate: 0.9999999999999818 \n","Score: 0.52\n","\n","Candidate: 0.9999999999999825 \n","Score: 0.52\n","\n","Candidate: 0.9999999999999829 \n","Score: 0.520392156862745\n","\n","Candidate: 0.9999999999999835 \n","Score: 0.5205882352941176\n","\n","Candidate: 0.9999999999999838 \n","Score: 0.5211764705882354\n","\n","Candidate: 0.999999999999984 \n","Score: 0.5213725490196078\n","\n","Candidate: 0.9999999999999843 \n","Score: 0.5213725490196078\n","\n","Candidate: 0.9999999999999848 \n","Score: 0.5217647058823529\n","\n","Candidate: 0.999999999999986 \n","Score: 0.5219607843137255\n","\n","Candidate: 0.9999999999999871 \n","Score: 0.5219607843137255\n","\n","Candidate: 0.9999999999999873 \n","Score: 0.5225490196078431\n","\n","Candidate: 0.9999999999999875 \n","Score: 0.5229411764705882\n","\n","Candidate: 0.9999999999999877 \n","Score: 0.5233333333333334\n","\n","Candidate: 0.999999999999988 \n","Score: 0.5235294117647059\n","\n","Candidate: 0.9999999999999888 \n","Score: 0.5237254901960784\n","\n","Candidate: 0.9999999999999896 \n","Score: 0.5247058823529412\n","\n","Candidate: 0.9999999999999898 \n","Score: 0.5250980392156863\n","\n","Candidate: 0.9999999999999901 \n","Score: 0.5194000000000001\n","\n","Candidate: 0.9999999999999902 \n","Score: 0.5194000000000001\n","\n","Candidate: 0.9999999999999905 \n","Score: 0.52\n","\n","Candidate: 0.9999999999999906 \n","Score: 0.5202\n","\n","Candidate: 0.9999999999999911 \n","Score: 0.5207999999999999\n","\n","Candidate: 0.9999999999999916 \n","Score: 0.5209999999999999\n","\n","Candidate: 0.999999999999992 \n","Score: 0.5267999999999999\n","\n","Candidate: 0.9999999999999922 \n","Score: 0.5271999999999999\n","\n","Candidate: 0.9999999999999926 \n","Score: 0.5281999999999998\n","\n","Candidate: 0.9999999999999929 \n","Score: 0.5281999999999998\n","\n","Candidate: 0.9999999999999931 \n","Score: 0.5283999999999999\n","\n","Candidate: 0.9999999999999933 \n","Score: 0.5285999999999998\n","\n","Candidate: 0.9999999999999938 \n","Score: 0.5287999999999999\n","\n","Candidate: 0.999999999999994 \n","Score: 0.5293999999999999\n","\n","Candidate: 0.9999999999999942 \n","Score: 0.5295999999999998\n","\n","Candidate: 0.9999999999999944 \n","Score: 0.5297999999999999\n","\n","Candidate: 0.9999999999999947 \n","Score: 0.5299999999999999\n","\n","Candidate: 0.9999999999999949 \n","Score: 0.5301999999999998\n","\n","Candidate: 0.9999999999999951 \n","Score: 0.5309999999999999\n","\n","Candidate: 0.9999999999999953 \n","Score: 0.5315999999999999\n","\n","Candidate: 0.9999999999999956 \n","Score: 0.5321999999999999\n","\n","Candidate: 0.9999999999999958 \n","Score: 0.5324\n","\n","Candidate: 0.999999999999996 \n","Score: 0.5327999999999999\n","\n","Candidate: 0.9999999999999962 \n","Score: 0.5333999999999999\n","\n","Candidate: 0.9999999999999964 \n","Score: 0.5339999999999998\n","\n","Candidate: 0.9999999999999967 \n","Score: 0.5339999999999998\n","\n","Candidate: 0.9999999999999969 \n","Score: 0.5353999999999999\n","\n","Candidate: 0.9999999999999971 \n","Score: 0.5359999999999999\n","\n","Candidate: 0.9999999999999973 \n","Score: 0.5384\n","\n","Candidate: 0.9999999999999974 \n","Score: 0.5289795918367347\n","\n","Candidate: 0.9999999999999976 \n","Score: 0.5289795918367347\n","\n","Candidate: 0.9999999999999978 \n","Score: 0.5295918367346939\n","\n","Candidate: 0.999999999999998 \n","Score: 0.5310204081632655\n","\n","Candidate: 0.9999999999999982 \n","Score: 0.5318367346938777\n","\n","Candidate: 0.9999999999999984 \n","Score: 0.5342857142857143\n","\n","Candidate: 0.9999999999999987 \n","Score: 0.535625\n","\n","Candidate: 0.9999999999999989 \n","Score: 0.5417021276595745\n","\n","Candidate: 0.9999999999999991 \n","Score: 0.5446808510638299\n","\n","Candidate: 0.9999999999999993 \n","Score: 0.546808510638298\n","\n","Candidate: 0.9999999999999996 \n","Score: 0.5506382978723405\n","\n","Candidate: 0.9999999999999998 \n","Score: 0.5565957446808512\n","\n","Candidate: 1.0 \n","Score: 0.5439534883720931\n","\n"]}]},{"cell_type":"code","source":["# aim is to minimise cost function -- find index in array where this is the case\n","lowest_cf_score = np.min(np.array(cost_function_values))\n","index_best_th = np.argmin(np.array(cost_function_values))"],"metadata":{"id":"P2IsLZXQ77oZ","executionInfo":{"status":"ok","timestamp":1651141592506,"user_tz":-60,"elapsed":56,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":182,"outputs":[]},{"cell_type":"code","source":["lowest_cf_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iZ3ba0jhY0I","executionInfo":{"status":"ok","timestamp":1651141592506,"user_tz":-60,"elapsed":53,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"a06c47de-8162-4ea5-8cdd-b53cee3882d8"},"execution_count":183,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.17403846153846156"]},"metadata":{},"execution_count":183}]},{"cell_type":"code","source":["index_best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBS0v3GAh77m","executionInfo":{"status":"ok","timestamp":1651141592506,"user_tz":-60,"elapsed":17,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"b1e049f8-6d90-48a9-b4d6-bee8e4e9b467"},"execution_count":184,"outputs":[{"output_type":"execute_result","data":{"text/plain":["38"]},"metadata":{},"execution_count":184}]},{"cell_type":"code","source":["best_th = list(threshold_candidates)[index_best_th]\n","best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmy0bv8N8YvW","executionInfo":{"status":"ok","timestamp":1651141592507,"user_tz":-60,"elapsed":16,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"bdb52dd0-3a52-4d1e-a3bf-009db9970fba"},"execution_count":185,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9857958695917803"]},"metadata":{},"execution_count":185}]},{"cell_type":"markdown","source":["#### Testing with best threshold"],"metadata":{"id":"ypFTpLSAir09"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions excluding the current test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # count inconclusive results\n","  inconc_count = 0\n","  \n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    for i in range(len(predictions)):\n","\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","    \n","      if(c >= best_th): # best confidence threshold from cost function\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","\n","        earliness.append(time_index/timestamps[-1])\n","\n","        if(pred == 1.0):\n","          print(f\"TTP: {time_to_result + 30}s\")\n","\n","        break\n","\n","      if(i == len(predictions)-1):\n","        print(\"Inconclusive\")\n","        inconc_count += 1\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","  print(f\"Average Earliness: {sum(earliness)/len(earliness)}\")\n","  print(f\"Total Inconclusive: {inconc_count}/{sample_idx}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfPwqWWHiqnY","executionInfo":{"status":"ok","timestamp":1651141698547,"user_tz":-60,"elapsed":5997,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"5f47c24e-56f6-461d-d076-6bcc0072bd46"},"execution_count":187,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_86_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 140.0s\n","\n","Sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 135.0s\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 161.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 142.0s\n","\n","Sample exp_28_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_14_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_40_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 164.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 162.0s\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 183s\n","\n","Sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 136.0s\n","\n","Sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 158.0s\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 159.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 161.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 163.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 167.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 164.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 139.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 140.0s\n","\n","Sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 179.0s\n","\n","Sample rv1y_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample rv1y_p4\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 166.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 191.0s\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 157.0s\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 161.0s\n","\n","Sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 160.0s\n","\n","Sample exp_118_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 162s\n","\n","Sample exp_86_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_129_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_165_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_35_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 169s\n","\n","Sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_14_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_40_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_97_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 162s\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 168.0s\n","\n","Sample yap1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample yap1n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 159.0s\n","\n","Sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145y_n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv7\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 166.0s\n","\n","Sample du145a_p1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145a_p2\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145a_p3\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Accuracy: 0.7692307692307693\n","Sensitivity/Recall: 0.7857142857142857\n","Specificity: 0.75\n","Precision: 0.7857142857142857\n","F1 Score: 0.7857142857142857\n","Average Earliness: 0.11730769230769239\n","Total Inconclusive: 0/52\n"]}]},{"cell_type":"markdown","source":["#### Testing with different alpha values"],"metadata":{"id":"w43_TkUVitvi"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"pJXWD05RjB-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"NSkTWcddjB-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981439090,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"f742fd4d-fa2c-4f24-c18f-ffde40f1d377","id":"KWOXfxRKjB-i"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"NXrd_74JjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"wcE9LintjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"qb9FWSPgjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are mad of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"bM7ILJSwjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981450827,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"23bf8873-4159-42ca-fc01-82fcb7e27198","id":"36WDfG-TjB-l"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1184"]},"metadata":{},"execution_count":497}]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  acc = []\n","  ear = []\n","\n","  for i in range(0,100,5):\n","\n","    # alpha\n","    alpha = i/100\n","\n","    print(f\"Alpha: {alpha}\")\n","\n","    # array to hold cost function value for each candidate\n","    cost_function_values = []\n","\n","    # create nN predictions using each dataset as the test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # evaluate every candidate\n","    for th in threshold_candidates:\n","\n","      # print(f\"Candidate: {th} \")\n","\n","      # array to hold earliness values for the samples \n","      earliness = []  \n","\n","      # dict to hold predictions vs true values for the samples  \n","      final_classifications = {}\n","\n","      # sample index\n","      sample_idx = 0\n","\n","      for key, value in all_samples.items():\n","        test_sample_name = key\n","        test_sample = value\n","  \n","        # get KNN predicition for the sample\n","        predictions = sample_predictions[sample_idx]\n","\n","        for i in range(len(predictions)):\n","\n","          # get the confidence for that prediction \n","          c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","          if(c >= th): # check if confidence is above confidence threshold\n","\n","            time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","            time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","            # predicted class for the sample is given by the prediction which led to the gien confidence value\n","            pred = predictions[i]\n","\n","            # update final outcomes dict\n","            final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","            # add to earliness array\n","            earliness.append(time_index/timestamps[-1])\n","\n","            break\n","        sample_idx += 1\n","\n","      # get avg accuracy and avg earliness for this threshold\n","      if(len(final_classifications) > 0):\n","        avg_accuracy = accuracy(final_classifications)\n","        avg_earliness = sum(earliness)/len(earliness)\n","\n","        # compute value of cost function and add to array \n","        cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","        cost_function_values.append(cf_score)\n","\n","    index_best_th = np.argmin(np.array(cost_function_values))    \n","    best_th = list(threshold_candidates)[index_best_th]\n","\n","###########################################################################################################\n","\n","    ## teating with best th\n","    final_classifications = {}\n","    earliness = []\n","\n","    # create nN predictions excluding the current test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    # count inconclusive results\n","    inconc_count = 0\n","    \n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      \n","        if(c >= best_th): # best confidence threshold from cost function\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          pred = predictions[i]\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","          earliness.append(time_index/timestamps[-1])\n","          break\n","\n","        if(i == len(predictions)-1):\n","          inconc_count += 1\n","      \n","      sample_idx += 1\n","\n","    print(f\"Avg Accuracy: {accuracy(final_classifications)}\")\n","    print(f\"Avg Earliness: {sum(earliness)/len(earliness)}\")\n","    print(\"\")\n","    acc.append(accuracy(final_classifications))\n","    ear.append(sum(earliness)/len(earliness))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"V6Fhz4hsiui6","executionInfo":{"status":"error","timestamp":1650981574100,"user_tz":-60,"elapsed":121427,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"5e8c4f9a-49b2-44fb-eed4-3494af98bb4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Alpha: 0.0\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.05\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.1\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.15\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-498-89cc9171be6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# create nN predictions excluding the current test sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0msample_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_predictions_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# create multipliers for every classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-66-ab459af536aa>\u001b[0m in \u001b[0;36mgenerate_predictions_table\u001b[0;34m(positives, negatives, timestamps)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_sample_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-100-5619c2d01103>\u001b[0m in \u001b[0;36mget_training_data_knn\u001b[0;34m(positive_samples, negative_samples, timestamp, test_samples)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m## truncate sample to length t = timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpos_subsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Average Output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## append subsample of length t to training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m             \u001b[0;31m# shortcut if the key is in columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3424\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3425\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4538\u001b[0m         \"\"\"\n\u001b[1;32m   4539\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = acc\n","y = ear\n","axes.set_xlabel(\"Accuracy\")\n","axes.set_ylabel(\"Earliness\")\n","axes.plot(x,y, '-o')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"R0a7Bbrabp6R","executionInfo":{"status":"ok","timestamp":1650975154308,"user_tz":-60,"elapsed":485,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"ecaa763d-1bfa-4fdc-9a86-c2e35604c565"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f4beae35050>]"]},"metadata":{},"execution_count":347},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"simepEdKIiL0"},"source":["### Github Commands"]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"YdlGDV3AzZ1L","executionInfo":{"status":"ok","timestamp":1651142212741,"user_tz":-60,"elapsed":246,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"137443d4-00d7-44c5-86cf-72139c7f009c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":193,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itbAqo9qGukN","outputId":"cc2fe625-b278-42d5-d46e-42822e92047a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project\n"]}],"source":["username = \"adityag16\"\n","git_token = \"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\"\n","repository = \"/content/drive/MyDrive/Final-Year-Project\"\n","%cd {repository}\n","!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNInxPqdG7nx"},"outputs":[],"source":["!git add 'Early Time Series Classification - Average Ouput.ipynb' 'Best Performances.docx'\n","!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1tS6nonHF9u"},"outputs":[],"source":["!git config --global user.email \"aditya.gupta18@imperial.ac.uk\"\n","!git config --global user.name \"adityag16\"\n","\n","!git commit -m \"Code Cleanup\"\n","!git push origin main"]},{"cell_type":"code","source":[""],"metadata":{"id":"8KO_iVTj0cIP"},"execution_count":null,"outputs":[]}]}
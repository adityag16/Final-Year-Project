{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Early Time Series Classification - Average Ouput.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1WYaF_HRa3IGG6auTN3SvWNlJMYRlk-43","authorship_tag":"ABX9TyPkuydhyi7EoLnmxbeCZpTx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Connect Drive"],"metadata":{"id":"XVaAULW6qhh1"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15568,"status":"ok","timestamp":1651222988336,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"_DdiqzlkZMhe","outputId":"173d86fb-c436-48ed-9bee-e9da3cd6e650"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"markdown","metadata":{"id":"ttpluWU4tHLq"},"source":["### Package Imports"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"Z_3NHgGwZIsI","executionInfo":{"status":"ok","timestamp":1651223164006,"user_tz":-60,"elapsed":343,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.signal import savgol_filter\n","from collections import Counter\n","import copy\n","from collections import defaultdict\n","from scipy.optimize import curve_fit\n","from scipy.signal import filtfilt"]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from scipy.spatial import distance\n","from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances"],"metadata":{"id":"5vMvjgqYCd2d","executionInfo":{"status":"ok","timestamp":1651222993537,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### GPU Device"],"metadata":{"id":"6cosBM9Jd74f"}},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kElpooT1fLzz","executionInfo":{"status":"ok","timestamp":1651223000192,"user_tz":-60,"elapsed":407,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"49e9288f-c227-4169-cf69-f48641dae443"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-670de5ef-3f12-9bce-204a-30bb253f0b26)\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1651223004699,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"bLu_lZGKu9dp","outputId":"3d1801c0-5b6b-4320-c488-7b03e536b558"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["gpu = tf.test.gpu_device_name()\n","print(gpu)"]},{"cell_type":"markdown","metadata":{"id":"ihJkU1v2STVo"},"source":["### Pre-Processing Helper Functions"]},{"cell_type":"code","source":["def decaying_exp(x, a, b):\n","    \"\"\" Returns exponential function\n","    Parameters\n","    ----------\n","    x : ndarray\n","        times\n","    a : double\n","        t(inf) value\n","    b : double\n","        slope to t=0\n","    Returns\n","    -------\n","    ndarray\n","        y-axis values of the function\n","    \"\"\"\n","    return a*(1-np.exp(-b * x))\n","\n","\n","def fit_pixels_interpolate(time, X, interpolate_idx):\n","    \"\"\" Interpolates the curves for each pixel\n","    Parameters\n","    ----------\n","    time : ndarray\n","        times\n","    X : ndarray\n","        TxNM array to be interpolated\n","    idx_active : ndarray\n","        NM array specifying pixels that are active\n","    interpolate_idx : int\n","        interpolation is performed until this index\n","    Returns\n","    -------\n","    popt : ndarray\n","        optimal parameters for interpolation of each pixel, with shape 2xNM\n","    \"\"\"\n","    popt = np.zeros((2, X.shape[1]))\n","\n","    # for every pixel\n","    for i in range(X.shape[1]):\n","\n","      data = filtfilt(b=np.ones(10) / 10, a=[1], x=X[:, i])\n","\n","      # Fit the curve (interpolate)\n","      try:\n","        popt[:, i], pcov = curve_fit(decaying_exp, time[:interpolate_idx], data[:interpolate_idx], p0=[-10, 0.1])\n","      except:\n","        # print('EXCEPT: could not fit this pixel', i)\n","        popt[:, i] = None\n","\n","    return popt"],"metadata":{"id":"g1nRYshEtGy2","executionInfo":{"status":"ok","timestamp":1651223036942,"user_tz":-60,"elapsed":368,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def filter_by_drift(df, interpolate_idx):\n","\n","  popt = fit_pixels_interpolate(np.array(df.index), df.values, interpolate_idx)\n","\n","  drift_avg = np.zeros(df.shape[0])\n","  pix_count = 0\n","  active = np.array(np.zeros(df.shape[1]), dtype=bool)\n","\n","  for idx in range(df.shape[1]):\n","\n","  # check if any of the drift params for the pixel are nan\n","    if(np.isnan(popt[0, idx]) and np.isnan(popt[1, idx])):\n","      active[idx] = False\n","    else:\n","      # if drift params exist then iterate over the values of the index and use these as x values for the drift curve\n","      y_vals = []\n","      for i in df.index:\n","        val = decaying_exp(i, popt[0,idx], popt[1,idx])\n","        y_vals.append(val)\n","      \n","      # subtract the extrapolated drift from the signal\n","      drift_error = np.abs(np.array(df.values[:, idx] - y_vals))\n","      \n","      # only keep pixels with drift error of less than 10mV\n","      if((drift_error < 12).all()):\n","        drift_avg = np.add(drift_avg, np.array(y_vals))\n","        pix_count += 1\n","        active[idx] = True\n","      else:\n","        active[idx] = False\n","\n","  drift_avg/=pix_count\n","\n","  df = df.loc[:, active]\n","\n","  return df, drift_avg"],"metadata":{"id":"R9gzaEl7wE7H","executionInfo":{"status":"ok","timestamp":1651223038321,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"W1YMbu9bSW5m","executionInfo":{"status":"ok","timestamp":1651223039764,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vref(X, v_thresh=70):\n","    '''\n","    Identifies active pixels by checking if one of the first 10 derivatives d(i) is > v_thresh\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_thresh : int, optional\n","        Minimum value of the derivative d(i)=X(i+1)-X(i) in mV. Default is 70\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if, during the first 10 samples,\n","        one of the derivatives is > v_thresh. The derivatives are calculated as d(i) = X(i+1)-X(i)\n","    '''\n","    return (np.diff(X[:10, :], axis=0) > v_thresh).any(axis=0)  # check if one of the first 10 derivatives is >v_thresh"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XjXkAhKwSgFB","executionInfo":{"status":"ok","timestamp":1651223047631,"user_tz":-60,"elapsed":388,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vrange(X, v_range=(100, 900)):\n","    '''\n","    Identifies active pixels by checking that all the values are in v_range\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_range : (int, int), optional\n","        tuple containing the minimum and maximum allowable voltage in mV. Default is (100, 900)\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if the value is always in v_range\n","    '''\n","    return (X < v_range[1]).all(axis=0) & (X > v_range[0]).all(axis=0)  # for each pixel, check if all the values are\n","    # within the given range\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"G5a7Uqi9Skg_","executionInfo":{"status":"ok","timestamp":1651223048014,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_derivative(X, vthresh=5):\n","    \"\"\" Identifies active pixels by checking that the absolute value of the derivative is always below vthresh\n","    Parameters\n","    ----------\n","    X : ndarray\n","        input 2D array of shape TxNM\n","    vthresh : int\n","        threshold for active pixels. Default is 5\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if all the derivatives are below vthresh\n","    \"\"\"\n","    x_diff = np.abs(np.diff(X, axis=0))\n","    return (x_diff < vthresh).all(axis=0)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"XUOV5CRYflUO","executionInfo":{"status":"ok","timestamp":1651223048508,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # set pixel values to 0/nan\n","  for idx, col in enumerate(df.columns):\n","    if(not active[idx]):\n","      df.loc[:, col] = 0\n","\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_drop(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"DhuoGbbPutKZ","executionInfo":{"status":"ok","timestamp":1651223048509,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ZZJkYzPiVvd6","executionInfo":{"status":"ok","timestamp":1651223049389,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels_deriv(df, v_thresh_deriv=5): \n","  active = filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # for idx, col in enumerate(df.columns):\n","  #   if(not active[idx]):\n","  #     df.loc[:, col] = 0\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_range(df, v_range=(100, 900)):\n","  active = filter_by_vrange(df.values, v_range)\n","\n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"imVXR8eVUrby","executionInfo":{"status":"ok","timestamp":1651223050046,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def reshape_data(df, rows, cols):\n","  X = df.values #pandas.DataFrame.values: Return a Numpy representation of the DataFrame.\n","  X = X.reshape(-1, rows, cols, order='F') #or C. different reshaping row by row or column by column but this works\n","  return X"],"metadata":{"id":"RTF9Vh78MZSB","executionInfo":{"status":"ok","timestamp":1651223050408,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def filter_chemical_pixels(df, arr_rows, arr_cols):\n","  X = reshape_data(df, arr_rows, arr_cols) # reshape data to T x 78 x 56\n","  X_mean = np.mean(X, axis=0) # get mean to have 78 x 56 shape\n","  X_mean[1::3, 1::3] = np.nan # set temperature pixels to nan\n","  X_mean = X_mean.flatten('F') # restore shape to 4068 \n","\n","  active_chemical = ~(np.isnan(X_mean)) # get bool array of all chemical pixels\n","\n","  # drop pixels \n","  df = df.loc[: , active_chemical]\n","  return df\n"],"metadata":{"id":"D9Xt8X4zL7hc","executionInfo":{"status":"ok","timestamp":1651223050751,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"o82EQTYe9euH","executionInfo":{"status":"ok","timestamp":1651223051125,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def time_to_index(times, time_vect):\n","    '''\n","    Returns index of the times closest to the desired ones time_vect\n","    Arguments\n","    ---------\n","    times : list\n","        list of integers containing the desired times\n","    time_vect : nparray\n","        array of the times at which the values are sampled\n","    Returns\n","    -------\n","    list\n","        for each element in the input list times, return an element in the output list\n","        with the index of the sample closest to the desired time\n","    '''\n","    indices = []\n","    for time in times:  # for each time in the input list\n","        indices.append( np.argmin(np.abs(time_vect - time)) )\n","        # find index of the sampled time (in time_vect) closest to the desired one (time)\n","    return indices\n","\n","\n","def find_loading_time(time_vect, X, bounds=(600, 900), viz=False):  # for v2\n","    ''' Finds loading and settling time for the data of v2 chip\n","    Parameters\n","    ----------\n","    time_vect : ndarray\n","        1D array with dimension T containing the sampling times\n","    X : ndarray\n","        2D array with dimension TxNM containing the sampled data\n","    bounds : list, optional\n","        tuple containing the minimum and maximum times (in ms) where the loading time has to be searched.\n","        Default is (600, 900)\n","    viz : bool, optional\n","        if viz=True, show the plot. Default is False\n","    Returns\n","    -------\n","    tuple\n","        - settled_index : index at which the settling occurs\n","        - settled_time : time at which the settling occurs\n","    '''\n","\n","    search_start, search_end = time_to_index(bounds, time_vect)  # for each time in bounds, find the index\n","    # of the sample (in time_vect) that is closest to the desired one (in bounds)\n","    X_mean = np.mean(X, axis=1)  # for each sample, calculate the mean of all pixels\n","    X_mean_diff = np.diff(X_mean)  # find the derivative\n","\n","    loading_index = np.argmax(X_mean_diff[search_start:search_end]) + search_start + 1  # find the index\n","    # where the derivative is max in the specified interval\n","    loading_index = loading_index  # add settling time\n","    settled_index = loading_index + 10  # add settling time\n","    settled_time = time_vect[settled_index]  # find the time that index corresponds to\n","\n","    if viz:  # if viz is true, plot the following\n","        fig, ax = plt.subplots(3, 1)\n","        fig.suptitle('Finding Loading Time...')\n","\n","        ax[0].set(title='Active Chemical Pixels, ACP')\n","        ax[0].plot(time_vect, X)  # plot the active chemical pixels\n","\n","        ax[1].set(title='Mean(ACP)')\n","        ax[1].plot(time_vect, X_mean)  # plot the average of the pixels\n","        ax[1].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[1].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[1].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        ax[2].set(title='Diff(Mean(ACP))')\n","        ax[2].plot(time_vect[1:], X_mean_diff)  # plot the derivative of the mean\n","        ax[2].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[2].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[2].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        plt.tight_layout()\n","        plt.show()\n","    return settled_index, settled_time"]},{"cell_type":"code","execution_count":218,"metadata":{"id":"9m8OqTUtQVb0","executionInfo":{"status":"ok","timestamp":1651227179580,"user_tz":-60,"elapsed":478,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def preprocess_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","  \n","  df = filter_chemical_pixels(df, 78, 56) # filter all chemical pixels\n","  \n","  df = filter_active_pixels_drop(df=df, v_thresh_deriv=deriv_thresh, v_range=(100,900))\n","\n","  settle_idx, settle_time = find_loading_time(df.index, df, bounds=(600, 900), viz=False) # find settling point\n","  df = df.iloc[settle_idx + 10:, :] # use only the data after the settling time + 30s to allow reaction to settle\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise don't\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +200 added on to see impact on graph after pre-processing\n","  \n","  df.index = df.index - df.index[0]\n","  \n","  X, drift = filter_by_drift(df, 40)\n","\n","  if(len(X.columns) != 0):\n","    df = X\n","  # for col in df.columns:\n","  #   df[col] = savgol_filter(df[col],101, 3)\n","\n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  if(len(X.columns) != 0):\n","    df['Average Output'] = df['Average Output'] - drift\n","\n","  df = df.iloc[0:150+250, :] \n","  \n","  df.index = df.index - df.index[0]\n","   \n","  return df"]},{"cell_type":"code","source":["def preprocess_partial_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","\n","  df = filter_active_pixels_range(df=df, v_range=(100,900)) # filter by range incase of any saturation\n","  \n","  df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh) # filter pixels by deriv\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise dont\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +250 added on to see impact on graph after pre-processing\n","  \n","  df.index = df.index - df.index[0]\n","\n","  X, drift = filter_by_drift(df, 40)\n","\n","  if(len(X.columns) != 0):\n","    df = X\n","  \n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  if(len(X.columns) != 0):\n","    df['Average Output'] = df['Average Output'] - drift\n","    \n","  return df"],"metadata":{"id":"JsSdU8xPZX4U","executionInfo":{"status":"ok","timestamp":1651227179581,"user_tz":-60,"elapsed":10,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":219,"outputs":[]},{"cell_type":"code","source":["def normalise_data(series):\n","  return (series - series.min()) / (series.max() - series.min())"],"metadata":{"id":"M6wMMfHZEADc","executionInfo":{"status":"ok","timestamp":1651223051946,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### Data Loading Helper Functions"],"metadata":{"id":"Dvvp28miEMsF"}},{"cell_type":"code","source":["def load_partial_covid_exp(filepath):\n","\n","  bot_filepath = filepath[:-4] + \"_bot.csv\"\n","  top_filepath = filepath[:-4] + \"_top.csv\"\n","\n","  ## load in 2 sheets\n","  df_neg = pd.read_csv(top_filepath, header=0, index_col=0)\n","  df_pos = pd.read_csv(bot_filepath, header=0, index_col=0)\n","\n","  return df_pos, df_neg"],"metadata":{"id":"vL28HCTcZUUG","executionInfo":{"status":"ok","timestamp":1651223056884,"user_tz":-60,"elapsed":358,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation Metric Helper Functions"],"metadata":{"id":"PaNIFO5iSa9C"}},{"cell_type":"code","source":["def accuracy(classifications):\n","  total = len(classifications)\n","  total_correct = 0\n","  for i in classifications.values():\n","    if(i[0] == i[1]):\n","      total_correct +=1\n","\n","  accuracy = (total_correct/total)\n","\n","  return accuracy"],"metadata":{"id":"U2zoSqPJLatm","executionInfo":{"status":"ok","timestamp":1651223057925,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def sensitivity(classifications):\n","  true_pos = 0\n","  false_neg = 0\n","\n","  for i in classifications.values():\n","\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","\n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 1 and predicted == 0):\n","      false_neg += 1\n","\n","  sensitivity = (true_pos/(true_pos + false_neg))\n","\n","  return sensitivity"],"metadata":{"id":"lzSAF5WsTIuF","executionInfo":{"status":"ok","timestamp":1651223058407,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def specificity(classifications):\n","  true_neg = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 0 and predicted == 0):\n","      true_neg += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  specificity = (true_neg/(true_neg + false_pos))\n","\n","  return specificity"],"metadata":{"id":"WP_kdiXMYeU1","executionInfo":{"status":"ok","timestamp":1651223058408,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def precision(classifications):\n","  true_pos = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  precision = (true_pos/(true_pos + false_pos))\n","\n","  return precision"],"metadata":{"id":"w7-_ZPDDaxRp","executionInfo":{"status":"ok","timestamp":1651223058769,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def f1(classifications):\n","  numerator = 2*precision(classifications)*sensitivity(classifications)\n","  denominator = precision(classifications) + sensitivity(classifications)\n","  return numerator/denominator"],"metadata":{"id":"qkFpU-UJbV1R","executionInfo":{"status":"ok","timestamp":1651223059525,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["### Array Dims"],"metadata":{"id":"W9kgS_-Cx1nm"}},{"cell_type":"code","source":["arr_rows = 78\n","arr_cols = 56"],"metadata":{"id":"whsJZh4Zx0xs","executionInfo":{"status":"ok","timestamp":1651223060711,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["### Load Data"],"metadata":{"id":"KCr7gvB_tf5-"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"AvJiLnQ8tiKx"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  avg_data_g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_data_export.csv\"\n","  avg_g1 = pd.read_csv(avg_data_g1_file, header=0)\n","\n","  ## Gamma 2\n","  avg_data_g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_data_export.csv\"\n","  avg_g2 = pd.read_csv(avg_data_g2_file, header=0)\n","\n","  ## Gamma 3\n","  avg_data_g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_data_export.csv\"\n","  avg_g3 = pd.read_csv(avg_data_g3_file, header=0)\n","  \n","  ## Gamma 5 \n","  avg_data_g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_data_export.csv\"\n","  avg_g5 = pd.read_csv(avg_data_g5_file, header=0)\n","\n","  ## 22RV1.ap1\n","  avg_data_22rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_data_export.csv\"\n","  avg_22rv1_ap1 = pd.read_csv(avg_data_22rv1_ap1_file, header=0)\n","\n","  ## 22RV1.ap2\n","  avg_data_22rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_data_export.csv\"\n","  avg_22rv1_ap2 = pd.read_csv(avg_data_22rv1_ap2_file, header=0)\n","\n","  ## 22RV1y.p1\n","  avg_data_22rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_data_export.csv\"\n","  avg_22rv1y_p1 = pd.read_csv(avg_data_22rv1y_p1_file, header=0)\n","\n","  ## 22RV1y.p3\n","  avg_data_22rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_data_export.csv\"\n","  avg_22rv1y_p3 = pd.read_csv(avg_data_22rv1y_p3_file, header=0)\n","\n","  ## 22RV1y.p4\n","  avg_data_22rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_data_export.csv\"\n","  avg_22rv1y_p4 = pd.read_csv(avg_data_22rv1y_p4_file, header=0)\n","\n","  ## ARV7.p1\n","  avg_data_arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_data_export.csv\"\n","  avg_arv7_p1 = pd.read_csv(avg_data_arv7_p1_file, header=0).iloc[1:, :].reset_index(drop=True) # row 0 was NAN\n","\n","  ## ARV7.p3\n","  avg_data_arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_data_export.csv\"\n","  avg_arv7_p3 = pd.read_csv(avg_data_arv7_p3_file, header=0)\n","\n","  ## ARV7.p4\n","  avg_data_arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_data_export.csv\"\n","  avg_arv7_p4 = pd.read_csv(avg_data_arv7_p4_file, header=0)\n","\n","  ## Beta 1\n","  avg_data_b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_data_export.csv\"\n","  avg_b1 = pd.read_csv(avg_data_b1_file, header=0)\n","\n","  ## Beta 2\n","  avg_data_b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_data_export.csv\"\n","  avg_b2 = pd.read_csv(avg_data_b2_file, header=0)\n","\n","  ## Beta 5\n","  avg_data_b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_data_export.csv\"\n","  avg_b5 = pd.read_csv(avg_data_b5_file, header=0)\n","  "],"metadata":{"id":"Ekqd_pB0tuTS","executionInfo":{"status":"ok","timestamp":1651227211264,"user_tz":-60,"elapsed":507,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":220,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_vsChem_export.csv\"\n","  g1 = pd.read_csv(g1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g1.index = avg_g1[\"Time Elapsed\"]\n","\n","  ## Gamma 2\n","  g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_vsChem_export.csv\"\n","  g2 = pd.read_csv(g2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g2.index = avg_g2[\"Time Elapsed\"]\n","\n","  ## Gamma 3\n","  g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_vsChem_export.csv\"\n","  g3 = pd.read_csv(g3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g3.index = avg_g3[\"Time Elapsed\"]\n","\n","  ## Gamma 5\n","  g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_vsChem_export.csv\"\n","  g5 = pd.read_csv(g5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g5.index = avg_g5[\"Time Elapsed\"]\n","\n","  ## 22RV1.ap1\n","  rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_vsChem_export.csv\"\n","  rv1_ap1 = pd.read_csv(rv1_ap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap1.index = avg_22rv1_ap1['Time Elapsed']\n","\n","  ## 22RV1.ap2\n","  rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_vsChem_export.csv\"\n","  rv1_ap2 = pd.read_csv(rv1_ap2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap2.index = avg_22rv1_ap2['Time Elapsed']\n","\n","  ## 22RV1y.p1\n","  rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_vsChem_export.csv\"\n","  rv1y_p1 = pd.read_csv(rv1y_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p1.index = avg_22rv1y_p1['Time Elapsed']\n","\n","  ## 22RV1y.p3\n","  rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_vsChem_export.csv\"\n","  rv1y_p3 = pd.read_csv(rv1y_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p3.index = avg_22rv1y_p3['Time Elapsed']\n","\n","  ## 22RV1y.p4\n","  rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_vsChem_export.csv\"\n","  rv1y_p4 = pd.read_csv(rv1y_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p4.index = avg_22rv1y_p4['Time Elapsed']\n","\n","  ## ARV7.p1 \n","  arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_vsChem_export.csv\"\n","  arv7_p1 = pd.read_csv(arv7_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)] \n","  arv7_p1.index = avg_arv7_p1[\"Time Elapsed\"]\n","\n","  ## ARV7.p3 \n","  arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_vsChem_export.csv\"\n","  arv7_p3 = pd.read_csv(arv7_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p3.index = avg_arv7_p3[\"Time Elapsed\"]\n","\n","  ## ARV7.p4 \n","  arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_vsChem_export.csv\"\n","  arv7_p4 = pd.read_csv(arv7_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p4.index = avg_arv7_p4[\"Time Elapsed\"]\n","\n","  ## Beta 1\n","  b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_vsChem_export.csv\"\n","  b1 = pd.read_csv(b1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b1.index = avg_b1[\"Time Elapsed\"]\n","\n","  ## Beta 2\n","  b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_vsChem_export.csv\"\n","  b2 = pd.read_csv(b2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b2.index = avg_b2[\"Time Elapsed\"]\n","\n","  ## Beta 5\n","  b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_vsChem_export.csv\"\n","  b5 = pd.read_csv(b5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b5.index = avg_b5[\"Time Elapsed\"]"],"metadata":{"id":"vZRah5zpxXp6","executionInfo":{"status":"ok","timestamp":1651227219741,"user_tz":-60,"elapsed":8121,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":221,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"7qOF9VBstkbe"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):  \n","  ## ARV7.n1\n","  avg_data_arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_data_export.csv\"\n","  avg_arv7 = pd.read_csv(avg_data_arv7_file, header=0)\n","\n","  ## Yap.n2\n","  avg_data_yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_data_export.csv\"\n","  avg_yap = pd.read_csv(avg_data_yap_file, header=0)\n","\n","  ## Yap1.n2\n","  avg_data_yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_data_export.csv\"\n","  avg_yap1 = pd.read_csv(avg_data_yap1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## Yap1.n1.1 \n","  avg_data_yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_data_export.csv\"\n","  avg_yap1n1 = pd.read_csv(avg_data_yap1n1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## ARV7.n2\n","  avg_data_arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_data_export.csv\"\n","  avg_arv72 = pd.read_csv(avg_data_arv72_file, header=0)\n","\n","  ## ARV7.n3\n","  avg_data_arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_data_export.csv\"\n","  avg_arv73 = pd.read_csv(avg_data_arv73_file, header=0)\n","\n","  ## DU145a.p1\n","  avg_data_du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_data_export.csv\"\n","  avg_du145a_p1 = pd.read_csv(avg_data_du145a_p1_file, header=0)\n","\n","  ## DU145a.p2\n","  avg_data_du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_data_export.csv\"\n","  avg_du145a_p2 = pd.read_csv(avg_data_du145a_p2_file, header=0)\n","\n","  ## DU145a.p3\n","  avg_data_du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_data_export.csv\"\n","  avg_du145a_p3 = pd.read_csv(avg_data_du145a_p3_file, header=0)\n","\n","  ## DU145y.n1\n","  avg_data_du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_data_export.csv\"\n","  avg_du145y_n1 = pd.read_csv(avg_data_du145y_n1_file, header=0)"],"metadata":{"id":"mlU83yKsuSHV","executionInfo":{"status":"ok","timestamp":1651227219742,"user_tz":-60,"elapsed":15,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":222,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):   \n","  ## ARV7.n1 \n","  arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_vsChem_export.csv\"\n","  arv7 = pd.read_csv(arv7_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7.index = avg_arv7[\"Time Elapsed\"]\n","\n","  ## Yap.n2\n","  yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_vsChem_export.csv\"\n","  yap = pd.read_csv(yap_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap.index = avg_yap[\"Time Elapsed\"]\n","\n","  ## Yap1.n2\n","  yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_vsChem_export.csv\"\n","  yap1 = pd.read_csv(yap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1.index = avg_yap1[\"Time Elapsed\"]\n","\n","  ## Yap1.n1.1\n","  yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_vsChem_export.csv\"\n","  yap1n1 = pd.read_csv(yap1n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1n1.index = avg_yap1n1[\"Time Elapsed\"]\n","\n","  ## ARV7.n2\n","  arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_vsChem_export.csv\"\n","  arv72 = pd.read_csv(arv72_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv72.index = avg_arv72[\"Time Elapsed\"]\n","\n","  ## ARV7.n3\n","  arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_vsChem_export.csv\"\n","  arv73 = pd.read_csv(arv73_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv73.index = avg_arv73[\"Time Elapsed\"]\n","\n","  ## DU145a.p1\n","  du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_vsChem_export.csv\"\n","  du145a_p1 = pd.read_csv(du145a_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p1.index = avg_du145a_p1[\"Time Elapsed\"]\n","\n","  ## DU145a.p2\n","  du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_vsChem_export.csv\"\n","  du145a_p2 = pd.read_csv(du145a_p2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p2.index = avg_du145a_p2[\"Time Elapsed\"]\n","\n","  ## DU145a.p3\n","  du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_vsChem_export.csv\"\n","  du145a_p3 = pd.read_csv(du145a_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p3.index = avg_du145a_p3[\"Time Elapsed\"]\n","\n","  ## DU145y.n1\n","  du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_vsChem_export.csv\"\n","  du145y_n1 = pd.read_csv(du145y_n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145y_n1.index = avg_du145y_n1[\"Time Elapsed\"]"],"metadata":{"id":"W3_XExOjypwI","executionInfo":{"status":"ok","timestamp":1651227224793,"user_tz":-60,"elapsed":5065,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":223,"outputs":[]},{"cell_type":"markdown","source":["#### Partial Covid Data"],"metadata":{"id":"yjXPLEfmRUJH"}},{"cell_type":"code","source":["## 150520_2_118\n","avg_118_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_2_118/exp_summary_118.csv\"\n","exp_118_pos, exp_118_neg = load_partial_covid_exp(avg_118_file)\n","\n","## 150520_4_2_86\n","avg_86_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_4_2_86/exp_summary_86.csv\"\n","exp_86_pos, exp_86_neg = load_partial_covid_exp(avg_86_file)\n","\n","## 150520_5_129\n","avg_129_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_5_129/exp_summary_129.csv\"\n","exp_129_pos, exp_129_neg = load_partial_covid_exp(avg_129_file)\n","\n","## 180520_4_165\n","avg_165_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_4_165/exp_summary_165.csv\"\n","exp_165_pos, exp_165_neg = load_partial_covid_exp(avg_165_file)\n","\n","## 180520_6_35\n","avg_35_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_6_35/exp_summary_35.csv\"\n","exp_35_pos, exp_35_neg = load_partial_covid_exp(avg_35_file)\n","\n","## 190520_1_28\n","avg_28_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_1_28/exp_summary_28.csv\"\n","exp_28_pos, exp_28_neg = load_partial_covid_exp(avg_28_file) \n","\n","## 190520_2_14\n","avg_14_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_2_14/exp_summary_14.csv\"\n","exp_14_pos, exp_14_neg = load_partial_covid_exp(avg_14_file)\n","\n","## 210520_2_40\n","avg_40_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_2_40/exp_summary_40.csv\"\n","exp_40_pos, exp_40_neg = load_partial_covid_exp(avg_40_file)\n","\n","## 210520_3_88\n","avg_88_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_3_88/exp_summary_88.csv\"\n","exp_88_pos, exp_88_neg = load_partial_covid_exp(avg_88_file)\n","\n","## 210520_6_27\n","avg_27_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_6_27/exp_summary_27.csv\"\n","exp_27_pos, exp_27_neg = load_partial_covid_exp(avg_27_file)\n","\n","## 250520_1_134\n","avg_134_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_1_134/exp_summary_134.csv\"\n","exp_134_pos, exp_134_neg = load_partial_covid_exp(avg_134_file)\n","\n","## 250520_2_97\n","avg_97_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_2_97/exp_summary_97.csv\"\n","exp_97_pos, exp_97_neg = load_partial_covid_exp(avg_97_file)\n","\n","## 250520_6_2D1\n","avg_2d1_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_6_2D1/exp_summary_2D1.csv\"\n","exp_2d1_pos, exp_2d1_neg = load_partial_covid_exp(avg_2d1_file)\n","\n","## 250520_7_64\n","avg_64_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_7_64/exp_summary_64.csv\"\n","exp_64_pos, exp_64_neg = load_partial_covid_exp(avg_64_file)"],"metadata":{"id":"ORRtMFfEZBwV","executionInfo":{"status":"ok","timestamp":1651227227770,"user_tz":-60,"elapsed":2985,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":224,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"7XgnkewwwPki"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"CTcUwvRiwUmJ"}},{"cell_type":"code","source":["g1 = preprocess_data(g1, 500)\n","g2 = preprocess_data(g2, 500)\n","g3 = preprocess_data(g3, 500)\n","g5 = preprocess_data(g5, 500)\n","rv1_ap1 = preprocess_data(rv1_ap1, 500)\n","rv1_ap2 = preprocess_data(rv1_ap2, 500)\n","rv1y_p1 = preprocess_data(rv1y_p1, 500)\n","rv1y_p3 = preprocess_data(rv1y_p3, 500)\n","rv1y_p4 = preprocess_data(rv1y_p4, 500)\n","arv7_p1 = preprocess_data(arv7_p1, 500)\n","arv7_p3 = preprocess_data(arv7_p3, 500)\n","arv7_p4 = preprocess_data(arv7_p4, 500)\n","b1 = preprocess_data(b1, 500)\n","b2 = preprocess_data(b2, 500)\n","b5 = preprocess_data(b5, 500)"],"metadata":{"id":"1-WlDoK49D2Y","executionInfo":{"status":"ok","timestamp":1651227288778,"user_tz":-60,"elapsed":61019,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c18c9933-0db6-45e2-e1dc-20f9c2bf5520"},"execution_count":225,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"]}]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"1WaPBFGuwYN4"}},{"cell_type":"code","source":["arv7 = preprocess_data(arv7, 500)\n","yap = preprocess_data(yap, 500)\n","yap1 = preprocess_data(yap1, 500)\n","yap1n1 = preprocess_data(yap1n1, 500)\n","arv72 = preprocess_data(arv72, 500)\n","arv73 = preprocess_data(arv73, 500)\n","du145y_n1 = preprocess_data(du145y_n1, 500)\n","du145a_p1 = preprocess_data(du145a_p1, 500)\n","du145a_p2 = preprocess_data(du145a_p2, 500)\n","du145a_p3 = preprocess_data(du145a_p3, 500)"],"metadata":{"id":"gazhgzLT9HLV","executionInfo":{"status":"ok","timestamp":1651227328259,"user_tz":-60,"elapsed":39499,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bdf90c5e-3533-4370-ef73-73963c0c0942"},"execution_count":226,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n","/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n"]}]},{"cell_type":"markdown","source":["#### Covid Partial Data"],"metadata":{"id":"nUwBPNQNjQ7w"}},{"cell_type":"code","source":["exp_118_pos = preprocess_partial_data(exp_118_pos, 500)\n","exp_86_pos = preprocess_partial_data(exp_86_pos, 500)\n","exp_129_pos = preprocess_partial_data(exp_129_pos, 500)\n","exp_165_pos = preprocess_partial_data(exp_165_pos, 500)\n","exp_35_pos = preprocess_partial_data(exp_35_pos, 500)\n","exp_28_pos = preprocess_partial_data(exp_28_pos, 500)\n","exp_14_pos = preprocess_partial_data(exp_14_pos, 500)\n","exp_40_pos = preprocess_partial_data(exp_40_pos, 500)\n","exp_88_pos = preprocess_partial_data(exp_88_pos, 500)\n","exp_27_pos = preprocess_partial_data(exp_27_pos, 500)\n","exp_134_pos = preprocess_partial_data(exp_134_pos, 500)\n","exp_97_pos = preprocess_partial_data(exp_97_pos, 500)\n","exp_2d1_pos = preprocess_partial_data(exp_2d1_pos, 500)\n","exp_64_pos = preprocess_partial_data(exp_64_pos, 500)"],"metadata":{"id":"HQBQ_1YF9Oqj","executionInfo":{"status":"ok","timestamp":1651227350967,"user_tz":-60,"elapsed":22730,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9271316f-5260-4f2a-880f-93337d710003"},"execution_count":227,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n","  category=OptimizeWarning)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"]}]},{"cell_type":"code","source":["exp_118_neg = preprocess_partial_data(exp_118_neg, 500)\n","exp_86_neg = preprocess_partial_data(exp_86_neg, 500)\n","exp_129_neg = preprocess_partial_data(exp_129_neg, 500)\n","exp_165_neg = preprocess_partial_data(exp_165_neg, 500)\n","exp_35_neg = preprocess_partial_data(exp_35_neg, 500)\n","exp_28_neg = preprocess_partial_data(exp_28_neg, 500)\n","exp_14_neg = preprocess_partial_data(exp_14_neg, 500)\n","exp_40_neg = preprocess_partial_data(exp_40_neg, 500)\n","exp_88_neg = preprocess_partial_data(exp_88_neg, 500)\n","exp_27_neg = preprocess_partial_data(exp_27_neg, 500)\n","exp_134_neg = preprocess_partial_data(exp_134_neg, 500)\n","exp_97_neg = preprocess_partial_data(exp_97_neg, 500)\n","exp_2d1_neg = preprocess_partial_data(exp_2d1_neg, 500)\n","exp_64_neg = preprocess_partial_data(exp_64_neg, 500)"],"metadata":{"id":"sYsOnsAW9Rob","executionInfo":{"status":"ok","timestamp":1651227373237,"user_tz":-60,"elapsed":22273,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":228,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - Neural Network Ensemble"],"metadata":{"id":"cco-BOwij9af"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"j5qgb5mx3rOW"}},{"cell_type":"code","source":["def get_training_data(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"OIYXEisg2WX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_test_data(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"xH5J1l0cgIHI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"d6Qyl80Wzy-r"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,\n","             \"arv7_p3\":arv7_p3,\n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7,  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3}"],"metadata":{"id":"d-bA8RfjcM35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Model Specs"],"metadata":{"id":"rxkmk6GHqC7g"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_classifiers = 50\n","\n","timestep = int(number_of_samples/number_of_classifiers)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]\n","\n","batch_size = 3\n","epochs = 10\n","loss_function = 'binary_crossentropy'\n","optimiser = 'adam'"],"metadata":{"id":"eztwFZUaloVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBcYHOw_BU4E","executionInfo":{"status":"ok","timestamp":1650888347765,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"62652afd-35c9-48f8-c037-b58efe79e12c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Creating Ensemble"],"metadata":{"id":"qG3eDbNkqG9A"}},{"cell_type":"code","source":["def create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples):\n","\n","  neural_nets = [0]*number_of_classifiers\n","\n","  for i in range(number_of_classifiers):\n","\n","    # print(f\"============================================== Neural Network {i} ============================================\")\n","\n","    ## make model \n","    neural_nets[i] = Sequential()\n","    neural_nets[i].add(Dense(16, activation='relu', input_dim = timestamps[i]))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(1, activation='sigmoid'))\n","\n","    ## compile model \n","    neural_nets[i].compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])\n","\n","    ## model summary\n","    # neural_nets[i].summary()\n","\n","    ## training data\n","    training_data, training_label = get_training_data(positive_samples=positives, negative_samples=negatives, timestamp=timestamps[i], test_samples=[test_samples])\n","\n","    ## train model\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n","    neural_nets[i].fit(training_data, training_label,  batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[callback], verbose=0)\n","\n","    # print(\"\\n\\n\")\n","\n","  return neural_nets"],"metadata":{"id":"GVVPVw4-ndtu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Evaluating Ensemble"],"metadata":{"id":"fGH97jNBfzdu"}},{"cell_type":"code","source":["def get_prediction(ensemble, timestamps, test_sample):\n","  predictions = []\n","\n","  for i in range(number_of_classifiers):\n","    test_data = get_test_data(test_sample, timestamps[i])\n","    prediction = ensemble[i].predict(test_data)\n","    predictions.append(prediction[0][0])\n","\n","  predictions = [int(i >= 0.5) for i in predictions]\n","  classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","\n","  return classification"],"metadata":{"id":"HslDzCxe1PaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with tule label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"TCTzCBpU0S8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  final_classifications = {}\n","\n","  ## use ensemble to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Testing sample: {test_sample_name}...\")\n","\n","    en = create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_sample_name)\n","    classification = get_prediction(en, timestamps, test_sample)\n","    \n","    \n","    final_classifications[key] = (classification, true_label_dict[key])\n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"HlIwk3By0Zqi","colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"status":"error","timestamp":1650888354674,"user_tz":-60,"elapsed":6919,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2e248431-2ec4-4c7b-e50c-96b007673ba4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample: exp_118_pos...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'sequential_1/dense_7/BiasAdd/ReadVariableOp/resource' has no attr named '_class'.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-5086e332c720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing sample: {test_sample_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0men\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-83e0a485fc39>\u001b[0m in \u001b[0;36mcreate_ensemble\u001b[0;34m(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m## train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mneural_nets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# print(\"\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    530\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m    531\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_compute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    673\u001b[0m           \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m           \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m               var.op.name):\n\u001b[1;32m    716\u001b[0m             update_op = distribution.extended.update(\n\u001b[0;32m--> 717\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False)\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_cross_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m               \u001b[0;31m# In cross-replica context, extended.update returns a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n\u001b[0;32m-> 2633\u001b[0;31m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[0m\u001b[1;32m   2634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2509\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3101\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3102\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3108\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3109\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2509\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2628\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2629\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3701\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3702\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3709\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3710\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    174\u001b[0m           \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m           \u001b[0;34m'Please pass these args as kwargs instead.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1447\u001b[0m                              \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m                              \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m                              use_nesterov=use_nesterov, name=name)\n\u001b[0m\u001b[1;32m   1450\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0mResourceApplyAdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_ops.ResourceApplyAdam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_apply_adam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[1;32m   1655\u001b[0m                            \"building a function.\")\n\u001b[0;32m-> 1656\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;31m# Large EagerTensors and resources are captured with Placeholder ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m       placeholder = _create_substitute_placeholder(\n\u001b[0;32m--> 765\u001b[0;31m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0m\u001b[1;32m    766\u001b[0m       \u001b[0;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0;31m# This attribute would be propogated into the arg_attr of the FunctionDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     placeholder = graph_placeholder(\n\u001b[0;32m-> 1306\u001b[0;31m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   1307\u001b[0m   \u001b[0mhandle_data_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       attrs=attrs, name=name)\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3785\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3872\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcolocation_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3874\u001b[0;31m           \u001b[0mall_colocation_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3876\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocation_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \u001b[0mdefault_colocation_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc:@%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m       \u001b[0mclass_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m       \u001b[0;31m# This op has no explicit colocation group, so it is itself its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["final_classifications"],"metadata":{"id":"4AuD_rrC2yYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"mhkc8Lnr9-c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"WCjSN-dLz9Mq"}},{"cell_type":"code","source":["# ## checking the timestap where majority of classifiers agree\n","\n","# from collections import defaultdict\n","\n","# def get_timestamp(timestamps, predictions):\n","\n","#   ## create dict to hold count of predictions\n","#   label_counters = defaultdict(int)\n","\n","#   ## add entries to dict\n","#   for index, pred in enumerate(predictions):\n","#     label_counters[pred] += 1\n","\n","#     ## if label count == half of total possible predictions then majority is achieved\n","#     if(label_counters[pred] == int(len(predictions)/2)+1):\n","#       return timestamps[index], index\n","  \n","#   return -1, -1\n"],"metadata":{"id":"3r69Gbpd99So"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Timestamp where majority aggement is reached: {timestamp_final}\")\n","# print(f\"Index of final time stamp in array : {pred_index}\")"],"metadata":{"id":"ghvOJ4Ot_fRB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Save Ensemble"],"metadata":{"id":"PppLDxSdv5Uk"}},{"cell_type":"code","source":["# !pwd"],"metadata":{"id":"jAJAZJtKv816"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G1Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G2Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G3Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G5Test"],"metadata":{"id":"UgtDxJjmxHQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/ARV7Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAPTest/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1N1Test/"],"metadata":{"id":"bwBDVrvMRsO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for i in range(number_of_classifiers):\n","#   filename = f\"ensemble-model-{i}.h5\"\n","#   neural_nets[i].save(filename)\n","\n","#   print(f\"Saved {filename}\")"],"metadata":{"id":"ZGXuLcuXx99S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - KNN Ensemble"],"metadata":{"id":"GvAKajynLNa9"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"H8ueQFk24bbg"}},{"cell_type":"code","source":["def get_training_data_knn(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"x4q6d44BLwpQ","executionInfo":{"status":"ok","timestamp":1651227373238,"user_tz":-60,"elapsed":26,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":229,"outputs":[]},{"cell_type":"code","source":["def get_test_data_knn(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"GZOfy-0GQuGA","executionInfo":{"status":"ok","timestamp":1651227373238,"user_tz":-60,"elapsed":25,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":230,"outputs":[]},{"cell_type":"code","source":["def get_time_index(timestamps, predictions):\n","\n","  ## create dict to hold count of predictions\n","  label_counters = defaultdict(int)\n","\n","  ## add entries to dict\n","  for index, pred in enumerate(predictions):\n","    label_counters[pred] += 1\n","\n","    ## if label count == half of total possible predictions then majority is achieved\n","    if(label_counters[pred] == int(len(predictions)/2)+1):\n","      return timestamps[index]\n","  \n","  return -1"],"metadata":{"id":"2hib6StpHWbU","executionInfo":{"status":"ok","timestamp":1651227373239,"user_tz":-60,"elapsed":25,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":231,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"FOMhNuiKNGAw"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","            #  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"-prfZYD_VgMB","executionInfo":{"status":"ok","timestamp":1651227373239,"user_tz":-60,"elapsed":24,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":232,"outputs":[]},{"cell_type":"markdown","source":["#### Timestamps"],"metadata":{"id":"Ry9pqKjnNKiI"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"3cDeyMc3M_bN","executionInfo":{"status":"ok","timestamp":1651227373239,"user_tz":-60,"elapsed":24,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":233,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIjHUplVOmH3","executionInfo":{"status":"ok","timestamp":1651227373240,"user_tz":-60,"elapsed":24,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"6dd803fe-7d27-4e3b-a408-45fd45b25a0f"},"execution_count":234,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Model"],"metadata":{"id":"DJBWoo1SNMy3"}},{"cell_type":"code","source":["def KNN(k, test_sample, train_data, train_labels, distance_metric):\n","  test = np.tile(test_sample, (len(train_data),1)) # repeat test sample and stack vertically\n","  \n","  distances = None\n","\n","  if(distance_metric.lower() == 'manhattan' or distance_metric.lower() == 'cityblock'):\n","    distances = manhattan_distances(test, train_data).diagonal() # get pair wise manhattan distance for every row\n","  elif(distance_metric.lower() == 'euclidean'):\n","    distances = euclidean_distances(test, train_data).diagonal() # get pair wise euclidean distance for every row \n","  elif(distance_metric.lower() == 'cosine'):\n","    distances = cosine_distances(test, train_data).diagonal() # get pair wise cosine distance for every row \n","\n","  min_indexes = np.argsort(distances)[:k] # get k smallest indexes\n","\n","  knn_labels = list(train_labels[min_indexes]) # get k predictions\n","  final_pred = max(set(knn_labels), key=knn_labels.count)\n","\n","  return final_pred"],"metadata":{"id":"sGJZphgaLeL0","executionInfo":{"status":"ok","timestamp":1651227373240,"user_tz":-60,"elapsed":23,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":235,"outputs":[]},{"cell_type":"markdown","source":["#### Model Predictions"],"metadata":{"id":"0C0XQKFHFtFV"}},{"cell_type":"markdown","source":["##### Held-out Test Set"],"metadata":{"id":"Vf8LAE4Qbxls"}},{"cell_type":"code","source":["# test_samples = {\"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \"exp_27_neg\":exp_27_neg,\"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg,\n","#                 \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \"g1\":g1, \"exp_86_pos\":exp_86_pos, \"rv1_ap1\":rv1_ap1,\"b5\":b5, \"exp_28_pos\":exp_28_pos}\n","# test_sample_keys = keys = list(test_samples.keys())\n","# test_labels = list(np.concatenate((np.ones(7),np.zeros(7))))\n","# test_label_dict = dict(zip(test_sample_keys, test_labels))"],"metadata":{"id":"AxaTjkExYX9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import time\n","# with tf.device(gpu):\n","\n","#   final_classifications = {}\n","\n","#   ## use KNN to evaluate the prediction for each of the samples individually\n","#   for key, value in test_samples.items():\n","#     test_sample_name = key\n","#     test_sample = value\n","\n","#     predictions = []\n","#     for t in timestamps:\n","#       train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=test_sample_keys)\n","#       test_data = get_test_data_knn(test_sample, t)\n","#       pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","#       predictions.append(pred)\n","    \n","#     print(f\"Testing sample {test_sample_name}\")\n","\n","#     time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","#     time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","#     classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","#     final_classifications[key] = (classification, true_label_dict[key])\n","  \n","#     print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","#     if(classification == 1.0):\n","#       print(f\"TTP: {time_to_result}s\")\n","\n","#     print(\"\")"],"metadata":{"id":"PVYWffD2Z5q6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Accuracy: {accuracy(final_classifications)}\")\n","# print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","# print(f\"Specificity: {specificity(final_classifications)}\")\n","# print(f\"Precision: {precision(final_classifications)}\")\n","# print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"uV2qejqoblws"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Cross Validation"],"metadata":{"id":"DuKAj66EbskM"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             #\"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"RGVdwT8rxS23","executionInfo":{"status":"ok","timestamp":1651231387617,"user_tz":-60,"elapsed":559,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":353,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"SUDmHpF-GigC","executionInfo":{"status":"ok","timestamp":1651231387620,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":354,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(5, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    print(f\"Testing sample {test_sample_name}\")\n","    time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","    time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","    classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","    final_classifications[key] = (classification, true_label_dict[key])\n","  \n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","    if(classification == 1.0):\n","      print(f\"TTP: {time_to_result + 30}s \\t {round((time_to_result+30)/60, 2)} mins\")\n","\n","    print(\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rptrj0arSjSR","executionInfo":{"status":"ok","timestamp":1651231394466,"user_tz":-60,"elapsed":5285,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2aebd8f4-b450-49e5-ee69-1b423a20b25d"},"execution_count":355,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1029.0s \t 17.15 mins\n","\n","Testing sample exp_86_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_129_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1119.0s \t 18.65 mins\n","\n","Testing sample exp_35_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1064.0s \t 17.73 mins\n","\n","Testing sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 793.0s \t 13.22 mins\n","\n","Testing sample exp_40_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 731.0s \t 12.18 mins\n","\n","Testing sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 963.0s \t 16.05 mins\n","\n","Testing sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 719.0s \t 11.98 mins\n","\n","Testing sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 670s \t 11.17 mins\n","\n","Testing sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 587.0s \t 9.78 mins\n","\n","Testing sample exp_2d1_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 616.0s \t 10.27 mins\n","\n","Testing sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 624.0s \t 10.4 mins\n","\n","Testing sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 612.0s \t 10.2 mins\n","\n","Testing sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 629.0s \t 10.48 mins\n","\n","Testing sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 738.0s \t 12.3 mins\n","\n","Testing sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1018.0s \t 16.97 mins\n","\n","Testing sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 948.0s \t 15.8 mins\n","\n","Testing sample arv7_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample rv1y_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample rv1y_p4\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 767.0s \t 12.78 mins\n","\n","Testing sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 912.0s \t 15.2 mins\n","\n","Testing sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 758.0s \t 12.63 mins\n","\n","Testing sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1028.0s \t 17.13 mins\n","\n","Testing sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 799.0s \t 13.32 mins\n","\n","Testing sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 617s \t 10.28 mins\n","\n","Testing sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 659s \t 10.98 mins\n","\n","Testing sample exp_165_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 680s \t 11.33 mins\n","\n","Testing sample exp_35_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 646s \t 10.77 mins\n","\n","Testing sample exp_40_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_134_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 624.0s \t 10.4 mins\n","\n","Testing sample exp_97_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 611s \t 10.18 mins\n","\n","Testing sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 641s \t 10.68 mins\n","\n","Testing sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 628.0s \t 10.47 mins\n","\n","Testing sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 648.0s \t 10.8 mins\n","\n","Testing sample yap1n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 948.0s \t 15.8 mins\n","\n","Testing sample arv7\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n"]}]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SilNigCLya5","executionInfo":{"status":"ok","timestamp":1651231394466,"user_tz":-60,"elapsed":10,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"4d7f48d7-e1c2-4b29-acb5-a5ffae9030b7"},"execution_count":356,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6530612244897959\n","Sensitivity/Recall: 0.75\n","Specificity: 0.5238095238095238\n","Precision: 0.6774193548387096\n","F1 Score: 0.7118644067796611\n"]}]},{"cell_type":"code","source":["# Accuracy: 0.6530612244897959\n","# Sensitivity/Recall: 0.7142857142857143\n","# Specificity: 0.5714285714285714\n","# Precision: 0.6896551724137931\n","# F1 Score: 0.7017543859649122"],"metadata":{"id":"hynDsCvoiBIa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Elbow Plot"],"metadata":{"id":"DgvFMAGtSbpy"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"i1xQt-8FxVXG","executionInfo":{"status":"ok","timestamp":1651226719798,"user_tz":-60,"elapsed":426,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":197,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  accuracies = []\n","  for k in range(1,30):\n","    final_classifications = {}\n","\n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = []\n","      for t in timestamps:\n","        train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","        test_data = get_test_data_knn(test_sample, t)\n","        pred = KNN(k, test_data, train_data, train_labels, 'cosine')\n","        predictions.append(pred)\n","      \n","      time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","      \n","      classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","      final_classifications[key] = (classification, true_label_dict[key])\n","\n","    acc = accuracy(final_classifications)\n","    accuracies.append(acc)\n","    print(f\"K: {k} \\t Accuracy: {acc}\")\n","    # print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"WwBbkDraFWF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651226802962,"user_tz":-60,"elapsed":81379,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"dab9f1e9-e85d-4fdc-e9e5-5c8951ba5ef3"},"execution_count":198,"outputs":[{"output_type":"stream","name":"stdout","text":["K: 1 \t Accuracy: 0.42857142857142855\n","K: 2 \t Accuracy: 0.5102040816326531\n","K: 3 \t Accuracy: 0.40816326530612246\n","K: 4 \t Accuracy: 0.4489795918367347\n","K: 5 \t Accuracy: 0.4897959183673469\n","K: 6 \t Accuracy: 0.5306122448979592\n","K: 7 \t Accuracy: 0.5102040816326531\n","K: 8 \t Accuracy: 0.42857142857142855\n","K: 9 \t Accuracy: 0.5102040816326531\n","K: 10 \t Accuracy: 0.4897959183673469\n","K: 11 \t Accuracy: 0.4489795918367347\n","K: 12 \t Accuracy: 0.4897959183673469\n","K: 13 \t Accuracy: 0.46938775510204084\n","K: 14 \t Accuracy: 0.5102040816326531\n","K: 15 \t Accuracy: 0.5102040816326531\n","K: 16 \t Accuracy: 0.4897959183673469\n","K: 17 \t Accuracy: 0.4489795918367347\n","K: 18 \t Accuracy: 0.5714285714285714\n","K: 19 \t Accuracy: 0.42857142857142855\n","K: 20 \t Accuracy: 0.5306122448979592\n","K: 21 \t Accuracy: 0.4489795918367347\n","K: 22 \t Accuracy: 0.5714285714285714\n","K: 23 \t Accuracy: 0.42857142857142855\n","K: 24 \t Accuracy: 0.46938775510204084\n","K: 25 \t Accuracy: 0.46938775510204084\n","K: 26 \t Accuracy: 0.46938775510204084\n","K: 27 \t Accuracy: 0.3469387755102041\n","K: 28 \t Accuracy: 0.46938775510204084\n","K: 29 \t Accuracy: 0.3673469387755102\n"]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = np.arange(1,30)\n","y = accuracies\n","axes.set_xlabel(\"K\")\n","axes.set_ylabel(\"Accuracy (%)\")\n","axes.plot(x,y)"],"metadata":{"id":"P8t0E1pS9YNL","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"ok","timestamp":1651226824053,"user_tz":-60,"elapsed":642,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"0f291594-4b47-428d-8435-cc7a7936baa4"},"execution_count":199,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f5b53ed0a50>]"]},"metadata":{},"execution_count":199},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Confidence "],"metadata":{"id":"qXrQKuQm8ery"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"oZRyLyYo7k36"}},{"cell_type":"code","source":["def get_rH_00(true_vals, classifier_outputs):\n","  correct_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 0)):\n","      correct_pred_0 += 1\n","\n","  return correct_pred_0/total_pred_0\n","\n","\n","def get_rH_01(true_vals, classifier_outputs):\n","  wrong_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 0)):\n","      wrong_pred_1 += 1\n","    \n","  return wrong_pred_1/total_pred_1\n","\n","def get_rH_10(true_vals, classifier_outputs):\n","  wrong_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 1)):\n","      wrong_pred_0 += 1\n","  \n","  return wrong_pred_0/total_pred_0\n","\n","def get_rH_11(true_vals, classifier_outputs):\n","  correct_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 1)):\n","      correct_pred_1 += 1\n","\n","  return correct_pred_1/total_pred_1"],"metadata":{"id":"6IQ6mN5uJ6z1","executionInfo":{"status":"ok","timestamp":1651227398506,"user_tz":-60,"elapsed":344,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":241,"outputs":[]},{"cell_type":"code","source":["def get_confidence_multipliers(sample_predictions, true_labels):\n","\n","  sample_predictions = np.asarray(sample_predictions) # array of all predictions made by every classifer for all samples\n","\n","  #2d array of all possible multipliers for each classifier\n","  multipliers_final = []\n","\n","  # generate 4 multipliers for each classifier\n","  for classifier in range(len(sample_predictions[0])):\n","    classifier_output = sample_predictions[:, classifier]\n","\n","    rH_00 = get_rH_00(true_labels, classifier_output)\n","    rH_01 = get_rH_01(true_labels, classifier_output)\n","    rH_10 = get_rH_10(true_labels, classifier_output)\n","    rH_11 = get_rH_11(true_labels, classifier_output)\n","    multipliers_classfier = [rH_00, rH_01, rH_10, rH_11] \n","\n","    # add multipliers to 2d array\n","    multipliers_final.append(multipliers_classfier)\n","\n","  return multipliers_final"],"metadata":{"id":"5r-wTh3nlga0","executionInfo":{"status":"ok","timestamp":1651227400806,"user_tz":-60,"elapsed":355,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":242,"outputs":[]},{"cell_type":"code","source":["def get_confidence(preds, multipliers):\n","  \n","  # initialise variable\n","  confidence = 1\n","\n","  # the prediction for which the confidence is being calculated -- predication at time t by classifier Ht (most recent prediction)\n","  pred_t = preds[-1]\n","\n","  for idx , pred in enumerate(preds):\n","    # prediction at time k made by classifier Hk\n","    pred_k = pred\n","\n","    # array of multipliers for Hk \n","    multiplier_k = multipliers[idx]\n","\n","    if(pred_t == 0 and pred_k == 0):\n","        confidence*=(1-multiplier_k[0])\n","    elif(pred_t == 0 and pred_k == 1):\n","        confidence*=(1-multiplier_k[1])\n","    elif(pred_t == 1 and pred_k == 0):\n","        confidence*=(1-multiplier_k[2])  \n","    elif(pred_t == 1 and pred_k == 1):\n","        confidence*=(1-multiplier_k[3])\n","        \n","        \n","\n","  confidence = 1 - confidence\n","\n","  return confidence\n","  "],"metadata":{"id":"8SmPp5iDzHQJ","executionInfo":{"status":"ok","timestamp":1651227401741,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":243,"outputs":[]},{"cell_type":"code","source":["def generate_predictions_table(positives, negatives, timestamps):\n","\n","  sample_predictions = []\n","\n","  true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    sample_predictions.append(predictions)\n","\n","  return sample_predictions, true_labels"],"metadata":{"id":"Qfe-e7-84_Zc","executionInfo":{"status":"ok","timestamp":1651228035474,"user_tz":-60,"elapsed":367,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":290,"outputs":[]},{"cell_type":"markdown","source":["#### Random Threshold Testing"],"metadata":{"id":"bwcY82bSq0t6"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651227511747,"user_tz":-60,"elapsed":381,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"bZnftjyQxXcw"},"execution_count":258,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651227512152,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"asGaVch58nEo"},"execution_count":259,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651227512525,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"032f1e44-700b-4abd-81db-7b9d219d9e4d","id":"YF_lFeGo8nE2"},"execution_count":260,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"68OVHXKmw-Hg","executionInfo":{"status":"ok","timestamp":1651227512526,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":261,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","  \n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","      if(c >= 0.999999969661240808167): # onfidence threshold\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","        if(pred == 1.0):\n","          print(f\"Earliness:  {time_index/timestamps[-1]}\")\n","          print(f\"TTP: {time_to_result+30}s \\t {round((time_to_result+30)/60, 2)} mins\")\n","          ttps.append(time_to_result+30) # 30 second delay from reaction start when preprocessing\n","          earliness.append(time_index/timestamps[-1])\n","        break\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxnI-jcElWhV","executionInfo":{"status":"ok","timestamp":1651227567037,"user_tz":-60,"elapsed":5795,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"be22d9ae-549c-48b9-8ebf-7da5052263fd"},"execution_count":264,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.32\n","TTP: 376.0s\n","\n","Sample exp_86_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.36\n","TTP: 416.0s\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.4\n","TTP: 475.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.36\n","TTP: 435.0s\n","\n","Sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.3\n","TTP: 365.0s\n","\n","Sample exp_40_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.38\n","TTP: 460.0s\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.34\n","TTP: 415.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.4\n","TTP: 475.0s\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.42\n","TTP: 502s\n","\n","Sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.46\n","TTP: 523.0s\n","\n","Sample exp_2d1_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.44\n","TTP: 508.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.44\n","TTP: 514.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.46\n","TTP: 545.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.46\n","TTP: 560.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.46\n","TTP: 539.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.3\n","TTP: 359.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.34\n","TTP: 411.0s\n","\n","Sample arv7_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample rv1y_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample rv1y_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.52\n","TTP: 618.0s\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.44\n","TTP: 535.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.44\n","TTP: 766.0s\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.4\n","TTP: 458.0s\n","\n","Sample b2\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.34\n","TTP: 402.0s\n","\n","Sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.46\n","TTP: 550s\n","\n","Sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.42\n","TTP: 485s\n","\n","Sample exp_165_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.46\n","TTP: 546s\n","\n","Sample exp_35_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.44\n","TTP: 533s\n","\n","Sample exp_40_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.4\n","TTP: 484s\n","\n","Sample exp_88_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.4\n","TTP: 487s\n","\n","Sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_134_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.48\n","TTP: 561.0s\n","\n","Sample exp_97_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.48\n","TTP: 546s\n","\n","Sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.46\n","TTP: 532s\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.48\n","TTP: 563.0s\n","\n","Sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.48\n","TTP: 580.0s\n","\n","Sample yap1n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145y_n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv7\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Accuracy: 0.6530612244897959\n","Sensitivity/Recall: 0.7857142857142857\n","Specificity: 0.47619047619047616\n","Precision: 0.6666666666666666\n","F1 Score: 0.721311475409836\n"]}]},{"cell_type":"markdown","source":["#### Learning best threshold"],"metadata":{"id":"KPuLuWoixCSR"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             # \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651228042017,"user_tz":-60,"elapsed":352,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"HAfi2bU4phQC"},"execution_count":291,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651228042531,"user_tz":-60,"elapsed":13,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"ps-swVLHphQD"},"execution_count":292,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651228042532,"user_tz":-60,"elapsed":14,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"3594881c-d103-4c93-8a9b-d2a5a68db29a","id":"z-c4frksphQD"},"execution_count":293,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1651228043741,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"r0eTLRQophQD"},"execution_count":294,"outputs":[]},{"cell_type":"markdown","source":["##### Generating candidates"],"metadata":{"id":"ErEA8XSGqh8a"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"_m7lA1HIer-y","executionInfo":{"status":"ok","timestamp":1651228046953,"user_tz":-60,"elapsed":2853,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":295,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"yVEuBQRb1BpE","executionInfo":{"status":"ok","timestamp":1651228046953,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":296,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are the set of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"rI2uBt6fxLlF","executionInfo":{"status":"ok","timestamp":1651228046954,"user_tz":-60,"elapsed":12,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":297,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTV9vJPW5zUg","executionInfo":{"status":"ok","timestamp":1651228046954,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"dc3cedf3-52d5-4511-b825-af22fb6eabb8"},"execution_count":298,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1737"]},"metadata":{},"execution_count":298}]},{"cell_type":"markdown","source":["##### Evaluating candidates"],"metadata":{"id":"872Hxw3fqlfv"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # array to hold cost function value for each candidate\n","  cost_function_values = []\n","\n","  accs = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # alpha\n","  alpha = 0.75\n","\n","  # evaluate every candidate\n","  for th in threshold_candidates:\n","\n","    print(f\"Candidate: {th} \")\n","\n","    # array to hold earliness values for the samples \n","    earliness = []  \n","\n","    # dict to hold predictions vs true values for the samples  \n","    final_classifications = {}\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      # get KNN predicition for the sample\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","        \n","        # get the confidence for that prediction \n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","        if(c >= th): # check if confidence is at or above confidence threshold\n","\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          # predicted class for the sample is given by the prediction which led to the gien confidence value\n","          pred = predictions[i]\n","\n","          # update final outcomes dict\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","          # add to earliness array\n","          earliness.append(time_index/timestamps[-1])\n","\n","          break\n","\n","      sample_idx += 1\n","\n","    # get avg accuracy and avg earliness for this threshold\n","    if(len(final_classifications) > 0):\n","      avg_accuracy = accuracy(final_classifications)\n","      avg_earliness = sum(earliness)/len(earliness)\n","      accs.append(avg_accuracy)\n","      # compute value of cost function and add to array \n","      cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","      cost_function_values.append(cf_score)\n","      print(f\"Score: {cf_score}\")\n","      print(\"\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKc1S0R6ebff","executionInfo":{"status":"ok","timestamp":1651231174217,"user_tz":-60,"elapsed":38997,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"7640e8cf-6b31-405e-97f6-81540c1ac38c"},"execution_count":345,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Score: 0.4005102040816326\n","\n","Candidate: 0.9805194247149325 \n","Score: 0.40061224489795916\n","\n","Candidate: 0.9807396369019792 \n","Score: 0.40061224489795916\n","\n","Candidate: 0.9810774578340067 \n","Score: 0.40061224489795916\n","\n","Candidate: 0.9812483394476234 \n","Score: 0.4164285714285715\n","\n","Candidate: 0.9814617000362724 \n","Score: 0.41663265306122454\n","\n","Candidate: 0.9820156227733985 \n","Score: 0.4167346938775511\n","\n","Candidate: 0.9824140672461767 \n","Score: 0.4168367346938776\n","\n","Candidate: 0.9824818103671653 \n","Score: 0.4168367346938776\n","\n","Candidate: 0.9836003153529018 \n","Score: 0.4168367346938776\n","\n","Candidate: 0.9847922427136468 \n","Score: 0.41693877551020414\n","\n","Candidate: 0.9848793838267169 \n","Score: 0.4171428571428572\n","\n","Candidate: 0.9852444786204811 \n","Score: 0.41724489795918374\n","\n","Candidate: 0.9856458918952135 \n","Score: 0.41734693877551027\n","\n","Candidate: 0.985746398747462 \n","Score: 0.41734693877551027\n","\n","Candidate: 0.985954673561626 \n","Score: 0.4177551020408164\n","\n","Candidate: 0.9861763886311559 \n","Score: 0.4177551020408164\n","\n","Candidate: 0.9864868615726137 \n","Score: 0.418061224489796\n","\n","Candidate: 0.9867957203042544 \n","Score: 0.40295918367346933\n","\n","Candidate: 0.98729964669543 \n","Score: 0.4186734693877551\n","\n","Candidate: 0.9877281955695094 \n","Score: 0.4186734693877551\n","\n","Candidate: 0.9880109626147069 \n","Score: 0.41877551020408166\n","\n","Candidate: 0.9884763592611863 \n","Score: 0.4188775510204082\n","\n","Candidate: 0.9887590132950681 \n","Score: 0.4189795918367347\n","\n","Candidate: 0.9890125575290626 \n","Score: 0.41908163265306125\n","\n","Candidate: 0.989213059374203 \n","Score: 0.4191836734693878\n","\n","Candidate: 0.9893087163747181 \n","Score: 0.4191836734693878\n","\n","Candidate: 0.9894705049979504 \n","Score: 0.42061224489795923\n","\n","Candidate: 0.989670286719937 \n","Score: 0.4209183673469388\n","\n","Candidate: 0.9898731319995635 \n","Score: 0.4209183673469388\n","\n","Candidate: 0.9900145334923225 \n","Score: 0.42102040816326536\n","\n","Candidate: 0.9901831627074512 \n","Score: 0.42102040816326536\n","\n","Candidate: 0.9904598281771162 \n","Score: 0.4213265306122449\n","\n","Candidate: 0.9907145755787441 \n","Score: 0.4213265306122449\n","\n","Candidate: 0.9908965923351027 \n","Score: 0.42142857142857143\n","\n","Candidate: 0.9911325407576783 \n","Score: 0.42142857142857143\n","\n","Candidate: 0.9914284007216503 \n","Score: 0.42153061224489796\n","\n","Candidate: 0.9917423056715087 \n","Score: 0.4216326530612245\n","\n","Candidate: 0.9920925253777754 \n","Score: 0.4072448979591836\n","\n","Candidate: 0.9923203248497471 \n","Score: 0.40734693877551015\n","\n","Candidate: 0.9924152994719717 \n","Score: 0.40734693877551015\n","\n","Candidate: 0.99244528072084 \n","Score: 0.42316326530612247\n","\n","Candidate: 0.9924897856430609 \n","Score: 0.42316326530612247\n","\n","Candidate: 0.9927015638933598 \n","Score: 0.42316326530612247\n","\n","Candidate: 0.9928917468685805 \n","Score: 0.42316326530612247\n","\n","Candidate: 0.9930073795360832 \n","Score: 0.423265306122449\n","\n","Candidate: 0.9931163499964129 \n","Score: 0.42336734693877554\n","\n","Candidate: 0.99319864505632 \n","Score: 0.40836734693877547\n","\n","Candidate: 0.9932950402457034 \n","Score: 0.40867346938775506\n","\n","Candidate: 0.9934907344136894 \n","Score: 0.40867346938775506\n","\n","Candidate: 0.9936856732521424 \n","Score: 0.4087755102040816\n","\n","Candidate: 0.9937246553508788 \n","Score: 0.4088775510204081\n","\n","Candidate: 0.9937907260151246 \n","Score: 0.39408163265306123\n","\n","Candidate: 0.9939278037607204 \n","Score: 0.39418367346938776\n","\n","Candidate: 0.9940803437285569 \n","Score: 0.3942857142857143\n","\n","Candidate: 0.9941582875796641 \n","Score: 0.3943877551020408\n","\n","Candidate: 0.9942435640106412 \n","Score: 0.3943877551020408\n","\n","Candidate: 0.9943234560615702 \n","Score: 0.3943877551020408\n","\n","Candidate: 0.9943836247162048 \n","Score: 0.39448979591836736\n","\n","Candidate: 0.9944530660677611 \n","Score: 0.39448979591836736\n","\n","Candidate: 0.9944893148382333 \n","Score: 0.3945918367346939\n","\n","Candidate: 0.9945944741039316 \n","Score: 0.37938775510204087\n","\n","Candidate: 0.9946928392751762 \n","Score: 0.4118367346938775\n","\n","Candidate: 0.994707273058473 \n","Score: 0.4118367346938775\n","\n","Candidate: 0.9947685531295328 \n","Score: 0.4118367346938775\n","\n","Candidate: 0.9948398249572343 \n","Score: 0.411938775510204\n","\n","Candidate: 0.9949015462521646 \n","Score: 0.41204081632653056\n","\n","Candidate: 0.9950930417579643 \n","Score: 0.4121428571428571\n","\n","Candidate: 0.9952506535073733 \n","Score: 0.4124489795918367\n","\n","Candidate: 0.9953429775064584 \n","Score: 0.4124489795918367\n","\n","Candidate: 0.9954328387445498 \n","Score: 0.4125510204081632\n","\n","Candidate: 0.9954550258104551 \n","Score: 0.4125510204081632\n","\n","Candidate: 0.9954748696868577 \n","Score: 0.41265306122448975\n","\n","Candidate: 0.9954989753241907 \n","Score: 0.42806122448979594\n","\n","Candidate: 0.9955273518869341 \n","Score: 0.4281632653061225\n","\n","Candidate: 0.9956158271671356 \n","Score: 0.428265306122449\n","\n","Candidate: 0.9957431561616974 \n","Score: 0.42836734693877554\n","\n","Candidate: 0.9958251388216903 \n","Score: 0.42846938775510207\n","\n","Candidate: 0.9958608511939904 \n","Score: 0.41326530612244894\n","\n","Candidate: 0.9959190272367747 \n","Score: 0.41326530612244894\n","\n","Candidate: 0.9959712392062466 \n","Score: 0.41387755102040813\n","\n","Candidate: 0.9959846875092249 \n","Score: 0.41387755102040813\n","\n","Candidate: 0.9960625757352889 \n","Score: 0.41397959183673466\n","\n","Candidate: 0.9961751354968269 \n","Score: 0.4141836734693877\n","\n","Candidate: 0.9962352182765115 \n","Score: 0.41428571428571426\n","\n","Candidate: 0.9962685359168619 \n","Score: 0.41428571428571426\n","\n","Candidate: 0.9963193267227285 \n","Score: 0.4143877551020408\n","\n","Candidate: 0.9963985868202687 \n","Score: 0.4144897959183673\n","\n","Candidate: 0.9965385450103823 \n","Score: 0.4146938775510204\n","\n","Candidate: 0.9966471876325005 \n","Score: 0.4146938775510204\n","\n","Candidate: 0.99669733353417 \n","Score: 0.4147959183673469\n","\n","Candidate: 0.9967603205354187 \n","Score: 0.41489795918367345\n","\n","Candidate: 0.9968157429830322 \n","Score: 0.43030612244897964\n","\n","Candidate: 0.9968897938444186 \n","Score: 0.4457142857142857\n","\n","Candidate: 0.9969514410710001 \n","Score: 0.4458163265306122\n","\n","Candidate: 0.9970168306514706 \n","Score: 0.4614285714285714\n","\n","Candidate: 0.9970702073764757 \n","Score: 0.46153061224489794\n","\n","Candidate: 0.9971181150245297 \n","Score: 0.4616326530612245\n","\n","Candidate: 0.997163689421172 \n","Score: 0.461734693877551\n","\n","Candidate: 0.9971878609706333 \n","Score: 0.46183673469387754\n","\n","Candidate: 0.9972294435323581 \n","Score: 0.46183673469387754\n","\n","Candidate: 0.9972533941618729 \n","Score: 0.46306122448979586\n","\n","Candidate: 0.9972680851139889 \n","Score: 0.4632653061224489\n","\n","Candidate: 0.9972825467078028 \n","Score: 0.46336734693877546\n","\n","Candidate: 0.9973300267910559 \n","Score: 0.463469387755102\n","\n","Candidate: 0.9974230747150143 \n","Score: 0.463469387755102\n","\n","Candidate: 0.9975441002447002 \n","Score: 0.463469387755102\n","\n","Candidate: 0.9976220052446241 \n","Score: 0.463469387755102\n","\n","Candidate: 0.9976328332496214 \n","Score: 0.4635714285714285\n","\n","Candidate: 0.9976803399315959 \n","Score: 0.46367346938775506\n","\n","Candidate: 0.9977562822289872 \n","Score: 0.4485714285714285\n","\n","Candidate: 0.997815660499396 \n","Score: 0.44867346938775504\n","\n","Candidate: 0.9978585473357912 \n","Score: 0.4487755102040816\n","\n","Candidate: 0.9978834543808599 \n","Score: 0.4488775510204081\n","\n","Candidate: 0.9979206294489433 \n","Score: 0.4488775510204081\n","\n","Candidate: 0.997956879963555 \n","Score: 0.4488775510204081\n","\n","Candidate: 0.9979749491760335 \n","Score: 0.44897959183673464\n","\n","Candidate: 0.9980064418850003 \n","Score: 0.44908163265306117\n","\n","Candidate: 0.9980368576247111 \n","Score: 0.44908163265306117\n","\n","Candidate: 0.9980618641550686 \n","Score: 0.4491836734693877\n","\n","Candidate: 0.9980914898755662 \n","Score: 0.46459183673469384\n","\n","Candidate: 0.9981235752803834 \n","Score: 0.4647959183673469\n","\n","Candidate: 0.9981473615992389 \n","Score: 0.46489795918367344\n","\n","Candidate: 0.9981810388113284 \n","Score: 0.46499999999999997\n","\n","Candidate: 0.9982331752426501 \n","Score: 0.46499999999999997\n","\n","Candidate: 0.9982639612969448 \n","Score: 0.4498979591836734\n","\n","Candidate: 0.9982910012079025 \n","Score: 0.44999999999999996\n","\n","Candidate: 0.9983252928803992 \n","Score: 0.44999999999999996\n","\n","Candidate: 0.998372249264046 \n","Score: 0.4501020408163265\n","\n","Candidate: 0.9984197769677261 \n","Score: 0.4501020408163265\n","\n","Candidate: 0.9984519496063163 \n","Score: 0.450204081632653\n","\n","Candidate: 0.9984771792521594 \n","Score: 0.4503061224489795\n","\n","Candidate: 0.9984970678754738 \n","Score: 0.4504081632653061\n","\n","Candidate: 0.9985200039171493 \n","Score: 0.4504081632653061\n","\n","Candidate: 0.9985390830494538 \n","Score: 0.46704081632653055\n","\n","Candidate: 0.9985541855875746 \n","Score: 0.46704081632653055\n","\n","Candidate: 0.9986091971177069 \n","Score: 0.4671428571428571\n","\n","Candidate: 0.9986629612372528 \n","Score: 0.4672448979591836\n","\n","Candidate: 0.9986768633601558 \n","Score: 0.4672448979591836\n","\n","Candidate: 0.9986878748067974 \n","Score: 0.46734693877551015\n","\n","Candidate: 0.9987077044805914 \n","Score: 0.4674489795918367\n","\n","Candidate: 0.9987297643392853 \n","Score: 0.4675510204081632\n","\n","Candidate: 0.998768942299807 \n","Score: 0.46765306122448974\n","\n","Candidate: 0.9988023732241139 \n","Score: 0.4677551020408163\n","\n","Candidate: 0.9988112561054263 \n","Score: 0.4678571428571428\n","\n","Candidate: 0.9988444244052319 \n","Score: 0.4678571428571428\n","\n","Candidate: 0.9988746237811672 \n","Score: 0.4678571428571428\n","\n","Candidate: 0.9988823793065387 \n","Score: 0.45265306122448973\n","\n","Candidate: 0.9989008084166672 \n","Score: 0.45275510204081626\n","\n","Candidate: 0.9989180861135882 \n","Score: 0.45275510204081626\n","\n","Candidate: 0.9989227868420876 \n","Score: 0.45275510204081626\n","\n","Candidate: 0.9989317336424839 \n","Score: 0.4528571428571428\n","\n","Candidate: 0.9989471511954311 \n","Score: 0.4529591836734693\n","\n","Candidate: 0.9989679664042109 \n","Score: 0.43806122448979595\n","\n","Candidate: 0.9989789051317792 \n","Score: 0.4381632653061225\n","\n","Candidate: 0.9989977265065895 \n","Score: 0.43836734693877555\n","\n","Candidate: 0.9990214785669944 \n","Score: 0.43836734693877555\n","\n","Candidate: 0.9990330703501328 \n","Score: 0.4384693877551021\n","\n","Candidate: 0.9990450377661302 \n","Score: 0.45459183673469383\n","\n","Candidate: 0.99905406540113 \n","Score: 0.47\n","\n","Candidate: 0.9991076788665354 \n","Score: 0.4701020408163265\n","\n","Candidate: 0.9991655197812102 \n","Score: 0.47020408163265304\n","\n","Candidate: 0.9991755508255957 \n","Score: 0.47030612244897957\n","\n","Candidate: 0.9991827418113532 \n","Score: 0.47030612244897957\n","\n","Candidate: 0.9991885645851911 \n","Score: 0.47030612244897957\n","\n","Candidate: 0.9991910384733546 \n","Score: 0.47030612244897957\n","\n","Candidate: 0.9991991879088653 \n","Score: 0.4704081632653061\n","\n","Candidate: 0.9992066908427599 \n","Score: 0.4704081632653061\n","\n","Candidate: 0.9992086229592279 \n","Score: 0.4705102040816326\n","\n","Candidate: 0.9992219605096286 \n","Score: 0.4718367346938775\n","\n","Candidate: 0.99923618985592 \n","Score: 0.471938775510204\n","\n","Candidate: 0.999238106330191 \n","Score: 0.47204081632653055\n","\n","Candidate: 0.99925404120549 \n","Score: 0.4568367346938775\n","\n","Candidate: 0.999286551752529 \n","Score: 0.456938775510204\n","\n","Candidate: 0.9993071438326083 \n","Score: 0.456938775510204\n","\n","Candidate: 0.9993151665057713 \n","Score: 0.45704081632653054\n","\n","Candidate: 0.9993192998764875 \n","Score: 0.4571428571428571\n","\n","Candidate: 0.9993399318346566 \n","Score: 0.4572448979591836\n","\n","Candidate: 0.9993679039753627 \n","Score: 0.4572448979591836\n","\n","Candidate: 0.9993768597208224 \n","Score: 0.45836734693877546\n","\n","Candidate: 0.9993917845509726 \n","Score: 0.458469387755102\n","\n","Candidate: 0.9994122419788278 \n","Score: 0.4585714285714285\n","\n","Candidate: 0.9994225355898685 \n","Score: 0.4585714285714285\n","\n","Candidate: 0.9994270091993196 \n","Score: 0.44336734693877555\n","\n","Candidate: 0.9994342694978644 \n","Score: 0.4435714285714286\n","\n","Candidate: 0.9994420481485796 \n","Score: 0.44367346938775515\n","\n","Candidate: 0.9994554530731372 \n","Score: 0.4437755102040817\n","\n","Candidate: 0.999469425569811 \n","Score: 0.4437755102040817\n","\n","Candidate: 0.9994831617060109 \n","Score: 0.4438775510204082\n","\n","Candidate: 0.9995053503491307 \n","Score: 0.4440816326530612\n","\n","Candidate: 0.9995218711052256 \n","Score: 0.4440816326530612\n","\n","Candidate: 0.9995278962721228 \n","Score: 0.44418367346938775\n","\n","Candidate: 0.9995282605772475 \n","Score: 0.44418367346938775\n","\n","Candidate: 0.9995414559868635 \n","Score: 0.4442857142857143\n","\n","Candidate: 0.9995559797941769 \n","Score: 0.44448979591836735\n","\n","Candidate: 0.9995606465498799 \n","Score: 0.44540816326530613\n","\n","Candidate: 0.9995645986062915 \n","Score: 0.44540816326530613\n","\n","Candidate: 0.9995661380142706 \n","Score: 0.44551020408163267\n","\n","Candidate: 0.9995722097038013 \n","Score: 0.44551020408163267\n","\n","Candidate: 0.9995788097706202 \n","Score: 0.44561224489795925\n","\n","Candidate: 0.9995805642215496 \n","Score: 0.44571428571428573\n","\n","Candidate: 0.9995930402280746 \n","Score: 0.44581632653061226\n","\n","Candidate: 0.99960601262135 \n","Score: 0.4459183673469388\n","\n","Candidate: 0.99960884464503 \n","Score: 0.4459183673469388\n","\n","Candidate: 0.9996148322714187 \n","Score: 0.4459183673469388\n","\n","Candidate: 0.9996256913938965 \n","Score: 0.43071428571428566\n","\n","Candidate: 0.9996329845608013 \n","Score: 0.4308163265306122\n","\n","Candidate: 0.9996395601128946 \n","Score: 0.4309183673469387\n","\n","Candidate: 0.9996459185462286 \n","Score: 0.4309183673469387\n","\n","Candidate: 0.9996506578473177 \n","Score: 0.4309183673469387\n","\n","Candidate: 0.999656645141502 \n","Score: 0.43102040816326526\n","\n","Candidate: 0.9996583050113985 \n","Score: 0.4311224489795918\n","\n","Candidate: 0.9996668688971877 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.9996774771464925 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.9996817462951317 \n","Score: 0.43132653061224485\n","\n","Candidate: 0.9996890114327297 \n","Score: 0.43132653061224485\n","\n","Candidate: 0.9996973774201331 \n","Score: 0.43132653061224485\n","\n","Candidate: 0.9997094000316535 \n","Score: 0.4314285714285714\n","\n","Candidate: 0.9997215001549884 \n","Score: 0.4315306122448979\n","\n","Candidate: 0.9997256118346203 \n","Score: 0.431734693877551\n","\n","Candidate: 0.9997274338564428 \n","Score: 0.4318367346938775\n","\n","Candidate: 0.999732567912397 \n","Score: 0.43193877551020404\n","\n","Candidate: 0.9997403170881323 \n","Score: 0.43224489795918364\n","\n","Candidate: 0.9997445293332922 \n","Score: 0.43234693877551017\n","\n","Candidate: 0.9997508737011852 \n","Score: 0.43234693877551017\n","\n","Candidate: 0.9997569657896718 \n","Score: 0.4324489795918367\n","\n","Candidate: 0.9997599131022139 \n","Score: 0.43255102040816323\n","\n","Candidate: 0.9997626452148054 \n","Score: 0.4331632653061224\n","\n","Candidate: 0.9997669401359148 \n","Score: 0.4331632653061224\n","\n","Candidate: 0.9997717465967981 \n","Score: 0.4331632653061224\n","\n","Candidate: 0.999772675605709 \n","Score: 0.43326530612244896\n","\n","Candidate: 0.9997798887544214 \n","Score: 0.4333673469387755\n","\n","Candidate: 0.9997871362594828 \n","Score: 0.4495918367346939\n","\n","Candidate: 0.9997886297757044 \n","Score: 0.4496938775510204\n","\n","Candidate: 0.9997908793549455 \n","Score: 0.4496938775510204\n","\n","Candidate: 0.9997924300832999 \n","Score: 0.449795918367347\n","\n","Candidate: 0.9997938461795712 \n","Score: 0.449795918367347\n","\n","Candidate: 0.9997983969525428 \n","Score: 0.4498979591836735\n","\n","Candidate: 0.9998030456463133 \n","Score: 0.45000000000000007\n","\n","Candidate: 0.9998060737564005 \n","Score: 0.4503061224489796\n","\n","Candidate: 0.9998113504709429 \n","Score: 0.45040816326530614\n","\n","Candidate: 0.9998153308617543 \n","Score: 0.45040816326530614\n","\n","Candidate: 0.999818361100718 \n","Score: 0.45051020408163267\n","\n","Candidate: 0.9998264628782196 \n","Score: 0.4506122448979592\n","\n","Candidate: 0.9998352144703646 \n","Score: 0.45071428571428573\n","\n","Candidate: 0.9998392166213557 \n","Score: 0.45081632653061227\n","\n","Candidate: 0.9998415174703743 \n","Score: 0.45081632653061227\n","\n","Candidate: 0.9998434211553869 \n","Score: 0.4509183673469388\n","\n","Candidate: 0.9998444158017317 \n","Score: 0.43571428571428567\n","\n","Candidate: 0.9998451025654105 \n","Score: 0.43571428571428567\n","\n","Candidate: 0.9998460113118666 \n","Score: 0.43571428571428567\n","\n","Candidate: 0.9998474243673141 \n","Score: 0.43571428571428567\n","\n","Candidate: 0.9998489397060741 \n","Score: 0.4358163265306122\n","\n","Candidate: 0.9998538830162645 \n","Score: 0.43591836734693873\n","\n","Candidate: 0.9998616520481725 \n","Score: 0.4361224489795918\n","\n","Candidate: 0.9998662784037655 \n","Score: 0.4362244897959183\n","\n","Candidate: 0.9998697651450811 \n","Score: 0.4362244897959183\n","\n","Candidate: 0.9998721958510648 \n","Score: 0.43632653061224486\n","\n","Candidate: 0.9998724396845391 \n","Score: 0.4364285714285714\n","\n","Candidate: 0.9998754600397839 \n","Score: 0.4365306122448979\n","\n","Candidate: 0.9998796419571104 \n","Score: 0.4365306122448979\n","\n","Candidate: 0.9998818618968169 \n","Score: 0.43663265306122445\n","\n","Candidate: 0.9998828959333912 \n","Score: 0.436734693877551\n","\n","Candidate: 0.9998846691383192 \n","Score: 0.4368367346938775\n","\n","Candidate: 0.999888271564151 \n","Score: 0.43693877551020405\n","\n","Candidate: 0.9998903084038546 \n","Score: 0.483673469387755\n","\n","Candidate: 0.9998931161259218 \n","Score: 0.4837755102040816\n","\n","Candidate: 0.9998975229757965 \n","Score: 0.4838775510204081\n","\n","Candidate: 0.9998993741866338 \n","Score: 0.48418367346938773\n","\n","Candidate: 0.9999002502537984 \n","Score: 0.48418367346938773\n","\n","Candidate: 0.9999010666922716 \n","Score: 0.4842857142857142\n","\n","Candidate: 0.9999043407338588 \n","Score: 0.48438775510204074\n","\n","Candidate: 0.9999075295366637 \n","Score: 0.48448979591836727\n","\n","Candidate: 0.9999093489207856 \n","Score: 0.48448979591836727\n","\n","Candidate: 0.9999120350104231 \n","Score: 0.48448979591836727\n","\n","Candidate: 0.9999131364572669 \n","Score: 0.4845918367346938\n","\n","Candidate: 0.9999134333471129 \n","Score: 0.4845918367346938\n","\n","Candidate: 0.9999135722134584 \n","Score: 0.48469387755102034\n","\n","Candidate: 0.9999143441759419 \n","Score: 0.48479591836734687\n","\n","Candidate: 0.9999164268920621 \n","Score: 0.4848979591836734\n","\n","Candidate: 0.9999185278056333 \n","Score: 0.48499999999999993\n","\n","Candidate: 0.9999204332030849 \n","Score: 0.48510204081632646\n","\n","Candidate: 0.9999221318870661 \n","Score: 0.47010204081632645\n","\n","Candidate: 0.9999248714121989 \n","Score: 0.4703061224489795\n","\n","Candidate: 0.9999277312665834 \n","Score: 0.4703061224489795\n","\n","Candidate: 0.9999307293502591 \n","Score: 0.4706122448979591\n","\n","Candidate: 0.9999338842911529 \n","Score: 0.4706122448979591\n","\n","Candidate: 0.9999354154871589 \n","Score: 0.4708163265306122\n","\n","Candidate: 0.9999361688858677 \n","Score: 0.4709183673469387\n","\n","Candidate: 0.9999374164168331 \n","Score: 0.47102040816326524\n","\n","Candidate: 0.9999387205174017 \n","Score: 0.47132653061224483\n","\n","Candidate: 0.99993920514099 \n","Score: 0.4715306122448979\n","\n","Candidate: 0.9999398659999659 \n","Score: 0.4716326530612244\n","\n","Candidate: 0.9999409742369446 \n","Score: 0.4721428571428571\n","\n","Candidate: 0.9999422536104339 \n","Score: 0.4721428571428571\n","\n","Candidate: 0.9999436089729414 \n","Score: 0.4577551020408164\n","\n","Candidate: 0.9999456789414329 \n","Score: 0.4578571428571429\n","\n","Candidate: 0.9999468703646658 \n","Score: 0.45795918367346944\n","\n","Candidate: 0.999947420070442 \n","Score: 0.44285714285714284\n","\n","Candidate: 0.9999484986700722 \n","Score: 0.44295918367346937\n","\n","Candidate: 0.9999491153994433 \n","Score: 0.4430612244897959\n","\n","Candidate: 0.9999495358260928 \n","Score: 0.4430612244897959\n","\n","Candidate: 0.9999505306596304 \n","Score: 0.44316326530612243\n","\n","Candidate: 0.9999526505573034 \n","Score: 0.44316326530612243\n","\n","Candidate: 0.9999548182286204 \n","Score: 0.44326530612244897\n","\n","Candidate: 0.9999554913701205 \n","Score: 0.44336734693877544\n","\n","Candidate: 0.9999561623667893 \n","Score: 0.44346938775510203\n","\n","Candidate: 0.9999571979508216 \n","Score: 0.4436734693877551\n","\n","Candidate: 0.9999576864323525 \n","Score: 0.44387755102040816\n","\n","Candidate: 0.999958096751947 \n","Score: 0.44387755102040816\n","\n","Candidate: 0.9999587503104846 \n","Score: 0.44397959183673463\n","\n","Candidate: 0.9999596465255635 \n","Score: 0.4440816326530612\n","\n","Candidate: 0.9999607286996802 \n","Score: 0.42887755102040814\n","\n","Candidate: 0.9999631337552579 \n","Score: 0.42887755102040814\n","\n","Candidate: 0.999965532439899 \n","Score: 0.42897959183673473\n","\n","Candidate: 0.9999665617044224 \n","Score: 0.4290816326530612\n","\n","Candidate: 0.9999671118291877 \n","Score: 0.4291836734693878\n","\n","Candidate: 0.9999675841242561 \n","Score: 0.44499999999999995\n","\n","Candidate: 0.9999686081739729 \n","Score: 0.4451020408163265\n","\n","Candidate: 0.9999692806326037 \n","Score: 0.445204081632653\n","\n","Candidate: 0.9999699559371626 \n","Score: 0.44530612244897955\n","\n","Candidate: 0.9999711347879344 \n","Score: 0.44530612244897955\n","\n","Candidate: 0.999971884483826 \n","Score: 0.44530612244897955\n","\n","Candidate: 0.9999721428551819 \n","Score: 0.44530612244897955\n","\n","Candidate: 0.999972759772759 \n","Score: 0.4454081632653061\n","\n","Candidate: 0.9999732954338152 \n","Score: 0.4454081632653061\n","\n","Candidate: 0.9999734716622166 \n","Score: 0.4455102040816326\n","\n","Candidate: 0.9999743215251047 \n","Score: 0.44561224489795914\n","\n","Candidate: 0.9999751843135681 \n","Score: 0.4304081632653061\n","\n","Candidate: 0.9999754803285028 \n","Score: 0.4306122448979592\n","\n","Candidate: 0.9999756618253233 \n","Score: 0.4307142857142857\n","\n","Candidate: 0.999975762809888 \n","Score: 0.43081632653061225\n","\n","Candidate: 0.9999759019242671 \n","Score: 0.43081632653061225\n","\n","Candidate: 0.9999762276780824 \n","Score: 0.43081632653061225\n","\n","Candidate: 0.9999767527086545 \n","Score: 0.43112244897959184\n","\n","Candidate: 0.9999770717816027 \n","Score: 0.4312244897959184\n","\n","Candidate: 0.9999771963113568 \n","Score: 0.4313265306122449\n","\n","Candidate: 0.9999775475963826 \n","Score: 0.43142857142857144\n","\n","Candidate: 0.9999782830255459 \n","Score: 0.43142857142857144\n","\n","Candidate: 0.9999788553234266 \n","Score: 0.4162244897959184\n","\n","Candidate: 0.9999792705987529 \n","Score: 0.41632653061224495\n","\n","Candidate: 0.9999796460852788 \n","Score: 0.41632653061224495\n","\n","Candidate: 0.9999798246850715 \n","Score: 0.4164285714285715\n","\n","Candidate: 0.9999804503641774 \n","Score: 0.4164285714285715\n","\n","Candidate: 0.9999809626068037 \n","Score: 0.4168367346938776\n","\n","Candidate: 0.9999810610159566 \n","Score: 0.41693877551020414\n","\n","Candidate: 0.9999813034455416 \n","Score: 0.41714285714285715\n","\n","Candidate: 0.9999817082280504 \n","Score: 0.41724489795918374\n","\n","Candidate: 0.9999819732768875 \n","Score: 0.41734693877551027\n","\n","Candidate: 0.9999823338081846 \n","Score: 0.41734693877551027\n","\n","Candidate: 0.9999828618263595 \n","Score: 0.4174489795918368\n","\n","Candidate: 0.9999837845853286 \n","Score: 0.4175510204081633\n","\n","Candidate: 0.9999846372802119 \n","Score: 0.4175510204081633\n","\n","Candidate: 0.9999849404150849 \n","Score: 0.41765306122448986\n","\n","Candidate: 0.9999856778795024 \n","Score: 0.41765306122448986\n","\n","Candidate: 0.9999864051729617 \n","Score: 0.41775510204081634\n","\n","Candidate: 0.9999865767260874 \n","Score: 0.4026530612244898\n","\n","Candidate: 0.9999866368549017 \n","Score: 0.4026530612244898\n","\n","Candidate: 0.9999866890500091 \n","Score: 0.4027551020408163\n","\n","Candidate: 0.9999867572975917 \n","Score: 0.40285714285714286\n","\n","Candidate: 0.9999868439237076 \n","Score: 0.4029591836734694\n","\n","Candidate: 0.9999868944284245 \n","Score: 0.4030612244897959\n","\n","Candidate: 0.9999869810301463 \n","Score: 0.4030612244897959\n","\n","Candidate: 0.9999870605047072 \n","Score: 0.4030612244897959\n","\n","Candidate: 0.9999872851197373 \n","Score: 0.40316326530612245\n","\n","Candidate: 0.9999875226793751 \n","Score: 0.403265306122449\n","\n","Candidate: 0.9999879578838469 \n","Score: 0.4033673469387755\n","\n","Candidate: 0.999988432676022 \n","Score: 0.4033673469387755\n","\n","Candidate: 0.9999886281991736 \n","Score: 0.40346938775510205\n","\n","Candidate: 0.9999888209285712 \n","Score: 0.4035714285714286\n","\n","Candidate: 0.9999889044601197 \n","Score: 0.4035714285714286\n","\n","Candidate: 0.9999889579957337 \n","Score: 0.4036734693877551\n","\n","Candidate: 0.999989255938165 \n","Score: 0.40377551020408164\n","\n","Candidate: 0.999989555763498 \n","Score: 0.4038775510204082\n","\n","Candidate: 0.9999897025113831 \n","Score: 0.4042857142857143\n","\n","Candidate: 0.9999900005860008 \n","Score: 0.4042857142857143\n","\n","Candidate: 0.9999902235165868 \n","Score: 0.40438775510204084\n","\n","Candidate: 0.9999903965635829 \n","Score: 0.40448979591836737\n","\n","Candidate: 0.999990695040047 \n","Score: 0.4045918367346939\n","\n","Candidate: 0.9999910027297425 \n","Score: 0.40469387755102043\n","\n","Candidate: 0.9999912807040852 \n","Score: 0.40479591836734696\n","\n","Candidate: 0.9999915142204718 \n","Score: 0.4048979591836735\n","\n","Candidate: 0.9999919380400479 \n","Score: 0.405\n","\n","Candidate: 0.999992262647136 \n","Score: 0.405\n","\n","Candidate: 0.999992384556775 \n","Score: 0.40510204081632656\n","\n","Candidate: 0.9999924966647039 \n","Score: 0.40510204081632656\n","\n","Candidate: 0.9999924982686919 \n","Score: 0.40540816326530615\n","\n","Candidate: 0.9999925274051886 \n","Score: 0.40551020408163263\n","\n","Candidate: 0.9999926270514867 \n","Score: 0.40551020408163263\n","\n","Candidate: 0.9999927369355313 \n","Score: 0.4056122448979592\n","\n","Candidate: 0.9999928948160529 \n","Score: 0.40571428571428575\n","\n","Candidate: 0.99999304680226 \n","Score: 0.4058163265306123\n","\n","Candidate: 0.9999931088964376 \n","Score: 0.4059183673469388\n","\n","Candidate: 0.9999931993691527 \n","Score: 0.40602040816326535\n","\n","Candidate: 0.9999934666796413 \n","Score: 0.40602040816326535\n","\n","Candidate: 0.9999936739490256 \n","Score: 0.4061224489795918\n","\n","Candidate: 0.9999936860134326 \n","Score: 0.4062244897959184\n","\n","Candidate: 0.9999939508099732 \n","Score: 0.40632653061224494\n","\n","Candidate: 0.9999942281270892 \n","Score: 0.4228571428571429\n","\n","Candidate: 0.9999942657413579 \n","Score: 0.4228571428571429\n","\n","Candidate: 0.9999942849224535 \n","Score: 0.4076530612244898\n","\n","Candidate: 0.999994330653303 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.9999944048062746 \n","Score: 0.40785714285714286\n","\n","Candidate: 0.9999944801510505 \n","Score: 0.4079591836734694\n","\n","Candidate: 0.9999945818087366 \n","Score: 0.4080612244897959\n","\n","Candidate: 0.9999946551513366 \n","Score: 0.39316326530612244\n","\n","Candidate: 0.9999947406683798 \n","Score: 0.39316326530612244\n","\n","Candidate: 0.9999948263000782 \n","Score: 0.393265306122449\n","\n","Candidate: 0.9999949732239077 \n","Score: 0.3933673469387755\n","\n","Candidate: 0.9999951163671648 \n","Score: 0.39346938775510204\n","\n","Candidate: 0.9999951511430756 \n","Score: 0.39357142857142857\n","\n","Candidate: 0.9999952182904488 \n","Score: 0.3936734693877551\n","\n","Candidate: 0.9999952728324801 \n","Score: 0.3936734693877551\n","\n","Candidate: 0.9999952855955836 \n","Score: 0.39377551020408164\n","\n","Candidate: 0.9999954289115368 \n","Score: 0.39387755102040817\n","\n","Candidate: 0.9999956285378189 \n","Score: 0.3939795918367347\n","\n","Candidate: 0.9999957227340752 \n","Score: 0.39408163265306123\n","\n","Candidate: 0.9999957728796985 \n","Score: 0.39418367346938776\n","\n","Candidate: 0.9999958290676576 \n","Score: 0.3942857142857143\n","\n","Candidate: 0.9999958908079938 \n","Score: 0.3942857142857143\n","\n","Candidate: 0.9999959623472794 \n","Score: 0.3943877551020408\n","\n","Candidate: 0.9999960375861088 \n","Score: 0.39448979591836736\n","\n","Candidate: 0.9999960920986255 \n","Score: 0.3945918367346939\n","\n","Candidate: 0.9999961573289704 \n","Score: 0.3945918367346939\n","\n","Candidate: 0.9999962353955224 \n","Score: 0.3946938775510204\n","\n","Candidate: 0.9999962870976462 \n","Score: 0.3946938775510204\n","\n","Candidate: 0.9999963167362591 \n","Score: 0.3946938775510204\n","\n","Candidate: 0.9999963709346632 \n","Score: 0.39479591836734695\n","\n","Candidate: 0.9999964140484199 \n","Score: 0.3948979591836735\n","\n","Candidate: 0.9999964373329779 \n","Score: 0.3948979591836735\n","\n","Candidate: 0.999996456444559 \n","Score: 0.395\n","\n","Candidate: 0.9999966027951341 \n","Score: 0.39510204081632655\n","\n","Candidate: 0.9999967483107767 \n","Score: 0.3952040816326531\n","\n","Candidate: 0.9999967580892715 \n","Score: 0.3953061224489796\n","\n","Candidate: 0.9999967896650859 \n","Score: 0.39540816326530615\n","\n","Candidate: 0.9999968897739344 \n","Score: 0.41132653061224494\n","\n","Candidate: 0.9999969743560568 \n","Score: 0.4114285714285715\n","\n","Candidate: 0.9999969916814766 \n","Score: 0.41153061224489795\n","\n","Candidate: 0.9999970048644806 \n","Score: 0.41153061224489795\n","\n","Candidate: 0.9999970224765089 \n","Score: 0.41163265306122454\n","\n","Candidate: 0.9999970859204395 \n","Score: 0.411734693877551\n","\n","Candidate: 0.9999972152973329 \n","Score: 0.41183673469387755\n","\n","Candidate: 0.9999973063734195 \n","Score: 0.4119387755102041\n","\n","Candidate: 0.9999973337150851 \n","Score: 0.4120408163265306\n","\n","Candidate: 0.9999973684680112 \n","Score: 0.4279591836734694\n","\n","Candidate: 0.9999974064525585 \n","Score: 0.4279591836734694\n","\n","Candidate: 0.9999974241865549 \n","Score: 0.42806122448979594\n","\n","Candidate: 0.9999974477528424 \n","Score: 0.4281632653061225\n","\n","Candidate: 0.9999974776771658 \n","Score: 0.428265306122449\n","\n","Candidate: 0.9999975017657387 \n","Score: 0.4285714285714286\n","\n","Candidate: 0.9999975258370226 \n","Score: 0.4286734693877551\n","\n","Candidate: 0.9999975606746274 \n","Score: 0.4286734693877551\n","\n","Candidate: 0.9999975977007983 \n","Score: 0.42877551020408167\n","\n","Candidate: 0.9999976284793682 \n","Score: 0.4288775510204082\n","\n","Candidate: 0.9999976533863295 \n","Score: 0.42897959183673473\n","\n","Candidate: 0.9999976739875358 \n","Score: 0.4290816326530612\n","\n","Candidate: 0.9999977012753404 \n","Score: 0.4291836734693878\n","\n","Candidate: 0.9999977709447465 \n","Score: 0.4291836734693878\n","\n","Candidate: 0.9999978278271744 \n","Score: 0.42928571428571427\n","\n","Candidate: 0.9999978413283628 \n","Score: 0.42938775510204086\n","\n","Candidate: 0.9999978731339905 \n","Score: 0.42948979591836733\n","\n","Candidate: 0.9999978976561452 \n","Score: 0.42959183673469387\n","\n","Candidate: 0.9999979066998772 \n","Score: 0.4296938775510204\n","\n","Candidate: 0.999997913555746 \n","Score: 0.429795918367347\n","\n","Candidate: 0.9999979395637548 \n","Score: 0.445204081632653\n","\n","Candidate: 0.9999979661908642 \n","Score: 0.445204081632653\n","\n","Candidate: 0.9999979746946603 \n","Score: 0.4301020408163265\n","\n","Candidate: 0.9999979916707109 \n","Score: 0.43020408163265306\n","\n","Candidate: 0.9999980280023402 \n","Score: 0.4303061224489796\n","\n","Candidate: 0.9999980619434334 \n","Score: 0.4304081632653061\n","\n","Candidate: 0.9999980751122883 \n","Score: 0.43051020408163265\n","\n","Candidate: 0.9999981113173226 \n","Score: 0.4306122448979592\n","\n","Candidate: 0.9999981831841982 \n","Score: 0.4307142857142857\n","\n","Candidate: 0.9999982275592446 \n","Score: 0.43081632653061225\n","\n","Candidate: 0.9999982466279438 \n","Score: 0.4309183673469388\n","\n","Candidate: 0.9999982823197842 \n","Score: 0.43102040816326537\n","\n","Candidate: 0.9999983217774271 \n","Score: 0.43112244897959184\n","\n","Candidate: 0.9999983406904132 \n","Score: 0.43112244897959184\n","\n","Candidate: 0.9999983496487582 \n","Score: 0.43122448979591843\n","\n","Candidate: 0.9999983816936429 \n","Score: 0.4313265306122449\n","\n","Candidate: 0.999998414539981 \n","Score: 0.4313265306122449\n","\n","Candidate: 0.9999984318377422 \n","Score: 0.4314285714285715\n","\n","Candidate: 0.9999984514161238 \n","Score: 0.43153061224489797\n","\n","Candidate: 0.9999984696816622 \n","Score: 0.43163265306122456\n","\n","Candidate: 0.9999984840312816 \n","Score: 0.43173469387755103\n","\n","Candidate: 0.9999985403024146 \n","Score: 0.43173469387755103\n","\n","Candidate: 0.9999985920368277 \n","Score: 0.4318367346938776\n","\n","Candidate: 0.9999986348705174 \n","Score: 0.4319387755102041\n","\n","Candidate: 0.9999986924072068 \n","Score: 0.4320408163265307\n","\n","Candidate: 0.9999987258571212 \n","Score: 0.43214285714285716\n","\n","Candidate: 0.9999987519668524 \n","Score: 0.4322448979591837\n","\n","Candidate: 0.9999987741140621 \n","Score: 0.4323469387755102\n","\n","Candidate: 0.9999987977296259 \n","Score: 0.43244897959183676\n","\n","Candidate: 0.9999988219726297 \n","Score: 0.4325510204081633\n","\n","Candidate: 0.9999988367080512 \n","Score: 0.4326530612244898\n","\n","Candidate: 0.9999988389609393 \n","Score: 0.43275510204081635\n","\n","Candidate: 0.9999988399699486 \n","Score: 0.43275510204081635\n","\n","Candidate: 0.9999988501730249 \n","Score: 0.4328571428571429\n","\n","Candidate: 0.9999988645567501 \n","Score: 0.4329591836734694\n","\n","Candidate: 0.9999988697300909 \n","Score: 0.43306122448979595\n","\n","Candidate: 0.9999988749166334 \n","Score: 0.4331632653061225\n","\n","Candidate: 0.9999988799413659 \n","Score: 0.4331632653061225\n","\n","Candidate: 0.9999988840324168 \n","Score: 0.433265306122449\n","\n","Candidate: 0.999998889500325 \n","Score: 0.43336734693877554\n","\n","Candidate: 0.9999989015505462 \n","Score: 0.43336734693877554\n","\n","Candidate: 0.9999989271057307 \n","Score: 0.41836734693877553\n","\n","Candidate: 0.9999989484622067 \n","Score: 0.41846938775510206\n","\n","Candidate: 0.999998963020942 \n","Score: 0.4351020408163266\n","\n","Candidate: 0.999998976957922 \n","Score: 0.4352040816326531\n","\n","Candidate: 0.9999989897807546 \n","Score: 0.43530612244897965\n","\n","Candidate: 0.9999990046896425 \n","Score: 0.4354081632653062\n","\n","Candidate: 0.9999990163844159 \n","Score: 0.4355102040816327\n","\n","Candidate: 0.9999990229036246 \n","Score: 0.43561224489795924\n","\n","Candidate: 0.99999902801636 \n","Score: 0.4357142857142858\n","\n","Candidate: 0.9999990370704553 \n","Score: 0.4358163265306123\n","\n","Candidate: 0.999999043575998 \n","Score: 0.43591836734693884\n","\n","Candidate: 0.9999990595061908 \n","Score: 0.43602040816326537\n","\n","Candidate: 0.9999990796586449 \n","Score: 0.4361224489795919\n","\n","Candidate: 0.9999990875140796 \n","Score: 0.43622448979591844\n","\n","Candidate: 0.9999990960138367 \n","Score: 0.43632653061224497\n","\n","Candidate: 0.9999991098523249 \n","Score: 0.4364285714285715\n","\n","Candidate: 0.9999991304405946 \n","Score: 0.43653061224489803\n","\n","Candidate: 0.9999991436907818 \n","Score: 0.43663265306122456\n","\n","Candidate: 0.9999991454399324 \n","Score: 0.4367346938775511\n","\n","Candidate: 0.9999991498190572 \n","Score: 0.4368367346938776\n","\n","Candidate: 0.9999991674581115 \n","Score: 0.43693877551020416\n","\n","Candidate: 0.999999193432137 \n","Score: 0.4370408163265307\n","\n","Candidate: 0.9999992183033115 \n","Score: 0.4370408163265307\n","\n","Candidate: 0.9999992407525717 \n","Score: 0.4371428571428572\n","\n","Candidate: 0.9999992542744033 \n","Score: 0.43724489795918375\n","\n","Candidate: 0.9999992685395279 \n","Score: 0.43724489795918375\n","\n","Candidate: 0.9999992842890583 \n","Score: 0.4373469387755103\n","\n","Candidate: 0.9999993032172158 \n","Score: 0.4373469387755103\n","\n","Candidate: 0.9999993189579905 \n","Score: 0.4373469387755103\n","\n","Candidate: 0.9999993246161227 \n","Score: 0.4373469387755103\n","\n","Candidate: 0.9999993332341717 \n","Score: 0.4373469387755103\n","\n","Candidate: 0.9999993447121205 \n","Score: 0.4374489795918368\n","\n","Candidate: 0.9999993612129954 \n","Score: 0.4374489795918368\n","\n","Candidate: 0.9999993771505743 \n","Score: 0.43755102040816335\n","\n","Candidate: 0.9999993845456636 \n","Score: 0.4376530612244899\n","\n","Candidate: 0.9999993870778688 \n","Score: 0.43775510204081636\n","\n","Candidate: 0.999999403223056 \n","Score: 0.43785714285714294\n","\n","Candidate: 0.9999994261094163 \n","Score: 0.4379591836734694\n","\n","Candidate: 0.9999994345788992 \n","Score: 0.438061224489796\n","\n","Candidate: 0.9999994362772546 \n","Score: 0.43816326530612254\n","\n","Candidate: 0.9999994394579651 \n","Score: 0.43826530612244907\n","\n","Candidate: 0.9999994438290507 \n","Score: 0.43836734693877555\n","\n","Candidate: 0.9999994576397302 \n","Score: 0.43846938775510214\n","\n","Candidate: 0.9999994722294299 \n","Score: 0.4385714285714286\n","\n","Candidate: 0.9999994762177865 \n","Score: 0.4236734693877552\n","\n","Candidate: 0.9999994778563652 \n","Score: 0.42377551020408166\n","\n","Candidate: 0.9999994801962933 \n","Score: 0.4240816326530613\n","\n","Candidate: 0.999999487323967 \n","Score: 0.4241836734693878\n","\n","Candidate: 0.9999994940160102 \n","Score: 0.4242857142857144\n","\n","Candidate: 0.999999497880584 \n","Score: 0.4243877551020409\n","\n","Candidate: 0.999999500828867 \n","Score: 0.42448979591836744\n","\n","Candidate: 0.9999995023360344 \n","Score: 0.42448979591836744\n","\n","Candidate: 0.9999995093323131 \n","Score: 0.424591836734694\n","\n","Candidate: 0.9999995165608011 \n","Score: 0.4246938775510205\n","\n","Candidate: 0.9999995190342451 \n","Score: 0.42479591836734704\n","\n","Candidate: 0.999999524907357 \n","Score: 0.42489795918367357\n","\n","Candidate: 0.999999539684546 \n","Score: 0.42602040816326536\n","\n","Candidate: 0.9999995515173594 \n","Score: 0.4262244897959184\n","\n","Candidate: 0.9999995561778693 \n","Score: 0.42632653061224496\n","\n","Candidate: 0.9999995591453608 \n","Score: 0.4112244897959184\n","\n","Candidate: 0.9999995648024105 \n","Score: 0.41132653061224494\n","\n","Candidate: 0.9999995710861636 \n","Score: 0.4114285714285715\n","\n","Candidate: 0.9999995762044827 \n","Score: 0.411530612244898\n","\n","Candidate: 0.999999584587119 \n","Score: 0.41163265306122454\n","\n","Candidate: 0.9999995897508958 \n","Score: 0.4117346938775511\n","\n","Candidate: 0.999999591028816 \n","Score: 0.4118367346938776\n","\n","Candidate: 0.9999995933881554 \n","Score: 0.41193877551020414\n","\n","Candidate: 0.9999995976105143 \n","Score: 0.41204081632653067\n","\n","Candidate: 0.9999996012413593 \n","Score: 0.4121428571428572\n","\n","Candidate: 0.9999996030635797 \n","Score: 0.4121428571428572\n","\n","Candidate: 0.9999996068340194 \n","Score: 0.41224489795918373\n","\n","Candidate: 0.999999628069978 \n","Score: 0.42765306122448987\n","\n","Candidate: 0.9999996491305765 \n","Score: 0.4277551020408164\n","\n","Candidate: 0.9999996555109184 \n","Score: 0.42785714285714294\n","\n","Candidate: 0.9999996588058311 \n","Score: 0.42795918367346947\n","\n","Candidate: 0.9999996620862365 \n","Score: 0.428061224489796\n","\n","Candidate: 0.9999996735457521 \n","Score: 0.42816326530612253\n","\n","Candidate: 0.9999996820972397 \n","Score: 0.42816326530612253\n","\n","Candidate: 0.9999996848995227 \n","Score: 0.42826530612244906\n","\n","Candidate: 0.9999996894170269 \n","Score: 0.4283673469387756\n","\n","Candidate: 0.9999996919270584 \n","Score: 0.4284693877551021\n","\n","Candidate: 0.9999996928534342 \n","Score: 0.4284693877551021\n","\n","Candidate: 0.9999996956334407 \n","Score: 0.4285714285714286\n","\n","Candidate: 0.9999997018324966 \n","Score: 0.4286734693877552\n","\n","Candidate: 0.9999997069681674 \n","Score: 0.42877551020408167\n","\n","Candidate: 0.9999997108256977 \n","Score: 0.4288775510204082\n","\n","Candidate: 0.9999997162462272 \n","Score: 0.4288775510204082\n","\n","Candidate: 0.999999723842893 \n","Score: 0.42897959183673473\n","\n","Candidate: 0.9999997286513772 \n","Score: 0.42897959183673473\n","\n","Candidate: 0.9999997290520046 \n","Score: 0.42908163265306126\n","\n","Candidate: 0.999999735937839 \n","Score: 0.4291836734693878\n","\n","Candidate: 0.9999997453058048 \n","Score: 0.4292857142857143\n","\n","Candidate: 0.9999997529761575 \n","Score: 0.42938775510204086\n","\n","Candidate: 0.9999997613807673 \n","Score: 0.42969387755102045\n","\n","Candidate: 0.999999767331835 \n","Score: 0.429795918367347\n","\n","Candidate: 0.9999997712240403 \n","Score: 0.43000000000000005\n","\n","Candidate: 0.9999997728865382 \n","Score: 0.4301020408163266\n","\n","Candidate: 0.9999997738772413 \n","Score: 0.4301020408163266\n","\n","Candidate: 0.9999997790026791 \n","Score: 0.4301020408163266\n","\n","Candidate: 0.9999997837032402 \n","Score: 0.4302040816326531\n","\n","Candidate: 0.9999997858376597 \n","Score: 0.43030612244897964\n","\n","Candidate: 0.9999997879052078 \n","Score: 0.41510204081632657\n","\n","Candidate: 0.9999997887252956 \n","Score: 0.4152040816326531\n","\n","Candidate: 0.9999997902671112 \n","Score: 0.41530612244897963\n","\n","Candidate: 0.9999997911317657 \n","Score: 0.41540816326530616\n","\n","Candidate: 0.9999997915906453 \n","Score: 0.4155102040816327\n","\n","Candidate: 0.9999997968676713 \n","Score: 0.4156122448979592\n","\n","Candidate: 0.9999998032711197 \n","Score: 0.41571428571428576\n","\n","Candidate: 0.9999998057372479 \n","Score: 0.41591836734693877\n","\n","Candidate: 0.9999998079921478 \n","Score: 0.41602040816326535\n","\n","Candidate: 0.9999998093933584 \n","Score: 0.41602040816326535\n","\n","Candidate: 0.999999811496875 \n","Score: 0.41612244897959183\n","\n","Candidate: 0.9999998137927142 \n","Score: 0.4162244897959184\n","\n","Candidate: 0.9999998160129084 \n","Score: 0.4163265306122449\n","\n","Candidate: 0.9999998204276934 \n","Score: 0.4164285714285714\n","\n","Candidate: 0.9999998246841246 \n","Score: 0.41653061224489796\n","\n","Candidate: 0.9999998269948405 \n","Score: 0.4166326530612245\n","\n","Candidate: 0.9999998277844693 \n","Score: 0.416734693877551\n","\n","Candidate: 0.9999998286814384 \n","Score: 0.4168367346938776\n","\n","Candidate: 0.9999998343100792 \n","Score: 0.4169387755102041\n","\n","Candidate: 0.9999998397736307 \n","Score: 0.41704081632653067\n","\n","Candidate: 0.9999998405653454 \n","Score: 0.41714285714285715\n","\n","Candidate: 0.9999998414145594 \n","Score: 0.41724489795918374\n","\n","Candidate: 0.9999998428809593 \n","Score: 0.41734693877551027\n","\n","Candidate: 0.9999998461490677 \n","Score: 0.41734693877551027\n","\n","Candidate: 0.9999998497287554 \n","Score: 0.4174489795918368\n","\n","Candidate: 0.9999998516450797 \n","Score: 0.4028571428571429\n","\n","Candidate: 0.9999998532438676 \n","Score: 0.4029591836734694\n","\n","Candidate: 0.9999998550820772 \n","Score: 0.403061224489796\n","\n","Candidate: 0.9999998582149088 \n","Score: 0.403061224489796\n","\n","Candidate: 0.9999998610865091 \n","Score: 0.40316326530612245\n","\n","Candidate: 0.9999998626968889 \n","Score: 0.40316326530612245\n","\n","Candidate: 0.9999998671816472 \n","Score: 0.40316326530612245\n","\n","Candidate: 0.9999998706909798 \n","Score: 0.40326530612244904\n","\n","Candidate: 0.9999998750084326 \n","Score: 0.4033673469387755\n","\n","Candidate: 0.9999998793338771 \n","Score: 0.4033673469387755\n","\n","Candidate: 0.9999998815885345 \n","Score: 0.4034693877551021\n","\n","Candidate: 0.9999998838067599 \n","Score: 0.4035714285714286\n","\n","Candidate: 0.9999998865828768 \n","Score: 0.4036734693877551\n","\n","Candidate: 0.9999998905487648 \n","Score: 0.40377551020408164\n","\n","Candidate: 0.9999998924067726 \n","Score: 0.4038775510204082\n","\n","Candidate: 0.9999998953484357 \n","Score: 0.4039795918367347\n","\n","Candidate: 0.9999998981697846 \n","Score: 0.40408163265306124\n","\n","Candidate: 0.9999998989380244 \n","Score: 0.40418367346938777\n","\n","Candidate: 0.999999899976159 \n","Score: 0.4042857142857143\n","\n","Candidate: 0.9999999010339536 \n","Score: 0.4042857142857143\n","\n","Candidate: 0.9999999040343718 \n","Score: 0.40438775510204084\n","\n","Candidate: 0.9999999070106962 \n","Score: 0.40448979591836737\n","\n","Candidate: 0.9999999075411878 \n","Score: 0.40448979591836737\n","\n","Candidate: 0.9999999086687168 \n","Score: 0.4045918367346939\n","\n","Candidate: 0.999999909677868 \n","Score: 0.40469387755102043\n","\n","Candidate: 0.9999999109597509 \n","Score: 0.40479591836734696\n","\n","Candidate: 0.9999999125202019 \n","Score: 0.4048979591836735\n","\n","Candidate: 0.9999999132751146 \n","Score: 0.405\n","\n","Candidate: 0.9999999151920689 \n","Score: 0.40510204081632656\n","\n","Candidate: 0.9999999170295378 \n","Score: 0.4052040816326531\n","\n","Candidate: 0.9999999172588481 \n","Score: 0.4053061224489796\n","\n","Candidate: 0.9999999176612879 \n","Score: 0.40540816326530615\n","\n","Candidate: 0.9999999181718469 \n","Score: 0.4208163265306123\n","\n","Candidate: 0.9999999187117699 \n","Score: 0.4209183673469388\n","\n","Candidate: 0.9999999205225509 \n","Score: 0.42102040816326536\n","\n","Candidate: 0.9999999219281839 \n","Score: 0.4211224489795919\n","\n","Candidate: 0.9999999225871476 \n","Score: 0.4213265306122449\n","\n","Candidate: 0.999999923576596 \n","Score: 0.4214285714285715\n","\n","Candidate: 0.9999999246785928 \n","Score: 0.42153061224489796\n","\n","Candidate: 0.9999999256630747 \n","Score: 0.42163265306122455\n","\n","Candidate: 0.9999999260085488 \n","Score: 0.421734693877551\n","\n","Candidate: 0.9999999262438303 \n","Score: 0.42183673469387756\n","\n","Candidate: 0.9999999265990202 \n","Score: 0.4219387755102041\n","\n","Candidate: 0.9999999275273935 \n","Score: 0.4219387755102041\n","\n","Candidate: 0.999999928540826 \n","Score: 0.4220408163265307\n","\n","Candidate: 0.9999999294482853 \n","Score: 0.42214285714285715\n","\n","Candidate: 0.9999999303897278 \n","Score: 0.42224489795918374\n","\n","Candidate: 0.9999999319188273 \n","Score: 0.4223469387755102\n","\n","Candidate: 0.9999999338465887 \n","Score: 0.4223469387755102\n","\n","Candidate: 0.9999999358666856 \n","Score: 0.42244897959183675\n","\n","Candidate: 0.999999937899237 \n","Score: 0.42244897959183675\n","\n","Candidate: 0.9999999388606886 \n","Score: 0.42244897959183675\n","\n","Candidate: 0.9999999393468505 \n","Score: 0.42244897959183675\n","\n","Candidate: 0.9999999407702029 \n","Score: 0.4225510204081633\n","\n","Candidate: 0.9999999429404725 \n","Score: 0.4226530612244898\n","\n","Candidate: 0.9999999442740679 \n","Score: 0.42275510204081634\n","\n","Candidate: 0.9999999457247287 \n","Score: 0.4228571428571429\n","\n","Candidate: 0.9999999473089624 \n","Score: 0.4228571428571429\n","\n","Candidate: 0.9999999478866402 \n","Score: 0.4229591836734694\n","\n","Candidate: 0.9999999482758697 \n","Score: 0.42306122448979594\n","\n","Candidate: 0.9999999493597417 \n","Score: 0.42306122448979594\n","\n","Candidate: 0.9999999502994872 \n","Score: 0.42316326530612247\n","\n","Candidate: 0.9999999521630942 \n","Score: 0.42316326530612247\n","\n","Candidate: 0.9999999545954827 \n","Score: 0.423265306122449\n","\n","Candidate: 0.9999999556804338 \n","Score: 0.42336734693877554\n","\n","Candidate: 0.99999995617911 \n","Score: 0.42346938775510207\n","\n","Candidate: 0.9999999567384854 \n","Score: 0.4235714285714286\n","\n","Candidate: 0.999999958446753 \n","Score: 0.42367346938775513\n","\n","Candidate: 0.9999999600578755 \n","Score: 0.42367346938775513\n","\n","Candidate: 0.9999999607284964 \n","Score: 0.42377551020408166\n","\n","Candidate: 0.9999999611090685 \n","Score: 0.4085714285714286\n","\n","Candidate: 0.9999999614810866 \n","Score: 0.4086734693877551\n","\n","Candidate: 0.9999999618232112 \n","Score: 0.40877551020408165\n","\n","Candidate: 0.9999999622189972 \n","Score: 0.4088775510204082\n","\n","Candidate: 0.9999999628356107 \n","Score: 0.4089795918367347\n","\n","Candidate: 0.999999963261951 \n","Score: 0.40908163265306124\n","\n","Candidate: 0.9999999635982818 \n","Score: 0.4091836734693878\n","\n","Candidate: 0.9999999641701562 \n","Score: 0.4092857142857143\n","\n","Candidate: 0.999999964677438 \n","Score: 0.40938775510204084\n","\n","Candidate: 0.999999964883817 \n","Score: 0.40948979591836737\n","\n","Candidate: 0.9999999649696338 \n","Score: 0.4095918367346939\n","\n","Candidate: 0.9999999652319776 \n","Score: 0.40969387755102044\n","\n","Candidate: 0.9999999658189319 \n","Score: 0.40979591836734697\n","\n","Candidate: 0.9999999665393247 \n","Score: 0.4098979591836735\n","\n","Candidate: 0.9999999673055915 \n","Score: 0.41000000000000003\n","\n","Candidate: 0.9999999677873324 \n","Score: 0.41010204081632656\n","\n","Candidate: 0.9999999681658877 \n","Score: 0.4102040816326531\n","\n","Candidate: 0.9999999685467614 \n","Score: 0.4103061224489796\n","\n","Candidate: 0.9999999687693927 \n","Score: 0.4103061224489796\n","\n","Candidate: 0.9999999688999885 \n","Score: 0.41040816326530616\n","\n","Candidate: 0.9999999690415771 \n","Score: 0.41051020408163263\n","\n","Candidate: 0.9999999692350496 \n","Score: 0.4106122448979592\n","\n","Candidate: 0.9999999696532911 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9999999702015258 \n","Score: 0.41081632653061223\n","\n","Candidate: 0.9999999708568541 \n","Score: 0.4110204081632653\n","\n","Candidate: 0.9999999713340507 \n","Score: 0.4110204081632653\n","\n","Candidate: 0.9999999715038026 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9999999718865755 \n","Score: 0.4112244897959184\n","\n","Candidate: 0.9999999722562735 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999729223088 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999738378409 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999742562192 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999743012322 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999746884815 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999751245963 \n","Score: 0.4114285714285714\n","\n","Candidate: 0.9999999754077122 \n","Score: 0.4114285714285714\n","\n","Candidate: 0.999999976606848 \n","Score: 0.4114285714285714\n","\n","Candidate: 0.9999999775936702 \n","Score: 0.41153061224489795\n","\n","Candidate: 0.9999999776627289 \n","Score: 0.3963265306122449\n","\n","Candidate: 0.9999999780519149 \n","Score: 0.3964285714285714\n","\n","Candidate: 0.9999999787168808 \n","Score: 0.39653061224489794\n","\n","Candidate: 0.999999979942682 \n","Score: 0.39663265306122447\n","\n","Candidate: 0.999999980901595 \n","Score: 0.396734693877551\n","\n","Candidate: 0.9999999813201311 \n","Score: 0.39683673469387754\n","\n","Candidate: 0.9999999817487799 \n","Score: 0.39693877551020407\n","\n","Candidate: 0.9999999820682158 \n","Score: 0.3970408163265306\n","\n","Candidate: 0.9999999826183414 \n","Score: 0.39714285714285713\n","\n","Candidate: 0.9999999830634849 \n","Score: 0.39714285714285713\n","\n","Candidate: 0.999999983218808 \n","Score: 0.39724489795918366\n","\n","Candidate: 0.9999999835333302 \n","Score: 0.3973469387755102\n","\n","Candidate: 0.9999999838932228 \n","Score: 0.3974489795918367\n","\n","Candidate: 0.9999999840534579 \n","Score: 0.39755102040816326\n","\n","Candidate: 0.9999999841911311 \n","Score: 0.3976530612244898\n","\n","Candidate: 0.999999984286007 \n","Score: 0.3977551020408163\n","\n","Candidate: 0.999999984542991 \n","Score: 0.3977551020408163\n","\n","Candidate: 0.9999999847690378 \n","Score: 0.39785714285714285\n","\n","Candidate: 0.9999999847926404 \n","Score: 0.39785714285714285\n","\n","Candidate: 0.9999999849112015 \n","Score: 0.3979591836734694\n","\n","Candidate: 0.9999999850298922 \n","Score: 0.3980612244897959\n","\n","Candidate: 0.9999999851636805 \n","Score: 0.39816326530612245\n","\n","Candidate: 0.9999999853556404 \n","Score: 0.398265306122449\n","\n","Candidate: 0.9999999854324172 \n","Score: 0.398469387755102\n","\n","Candidate: 0.9999999854691657 \n","Score: 0.3985714285714286\n","\n","Candidate: 0.9999999857518493 \n","Score: 0.39867346938775505\n","\n","Candidate: 0.9999999861365314 \n","Score: 0.39877551020408164\n","\n","Candidate: 0.9999999864153465 \n","Score: 0.3837755102040816\n","\n","Candidate: 0.9999999865965435 \n","Score: 0.38387755102040816\n","\n","Candidate: 0.9999999866706203 \n","Score: 0.3839795918367347\n","\n","Candidate: 0.9999999867160239 \n","Score: 0.3840816326530612\n","\n","Candidate: 0.9999999869083523 \n","Score: 0.3840816326530612\n","\n","Candidate: 0.9999999871217864 \n","Score: 0.3840816326530612\n","\n","Candidate: 0.999999987199851 \n","Score: 0.38418367346938775\n","\n","Candidate: 0.999999987353483 \n","Score: 0.3842857142857143\n","\n","Candidate: 0.9999999875062779 \n","Score: 0.3842857142857143\n","\n","Candidate: 0.9999999875699739 \n","Score: 0.3843877551020408\n","\n","Candidate: 0.9999999876266092 \n","Score: 0.38448979591836735\n","\n","Candidate: 0.9999999877820799 \n","Score: 0.3845918367346939\n","\n","Candidate: 0.9999999879705823 \n","Score: 0.3845918367346939\n","\n","Candidate: 0.999999988070565 \n","Score: 0.3846938775510204\n","\n","Candidate: 0.9999999881839609 \n","Score: 0.3846938775510204\n","\n","Candidate: 0.9999999883135648 \n","Score: 0.38479591836734695\n","\n","Candidate: 0.999999988563602 \n","Score: 0.3848979591836735\n","\n","Candidate: 0.9999999887956874 \n","Score: 0.385\n","\n","Candidate: 0.9999999889769057 \n","Score: 0.385\n","\n","Candidate: 0.9999999891505916 \n","Score: 0.385\n","\n","Candidate: 0.9999999893147687 \n","Score: 0.385\n","\n","Candidate: 0.9999999894737712 \n","Score: 0.38510204081632654\n","\n","Candidate: 0.9999999898063548 \n","Score: 0.3852040816326531\n","\n","Candidate: 0.9999999902933239 \n","Score: 0.38540816326530614\n","\n","Candidate: 0.9999999905421828 \n","Score: 0.3855102040816326\n","\n","Candidate: 0.9999999910311135 \n","Score: 0.3856122448979592\n","\n","Candidate: 0.9999999914676567 \n","Score: 0.3857142857142857\n","\n","Candidate: 0.9999999916413069 \n","Score: 0.38581632653061226\n","\n","Candidate: 0.9999999918672235 \n","Score: 0.38591836734693874\n","\n","Candidate: 0.9999999920410518 \n","Score: 0.38602040816326527\n","\n","Candidate: 0.9999999922295602 \n","Score: 0.3861224489795918\n","\n","Candidate: 0.9999999923989015 \n","Score: 0.3862244897959184\n","\n","Candidate: 0.9999999925525935 \n","Score: 0.3862244897959184\n","\n","Candidate: 0.9999999926889468 \n","Score: 0.3862244897959184\n","\n","Candidate: 0.9999999928087862 \n","Score: 0.38632653061224487\n","\n","Candidate: 0.9999999928930878 \n","Score: 0.38632653061224487\n","\n","Candidate: 0.9999999929370194 \n","Score: 0.38642857142857145\n","\n","Candidate: 0.9999999930042718 \n","Score: 0.38653061224489793\n","\n","Candidate: 0.9999999930439402 \n","Score: 0.3866326530612245\n","\n","Candidate: 0.9999999931094627 \n","Score: 0.386734693877551\n","\n","Candidate: 0.9999999931958956 \n","Score: 0.386734693877551\n","\n","Candidate: 0.9999999933270091 \n","Score: 0.3868367346938776\n","\n","Candidate: 0.9999999934622178 \n","Score: 0.38693877551020406\n","\n","Candidate: 0.99999999355682 \n","Score: 0.3870408163265306\n","\n","Candidate: 0.9999999936400448 \n","Score: 0.3870408163265306\n","\n","Candidate: 0.9999999936721715 \n","Score: 0.3871428571428571\n","\n","Candidate: 0.9999999937033051 \n","Score: 0.38724489795918365\n","\n","Candidate: 0.9999999937454914 \n","Score: 0.3873469387755102\n","\n","Candidate: 0.9999999937925323 \n","Score: 0.3874489795918368\n","\n","Candidate: 0.9999999938182971 \n","Score: 0.38755102040816325\n","\n","Candidate: 0.9999999938694593 \n","Score: 0.38755102040816325\n","\n","Candidate: 0.9999999939328458 \n","Score: 0.38755102040816325\n","\n","Candidate: 0.9999999940730426 \n","Score: 0.3876530612244898\n","\n","Candidate: 0.9999999941997394 \n","Score: 0.3876530612244898\n","\n","Candidate: 0.9999999942116182 \n","Score: 0.3877551020408163\n","\n","Candidate: 0.9999999942173796 \n","Score: 0.38785714285714284\n","\n","Candidate: 0.9999999942296969 \n","Score: 0.3879591836734694\n","\n","Candidate: 0.9999999942793303 \n","Score: 0.3880612244897959\n","\n","Candidate: 0.9999999943596614 \n","Score: 0.38816326530612244\n","\n","Candidate: 0.9999999944770904 \n","Score: 0.38826530612244897\n","\n","Candidate: 0.9999999945625505 \n","Score: 0.38826530612244897\n","\n","Candidate: 0.9999999946460709 \n","Score: 0.3883673469387755\n","\n","Candidate: 0.9999999947350731 \n","Score: 0.3883673469387755\n","\n","Candidate: 0.9999999948095208 \n","Score: 0.3883673469387755\n","\n","Candidate: 0.999999994872794 \n","Score: 0.3883673469387755\n","\n","Candidate: 0.9999999948874181 \n","Score: 0.4037755102040816\n","\n","Candidate: 0.9999999949080975 \n","Score: 0.4038775510204081\n","\n","Candidate: 0.9999999949759726 \n","Score: 0.40397959183673465\n","\n","Candidate: 0.9999999951327574 \n","Score: 0.4040816326530612\n","\n","Candidate: 0.9999999952505814 \n","Score: 0.4040816326530612\n","\n","Candidate: 0.9999999952745331 \n","Score: 0.4040816326530612\n","\n","Candidate: 0.9999999953017646 \n","Score: 0.4041836734693877\n","\n","Candidate: 0.9999999954889607 \n","Score: 0.38948979591836735\n","\n","Candidate: 0.9999999956800363 \n","Score: 0.38948979591836735\n","\n","Candidate: 0.9999999957621537 \n","Score: 0.3895918367346939\n","\n","Candidate: 0.9999999958605914 \n","Score: 0.3895918367346939\n","\n","Candidate: 0.9999999960099626 \n","Score: 0.3896938775510204\n","\n","Candidate: 0.999999996175811 \n","Score: 0.38979591836734695\n","\n","Candidate: 0.9999999962425703 \n","Score: 0.38979591836734695\n","\n","Candidate: 0.9999999962634767 \n","Score: 0.3898979591836735\n","\n","Candidate: 0.999999996288752 \n","Score: 0.39\n","\n","Candidate: 0.9999999964605484 \n","Score: 0.3901020408163265\n","\n","Candidate: 0.9999999966572295 \n","Score: 0.3902040816326531\n","\n","Candidate: 0.9999999967129292 \n","Score: 0.3902040816326531\n","\n","Candidate: 0.9999999967538538 \n","Score: 0.40714285714285714\n","\n","Candidate: 0.9999999967790351 \n","Score: 0.4072448979591836\n","\n","Candidate: 0.9999999967900027 \n","Score: 0.40734693877551015\n","\n","Candidate: 0.999999996813217 \n","Score: 0.40734693877551015\n","\n","Candidate: 0.999999996839635 \n","Score: 0.4075510204081632\n","\n","Candidate: 0.9999999968918241 \n","Score: 0.40765306122448974\n","\n","Candidate: 0.9999999969492614 \n","Score: 0.4077551020408163\n","\n","Candidate: 0.9999999969761828 \n","Score: 0.4077551020408163\n","\n","Candidate: 0.9999999969868759 \n","Score: 0.4078571428571428\n","\n","Candidate: 0.9999999969920472 \n","Score: 0.4078571428571428\n","\n","Candidate: 0.9999999970098471 \n","Score: 0.40795918367346934\n","\n","Candidate: 0.9999999970397906 \n","Score: 0.40806122448979587\n","\n","Candidate: 0.9999999970565024 \n","Score: 0.40806122448979587\n","\n","Candidate: 0.9999999970631609 \n","Score: 0.40816326530612235\n","\n","Candidate: 0.9999999970776743 \n","Score: 0.40826530612244893\n","\n","Candidate: 0.99999999712103 \n","Score: 0.40826530612244893\n","\n","Candidate: 0.9999999971615245 \n","Score: 0.4083673469387754\n","\n","Candidate: 0.9999999972144167 \n","Score: 0.408469387755102\n","\n","Candidate: 0.9999999972703757 \n","Score: 0.408469387755102\n","\n","Candidate: 0.9999999972828593 \n","Score: 0.40857142857142853\n","\n","Candidate: 0.999999997289192 \n","Score: 0.40867346938775506\n","\n","Candidate: 0.9999999972930229 \n","Score: 0.40867346938775506\n","\n","Candidate: 0.9999999973061073 \n","Score: 0.40867346938775506\n","\n","Candidate: 0.9999999973390885 \n","Score: 0.4087755102040816\n","\n","Candidate: 0.9999999973789638 \n","Score: 0.4088775510204081\n","\n","Candidate: 0.9999999974267769 \n","Score: 0.40897959183673466\n","\n","Candidate: 0.999999997458354 \n","Score: 0.4090816326530612\n","\n","Candidate: 0.9999999974684277 \n","Score: 0.4091836734693877\n","\n","Candidate: 0.9999999974813221 \n","Score: 0.40928571428571425\n","\n","Candidate: 0.9999999974981966 \n","Score: 0.4093877551020408\n","\n","Candidate: 0.9999999975109669 \n","Score: 0.4094897959183673\n","\n","Candidate: 0.9999999975178593 \n","Score: 0.40959183673469385\n","\n","Candidate: 0.9999999975699587 \n","Score: 0.40959183673469385\n","\n","Candidate: 0.9999999976487206 \n","Score: 0.40959183673469385\n","\n","Candidate: 0.9999999976819367 \n","Score: 0.4096938775510204\n","\n","Candidate: 0.9999999976895741 \n","Score: 0.40979591836734686\n","\n","Candidate: 0.9999999977326413 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.999999997810699 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.9999999978596557 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.9999999978880616 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.9999999979110108 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.9999999979400453 \n","Score: 0.41\n","\n","Candidate: 0.9999999980174764 \n","Score: 0.4101020408163265\n","\n","Candidate: 0.9999999980680867 \n","Score: 0.41020408163265304\n","\n","Candidate: 0.9999999980707182 \n","Score: 0.41020408163265304\n","\n","Candidate: 0.9999999980892367 \n","Score: 0.41030612244897957\n","\n","Candidate: 0.9999999981066473 \n","Score: 0.4104081632653061\n","\n","Candidate: 0.9999999981117653 \n","Score: 0.41051020408163263\n","\n","Candidate: 0.9999999981541614 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9999999981999438 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9999999982463447 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9999999982857235 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9999999983110568 \n","Score: 0.4107142857142857\n","\n","Candidate: 0.9999999983392569 \n","Score: 0.4108163265306122\n","\n","Candidate: 0.9999999983835546 \n","Score: 0.41091836734693876\n","\n","Candidate: 0.9999999984255653 \n","Score: 0.41102040816326524\n","\n","Candidate: 0.9999999984662321 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9999999985194131 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9999999985512588 \n","Score: 0.4111224489795918\n","\n","Candidate: 0.9999999985737124 \n","Score: 0.4112244897959183\n","\n","Candidate: 0.9999999986216621 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999986732473 \n","Score: 0.4113265306122449\n","\n","Candidate: 0.9999999986813362 \n","Score: 0.42673469387755103\n","\n","Candidate: 0.999999998682173 \n","Score: 0.4268367346938775\n","\n","Candidate: 0.9999999986866466 \n","Score: 0.4269387755102041\n","\n","Candidate: 0.9999999986943712 \n","Score: 0.4269387755102041\n","\n","Candidate: 0.9999999987091652 \n","Score: 0.4270408163265306\n","\n","Candidate: 0.9999999987265287 \n","Score: 0.4270408163265306\n","\n","Candidate: 0.9999999987425761 \n","Score: 0.4270408163265306\n","\n","Candidate: 0.9999999987576244 \n","Score: 0.42714285714285716\n","\n","Candidate: 0.999999998778639 \n","Score: 0.42724489795918363\n","\n","Candidate: 0.9999999987942234 \n","Score: 0.4273469387755102\n","\n","Candidate: 0.9999999988000667 \n","Score: 0.42744897959183675\n","\n","Candidate: 0.9999999988069566 \n","Score: 0.4275510204081633\n","\n","Candidate: 0.9999999988087602 \n","Score: 0.4275510204081633\n","\n","Candidate: 0.9999999988094936 \n","Score: 0.4276530612244898\n","\n","Candidate: 0.9999999988133053 \n","Score: 0.4276530612244898\n","\n","Candidate: 0.9999999988266518 \n","Score: 0.42775510204081635\n","\n","Candidate: 0.9999999988492392 \n","Score: 0.4278571428571428\n","\n","Candidate: 0.9999999988623207 \n","Score: 0.4278571428571428\n","\n","Candidate: 0.9999999988778631 \n","Score: 0.4279591836734694\n","\n","Candidate: 0.9999999988954642 \n","Score: 0.4280612244897959\n","\n","Candidate: 0.9999999988986201 \n","Score: 0.4281632653061225\n","\n","Candidate: 0.999999998902448 \n","Score: 0.42826530612244895\n","\n","Candidate: 0.9999999989093233 \n","Score: 0.42836734693877554\n","\n","Candidate: 0.9999999989167714 \n","Score: 0.428469387755102\n","\n","Candidate: 0.9999999989236372 \n","Score: 0.42857142857142855\n","\n","Candidate: 0.999999998940915 \n","Score: 0.4286734693877551\n","\n","Candidate: 0.9999999989630249 \n","Score: 0.4286734693877551\n","\n","Candidate: 0.9999999989758059 \n","Score: 0.4286734693877551\n","\n","Candidate: 0.9999999989827288 \n","Score: 0.44448979591836735\n","\n","Candidate: 0.999999998986074 \n","Score: 0.44459183673469393\n","\n","Candidate: 0.9999999990148369 \n","Score: 0.42938775510204086\n","\n","Candidate: 0.9999999990446394 \n","Score: 0.42948979591836733\n","\n","Candidate: 0.9999999990502184 \n","Score: 0.4295918367346939\n","\n","Candidate: 0.9999999990549322 \n","Score: 0.4295918367346939\n","\n","Candidate: 0.9999999990593446 \n","Score: 0.4295918367346939\n","\n","Candidate: 0.9999999990645216 \n","Score: 0.4295918367346939\n","\n","Candidate: 0.9999999990741669 \n","Score: 0.4295918367346939\n","\n","Candidate: 0.9999999990856809 \n","Score: 0.4295918367346939\n","\n","Candidate: 0.9999999990909073 \n","Score: 0.4296938775510204\n","\n","Candidate: 0.9999999991067074 \n","Score: 0.42979591836734693\n","\n","Candidate: 0.9999999991212765 \n","Score: 0.42989795918367346\n","\n","Candidate: 0.9999999991239137 \n","Score: 0.43000000000000005\n","\n","Candidate: 0.9999999991425819 \n","Score: 0.4301020408163265\n","\n","Candidate: 0.9999999991747917 \n","Score: 0.43020408163265306\n","\n","Candidate: 0.9999999991968651 \n","Score: 0.43020408163265306\n","\n","Candidate: 0.9999999992160513 \n","Score: 0.43020408163265306\n","\n","Candidate: 0.9999999992362972 \n","Score: 0.4303061224489796\n","\n","Candidate: 0.9999999992491109 \n","Score: 0.4304081632653061\n","\n","Candidate: 0.9999999992936677 \n","Score: 0.43051020408163265\n","\n","Candidate: 0.9999999993511975 \n","Score: 0.43051020408163265\n","\n","Candidate: 0.9999999993701407 \n","Score: 0.4306122448979592\n","\n","Candidate: 0.9999999993755209 \n","Score: 0.4307142857142857\n","\n","Candidate: 0.9999999993843722 \n","Score: 0.43081632653061225\n","\n","Candidate: 0.9999999993896901 \n","Score: 0.4309183673469388\n","\n","Candidate: 0.9999999993979624 \n","Score: 0.43112244897959184\n","\n","Candidate: 0.9999999994157539 \n","Score: 0.43112244897959184\n","\n","Candidate: 0.9999999994273062 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.999999999436916 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.9999999994474347 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.9999999994507804 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.9999999994555513 \n","Score: 0.4313265306122449\n","\n","Candidate: 0.9999999994612236 \n","Score: 0.4313265306122449\n","\n","Candidate: 0.9999999994656459 \n","Score: 0.4313265306122449\n","\n","Candidate: 0.9999999994683635 \n","Score: 0.4314285714285714\n","\n","Candidate: 0.999999999470137 \n","Score: 0.43153061224489797\n","\n","Candidate: 0.9999999994750925 \n","Score: 0.43163265306122445\n","\n","Candidate: 0.9999999994864142 \n","Score: 0.43173469387755103\n","\n","Candidate: 0.9999999994937568 \n","Score: 0.43173469387755103\n","\n","Candidate: 0.9999999994941652 \n","Score: 0.4318367346938775\n","\n","Candidate: 0.999999999494852 \n","Score: 0.43193877551020404\n","\n","Candidate: 0.9999999994968285 \n","Score: 0.43193877551020404\n","\n","Candidate: 0.9999999995056623 \n","Score: 0.43193877551020404\n","\n","Candidate: 0.999999999513518 \n","Score: 0.4320408163265306\n","\n","Candidate: 0.999999999515023 \n","Score: 0.4320408163265306\n","\n","Candidate: 0.9999999995210378 \n","Score: 0.4321428571428571\n","\n","Candidate: 0.9999999995282598 \n","Score: 0.43224489795918364\n","\n","Candidate: 0.9999999995365904 \n","Score: 0.43234693877551017\n","\n","Candidate: 0.999999999543257 \n","Score: 0.4180612244897959\n","\n","Candidate: 0.9999999995448308 \n","Score: 0.41816326530612236\n","\n","Candidate: 0.9999999995528333 \n","Score: 0.41826530612244894\n","\n","Candidate: 0.9999999995641076 \n","Score: 0.4183673469387755\n","\n","Candidate: 0.9999999995684352 \n","Score: 0.4183673469387755\n","\n","Candidate: 0.9999999995717295 \n","Score: 0.418469387755102\n","\n","Candidate: 0.9999999995839972 \n","Score: 0.418469387755102\n","\n","Candidate: 0.9999999995959644 \n","Score: 0.4185714285714285\n","\n","Candidate: 0.999999999599659 \n","Score: 0.41867346938775507\n","\n","Candidate: 0.9999999996011838 \n","Score: 0.41877551020408155\n","\n","Candidate: 0.9999999996034703 \n","Score: 0.41887755102040813\n","\n","Candidate: 0.999999999608543 \n","Score: 0.41887755102040813\n","\n","Candidate: 0.9999999996140545 \n","Score: 0.4189795918367346\n","\n","Candidate: 0.999999999617844 \n","Score: 0.4190816326530612\n","\n","Candidate: 0.9999999996210345 \n","Score: 0.4190816326530612\n","\n","Candidate: 0.9999999996238526 \n","Score: 0.4191836734693877\n","\n","Candidate: 0.999999999627607 \n","Score: 0.41928571428571426\n","\n","Candidate: 0.9999999996352757 \n","Score: 0.41938775510204074\n","\n","Candidate: 0.9999999996445066 \n","Score: 0.41948979591836727\n","\n","Candidate: 0.9999999996550493 \n","Score: 0.4195918367346938\n","\n","Candidate: 0.9999999996640232 \n","Score: 0.41969387755102033\n","\n","Candidate: 0.9999999996736109 \n","Score: 0.41969387755102033\n","\n","Candidate: 0.9999999996815465 \n","Score: 0.41979591836734687\n","\n","Candidate: 0.9999999996836503 \n","Score: 0.4198979591836734\n","\n","Candidate: 0.9999999996851863 \n","Score: 0.41999999999999993\n","\n","Candidate: 0.9999999996870261 \n","Score: 0.42010204081632646\n","\n","Candidate: 0.9999999996896609 \n","Score: 0.420204081632653\n","\n","Candidate: 0.9999999996932469 \n","Score: 0.42030612244897947\n","\n","Candidate: 0.999999999699174 \n","Score: 0.42030612244897947\n","\n","Candidate: 0.9999999997028692 \n","Score: 0.42030612244897947\n","\n","Candidate: 0.9999999997051731 \n","Score: 0.42030612244897947\n","\n","Candidate: 0.9999999997071517 \n","Score: 0.42040816326530606\n","\n","Candidate: 0.9999999997080308 \n","Score: 0.4205102040816326\n","\n","Candidate: 0.9999999997126333 \n","Score: 0.4206122448979591\n","\n","Candidate: 0.9999999997181992 \n","Score: 0.4206122448979591\n","\n","Candidate: 0.9999999997231035 \n","Score: 0.4207142857142856\n","\n","Candidate: 0.9999999997280926 \n","Score: 0.4208163265306122\n","\n","Candidate: 0.9999999997303699 \n","Score: 0.4208163265306122\n","\n","Candidate: 0.9999999997327913 \n","Score: 0.4208163265306122\n","\n","Candidate: 0.9999999997371707 \n","Score: 0.42091836734693866\n","\n","Candidate: 0.9999999997397379 \n","Score: 0.42091836734693866\n","\n","Candidate: 0.9999999997414317 \n","Score: 0.42091836734693866\n","\n","Candidate: 0.9999999997497739 \n","Score: 0.42102040816326525\n","\n","Candidate: 0.9999999997569946 \n","Score: 0.4211224489795917\n","\n","Candidate: 0.9999999997589484 \n","Score: 0.4212244897959183\n","\n","Candidate: 0.999999999763806 \n","Score: 0.4213265306122448\n","\n","Candidate: 0.9999999997684862 \n","Score: 0.4214285714285714\n","\n","Candidate: 0.9999999997715527 \n","Score: 0.4214285714285714\n","\n","Candidate: 0.9999999997758442 \n","Score: 0.4214285714285714\n","\n","Candidate: 0.9999999997791924 \n","Score: 0.4214285714285714\n","\n","Candidate: 0.9999999997816961 \n","Score: 0.42153061224489785\n","\n","Candidate: 0.9999999997844895 \n","Score: 0.42153061224489785\n","\n","Candidate: 0.9999999997875934 \n","Score: 0.42153061224489785\n","\n","Candidate: 0.999999999793374 \n","Score: 0.4216326530612244\n","\n","Candidate: 0.9999999997973648 \n","Score: 0.4216326530612244\n","\n","Candidate: 0.9999999997992264 \n","Score: 0.4217346938775509\n","\n","Candidate: 0.9999999998011235 \n","Score: 0.42183673469387745\n","\n","Candidate: 0.9999999998018507 \n","Score: 0.421938775510204\n","\n","Candidate: 0.999999999802418 \n","Score: 0.42204081632653057\n","\n","Candidate: 0.9999999998025642 \n","Score: 0.42214285714285704\n","\n","Candidate: 0.9999999998076625 \n","Score: 0.42214285714285704\n","\n","Candidate: 0.9999999998138288 \n","Score: 0.4222448979591836\n","\n","Candidate: 0.9999999998156353 \n","Score: 0.4223469387755101\n","\n","Candidate: 0.9999999998175251 \n","Score: 0.42244897959183664\n","\n","Candidate: 0.9999999998187605 \n","Score: 0.42255102040816317\n","\n","Candidate: 0.9999999998229974 \n","Score: 0.42255102040816317\n","\n","Candidate: 0.9999999998296952 \n","Score: 0.42255102040816317\n","\n","Candidate: 0.9999999998326128 \n","Score: 0.4226530612244897\n","\n","Candidate: 0.9999999998352522 \n","Score: 0.42275510204081623\n","\n","Candidate: 0.9999999998376513 \n","Score: 0.42285714285714276\n","\n","Candidate: 0.9999999998388396 \n","Score: 0.42285714285714276\n","\n","Candidate: 0.9999999998409179 \n","Score: 0.42285714285714276\n","\n","Candidate: 0.999999999842317 \n","Score: 0.42285714285714276\n","\n","Candidate: 0.9999999998430096 \n","Score: 0.4229591836734693\n","\n","Candidate: 0.9999999998435707 \n","Score: 0.42306122448979583\n","\n","Candidate: 0.999999999844968 \n","Score: 0.42316326530612236\n","\n","Candidate: 0.9999999998462951 \n","Score: 0.42316326530612236\n","\n","Candidate: 0.9999999998470279 \n","Score: 0.4232653061224489\n","\n","Candidate: 0.9999999998482259 \n","Score: 0.4233673469387754\n","\n","Candidate: 0.9999999998523671 \n","Score: 0.4233673469387754\n","\n","Candidate: 0.9999999998560483 \n","Score: 0.4233673469387754\n","\n","Candidate: 0.9999999998562584 \n","Score: 0.42346938775510196\n","\n","Candidate: 0.9999999998564075 \n","Score: 0.42346938775510196\n","\n","Candidate: 0.9999999998568067 \n","Score: 0.42346938775510196\n","\n","Candidate: 0.9999999998594168 \n","Score: 0.42346938775510196\n","\n","Candidate: 0.9999999998618359 \n","Score: 0.43948979591836723\n","\n","Candidate: 0.9999999998631659 \n","Score: 0.43948979591836723\n","\n","Candidate: 0.9999999998647251 \n","Score: 0.4395918367346938\n","\n","Candidate: 0.9999999998651221 \n","Score: 0.4395918367346938\n","\n","Candidate: 0.9999999998652955 \n","Score: 0.4396938775510203\n","\n","Candidate: 0.9999999998664025 \n","Score: 0.4397959183673469\n","\n","Candidate: 0.9999999998679938 \n","Score: 0.43989795918367336\n","\n","Candidate: 0.9999999998697131 \n","Score: 0.43999999999999995\n","\n","Candidate: 0.9999999998714226 \n","Score: 0.4401020408163265\n","\n","Candidate: 0.9999999998736826 \n","Score: 0.440204081632653\n","\n","Candidate: 0.9999999998754996 \n","Score: 0.44030612244897954\n","\n","Candidate: 0.9999999998762183 \n","Score: 0.44030612244897954\n","\n","Candidate: 0.9999999998769875 \n","Score: 0.4404081632653061\n","\n","Candidate: 0.9999999998777442 \n","Score: 0.4404081632653061\n","\n","Candidate: 0.9999999998785071 \n","Score: 0.4405102040816326\n","\n","Candidate: 0.9999999998793894 \n","Score: 0.4258163265306122\n","\n","Candidate: 0.9999999998818083 \n","Score: 0.4259183673469387\n","\n","Candidate: 0.9999999998877019 \n","Score: 0.42602040816326525\n","\n","Candidate: 0.9999999998946235 \n","Score: 0.42602040816326525\n","\n","Candidate: 0.9999999998975442 \n","Score: 0.4261224489795918\n","\n","Candidate: 0.9999999998977527 \n","Score: 0.4261224489795918\n","\n","Candidate: 0.9999999998983162 \n","Score: 0.4262244897959183\n","\n","Candidate: 0.9999999998989273 \n","Score: 0.42632653061224485\n","\n","Candidate: 0.9999999998994202 \n","Score: 0.4264285714285714\n","\n","Candidate: 0.9999999999006357 \n","Score: 0.4265306122448979\n","\n","Candidate: 0.9999999999022431 \n","Score: 0.4265306122448979\n","\n","Candidate: 0.9999999999033558 \n","Score: 0.42663265306122444\n","\n","Candidate: 0.9999999999042175 \n","Score: 0.42663265306122444\n","\n","Candidate: 0.9999999999052644 \n","Score: 0.4267346938775509\n","\n","Candidate: 0.9999999999061033 \n","Score: 0.4268367346938775\n","\n","Candidate: 0.9999999999066559 \n","Score: 0.426938775510204\n","\n","Candidate: 0.9999999999072021 \n","Score: 0.42704081632653057\n","\n","Candidate: 0.9999999999092302 \n","Score: 0.42714285714285705\n","\n","Candidate: 0.9999999999116322 \n","Score: 0.42724489795918363\n","\n","Candidate: 0.9999999999128997 \n","Score: 0.4273469387755101\n","\n","Candidate: 0.9999999999152343 \n","Score: 0.4273469387755101\n","\n","Candidate: 0.9999999999171716 \n","Score: 0.4273469387755101\n","\n","Candidate: 0.9999999999173954 \n","Score: 0.4274489795918367\n","\n","Candidate: 0.999999999917498 \n","Score: 0.4275510204081632\n","\n","Candidate: 0.9999999999182168 \n","Score: 0.4275510204081632\n","\n","Candidate: 0.9999999999190999 \n","Score: 0.42765306122448976\n","\n","Candidate: 0.9999999999199554 \n","Score: 0.42765306122448976\n","\n","Candidate: 0.9999999999207403 \n","Score: 0.42775510204081624\n","\n","Candidate: 0.9999999999211102 \n","Score: 0.4278571428571428\n","\n","Candidate: 0.9999999999222249 \n","Score: 0.4278571428571428\n","\n","Candidate: 0.999999999923274 \n","Score: 0.4278571428571428\n","\n","Candidate: 0.9999999999236795 \n","Score: 0.4278571428571428\n","\n","Candidate: 0.9999999999241437 \n","Score: 0.4278571428571428\n","\n","Candidate: 0.9999999999243894 \n","Score: 0.4278571428571428\n","\n","Candidate: 0.9999999999251962 \n","Score: 0.4279591836734693\n","\n","Candidate: 0.9999999999260437 \n","Score: 0.4279591836734693\n","\n","Candidate: 0.9999999999268364 \n","Score: 0.4280612244897959\n","\n","Candidate: 0.9999999999276239 \n","Score: 0.4280612244897959\n","\n","Candidate: 0.9999999999287561 \n","Score: 0.4280612244897959\n","\n","Candidate: 0.9999999999305575 \n","Score: 0.42816326530612236\n","\n","Candidate: 0.9999999999315374 \n","Score: 0.4282653061224489\n","\n","Candidate: 0.9999999999318108 \n","Score: 0.4130612244897959\n","\n","Candidate: 0.9999999999322777 \n","Score: 0.4131632653061224\n","\n","Candidate: 0.9999999999331853 \n","Score: 0.4131632653061224\n","\n","Candidate: 0.9999999999337978 \n","Score: 0.4131632653061224\n","\n","Candidate: 0.9999999999340323 \n","Score: 0.41326530612244894\n","\n","Candidate: 0.9999999999352491 \n","Score: 0.41336734693877547\n","\n","Candidate: 0.999999999936495 \n","Score: 0.413469387755102\n","\n","Candidate: 0.9999999999375175 \n","Score: 0.3988775510204081\n","\n","Candidate: 0.999999999939971 \n","Score: 0.3989795918367347\n","\n","Candidate: 0.9999999999416804 \n","Score: 0.39908163265306124\n","\n","Candidate: 0.9999999999420479 \n","Score: 0.39918367346938777\n","\n","Candidate: 0.9999999999426885 \n","Score: 0.39918367346938777\n","\n","Candidate: 0.9999999999435133 \n","Score: 0.39928571428571424\n","\n","Candidate: 0.9999999999440736 \n","Score: 0.39938775510204083\n","\n","Candidate: 0.9999999999442113 \n","Score: 0.3994897959183673\n","\n","Candidate: 0.9999999999442877 \n","Score: 0.3844897959183673\n","\n","Candidate: 0.9999999999447611 \n","Score: 0.3845918367346939\n","\n","Candidate: 0.9999999999462132 \n","Score: 0.3845918367346939\n","\n","Candidate: 0.9999999999475242 \n","Score: 0.3845918367346939\n","\n","Candidate: 0.9999999999494121 \n","Score: 0.38469387755102036\n","\n","Candidate: 0.9999999999523986 \n","Score: 0.3847959183673469\n","\n","Candidate: 0.9999999999538218 \n","Score: 0.3848979591836734\n","\n","Candidate: 0.9999999999542059 \n","Score: 0.3848979591836734\n","\n","Candidate: 0.9999999999550628 \n","Score: 0.3848979591836734\n","\n","Candidate: 0.9999999999556847 \n","Score: 0.385\n","\n","Candidate: 0.9999999999560883 \n","Score: 0.385\n","\n","Candidate: 0.9999999999565288 \n","Score: 0.3851020408163265\n","\n","Candidate: 0.9999999999567714 \n","Score: 0.385204081632653\n","\n","Candidate: 0.9999999999569066 \n","Score: 0.38530612244897955\n","\n","Candidate: 0.9999999999569344 \n","Score: 0.38591836734693874\n","\n","Candidate: 0.9999999999574005 \n","Score: 0.38591836734693874\n","\n","Candidate: 0.9999999999579416 \n","Score: 0.38591836734693874\n","\n","Candidate: 0.9999999999580458 \n","Score: 0.38591836734693874\n","\n","Candidate: 0.999999999958351 \n","Score: 0.3860204081632652\n","\n","Candidate: 0.9999999999587521 \n","Score: 0.3861224489795918\n","\n","Candidate: 0.9999999999590066 \n","Score: 0.38622448979591834\n","\n","Candidate: 0.9999999999593869 \n","Score: 0.38622448979591834\n","\n","Candidate: 0.9999999999597783 \n","Score: 0.38622448979591834\n","\n","Candidate: 0.9999999999600256 \n","Score: 0.38632653061224487\n","\n","Candidate: 0.9999999999604812 \n","Score: 0.38632653061224487\n","\n","Candidate: 0.9999999999612128 \n","Score: 0.3864285714285714\n","\n","Candidate: 0.9999999999617893 \n","Score: 0.3864285714285714\n","\n","Candidate: 0.9999999999623783 \n","Score: 0.3864285714285714\n","\n","Candidate: 0.999999999962925 \n","Score: 0.38653061224489793\n","\n","Candidate: 0.9999999999633913 \n","Score: 0.38663265306122446\n","\n","Candidate: 0.9999999999638973 \n","Score: 0.386734693877551\n","\n","Candidate: 0.9999999999642422 \n","Score: 0.386734693877551\n","\n","Candidate: 0.9999999999645366 \n","Score: 0.3868367346938775\n","\n","Candidate: 0.9999999999646842 \n","Score: 0.38693877551020406\n","\n","Candidate: 0.999999999964893 \n","Score: 0.3870408163265306\n","\n","Candidate: 0.9999999999651474 \n","Score: 0.3871428571428571\n","\n","Candidate: 0.9999999999654516 \n","Score: 0.3872448979591836\n","\n","Candidate: 0.9999999999660609 \n","Score: 0.3872448979591836\n","\n","Candidate: 0.9999999999667006 \n","Score: 0.3873469387755102\n","\n","Candidate: 0.9999999999670088 \n","Score: 0.38744897959183666\n","\n","Candidate: 0.9999999999670985 \n","Score: 0.38755102040816325\n","\n","Candidate: 0.9999999999674747 \n","Score: 0.3876530612244897\n","\n","Candidate: 0.9999999999678812 \n","Score: 0.3877551020408163\n","\n","Candidate: 0.9999999999681688 \n","Score: 0.3878571428571428\n","\n","Candidate: 0.9999999999687306 \n","Score: 0.3878571428571428\n","\n","Candidate: 0.9999999999691311 \n","Score: 0.3879591836734693\n","\n","Candidate: 0.9999999999691738 \n","Score: 0.38806122448979585\n","\n","Candidate: 0.9999999999692981 \n","Score: 0.3881632653061224\n","\n","Candidate: 0.999999999969555 \n","Score: 0.3882653061224489\n","\n","Candidate: 0.9999999999697147 \n","Score: 0.38836734693877545\n","\n","Candidate: 0.9999999999697395 \n","Score: 0.388469387755102\n","\n","Candidate: 0.9999999999698304 \n","Score: 0.388469387755102\n","\n","Candidate: 0.9999999999699594 \n","Score: 0.3885714285714285\n","\n","Candidate: 0.9999999999704536 \n","Score: 0.3888775510204081\n","\n","Candidate: 0.9999999999712064 \n","Score: 0.3888775510204081\n","\n","Candidate: 0.9999999999717878 \n","Score: 0.38897959183673464\n","\n","Candidate: 0.9999999999727556 \n","Score: 0.38908163265306117\n","\n","Candidate: 0.9999999999735042 \n","Score: 0.3891836734693877\n","\n","Candidate: 0.9999999999741322 \n","Score: 0.38928571428571423\n","\n","Candidate: 0.9999999999750255 \n","Score: 0.38928571428571423\n","\n","Candidate: 0.9999999999755489 \n","Score: 0.38928571428571423\n","\n","Candidate: 0.9999999999757854 \n","Score: 0.38928571428571423\n","\n","Candidate: 0.9999999999760707 \n","Score: 0.3893877551020407\n","\n","Candidate: 0.9999999999763696 \n","Score: 0.3894897959183673\n","\n","Candidate: 0.9999999999766734 \n","Score: 0.3894897959183673\n","\n","Candidate: 0.9999999999769518 \n","Score: 0.3894897959183673\n","\n","Candidate: 0.9999999999771012 \n","Score: 0.38959183673469383\n","\n","Candidate: 0.9999999999773785 \n","Score: 0.38969387755102036\n","\n","Candidate: 0.9999999999779066 \n","Score: 0.38969387755102036\n","\n","Candidate: 0.9999999999783082 \n","Score: 0.38969387755102036\n","\n","Candidate: 0.999999999978533 \n","Score: 0.3897959183673469\n","\n","Candidate: 0.9999999999787876 \n","Score: 0.3897959183673469\n","\n","Candidate: 0.9999999999789377 \n","Score: 0.3898979591836734\n","\n","Candidate: 0.9999999999790785 \n","Score: 0.38999999999999996\n","\n","Candidate: 0.9999999999792729 \n","Score: 0.38999999999999996\n","\n","Candidate: 0.9999999999795579 \n","Score: 0.38999999999999996\n","\n","Candidate: 0.9999999999801821 \n","Score: 0.3901020408163265\n","\n","Candidate: 0.9999999999808331 \n","Score: 0.390204081632653\n","\n","Candidate: 0.9999999999810106 \n","Score: 0.390204081632653\n","\n","Candidate: 0.9999999999810534 \n","Score: 0.39030612244897955\n","\n","Candidate: 0.9999999999812528 \n","Score: 0.3904081632653061\n","\n","Candidate: 0.9999999999814833 \n","Score: 0.3904081632653061\n","\n","Candidate: 0.9999999999818259 \n","Score: 0.3905102040816326\n","\n","Candidate: 0.9999999999824827 \n","Score: 0.39061224489795915\n","\n","Candidate: 0.9999999999828675 \n","Score: 0.39061224489795915\n","\n","Candidate: 0.9999999999829976 \n","Score: 0.3907142857142857\n","\n","Candidate: 0.9999999999831192 \n","Score: 0.3908163265306122\n","\n","Candidate: 0.9999999999832891 \n","Score: 0.3908163265306122\n","\n","Candidate: 0.9999999999836603 \n","Score: 0.39091836734693874\n","\n","Candidate: 0.9999999999840208 \n","Score: 0.39091836734693874\n","\n","Candidate: 0.999999999984223 \n","Score: 0.3910204081632652\n","\n","Candidate: 0.9999999999842805 \n","Score: 0.3911224489795918\n","\n","Candidate: 0.999999999984376 \n","Score: 0.39122448979591834\n","\n","Candidate: 0.9999999999844709 \n","Score: 0.39132653061224487\n","\n","Candidate: 0.9999999999845055 \n","Score: 0.39132653061224487\n","\n","Candidate: 0.9999999999845415 \n","Score: 0.3914285714285714\n","\n","Candidate: 0.9999999999848455 \n","Score: 0.39153061224489794\n","\n","Candidate: 0.999999999985175 \n","Score: 0.39163265306122447\n","\n","Candidate: 0.9999999999853284 \n","Score: 0.391734693877551\n","\n","Candidate: 0.99999999998548 \n","Score: 0.39183673469387753\n","\n","Candidate: 0.9999999999856659 \n","Score: 0.39193877551020406\n","\n","Candidate: 0.9999999999858218 \n","Score: 0.39204081632653054\n","\n","Candidate: 0.9999999999859048 \n","Score: 0.4074489795918367\n","\n","Candidate: 0.9999999999860825 \n","Score: 0.40755102040816327\n","\n","Candidate: 0.999999999986195 \n","Score: 0.4076530612244898\n","\n","Candidate: 0.99999999998636 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.999999999986789 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.9999999999871702 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.9999999999874725 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.9999999999877369 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.999999999987883 \n","Score: 0.40775510204081633\n","\n","Candidate: 0.9999999999880123 \n","Score: 0.4079591836734694\n","\n","Candidate: 0.999999999988154 \n","Score: 0.40806122448979587\n","\n","Candidate: 0.9999999999883121 \n","Score: 0.40816326530612246\n","\n","Candidate: 0.9999999999883875 \n","Score: 0.40816326530612246\n","\n","Candidate: 0.9999999999885152 \n","Score: 0.408265306122449\n","\n","Candidate: 0.9999999999886398 \n","Score: 0.4083673469387755\n","\n","Candidate: 0.9999999999886535 \n","Score: 0.4083673469387755\n","\n","Candidate: 0.9999999999886684 \n","Score: 0.4083673469387755\n","\n","Candidate: 0.9999999999888991 \n","Score: 0.408469387755102\n","\n","Candidate: 0.9999999999891318 \n","Score: 0.4085714285714286\n","\n","Candidate: 0.9999999999891542 \n","Score: 0.4085714285714286\n","\n","Candidate: 0.9999999999892457 \n","Score: 0.40867346938775506\n","\n","Candidate: 0.999999999989422 \n","Score: 0.4087755102040816\n","\n","Candidate: 0.9999999999895393 \n","Score: 0.4088775510204081\n","\n","Candidate: 0.9999999999895608 \n","Score: 0.4088775510204081\n","\n","Candidate: 0.9999999999895611 \n","Score: 0.40897959183673466\n","\n","Candidate: 0.9999999999895928 \n","Score: 0.4090816326530612\n","\n","Candidate: 0.9999999999897521 \n","Score: 0.4091836734693877\n","\n","Candidate: 0.9999999999901037 \n","Score: 0.40928571428571425\n","\n","Candidate: 0.9999999999904161 \n","Score: 0.4093877551020408\n","\n","Candidate: 0.9999999999905094 \n","Score: 0.4094897959183673\n","\n","Candidate: 0.9999999999906137 \n","Score: 0.4095918367346939\n","\n","Candidate: 0.9999999999907714 \n","Score: 0.4095918367346939\n","\n","Candidate: 0.9999999999908371 \n","Score: 0.4096938775510204\n","\n","Candidate: 0.9999999999908608 \n","Score: 0.40979591836734697\n","\n","Candidate: 0.9999999999910079 \n","Score: 0.40979591836734697\n","\n","Candidate: 0.9999999999912053 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.9999999999913336 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.9999999999914897 \n","Score: 0.40989795918367344\n","\n","Candidate: 0.9999999999916529 \n","Score: 0.41\n","\n","Candidate: 0.9999999999918385 \n","Score: 0.41\n","\n","Candidate: 0.9999999999919872 \n","Score: 0.4101020408163265\n","\n","Candidate: 0.9999999999920637 \n","Score: 0.41020408163265304\n","\n","Candidate: 0.9999999999921696 \n","Score: 0.41030612244897957\n","\n","Candidate: 0.9999999999922535 \n","Score: 0.4257142857142857\n","\n","Candidate: 0.9999999999923034 \n","Score: 0.4258163265306122\n","\n","Candidate: 0.9999999999924097 \n","Score: 0.4259183673469388\n","\n","Candidate: 0.9999999999926039 \n","Score: 0.42602040816326525\n","\n","Candidate: 0.9999999999928709 \n","Score: 0.42612244897959184\n","\n","Candidate: 0.9999999999930296 \n","Score: 0.42612244897959184\n","\n","Candidate: 0.9999999999930699 \n","Score: 0.4262244897959183\n","\n","Candidate: 0.9999999999931507 \n","Score: 0.4262244897959183\n","\n","Candidate: 0.9999999999932052 \n","Score: 0.4263265306122449\n","\n","Candidate: 0.9999999999933847 \n","Score: 0.4263265306122449\n","\n","Candidate: 0.9999999999935805 \n","Score: 0.4264285714285714\n","\n","Candidate: 0.999999999993656 \n","Score: 0.42653061224489797\n","\n","Candidate: 0.9999999999938046 \n","Score: 0.4266326530612245\n","\n","Candidate: 0.9999999999939231 \n","Score: 0.4266326530612245\n","\n","Candidate: 0.9999999999939486 \n","Score: 0.4266326530612245\n","\n","Candidate: 0.9999999999939745 \n","Score: 0.4266326530612245\n","\n","Candidate: 0.9999999999940873 \n","Score: 0.42673469387755103\n","\n","Candidate: 0.9999999999941779 \n","Score: 0.4268367346938775\n","\n","Candidate: 0.9999999999941833 \n","Score: 0.41377551020408165\n","\n","Candidate: 0.9999999999942191 \n","Score: 0.41377551020408165\n","\n","Candidate: 0.9999999999943413 \n","Score: 0.4138775510204082\n","\n","Candidate: 0.9999999999946159 \n","Score: 0.4139795918367347\n","\n","Candidate: 0.9999999999948143 \n","Score: 0.4140816326530612\n","\n","Candidate: 0.9999999999948526 \n","Score: 0.4141836734693878\n","\n","Candidate: 0.9999999999949081 \n","Score: 0.41428571428571426\n","\n","Candidate: 0.9999999999949545 \n","Score: 0.4143877551020408\n","\n","Candidate: 0.9999999999950392 \n","Score: 0.4144897959183673\n","\n","Candidate: 0.9999999999951386 \n","Score: 0.4145918367346939\n","\n","Candidate: 0.9999999999952008 \n","Score: 0.4146938775510204\n","\n","Candidate: 0.9999999999952376 \n","Score: 0.41479591836734697\n","\n","Candidate: 0.9999999999952488 \n","Score: 0.4148979591836735\n","\n","Candidate: 0.9999999999952632 \n","Score: 0.41500000000000004\n","\n","Candidate: 0.999999999995313 \n","Score: 0.41500000000000004\n","\n","Candidate: 0.999999999995381 \n","Score: 0.4151020408163265\n","\n","Candidate: 0.9999999999954083 \n","Score: 0.4152040816326531\n","\n","Candidate: 0.9999999999954792 \n","Score: 0.4152040816326531\n","\n","Candidate: 0.9999999999955662 \n","Score: 0.4153061224489796\n","\n","Candidate: 0.9999999999956104 \n","Score: 0.4153061224489796\n","\n","Candidate: 0.9999999999957703 \n","Score: 0.4153061224489796\n","\n","Candidate: 0.9999999999959095 \n","Score: 0.4154081632653061\n","\n","Candidate: 0.999999999995945 \n","Score: 0.41551020408163264\n","\n","Candidate: 0.9999999999959996 \n","Score: 0.41561224489795917\n","\n","Candidate: 0.9999999999960516 \n","Score: 0.4310204081632653\n","\n","Candidate: 0.9999999999960878 \n","Score: 0.43112244897959184\n","\n","Candidate: 0.9999999999961569 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.999999999996255 \n","Score: 0.4312244897959183\n","\n","Candidate: 0.9999999999963116 \n","Score: 0.4313265306122449\n","\n","Candidate: 0.9999999999963454 \n","Score: 0.4314285714285714\n","\n","Candidate: 0.9999999999963698 \n","Score: 0.4315306122448979\n","\n","Candidate: 0.99999999999639 \n","Score: 0.43163265306122445\n","\n","Candidate: 0.9999999999964113 \n","Score: 0.43173469387755103\n","\n","Candidate: 0.9999999999964464 \n","Score: 0.43183673469387757\n","\n","Candidate: 0.999999999996491 \n","Score: 0.4319387755102041\n","\n","Candidate: 0.9999999999965148 \n","Score: 0.4319387755102041\n","\n","Candidate: 0.9999999999965405 \n","Score: 0.43204081632653063\n","\n","Candidate: 0.9999999999966229 \n","Score: 0.43214285714285716\n","\n","Candidate: 0.9999999999967271 \n","Score: 0.43214285714285716\n","\n","Candidate: 0.9999999999967848 \n","Score: 0.43214285714285716\n","\n","Candidate: 0.9999999999968181 \n","Score: 0.43224489795918375\n","\n","Candidate: 0.9999999999968402 \n","Score: 0.4323469387755102\n","\n","Candidate: 0.9999999999969368 \n","Score: 0.4324489795918368\n","\n","Candidate: 0.999999999997083 \n","Score: 0.4325510204081633\n","\n","Candidate: 0.999999999997161 \n","Score: 0.4326530612244898\n","\n","Candidate: 0.999999999997244 \n","Score: 0.43275510204081635\n","\n","Candidate: 0.9999999999973024 \n","Score: 0.43285714285714294\n","\n","Candidate: 0.9999999999973472 \n","Score: 0.4329591836734694\n","\n","Candidate: 0.9999999999974029 \n","Score: 0.4177551020408164\n","\n","Candidate: 0.999999999997449 \n","Score: 0.4178571428571429\n","\n","Candidate: 0.9999999999975034 \n","Score: 0.4178571428571429\n","\n","Candidate: 0.9999999999975353 \n","Score: 0.41795918367346946\n","\n","Candidate: 0.9999999999975631 \n","Score: 0.41795918367346946\n","\n","Candidate: 0.9999999999975961 \n","Score: 0.41795918367346946\n","\n","Candidate: 0.9999999999976135 \n","Score: 0.41795918367346946\n","\n","Candidate: 0.9999999999976157 \n","Score: 0.418061224489796\n","\n","Candidate: 0.9999999999976361 \n","Score: 0.4181632653061225\n","\n","Candidate: 0.9999999999976581 \n","Score: 0.41826530612244905\n","\n","Candidate: 0.9999999999976925 \n","Score: 0.41836734693877553\n","\n","Candidate: 0.9999999999977485 \n","Score: 0.4184693877551021\n","\n","Candidate: 0.9999999999977767 \n","Score: 0.41857142857142865\n","\n","Candidate: 0.9999999999978453 \n","Score: 0.4186734693877552\n","\n","Candidate: 0.9999999999979468 \n","Score: 0.41877551020408166\n","\n","Candidate: 0.9999999999979858 \n","Score: 0.41877551020408166\n","\n","Candidate: 0.9999999999979968 \n","Score: 0.41887755102040825\n","\n","Candidate: 0.9999999999980111 \n","Score: 0.43500000000000005\n","\n","Candidate: 0.9999999999980361 \n","Score: 0.4351020408163266\n","\n","Candidate: 0.9999999999980569 \n","Score: 0.4352040816326531\n","\n","Candidate: 0.9999999999980641 \n","Score: 0.4353061224489796\n","\n","Candidate: 0.9999999999980733 \n","Score: 0.4354081632653062\n","\n","Candidate: 0.9999999999980843 \n","Score: 0.43551020408163266\n","\n","Candidate: 0.9999999999981045 \n","Score: 0.43561224489795924\n","\n","Candidate: 0.9999999999981488 \n","Score: 0.4357142857142857\n","\n","Candidate: 0.9999999999982054 \n","Score: 0.43581632653061225\n","\n","Candidate: 0.9999999999982321 \n","Score: 0.43581632653061225\n","\n","Candidate: 0.9999999999982461 \n","Score: 0.4359183673469388\n","\n","Candidate: 0.9999999999982685 \n","Score: 0.4360204081632653\n","\n","Candidate: 0.9999999999982851 \n","Score: 0.4360204081632653\n","\n","Candidate: 0.9999999999983131 \n","Score: 0.43612244897959185\n","\n","Candidate: 0.9999999999983518 \n","Score: 0.43622448979591844\n","\n","Candidate: 0.9999999999983907 \n","Score: 0.43632653061224497\n","\n","Candidate: 0.9999999999984139 \n","Score: 0.4364285714285715\n","\n","Candidate: 0.9999999999984885 \n","Score: 0.43653061224489803\n","\n","Candidate: 0.9999999999985812 \n","Score: 0.43663265306122456\n","\n","Candidate: 0.9999999999986298 \n","Score: 0.43673469387755104\n","\n","Candidate: 0.9999999999986685 \n","Score: 0.43673469387755104\n","\n","Candidate: 0.9999999999986815 \n","Score: 0.4368367346938776\n","\n","Candidate: 0.9999999999986848 \n","Score: 0.4369387755102041\n","\n","Candidate: 0.9999999999986896 \n","Score: 0.4370408163265307\n","\n","Candidate: 0.9999999999986959 \n","Score: 0.43714285714285717\n","\n","Candidate: 0.9999999999987029 \n","Score: 0.43724489795918375\n","\n","Candidate: 0.999999999998708 \n","Score: 0.43734693877551023\n","\n","Candidate: 0.9999999999987162 \n","Score: 0.43734693877551023\n","\n","Candidate: 0.9999999999987332 \n","Score: 0.4374489795918368\n","\n","Candidate: 0.9999999999987506 \n","Score: 0.4375510204081633\n","\n","Candidate: 0.9999999999987605 \n","Score: 0.4376530612244899\n","\n","Candidate: 0.9999999999987698 \n","Score: 0.4376530612244899\n","\n","Candidate: 0.9999999999987885 \n","Score: 0.43775510204081636\n","\n","Candidate: 0.9999999999988038 \n","Score: 0.43785714285714294\n","\n","Candidate: 0.9999999999988116 \n","Score: 0.4379591836734694\n","\n","Candidate: 0.9999999999988177 \n","Score: 0.43806122448979595\n","\n","Candidate: 0.9999999999988531 \n","Score: 0.4381632653061225\n","\n","Candidate: 0.999999999998914 \n","Score: 0.438265306122449\n","\n","Candidate: 0.9999999999989417 \n","Score: 0.43836734693877555\n","\n","Candidate: 0.9999999999989451 \n","Score: 0.4384693877551021\n","\n","Candidate: 0.9999999999989522 \n","Score: 0.4385714285714286\n","\n","Candidate: 0.9999999999989764 \n","Score: 0.4385714285714286\n","\n","Candidate: 0.9999999999989997 \n","Score: 0.43867346938775514\n","\n","Candidate: 0.9999999999990077 \n","Score: 0.4387755102040817\n","\n","Candidate: 0.9999999999990196 \n","Score: 0.43887755102040815\n","\n","Candidate: 0.9999999999990412 \n","Score: 0.43897959183673474\n","\n","Candidate: 0.9999999999990703 \n","Score: 0.43897959183673474\n","\n","Candidate: 0.9999999999990872 \n","Score: 0.43897959183673474\n","\n","Candidate: 0.9999999999991078 \n","Score: 0.4390816326530612\n","\n","Candidate: 0.9999999999991289 \n","Score: 0.43918367346938775\n","\n","Candidate: 0.9999999999991329 \n","Score: 0.4392857142857143\n","\n","Candidate: 0.999999999999143 \n","Score: 0.4393877551020408\n","\n","Candidate: 0.999999999999158 \n","Score: 0.42438775510204085\n","\n","Candidate: 0.9999999999991779 \n","Score: 0.42448979591836733\n","\n","Candidate: 0.9999999999991922 \n","Score: 0.4245918367346939\n","\n","Candidate: 0.9999999999991989 \n","Score: 0.4246938775510204\n","\n","Candidate: 0.9999999999992184 \n","Score: 0.424795918367347\n","\n","Candidate: 0.9999999999992402 \n","Score: 0.42489795918367346\n","\n","Candidate: 0.9999999999992495 \n","Score: 0.42500000000000004\n","\n","Candidate: 0.999999999999263 \n","Score: 0.4251020408163265\n","\n","Candidate: 0.9999999999992777 \n","Score: 0.42520408163265305\n","\n","Candidate: 0.999999999999288 \n","Score: 0.4253061224489796\n","\n","Candidate: 0.9999999999992957 \n","Score: 0.4254081632653061\n","\n","Candidate: 0.9999999999993008 \n","Score: 0.42551020408163265\n","\n","Candidate: 0.999999999999311 \n","Score: 0.42551020408163265\n","\n","Candidate: 0.9999999999993242 \n","Score: 0.4256122448979592\n","\n","Candidate: 0.9999999999993452 \n","Score: 0.4256122448979592\n","\n","Candidate: 0.9999999999993634 \n","Score: 0.4257142857142857\n","\n","Candidate: 0.9999999999993741 \n","Score: 0.4258163265306123\n","\n","Candidate: 0.9999999999993837 \n","Score: 0.4259183673469388\n","\n","Candidate: 0.9999999999993947 \n","Score: 0.42602040816326536\n","\n","Candidate: 0.9999999999994063 \n","Score: 0.42612244897959184\n","\n","Candidate: 0.9999999999994118 \n","Score: 0.4262244897959184\n","\n","Candidate: 0.9999999999994188 \n","Score: 0.4263265306122449\n","\n","Candidate: 0.99999999999943 \n","Score: 0.42642857142857143\n","\n","Candidate: 0.9999999999994399 \n","Score: 0.42653061224489797\n","\n","Candidate: 0.999999999999448 \n","Score: 0.4266326530612245\n","\n","Candidate: 0.999999999999458 \n","Score: 0.42673469387755103\n","\n","Candidate: 0.9999999999994651 \n","Score: 0.42683673469387756\n","\n","Candidate: 0.9999999999994658 \n","Score: 0.4269387755102041\n","\n","Candidate: 0.9999999999994722 \n","Score: 0.4270408163265306\n","\n","Candidate: 0.9999999999994873 \n","Score: 0.4270408163265306\n","\n","Candidate: 0.9999999999994984 \n","Score: 0.4270408163265306\n","\n","Candidate: 0.9999999999995088 \n","Score: 0.41183673469387755\n","\n","Candidate: 0.9999999999995233 \n","Score: 0.4119387755102041\n","\n","Candidate: 0.999999999999533 \n","Score: 0.4120408163265306\n","\n","Candidate: 0.9999999999995415 \n","Score: 0.41214285714285714\n","\n","Candidate: 0.9999999999995466 \n","Score: 0.41224489795918373\n","\n","Candidate: 0.9999999999995557 \n","Score: 0.4123469387755102\n","\n","Candidate: 0.9999999999995655 \n","Score: 0.4124489795918368\n","\n","Candidate: 0.9999999999995729 \n","Score: 0.41255102040816327\n","\n","Candidate: 0.9999999999995829 \n","Score: 0.4126530612244898\n","\n","Candidate: 0.9999999999995968 \n","Score: 0.41275510204081634\n","\n","Candidate: 0.9999999999996099 \n","Score: 0.4128571428571429\n","\n","Candidate: 0.9999999999996131 \n","Score: 0.4129591836734694\n","\n","Candidate: 0.9999999999996134 \n","Score: 0.413061224489796\n","\n","Candidate: 0.9999999999996141 \n","Score: 0.41316326530612246\n","\n","Candidate: 0.9999999999996194 \n","Score: 0.4136734693877551\n","\n","Candidate: 0.9999999999996345 \n","Score: 0.41377551020408165\n","\n","Candidate: 0.9999999999996456 \n","Score: 0.4138775510204082\n","\n","Candidate: 0.9999999999996498 \n","Score: 0.4139795918367347\n","\n","Candidate: 0.9999999999996546 \n","Score: 0.4139795918367347\n","\n","Candidate: 0.9999999999996578 \n","Score: 0.4140816326530613\n","\n","Candidate: 0.9999999999996613 \n","Score: 0.4141836734693878\n","\n","Candidate: 0.9999999999996646 \n","Score: 0.41428571428571437\n","\n","Candidate: 0.999999999999669 \n","Score: 0.41428571428571437\n","\n","Candidate: 0.9999999999996751 \n","Score: 0.4144897959183673\n","\n","Candidate: 0.9999999999996833 \n","Score: 0.4145918367346939\n","\n","Candidate: 0.9999999999996889 \n","Score: 0.4146938775510204\n","\n","Candidate: 0.9999999999996975 \n","Score: 0.41479591836734697\n","\n","Candidate: 0.9999999999997059 \n","Score: 0.41489795918367345\n","\n","Candidate: 0.9999999999997071 \n","Score: 0.41500000000000004\n","\n","Candidate: 0.9999999999997136 \n","Score: 0.4151020408163265\n","\n","Candidate: 0.9999999999997211 \n","Score: 0.4152040816326531\n","\n","Candidate: 0.9999999999997236 \n","Score: 0.4153061224489796\n","\n","Candidate: 0.9999999999997273 \n","Score: 0.41540816326530616\n","\n","Candidate: 0.9999999999997349 \n","Score: 0.41551020408163264\n","\n","Candidate: 0.9999999999997419 \n","Score: 0.41551020408163264\n","\n","Candidate: 0.9999999999997452 \n","Score: 0.4156122448979592\n","\n","Candidate: 0.9999999999997478 \n","Score: 0.4157142857142857\n","\n","Candidate: 0.9999999999997549 \n","Score: 0.4158163265306123\n","\n","Candidate: 0.9999999999997627 \n","Score: 0.41591836734693877\n","\n","Candidate: 0.9999999999997686 \n","Score: 0.4160204081632653\n","\n","Candidate: 0.9999999999997731 \n","Score: 0.41612244897959183\n","\n","Candidate: 0.9999999999997747 \n","Score: 0.41622448979591836\n","\n","Candidate: 0.9999999999997754 \n","Score: 0.4163265306122449\n","\n","Candidate: 0.9999999999997775 \n","Score: 0.4164285714285715\n","\n","Candidate: 0.9999999999997867 \n","Score: 0.41653061224489796\n","\n","Candidate: 0.9999999999997939 \n","Score: 0.4166326530612245\n","\n","Candidate: 0.9999999999997968 \n","Score: 0.4014285714285714\n","\n","Candidate: 0.999999999999805 \n","Score: 0.40153061224489794\n","\n","Candidate: 0.9999999999998113 \n","Score: 0.40163265306122453\n","\n","Candidate: 0.9999999999998137 \n","Score: 0.401734693877551\n","\n","Candidate: 0.9999999999998171 \n","Score: 0.4018367346938776\n","\n","Candidate: 0.999999999999821 \n","Score: 0.40193877551020407\n","\n","Candidate: 0.9999999999998243 \n","Score: 0.40204081632653066\n","\n","Candidate: 0.9999999999998292 \n","Score: 0.40214285714285714\n","\n","Candidate: 0.9999999999998342 \n","Score: 0.40224489795918367\n","\n","Candidate: 0.9999999999998356 \n","Score: 0.4023469387755102\n","\n","Candidate: 0.9999999999998379 \n","Score: 0.40244897959183673\n","\n","Candidate: 0.9999999999998415 \n","Score: 0.40255102040816326\n","\n","Candidate: 0.9999999999998432 \n","Score: 0.4026530612244898\n","\n","Candidate: 0.9999999999998437 \n","Score: 0.4028571428571429\n","\n","Candidate: 0.9999999999998453 \n","Score: 0.4029591836734694\n","\n","Candidate: 0.9999999999998477 \n","Score: 0.403061224489796\n","\n","Candidate: 0.9999999999998499 \n","Score: 0.40316326530612245\n","\n","Candidate: 0.9999999999998527 \n","Score: 0.40326530612244904\n","\n","Candidate: 0.9999999999998546 \n","Score: 0.40645833333333337\n","\n","Candidate: 0.9999999999998558 \n","Score: 0.3927083333333334\n","\n","Candidate: 0.999999999999863 \n","Score: 0.39281250000000006\n","\n","Candidate: 0.9999999999998717 \n","Score: 0.39585106382978724\n","\n","Candidate: 0.9999999999998739 \n","Score: 0.39595744680851064\n","\n","Candidate: 0.999999999999877 \n","Score: 0.396063829787234\n","\n","Candidate: 0.9999999999998799 \n","Score: 0.39617021276595743\n","\n","Candidate: 0.9999999999998805 \n","Score: 0.3830434782608696\n","\n","Candidate: 0.9999999999998817 \n","Score: 0.38315217391304346\n","\n","Candidate: 0.9999999999998832 \n","Score: 0.38326086956521743\n","\n","Candidate: 0.9999999999998852 \n","Score: 0.3833695652173913\n","\n","Candidate: 0.9999999999998882 \n","Score: 0.38347826086956527\n","\n","Candidate: 0.9999999999998903 \n","Score: 0.38358695652173913\n","\n","Candidate: 0.999999999999891 \n","Score: 0.3836956521739131\n","\n","Candidate: 0.9999999999998923 \n","Score: 0.38380434782608697\n","\n","Candidate: 0.9999999999998961 \n","Score: 0.38391304347826094\n","\n","Candidate: 0.999999999999899 \n","Score: 0.3840217391304348\n","\n","Candidate: 0.9999999999999003 \n","Score: 0.3841304347826087\n","\n","Candidate: 0.9999999999999025 \n","Score: 0.38423913043478264\n","\n","Candidate: 0.9999999999999039 \n","Score: 0.3843478260869565\n","\n","Candidate: 0.9999999999999065 \n","Score: 0.3844565217391305\n","\n","Candidate: 0.9999999999999097 \n","Score: 0.38456521739130434\n","\n","Candidate: 0.999999999999913 \n","Score: 0.38467391304347825\n","\n","Candidate: 0.9999999999999158 \n","Score: 0.3847826086956522\n","\n","Candidate: 0.999999999999917 \n","Score: 0.38489130434782615\n","\n","Candidate: 0.9999999999999178 \n","Score: 0.38489130434782615\n","\n","Candidate: 0.9999999999999185 \n","Score: 0.385108695652174\n","\n","Candidate: 0.9999999999999196 \n","Score: 0.38521739130434784\n","\n","Candidate: 0.9999999999999216 \n","Score: 0.38532608695652176\n","\n","Candidate: 0.9999999999999268 \n","Score: 0.3854347826086957\n","\n","Candidate: 0.9999999999999308 \n","Score: 0.38554347826086965\n","\n","Candidate: 0.9999999999999318 \n","Score: 0.3856521739130435\n","\n","Candidate: 0.999999999999933 \n","Score: 0.3857608695652175\n","\n","Candidate: 0.999999999999935 \n","Score: 0.38586956521739135\n","\n","Candidate: 0.9999999999999369 \n","Score: 0.38597826086956527\n","\n","Candidate: 0.9999999999999385 \n","Score: 0.3860869565217392\n","\n","Candidate: 0.9999999999999405 \n","Score: 0.38619565217391305\n","\n","Candidate: 0.9999999999999416 \n","Score: 0.386304347826087\n","\n","Candidate: 0.9999999999999427 \n","Score: 0.3726666666666667\n","\n","Candidate: 0.9999999999999439 \n","Score: 0.37277777777777776\n","\n","Candidate: 0.9999999999999449 \n","Score: 0.37288888888888894\n","\n","Candidate: 0.9999999999999457 \n","Score: 0.37300000000000005\n","\n","Candidate: 0.9999999999999462 \n","Score: 0.37311111111111117\n","\n","Candidate: 0.9999999999999467 \n","Score: 0.3732222222222223\n","\n","Candidate: 0.9999999999999476 \n","Score: 0.3733333333333334\n","\n","Candidate: 0.9999999999999482 \n","Score: 0.37344444444444447\n","\n","Candidate: 0.9999999999999487 \n","Score: 0.37355555555555564\n","\n","Candidate: 0.9999999999999492 \n","Score: 0.3736666666666667\n","\n","Candidate: 0.99999999999995 \n","Score: 0.3737777777777779\n","\n","Candidate: 0.9999999999999518 \n","Score: 0.37388888888888894\n","\n","Candidate: 0.9999999999999534 \n","Score: 0.37400000000000005\n","\n","Candidate: 0.9999999999999545 \n","Score: 0.37411111111111117\n","\n","Candidate: 0.9999999999999558 \n","Score: 0.37422222222222223\n","\n","Candidate: 0.999999999999957 \n","Score: 0.3743333333333334\n","\n","Candidate: 0.9999999999999585 \n","Score: 0.37444444444444447\n","\n","Candidate: 0.9999999999999603 \n","Score: 0.3602272727272728\n","\n","Candidate: 0.9999999999999611 \n","Score: 0.36034090909090916\n","\n","Candidate: 0.9999999999999615 \n","Score: 0.36045454545454547\n","\n","Candidate: 0.9999999999999623 \n","Score: 0.36056818181818184\n","\n","Candidate: 0.9999999999999638 \n","Score: 0.3606818181818182\n","\n","Candidate: 0.9999999999999651 \n","Score: 0.3607954545454546\n","\n","Candidate: 0.9999999999999658 \n","Score: 0.36090909090909096\n","\n","Candidate: 0.9999999999999662 \n","Score: 0.3610227272727273\n","\n","Candidate: 0.9999999999999666 \n","Score: 0.36125\n","\n","Candidate: 0.9999999999999674 \n","Score: 0.3613636363636364\n","\n","Candidate: 0.9999999999999682 \n","Score: 0.36147727272727276\n","\n","Candidate: 0.9999999999999689 \n","Score: 0.3615909090909091\n","\n","Candidate: 0.99999999999997 \n","Score: 0.3617045454545455\n","\n","Candidate: 0.9999999999999714 \n","Score: 0.3618181818181818\n","\n","Candidate: 0.9999999999999716 \n","Score: 0.3619318181818182\n","\n","Candidate: 0.9999999999999721 \n","Score: 0.36215909090909093\n","\n","Candidate: 0.9999999999999731 \n","Score: 0.3622727272727273\n","\n","Candidate: 0.9999999999999741 \n","Score: 0.3623863636363637\n","\n","Candidate: 0.9999999999999748 \n","Score: 0.365\n","\n","Candidate: 0.9999999999999751 \n","Score: 0.3651162790697674\n","\n","Candidate: 0.9999999999999754 \n","Score: 0.3651162790697674\n","\n","Candidate: 0.9999999999999765 \n","Score: 0.36546511627906975\n","\n","Candidate: 0.9999999999999776 \n","Score: 0.36558139534883716\n","\n","Candidate: 0.9999999999999785 \n","Score: 0.3656976744186046\n","\n","Candidate: 0.9999999999999796 \n","Score: 0.36581395348837203\n","\n","Candidate: 0.9999999999999801 \n","Score: 0.3659302325581395\n","\n","Candidate: 0.9999999999999807 \n","Score: 0.36604651162790697\n","\n","Candidate: 0.9999999999999811 \n","Score: 0.36604651162790697\n","\n","Candidate: 0.9999999999999815 \n","Score: 0.36627906976744184\n","\n","Candidate: 0.9999999999999818 \n","Score: 0.36639534883720926\n","\n","Candidate: 0.9999999999999822 \n","Score: 0.3666279069767442\n","\n","Candidate: 0.999999999999983 \n","Score: 0.3667441860465116\n","\n","Candidate: 0.9999999999999836 \n","Score: 0.3668604651162791\n","\n","Candidate: 0.999999999999984 \n","Score: 0.36697674418604653\n","\n","Candidate: 0.9999999999999845 \n","Score: 0.36709302325581394\n","\n","Candidate: 0.9999999999999847 \n","Score: 0.3722619047619048\n","\n","Candidate: 0.9999999999999849 \n","Score: 0.3722619047619048\n","\n","Candidate: 0.9999999999999856 \n","Score: 0.37250000000000005\n","\n","Candidate: 0.9999999999999865 \n","Score: 0.3727380952380953\n","\n","Candidate: 0.9999999999999869 \n","Score: 0.37285714285714294\n","\n","Candidate: 0.9999999999999871 \n","Score: 0.37309523809523815\n","\n","Candidate: 0.9999999999999873 \n","Score: 0.3732142857142858\n","\n","Candidate: 0.9999999999999876 \n","Score: 0.3733333333333334\n","\n","Candidate: 0.9999999999999878 \n","Score: 0.3733333333333334\n","\n","Candidate: 0.9999999999999882 \n","Score: 0.37369047619047624\n","\n","Candidate: 0.9999999999999889 \n","Score: 0.37380952380952387\n","\n","Candidate: 0.9999999999999893 \n","Score: 0.37380952380952387\n","\n","Candidate: 0.9999999999999896 \n","Score: 0.3740476190476191\n","\n","Candidate: 0.9999999999999898 \n","Score: 0.37428571428571433\n","\n","Candidate: 0.99999999999999 \n","Score: 0.37440476190476196\n","\n","Candidate: 0.9999999999999902 \n","Score: 0.37440476190476196\n","\n","Candidate: 0.9999999999999905 \n","Score: 0.37464285714285717\n","\n","Candidate: 0.999999999999991 \n","Score: 0.3747619047619048\n","\n","Candidate: 0.9999999999999916 \n","Score: 0.3748809523809524\n","\n","Candidate: 0.9999999999999918 \n","Score: 0.3597560975609756\n","\n","Candidate: 0.999999999999992 \n","Score: 0.36250000000000004\n","\n","Candidate: 0.9999999999999921 \n","Score: 0.36262500000000003\n","\n","Candidate: 0.9999999999999925 \n","Score: 0.36275\n","\n","Candidate: 0.9999999999999927 \n","Score: 0.36287500000000006\n","\n","Candidate: 0.9999999999999931 \n","Score: 0.36312500000000003\n","\n","Candidate: 0.9999999999999933 \n","Score: 0.3632500000000001\n","\n","Candidate: 0.9999999999999936 \n","Score: 0.36362500000000003\n","\n","Candidate: 0.9999999999999938 \n","Score: 0.364\n","\n","Candidate: 0.999999999999994 \n","Score: 0.36412500000000003\n","\n","Candidate: 0.9999999999999943 \n","Score: 0.36425\n","\n","Candidate: 0.9999999999999944 \n","Score: 0.36425\n","\n","Candidate: 0.9999999999999947 \n","Score: 0.364625\n","\n","Candidate: 0.9999999999999949 \n","Score: 0.36475\n","\n","Candidate: 0.9999999999999951 \n","Score: 0.36512500000000003\n","\n","Candidate: 0.9999999999999953 \n","Score: 0.3680769230769231\n","\n","Candidate: 0.9999999999999956 \n","Score: 0.3680769230769231\n","\n","Candidate: 0.9999999999999958 \n","Score: 0.3684615384615384\n","\n","Candidate: 0.999999999999996 \n","Score: 0.3688461538461538\n","\n","Candidate: 0.9999999999999963 \n","Score: 0.36897435897435893\n","\n","Candidate: 0.9999999999999966 \n","Score: 0.3692307692307692\n","\n","Candidate: 0.9999999999999967 \n","Score: 0.3692307692307692\n","\n","Candidate: 0.9999999999999969 \n","Score: 0.37263157894736837\n","\n","Candidate: 0.9999999999999971 \n","Score: 0.3753947368421052\n","\n","Candidate: 0.9999999999999974 \n","Score: 0.3756578947368421\n","\n","Candidate: 0.9999999999999977 \n","Score: 0.37592105263157893\n","\n","Candidate: 0.9999999999999978 \n","Score: 0.37592105263157893\n","\n","Candidate: 0.999999999999998 \n","Score: 0.3834722222222222\n","\n","Candidate: 0.9999999999999982 \n","Score: 0.38430555555555557\n","\n","Candidate: 0.9999999999999984 \n","Score: 0.3847222222222222\n","\n","Candidate: 0.9999999999999987 \n","Score: 0.38555555555555554\n","\n","Candidate: 0.9999999999999988 \n","Score: 0.3858333333333333\n","\n","Candidate: 0.9999999999999989 \n","Score: 0.3858333333333333\n","\n","Candidate: 0.9999999999999991 \n","Score: 0.3868055555555555\n","\n","Candidate: 0.9999999999999993 \n","Score: 0.39573529411764696\n","\n","Candidate: 0.9999999999999996 \n","Score: 0.4084375\n","\n","Candidate: 0.9999999999999998 \n","Score: 0.41564516129032253\n","\n","Candidate: 1.0 \n","Score: 0.41448275862068973\n","\n"]}]},{"cell_type":"code","source":["# aim is to minimise cost function -- find index in array where this is the case\n","lowest_cf_score = np.min(np.array(cost_function_values))\n","index_best_th = np.argmin(np.array(cost_function_values))"],"metadata":{"id":"P2IsLZXQ77oZ","executionInfo":{"status":"ok","timestamp":1651231174217,"user_tz":-60,"elapsed":45,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":346,"outputs":[]},{"cell_type":"code","source":["lowest_cf_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iZ3ba0jhY0I","executionInfo":{"status":"ok","timestamp":1651231174217,"user_tz":-60,"elapsed":44,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"467e5888-31bd-4897-e339-cd84b5cb0c7a"},"execution_count":347,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3597560975609756"]},"metadata":{},"execution_count":347}]},{"cell_type":"code","source":["index_best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBS0v3GAh77m","executionInfo":{"status":"ok","timestamp":1651231174218,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"c350a2db-4b98-48dd-dadf-f8f22c10b73f"},"execution_count":348,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1699"]},"metadata":{},"execution_count":348}]},{"cell_type":"code","source":["best_th = list(threshold_candidates)[index_best_th]\n","best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmy0bv8N8YvW","executionInfo":{"status":"ok","timestamp":1651231174621,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8469e884-e52c-44be-b666-b3eb600c8cd9"},"execution_count":349,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9999999999999918"]},"metadata":{},"execution_count":349}]},{"cell_type":"markdown","source":["#### Testing with best threshold"],"metadata":{"id":"ypFTpLSAir09"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions excluding the current test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # count inconclusive results\n","  inconc_count = 0\n","  \n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    for i in range(len(predictions)):\n","\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","    \n","      if(c >= best_th ): # best confidence threshold from cost function\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","\n","        earliness.append(time_index/timestamps[-1])\n","\n","        if(pred == 1.0):\n","          print(f\"TTP: {time_to_result + 30}s \\t {round((time_to_result+30)/60, 2)} mins\")\n","\n","        break\n","\n","      if(i == len(predictions)-1):\n","        print(\"Inconclusive\")\n","        inconc_count += 1\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","  print(f\"Average Earliness: {sum(earliness)/len(earliness)}\")\n","  print(f\"Total Inconclusive: {inconc_count}/{sample_idx}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfPwqWWHiqnY","executionInfo":{"status":"ok","timestamp":1651231271739,"user_tz":-60,"elapsed":6318,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"938c1bca-7b0f-4f04-e417-9424dabb15f8"},"execution_count":352,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 659.0s \t 10.98 mins\n","\n","Sample exp_86_pos\n","Inconclusive\n","\n","Sample exp_129_pos\n","Inconclusive\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 698.0s \t 11.63 mins\n","\n","Sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1117.0s \t 18.62 mins\n","\n","Sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 705.0s \t 11.75 mins\n","\n","Sample exp_14_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 771.0s \t 12.85 mins\n","\n","Sample exp_40_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 822.0s \t 13.7 mins\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 849.0s \t 14.15 mins\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 786.0s \t 13.1 mins\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 755s \t 12.58 mins\n","\n","Sample exp_97_pos\n","Inconclusive\n","\n","Sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 765.0s \t 12.75 mins\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 768.0s \t 12.8 mins\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 823.0s \t 13.72 mins\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 770.0s \t 12.83 mins\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1021.0s \t 17.02 mins\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 826.0s \t 13.77 mins\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 842.0s \t 14.03 mins\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 814.0s \t 13.57 mins\n","\n","Sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1337.0s \t 22.28 mins\n","\n","Sample rv1y_p3\n","Inconclusive\n","\n","Sample rv1y_p4\n","Inconclusive\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 813.0s \t 13.55 mins\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1121.0s \t 18.68 mins\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 801.0s \t 13.35 mins\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 917.0s \t 15.28 mins\n","\n","Sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 777.0s \t 12.95 mins\n","\n","Sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_86_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 910s \t 15.17 mins\n","\n","Sample exp_129_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 767s \t 12.78 mins\n","\n","Sample exp_165_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 791s \t 13.18 mins\n","\n","Sample exp_35_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 986s \t 16.43 mins\n","\n","Sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 849s \t 14.15 mins\n","\n","Sample exp_40_neg\n","Inconclusive\n","\n","Sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_27_neg\n","Inconclusive\n","\n","Sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_97_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 847s \t 14.12 mins\n","\n","Sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_64_neg\n","Inconclusive\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 824.0s \t 13.73 mins\n","\n","Sample yap1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 968.0s \t 16.13 mins\n","\n","Sample yap1n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 1017.0s \t 16.95 mins\n","\n","Sample arv7\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Accuracy: 0.7804878048780488\n","Sensitivity/Recall: 1.0\n","Specificity: 0.5\n","Precision: 0.71875\n","F1 Score: 0.8363636363636363\n","Average Earliness: 0.7804878048780489\n","Total Inconclusive: 8/49\n"]}]},{"cell_type":"markdown","source":["#### Testing with different alpha values"],"metadata":{"id":"w43_TkUVitvi"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"pJXWD05RjB-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"NSkTWcddjB-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981439090,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"f742fd4d-fa2c-4f24-c18f-ffde40f1d377","id":"KWOXfxRKjB-i"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"NXrd_74JjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"wcE9LintjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"qb9FWSPgjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are mad of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"bM7ILJSwjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650981450827,"user_tz":-60,"elapsed":2,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"23bf8873-4159-42ca-fc01-82fcb7e27198","id":"36WDfG-TjB-l"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1184"]},"metadata":{},"execution_count":497}]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  acc = []\n","  ear = []\n","\n","  for i in range(0,100,5):\n","\n","    # alpha\n","    alpha = i/100\n","\n","    print(f\"Alpha: {alpha}\")\n","\n","    # array to hold cost function value for each candidate\n","    cost_function_values = []\n","\n","    # create nN predictions using each dataset as the test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # evaluate every candidate\n","    for th in threshold_candidates:\n","\n","      # print(f\"Candidate: {th} \")\n","\n","      # array to hold earliness values for the samples \n","      earliness = []  \n","\n","      # dict to hold predictions vs true values for the samples  \n","      final_classifications = {}\n","\n","      # sample index\n","      sample_idx = 0\n","\n","      for key, value in all_samples.items():\n","        test_sample_name = key\n","        test_sample = value\n","  \n","        # get KNN predicition for the sample\n","        predictions = sample_predictions[sample_idx]\n","\n","        for i in range(len(predictions)):\n","\n","          # get the confidence for that prediction \n","          c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","          if(c >= th): # check if confidence is above confidence threshold\n","\n","            time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","            time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","            # predicted class for the sample is given by the prediction which led to the gien confidence value\n","            pred = predictions[i]\n","\n","            # update final outcomes dict\n","            final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","            # add to earliness array\n","            earliness.append(time_index/timestamps[-1])\n","\n","            break\n","        sample_idx += 1\n","\n","      # get avg accuracy and avg earliness for this threshold\n","      if(len(final_classifications) > 0):\n","        avg_accuracy = accuracy(final_classifications)\n","        avg_earliness = sum(earliness)/len(earliness)\n","\n","        # compute value of cost function and add to array \n","        cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","        cost_function_values.append(cf_score)\n","\n","    index_best_th = np.argmin(np.array(cost_function_values))    \n","    best_th = list(threshold_candidates)[index_best_th]\n","\n","###########################################################################################################\n","\n","    ## teating with best th\n","    final_classifications = {}\n","    earliness = []\n","\n","    # create nN predictions excluding the current test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    # count inconclusive results\n","    inconc_count = 0\n","    \n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      \n","        if(c >= best_th): # best confidence threshold from cost function\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          pred = predictions[i]\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","          earliness.append(time_index/timestamps[-1])\n","          break\n","\n","        if(i == len(predictions)-1):\n","          inconc_count += 1\n","      \n","      sample_idx += 1\n","\n","    print(f\"Avg Accuracy: {accuracy(final_classifications)}\")\n","    print(f\"Avg Earliness: {sum(earliness)/len(earliness)}\")\n","    print(\"\")\n","    acc.append(accuracy(final_classifications))\n","    ear.append(sum(earliness)/len(earliness))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"V6Fhz4hsiui6","executionInfo":{"status":"error","timestamp":1650981574100,"user_tz":-60,"elapsed":121427,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"5e8c4f9a-49b2-44fb-eed4-3494af98bb4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Alpha: 0.0\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.05\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.1\n","Avg Accuracy: 0.4807692307692308\n","Avg Earliness: 0.02884615384615386\n","\n","Alpha: 0.15\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-498-89cc9171be6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# create nN predictions excluding the current test sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0msample_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_predictions_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# create multipliers for every classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-66-ab459af536aa>\u001b[0m in \u001b[0;36mgenerate_predictions_table\u001b[0;34m(positives, negatives, timestamps)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_sample_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_data_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-100-5619c2d01103>\u001b[0m in \u001b[0;36mget_training_data_knn\u001b[0;34m(positive_samples, negative_samples, timestamp, test_samples)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m## truncate sample to length t = timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpos_subsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Average Output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## append subsample of length t to training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m             \u001b[0;31m# shortcut if the key is in columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3424\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3425\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4538\u001b[0m         \"\"\"\n\u001b[1;32m   4539\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = acc\n","y = ear\n","axes.set_xlabel(\"Accuracy\")\n","axes.set_ylabel(\"Earliness\")\n","axes.plot(x,y, '-o')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"R0a7Bbrabp6R","executionInfo":{"status":"ok","timestamp":1650975154308,"user_tz":-60,"elapsed":485,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"ecaa763d-1bfa-4fdc-9a86-c2e35604c565"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f4beae35050>]"]},"metadata":{},"execution_count":347},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"simepEdKIiL0"},"source":["### Github Commands"]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"YdlGDV3AzZ1L","executionInfo":{"status":"ok","timestamp":1651228662452,"user_tz":-60,"elapsed":366,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"b519794a-1e9e-4529-e695-9a1f49327ce3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":340,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project\n"]}]},{"cell_type":"code","execution_count":341,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1651228662785,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"itbAqo9qGukN","outputId":"eed2f7d0-4242-4520-9264-917ef7f667fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   Early Time Series Classification - Average Ouput.ipynb\u001b[m\n","\t\u001b[31mmodified:   Early Time Series Classification - Pixel Data NN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Visualisations.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}],"source":["username = \"adityag16\"\n","git_token = \"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\"\n","repository = \"/content/drive/MyDrive/Final-Year-Project\"\n","%cd {repository}\n","!git status"]},{"cell_type":"code","execution_count":342,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1642,"status":"ok","timestamp":1651228667363,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"pNInxPqdG7nx","outputId":"854caa61-c2d4-45ea-e8e9-329093a531fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git reset HEAD <file>...\" to unstage)\n","\n","\t\u001b[32mmodified:   Early Time Series Classification - Average Ouput.ipynb\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   Early Time Series Classification - Pixel Data NN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Visualisations.ipynb\u001b[m\n","\n"]}],"source":["!git add 'Early Time Series Classification - Average Ouput.ipynb' 'Best Performances.docx'\n","!git status"]},{"cell_type":"code","execution_count":343,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2956,"status":"ok","timestamp":1651228691806,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"K1tS6nonHF9u","outputId":"4157952e-0f1b-4d3f-c6ab-6166f53b1a97"},"outputs":[{"output_type":"stream","name":"stdout","text":["[main 49be48a] Results realistic with alpha = 0.75 with K=3 in the confidence\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n","Counting objects: 3, done.\n","Delta compression using up to 2 threads.\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 20.26 KiB | 1.19 MiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/adityag16/Final-Year-Project\n","   cb33562..49be48a  main -> main\n"]}],"source":["!git config --global user.email \"aditya.gupta18@imperial.ac.uk\"\n","!git config --global user.name \"adityag16\"\n","\n","!git commit -m \"Results realistic with alpha = 0.75 with K=3 in the confidence\"\n","!git push origin main"]},{"cell_type":"code","source":[""],"metadata":{"id":"8KO_iVTj0cIP"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Early Time Series Classification - Average Ouput.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1WYaF_HRa3IGG6auTN3SvWNlJMYRlk-43","authorship_tag":"ABX9TyM6kD9WiRi3Qw6Ryjb8EOrK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Connect Drive"],"metadata":{"id":"XVaAULW6qhh1"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2893,"status":"ok","timestamp":1650964560919,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"_DdiqzlkZMhe","outputId":"10f2b2ad-301f-4ec3-d0bb-487309638f4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"markdown","metadata":{"id":"ttpluWU4tHLq"},"source":["### Package Imports"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Z_3NHgGwZIsI","executionInfo":{"status":"ok","timestamp":1650964563497,"user_tz":-60,"elapsed":2590,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.signal import savgol_filter\n","from collections import Counter\n","import copy\n","from collections import defaultdict"]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from scipy.spatial import distance\n","from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances"],"metadata":{"id":"5vMvjgqYCd2d","executionInfo":{"status":"ok","timestamp":1650964563499,"user_tz":-60,"elapsed":15,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### GPU Device"],"metadata":{"id":"6cosBM9Jd74f"}},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kElpooT1fLzz","executionInfo":{"status":"ok","timestamp":1650964566238,"user_tz":-60,"elapsed":279,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"33affe78-d5fb-4371-c301-3147684d7af9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-d7a81eed-79fa-a323-7c76-bba63d07e27c)\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230,"status":"ok","timestamp":1650964570292,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"bLu_lZGKu9dp","outputId":"5d0d50bb-32e0-4668-d869-478ebe875ec2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["gpu = tf.test.gpu_device_name()\n","print(gpu)"]},{"cell_type":"markdown","metadata":{"id":"ihJkU1v2STVo"},"source":["### Pre-Processing Helper Functions"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"W1YMbu9bSW5m","executionInfo":{"status":"ok","timestamp":1650964570294,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vref(X, v_thresh=70):\n","    '''\n","    Identifies active pixels by checking if one of the first 10 derivatives d(i) is > v_thresh\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_thresh : int, optional\n","        Minimum value of the derivative d(i)=X(i+1)-X(i) in mV. Default is 70\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if, during the first 10 samples,\n","        one of the derivatives is > v_thresh. The derivatives are calculated as d(i) = X(i+1)-X(i)\n","    '''\n","    return (np.diff(X[:10, :], axis=0) > v_thresh).any(axis=0)  # check if one of the first 10 derivatives is >v_thresh"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"XjXkAhKwSgFB","executionInfo":{"status":"ok","timestamp":1650964576867,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_vrange(X, v_range=(100, 900)):\n","    '''\n","    Identifies active pixels by checking that all the values are in v_range\n","    Parameters\n","    ---------\n","    X : ndarray\n","        Input 2D array (T x NM). T = time samples, NM = total number of pixels\n","    v_range : (int, int), optional\n","        tuple containing the minimum and maximum allowable voltage in mV. Default is (100, 900)\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if the value is always in v_range\n","    '''\n","    return (X < v_range[1]).all(axis=0) & (X > v_range[0]).all(axis=0)  # for each pixel, check if all the values are\n","    # within the given range\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"G5a7Uqi9Skg_","executionInfo":{"status":"ok","timestamp":1650964577562,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_by_derivative(X, vthresh=5):\n","    \"\"\" Identifies active pixels by checking that the absolute value of the derivative is always below vthresh\n","    Parameters\n","    ----------\n","    X : ndarray\n","        input 2D array of shape TxNM\n","    vthresh : int\n","        threshold for active pixels. Default is 5\n","    Returns\n","    -------\n","    ndarray\n","        1D array of bool with dimension (NM). For each pixel, returns True if all the derivatives are below vthresh\n","    \"\"\"\n","    x_diff = np.abs(np.diff(X, axis=0))\n","    return (x_diff < vthresh).all(axis=0)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"XUOV5CRYflUO","executionInfo":{"status":"ok","timestamp":1650964577807,"user_tz":-60,"elapsed":19,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # set pixel values to 0/nan\n","  for idx, col in enumerate(df.columns):\n","    if(not active[idx]):\n","      df.loc[:, col] = 0\n","\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_drop(df, v_thresh_ref=50, v_range=(100, 900), v_thresh_deriv=5): #v_thresh_ref changed from 70 to 50\n","  active = filter_by_vref(df.values, v_thresh_ref) & filter_by_vrange(df.values, v_range) & filter_by_derivative(df.values, v_thresh_deriv)\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"DhuoGbbPutKZ","executionInfo":{"status":"ok","timestamp":1650964577809,"user_tz":-60,"elapsed":19,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ZZJkYzPiVvd6","executionInfo":{"status":"ok","timestamp":1650964577810,"user_tz":-60,"elapsed":19,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def filter_active_pixels_deriv(df, v_thresh_deriv=5): \n","  active = filter_by_derivative(df.values, v_thresh_deriv)\n","\n","  # for idx, col in enumerate(df.columns):\n","  #   if(not active[idx]):\n","  #     df.loc[:, col] = 0\n","  \n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"]},{"cell_type":"code","source":["def filter_active_pixels_range(df, v_range=(100, 900)):\n","  active = filter_by_vrange(df.values, v_range)\n","\n","  # drop pixels \n","  df = df.loc[: , active]\n","  return df"],"metadata":{"id":"imVXR8eVUrby","executionInfo":{"status":"ok","timestamp":1650964577811,"user_tz":-60,"elapsed":18,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def reshape_data(df, rows, cols):\n","  X = df.values #pandas.DataFrame.values: Return a Numpy representation of the DataFrame.\n","  X = X.reshape(-1, rows, cols, order='F') #or C. different reshaping row by row or column by column but this works\n","  return X"],"metadata":{"id":"RTF9Vh78MZSB","executionInfo":{"status":"ok","timestamp":1650964577812,"user_tz":-60,"elapsed":18,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def filter_chemical_pixels(df, arr_rows, arr_cols):\n","  X = reshape_data(df, arr_rows, arr_cols) # reshape data to T x 78 x 56\n","  X_mean = np.mean(X, axis=0) # get mean to have 78 x 56 shape\n","  X_mean[1::3, 1::3] = np.nan # set temperature pixels to nan\n","  X_mean = X_mean.flatten('F') # restore shape to 4068 \n","\n","  active_chemical = ~(np.isnan(X_mean)) # get bool array of all chemical pixels\n","\n","  # drop pixels \n","  df = df.loc[: , active_chemical]\n","  return df\n"],"metadata":{"id":"D9Xt8X4zL7hc","executionInfo":{"status":"ok","timestamp":1650964577814,"user_tz":-60,"elapsed":19,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"o82EQTYe9euH","executionInfo":{"status":"ok","timestamp":1650964586620,"user_tz":-60,"elapsed":349,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def time_to_index(times, time_vect):\n","    '''\n","    Returns index of the times closest to the desired ones time_vect\n","    Arguments\n","    ---------\n","    times : list\n","        list of integers containing the desired times\n","    time_vect : nparray\n","        array of the times at which the values are sampled\n","    Returns\n","    -------\n","    list\n","        for each element in the input list times, return an element in the output list\n","        with the index of the sample closest to the desired time\n","    '''\n","    indices = []\n","    for time in times:  # for each time in the input list\n","        indices.append( np.argmin(np.abs(time_vect - time)) )\n","        # find index of the sampled time (in time_vect) closest to the desired one (time)\n","    return indices\n","\n","\n","def find_loading_time(time_vect, X, bounds=(600, 900), viz=False):  # for v2\n","    ''' Finds loading and settling time for the data of v2 chip\n","    Parameters\n","    ----------\n","    time_vect : ndarray\n","        1D array with dimension T containing the sampling times\n","    X : ndarray\n","        2D array with dimension TxNM containing the sampled data\n","    bounds : list, optional\n","        tuple containing the minimum and maximum times (in ms) where the loading time has to be searched.\n","        Default is (600, 900)\n","    viz : bool, optional\n","        if viz=True, show the plot. Default is False\n","    Returns\n","    -------\n","    tuple\n","        - settled_index : index at which the settling occurs\n","        - settled_time : time at which the settling occurs\n","    '''\n","\n","    search_start, search_end = time_to_index(bounds, time_vect)  # for each time in bounds, find the index\n","    # of the sample (in time_vect) that is closest to the desired one (in bounds)\n","    X_mean = np.mean(X, axis=1)  # for each sample, calculate the mean of all pixels\n","    X_mean_diff = np.diff(X_mean)  # find the derivative\n","\n","    loading_index = np.argmax(X_mean_diff[search_start:search_end]) + search_start + 1  # find the index\n","    # where the derivative is max in the specified interval\n","    loading_index = loading_index  # add settling time\n","    settled_index = loading_index + 10  # add settling time\n","    settled_time = time_vect[settled_index]  # find the time that index corresponds to\n","\n","    if viz:  # if viz is true, plot the following\n","        fig, ax = plt.subplots(3, 1)\n","        fig.suptitle('Finding Loading Time...')\n","\n","        ax[0].set(title='Active Chemical Pixels, ACP')\n","        ax[0].plot(time_vect, X)  # plot the active chemical pixels\n","\n","        ax[1].set(title='Mean(ACP)')\n","        ax[1].plot(time_vect, X_mean)  # plot the average of the pixels\n","        ax[1].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[1].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[1].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        ax[2].set(title='Diff(Mean(ACP))')\n","        ax[2].plot(time_vect[1:], X_mean_diff)  # plot the derivative of the mean\n","        ax[2].axvline(time_vect[search_start], color='C1')  # plot vertical line: beginning of the interval\n","        ax[2].axvline(time_vect[search_end], color='C1')  # plot vertical line: end of the interval\n","        ax[2].axvline(settled_time, color='C2')  # plot vertical line: the loading time that was found\n","\n","        plt.tight_layout()\n","        plt.show()\n","    return settled_index, settled_time"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"9m8OqTUtQVb0","executionInfo":{"status":"ok","timestamp":1650964586970,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"outputs":[],"source":["def preprocess_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","  \n","  df = filter_chemical_pixels(df, 78, 56) # filter all chemical pixels\n","  \n","  df = filter_active_pixels_drop(df=df, v_thresh_deriv=deriv_thresh, v_range=(100,900))\n","\n","  settle_idx, settle_time = find_loading_time(df.index, df, bounds=(600, 900), viz=False) # find settling point\n","  df = df.iloc[settle_idx + 10:, :] # use only the data after the settling time + 30s to allow reaction to settle\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise don't\n","\n","  df = df.iloc[0:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +200 added on to see impact on graph after pre-processing\n","  \n","  # for col in df.columns:\n","  #   df[col] = savgol_filter(df[col],101, 3)\n","\n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  df['Average Output'] = normalise_data(df['Average Output']) # normalise data using mix-max scaling\n","\n","   \n","  return df"]},{"cell_type":"code","source":["def preprocess_partial_data(df, deriv_thresh, deriv_thresh_bgsub=5):\n","\n","  df = filter_active_pixels_range(df=df, v_range=(100,900)) # filter by range incase of any saturation\n","  \n","  df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh) # filter pixels by deriv\n","\n","  df = df.sub(df.iloc[0, :], axis='columns') # subtract value of first pixel from all pixels\n","\n","  if(len(filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub).columns) != 0): # check if there is still data present after filtering\n","    df = filter_active_pixels_deriv(df=df, v_thresh_deriv=deriv_thresh_bgsub) # if data is present do filtering otherwise dont\n","\n","  df = df.iloc[:150+250, :] # take only 150 samples after settling point (approx 19-20mins) - extra +250 added on to see impact on graph after pre-processing\n","  \n","  df['Average Output'] = df.mean(axis=1) # compute the mean value after filtering inactive pixels \n","\n","  df['Average Output'] = savgol_filter(df['Average Output'],101, 3) # filter to smooth out the noise in the data\n","\n","  df['Average Output'] = normalise_data(df['Average Output']) # normalise data using mix-max scaling\n","    \n","  return df"],"metadata":{"id":"JsSdU8xPZX4U","executionInfo":{"status":"ok","timestamp":1650964589540,"user_tz":-60,"elapsed":270,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def normalise_data(series):\n","  return (series - series.min()) / (series.max() - series.min())"],"metadata":{"id":"M6wMMfHZEADc","executionInfo":{"status":"ok","timestamp":1650964591436,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["### Data Loading Helper Functions"],"metadata":{"id":"Dvvp28miEMsF"}},{"cell_type":"code","source":["def load_partial_covid_exp(filepath):\n","\n","  bot_filepath = filepath[:-4] + \"_bot.csv\"\n","  top_filepath = filepath[:-4] + \"_top.csv\"\n","\n","  ## load in 2 sheets\n","  df_neg = pd.read_csv(top_filepath, header=0, index_col=0)\n","  df_pos = pd.read_csv(bot_filepath, header=0, index_col=0)\n","\n","  return df_pos, df_neg"],"metadata":{"id":"vL28HCTcZUUG","executionInfo":{"status":"ok","timestamp":1650964591736,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation Metric Helper Functions"],"metadata":{"id":"PaNIFO5iSa9C"}},{"cell_type":"code","source":["def accuracy(classifications):\n","  total = len(classifications)\n","  total_correct = 0\n","  for i in classifications.values():\n","    if(i[0] == i[1]):\n","      total_correct +=1\n","\n","  accuracy = (total_correct/total)\n","\n","  return accuracy"],"metadata":{"id":"U2zoSqPJLatm","executionInfo":{"status":"ok","timestamp":1650965339589,"user_tz":-60,"elapsed":595,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["def sensitivity(classifications):\n","  true_pos = 0\n","  false_neg = 0\n","\n","  for i in classifications.values():\n","\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","\n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 1 and predicted == 0):\n","      false_neg += 1\n","\n","  sensitivity = (true_pos/(true_pos + false_neg))\n","\n","  return sensitivity"],"metadata":{"id":"lzSAF5WsTIuF","executionInfo":{"status":"ok","timestamp":1650965340031,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["def specificity(classifications):\n","  true_neg = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 0 and predicted == 0):\n","      true_neg += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  specificity = (true_neg/(true_neg + false_pos))\n","\n","  return specificity"],"metadata":{"id":"WP_kdiXMYeU1","executionInfo":{"status":"ok","timestamp":1650965344241,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["def precision(classifications):\n","  true_pos = 0\n","  false_pos = 0\n","\n","  for i in classifications.values():\n","    true_label = int(i[1])\n","    predicted = int(i[0])\n","    \n","    if(true_label == 1 and predicted == 1):\n","      true_pos += 1\n","    \n","    if(true_label == 0 and predicted == 1):\n","      false_pos += 1\n","\n","  precision = (true_pos/(true_pos + false_pos))\n","\n","  return precision"],"metadata":{"id":"w7-_ZPDDaxRp","executionInfo":{"status":"ok","timestamp":1650965349612,"user_tz":-60,"elapsed":318,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":98,"outputs":[]},{"cell_type":"code","source":["def f1(classifications):\n","  numerator = 2*precision(classifications)*sensitivity(classifications)\n","  denominator = precision(classifications) + sensitivity(classifications)\n","  return numerator/denominator"],"metadata":{"id":"qkFpU-UJbV1R","executionInfo":{"status":"ok","timestamp":1650965352975,"user_tz":-60,"elapsed":230,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":["### Array Dims"],"metadata":{"id":"W9kgS_-Cx1nm"}},{"cell_type":"code","source":["arr_rows = 78\n","arr_cols = 56"],"metadata":{"id":"whsJZh4Zx0xs","executionInfo":{"status":"ok","timestamp":1650964636476,"user_tz":-60,"elapsed":4,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["### Load Data"],"metadata":{"id":"KCr7gvB_tf5-"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"AvJiLnQ8tiKx"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  avg_data_g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_data_export.csv\"\n","  avg_g1 = pd.read_csv(avg_data_g1_file, header=0)\n","\n","  ## Gamma 2\n","  avg_data_g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_data_export.csv\"\n","  avg_g2 = pd.read_csv(avg_data_g2_file, header=0)\n","\n","  ## Gamma 3\n","  avg_data_g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_data_export.csv\"\n","  avg_g3 = pd.read_csv(avg_data_g3_file, header=0)\n","  \n","  ## Gamma 5 \n","  avg_data_g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_data_export.csv\"\n","  avg_g5 = pd.read_csv(avg_data_g5_file, header=0)\n","\n","  ## 22RV1.ap1\n","  avg_data_22rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_data_export.csv\"\n","  avg_22rv1_ap1 = pd.read_csv(avg_data_22rv1_ap1_file, header=0)\n","\n","  ## 22RV1.ap2\n","  avg_data_22rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_data_export.csv\"\n","  avg_22rv1_ap2 = pd.read_csv(avg_data_22rv1_ap2_file, header=0)\n","\n","  ## 22RV1y.p1\n","  avg_data_22rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_data_export.csv\"\n","  avg_22rv1y_p1 = pd.read_csv(avg_data_22rv1y_p1_file, header=0)\n","\n","  ## 22RV1y.p3\n","  avg_data_22rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_data_export.csv\"\n","  avg_22rv1y_p3 = pd.read_csv(avg_data_22rv1y_p3_file, header=0)\n","\n","  ## 22RV1y.p4\n","  avg_data_22rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_data_export.csv\"\n","  avg_22rv1y_p4 = pd.read_csv(avg_data_22rv1y_p4_file, header=0)\n","\n","  ## ARV7.p1\n","  avg_data_arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_data_export.csv\"\n","  avg_arv7_p1 = pd.read_csv(avg_data_arv7_p1_file, header=0).iloc[1:, :].reset_index(drop=True) # row 0 was NAN\n","\n","  ## ARV7.p3\n","  avg_data_arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_data_export.csv\"\n","  avg_arv7_p3 = pd.read_csv(avg_data_arv7_p3_file, header=0)\n","\n","  ## ARV7.p4\n","  avg_data_arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_data_export.csv\"\n","  avg_arv7_p4 = pd.read_csv(avg_data_arv7_p4_file, header=0)\n","\n","  ## Beta 1\n","  avg_data_b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_data_export.csv\"\n","  avg_b1 = pd.read_csv(avg_data_b1_file, header=0)\n","\n","  ## Beta 2\n","  avg_data_b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_data_export.csv\"\n","  avg_b2 = pd.read_csv(avg_data_b2_file, header=0)\n","\n","  ## Beta 5\n","  avg_data_b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_data_export.csv\"\n","  avg_b5 = pd.read_csv(avg_data_b5_file, header=0)\n","  "],"metadata":{"id":"Ekqd_pB0tuTS","executionInfo":{"status":"ok","timestamp":1650964640619,"user_tz":-60,"elapsed":245,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):\n","  ## Gamma 1\n","  g1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma1.app.1e5/gamma1.app.1e5_vsChem_export.csv\"\n","  g1 = pd.read_csv(g1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g1.index = avg_g1[\"Time Elapsed\"]\n","\n","  ## Gamma 2\n","  g2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma2.app.1e4/gamma2.app.1e4_vsChem_export.csv\"\n","  g2 = pd.read_csv(g2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g2.index = avg_g2[\"Time Elapsed\"]\n","\n","  ## Gamma 3\n","  g3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma3.app.1e5/gamma3.app.1e5_vsChem_export.csv\"\n","  g3 = pd.read_csv(g3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g3.index = avg_g3[\"Time Elapsed\"]\n","\n","  ## Gamma 5\n","  g5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/gamma5.app.1e4/gamma5.app.1e4_vsChem_export.csv\"\n","  g5 = pd.read_csv(g5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  g5.index = avg_g5[\"Time Elapsed\"]\n","\n","  ## 22RV1.ap1\n","  rv1_ap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap1/22RV1.ap1_vsChem_export.csv\"\n","  rv1_ap1 = pd.read_csv(rv1_ap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap1.index = avg_22rv1_ap1['Time Elapsed']\n","\n","  ## 22RV1.ap2\n","  rv1_ap2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22RV1.ap2/22RV1.ap2_vsChem_export.csv\"\n","  rv1_ap2 = pd.read_csv(rv1_ap2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1_ap2.index = avg_22rv1_ap2['Time Elapsed']\n","\n","  ## 22RV1y.p1\n","  rv1y_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p1/22Rv1y.p1_vsChem_export.csv\"\n","  rv1y_p1 = pd.read_csv(rv1y_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p1.index = avg_22rv1y_p1['Time Elapsed']\n","\n","  ## 22RV1y.p3\n","  rv1y_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p3/22Rv1y.p3_vsChem_export.csv\"\n","  rv1y_p3 = pd.read_csv(rv1y_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p3.index = avg_22rv1y_p3['Time Elapsed']\n","\n","  ## 22RV1y.p4\n","  rv1y_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/22Rv1y.p4/22Rv1y.p4_vsChem_export.csv\"\n","  rv1y_p4 = pd.read_csv(rv1y_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  rv1y_p4.index = avg_22rv1y_p4['Time Elapsed']\n","\n","  ## ARV7.p1 \n","  arv7_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p1/ARV7.p1_vsChem_export.csv\"\n","  arv7_p1 = pd.read_csv(arv7_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)] \n","  arv7_p1.index = avg_arv7_p1[\"Time Elapsed\"]\n","\n","  ## ARV7.p3 \n","  arv7_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p3/ARV7.p3_vsChem_export.csv\"\n","  arv7_p3 = pd.read_csv(arv7_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p3.index = avg_arv7_p3[\"Time Elapsed\"]\n","\n","  ## ARV7.p4 \n","  arv7_p4_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/ARV7.p4/ARV7.p4_vsChem_export.csv\"\n","  arv7_p4 = pd.read_csv(arv7_p4_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7_p4.index = avg_arv7_p4[\"Time Elapsed\"]\n","\n","  ## Beta 1\n","  b1_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta1.app.1e4/beta1.app.1e4_vsChem_export.csv\"\n","  b1 = pd.read_csv(b1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b1.index = avg_b1[\"Time Elapsed\"]\n","\n","  ## Beta 2\n","  b2_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta2.app.1e5/beta2.app.1e5_vsChem_export.csv\"\n","  b2 = pd.read_csv(b2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b2.index = avg_b2[\"Time Elapsed\"]\n","\n","  ## Beta 5\n","  b5_file = \"/content/drive/MyDrive/Final-Year-Project/DNAPositives/100921_DNA/100921_DNA/Data/beta5.app.1e5/beta5.app.1e5_vsChem_export.csv\"\n","  b5 = pd.read_csv(b5_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  b5.index = avg_b5[\"Time Elapsed\"]"],"metadata":{"id":"vZRah5zpxXp6","executionInfo":{"status":"ok","timestamp":1650964677581,"user_tz":-60,"elapsed":9365,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"7qOF9VBstkbe"}},{"cell_type":"code","source":["## Average pixel value for all samples \n","\n","with tf.device(gpu):  \n","  ## ARV7.n1\n","  avg_data_arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_data_export.csv\"\n","  avg_arv7 = pd.read_csv(avg_data_arv7_file, header=0)\n","\n","  ## Yap.n2\n","  avg_data_yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_data_export.csv\"\n","  avg_yap = pd.read_csv(avg_data_yap_file, header=0)\n","\n","  ## Yap1.n2\n","  avg_data_yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_data_export.csv\"\n","  avg_yap1 = pd.read_csv(avg_data_yap1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## Yap1.n1.1 \n","  avg_data_yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_data_export.csv\"\n","  avg_yap1n1 = pd.read_csv(avg_data_yap1n1_file, header=0).iloc[1:, :].reset_index() # row 0 was NAN\n","\n","  ## ARV7.n2\n","  avg_data_arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_data_export.csv\"\n","  avg_arv72 = pd.read_csv(avg_data_arv72_file, header=0)\n","\n","  ## ARV7.n3\n","  avg_data_arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_data_export.csv\"\n","  avg_arv73 = pd.read_csv(avg_data_arv73_file, header=0)\n","\n","  ## DU145a.p1\n","  avg_data_du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_data_export.csv\"\n","  avg_du145a_p1 = pd.read_csv(avg_data_du145a_p1_file, header=0)\n","\n","  ## DU145a.p2\n","  avg_data_du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_data_export.csv\"\n","  avg_du145a_p2 = pd.read_csv(avg_data_du145a_p2_file, header=0)\n","\n","  ## DU145a.p3\n","  avg_data_du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_data_export.csv\"\n","  avg_du145a_p3 = pd.read_csv(avg_data_du145a_p3_file, header=0)\n","\n","  ## DU145y.n1\n","  avg_data_du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_data_export.csv\"\n","  avg_du145y_n1 = pd.read_csv(avg_data_du145y_n1_file, header=0)"],"metadata":{"id":"mlU83yKsuSHV","executionInfo":{"status":"ok","timestamp":1650964663743,"user_tz":-60,"elapsed":346,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["## All pixel values for each time stamp\n","\n","with tf.device(gpu):   \n","  ## ARV7.n1 \n","  arv7_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n1/ARV7.n1_vsChem_export.csv\"\n","  arv7 = pd.read_csv(arv7_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv7.index = avg_arv7[\"Time Elapsed\"]\n","\n","  ## Yap.n2\n","  yap_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap.n2/yap.n2_vsChem_export.csv\"\n","  yap = pd.read_csv(yap_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap.index = avg_yap[\"Time Elapsed\"]\n","\n","  ## Yap1.n2\n","  yap1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n2/yap1.n2_vsChem_export.csv\"\n","  yap1 = pd.read_csv(yap1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1.index = avg_yap1[\"Time Elapsed\"]\n","\n","  ## Yap1.n1.1\n","  yap1n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/yap1.n1.1/yap1.n1.1_vsChem_export.csv\"\n","  yap1n1 = pd.read_csv(yap1n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  yap1n1.index = avg_yap1n1[\"Time Elapsed\"]\n","\n","  ## ARV7.n2\n","  arv72_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n2/ARV7.n2_vsChem_export.csv\"\n","  arv72 = pd.read_csv(arv72_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv72.index = avg_arv72[\"Time Elapsed\"]\n","\n","  ## ARV7.n3\n","  arv73_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/ARV7.n3/ARV7.n3_vsChem_export.csv\"\n","  arv73 = pd.read_csv(arv73_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  arv73.index = avg_arv73[\"Time Elapsed\"]\n","\n","  ## DU145a.p1\n","  du145a_p1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p1/DU145a.p1_vsChem_export.csv\"\n","  du145a_p1 = pd.read_csv(du145a_p1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p1.index = avg_du145a_p1[\"Time Elapsed\"]\n","\n","  ## DU145a.p2\n","  du145a_p2_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p2/DU145a.p2_vsChem_export.csv\"\n","  du145a_p2 = pd.read_csv(du145a_p2_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p2.index = avg_du145a_p2[\"Time Elapsed\"]\n","\n","  ## DU145a.p3\n","  du145a_p3_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145a.p3/DU145a.p3_vsChem_export.csv\"\n","  du145a_p3 = pd.read_csv(du145a_p3_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145a_p3.index = avg_du145a_p3[\"Time Elapsed\"]\n","\n","  ## DU145y.n1\n","  du145y_n1_file = \"/content/drive/MyDrive/Final-Year-Project/DNANegatives/DU145y.n1/DU145y.n1_vsChem_export.csv\"\n","  du145y_n1 = pd.read_csv(du145y_n1_file, header=None).iloc[:, :(arr_rows*arr_cols)]\n","  du145y_n1.index = avg_du145y_n1[\"Time Elapsed\"]"],"metadata":{"id":"W3_XExOjypwI","executionInfo":{"status":"ok","timestamp":1650964684687,"user_tz":-60,"elapsed":5585,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["#### Partial Covid Data"],"metadata":{"id":"yjXPLEfmRUJH"}},{"cell_type":"code","source":["## 150520_2_118\n","avg_118_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_2_118/exp_summary_118.csv\"\n","exp_118_pos, exp_118_neg = load_partial_covid_exp(avg_118_file)\n","\n","## 150520_4_2_86\n","avg_86_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_4_2_86/exp_summary_86.csv\"\n","exp_86_pos, exp_86_neg = load_partial_covid_exp(avg_86_file)\n","\n","## 150520_5_129\n","avg_129_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/150520_5_129/exp_summary_129.csv\"\n","exp_129_pos, exp_129_neg = load_partial_covid_exp(avg_129_file)\n","\n","## 180520_4_165\n","avg_165_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_4_165/exp_summary_165.csv\"\n","exp_165_pos, exp_165_neg = load_partial_covid_exp(avg_165_file)\n","\n","## 180520_6_35\n","avg_35_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/180520_6_35/exp_summary_35.csv\"\n","exp_35_pos, exp_35_neg = load_partial_covid_exp(avg_35_file)\n","\n","## 190520_1_28\n","avg_28_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_1_28/exp_summary_28.csv\"\n","exp_28_pos, exp_28_neg = load_partial_covid_exp(avg_28_file) \n","\n","## 190520_2_14\n","avg_14_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/190520_2_14/exp_summary_14.csv\"\n","exp_14_pos, exp_14_neg = load_partial_covid_exp(avg_14_file)\n","\n","## 210520_2_40\n","avg_40_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_2_40/exp_summary_40.csv\"\n","exp_40_pos, exp_40_neg = load_partial_covid_exp(avg_40_file)\n","\n","## 210520_3_88\n","avg_88_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_3_88/exp_summary_88.csv\"\n","exp_88_pos, exp_88_neg = load_partial_covid_exp(avg_88_file)\n","\n","## 210520_6_27\n","avg_27_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/210520_6_27/exp_summary_27.csv\"\n","exp_27_pos, exp_27_neg = load_partial_covid_exp(avg_27_file)\n","\n","## 250520_1_134\n","avg_134_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_1_134/exp_summary_134.csv\"\n","exp_134_pos, exp_134_neg = load_partial_covid_exp(avg_134_file)\n","\n","## 250520_2_97\n","avg_97_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_2_97/exp_summary_97.csv\"\n","exp_97_pos, exp_97_neg = load_partial_covid_exp(avg_97_file)\n","\n","## 250520_6_2D1\n","avg_2d1_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_6_2D1/exp_summary_2D1.csv\"\n","exp_2d1_pos, exp_2d1_neg = load_partial_covid_exp(avg_2d1_file)\n","\n","## 250520_7_64\n","avg_64_file = \"/content/drive/MyDrive/Final-Year-Project/COVIDPartialData/250520_7_64/exp_summary_64.csv\"\n","exp_64_pos, exp_64_neg = load_partial_covid_exp(avg_64_file)"],"metadata":{"id":"ORRtMFfEZBwV","executionInfo":{"status":"ok","timestamp":1650964689006,"user_tz":-60,"elapsed":3229,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"7XgnkewwwPki"}},{"cell_type":"markdown","source":["#### Positive Samples"],"metadata":{"id":"CTcUwvRiwUmJ"}},{"cell_type":"code","source":["g1 = preprocess_data(g1, 500)\n","g2 = preprocess_data(g2, 500)\n","g3 = preprocess_data(g3, 500)\n","g5 = preprocess_data(g5, 500)\n","rv1_ap1 = preprocess_data(rv1_ap1, 500)\n","rv1_ap2 = preprocess_data(rv1_ap2, 500)\n","rv1y_p1 = preprocess_data(rv1y_p1, 500)\n","rv1y_p3 = preprocess_data(rv1y_p3, 500)\n","rv1y_p4 = preprocess_data(rv1y_p4, 500)\n","arv7_p1 = preprocess_data(arv7_p1, 500)\n","arv7_p3 = preprocess_data(arv7_p3, 500)\n","arv7_p4 = preprocess_data(arv7_p4, 500)\n","b1 = preprocess_data(b1, 500)\n","b2 = preprocess_data(b2, 500)\n","b5 = preprocess_data(b5, 500)"],"metadata":{"id":"1-WlDoK49D2Y","executionInfo":{"status":"ok","timestamp":1650964701561,"user_tz":-60,"elapsed":2067,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["#### Negative Samples"],"metadata":{"id":"1WaPBFGuwYN4"}},{"cell_type":"code","source":["arv7 = preprocess_data(arv7, 500)\n","yap = preprocess_data(yap, 500)\n","yap1 = preprocess_data(yap1, 500)\n","yap1n1 = preprocess_data(yap1n1, 500)\n","arv72 = preprocess_data(arv72, 500)\n","arv73 = preprocess_data(arv73, 500)\n","du145y_n1 = preprocess_data(du145y_n1, 500)\n","du145a_p1 = preprocess_data(du145a_p1, 500)\n","du145a_p2 = preprocess_data(du145a_p2, 500)\n","du145a_p3 = preprocess_data(du145a_p3, 500)"],"metadata":{"id":"gazhgzLT9HLV","executionInfo":{"status":"ok","timestamp":1650964707054,"user_tz":-60,"elapsed":1001,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["#### Covid Partial Data"],"metadata":{"id":"nUwBPNQNjQ7w"}},{"cell_type":"code","source":["exp_118_pos = preprocess_partial_data(exp_118_pos, 500)\n","exp_86_pos = preprocess_partial_data(exp_86_pos, 500)\n","exp_129_pos = preprocess_partial_data(exp_129_pos, 500)\n","exp_165_pos = preprocess_partial_data(exp_165_pos, 500)\n","exp_35_pos = preprocess_partial_data(exp_35_pos, 500)\n","exp_28_pos = preprocess_partial_data(exp_28_pos, 500)\n","exp_14_pos = preprocess_partial_data(exp_14_pos, 500)\n","exp_40_pos = preprocess_partial_data(exp_40_pos, 500)\n","exp_88_pos = preprocess_partial_data(exp_88_pos, 500)\n","exp_27_pos = preprocess_partial_data(exp_27_pos, 500)\n","exp_134_pos = preprocess_partial_data(exp_134_pos, 500)\n","exp_97_pos = preprocess_partial_data(exp_97_pos, 500)\n","exp_2d1_pos = preprocess_partial_data(exp_2d1_pos, 500)\n","exp_64_pos = preprocess_partial_data(exp_64_pos, 500)"],"metadata":{"id":"HQBQ_1YF9Oqj","executionInfo":{"status":"ok","timestamp":1650964711711,"user_tz":-60,"elapsed":1127,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["exp_118_neg = preprocess_partial_data(exp_118_neg, 500)\n","exp_86_neg = preprocess_partial_data(exp_86_neg, 500)\n","exp_129_neg = preprocess_partial_data(exp_129_neg, 500)\n","exp_165_neg = preprocess_partial_data(exp_165_neg, 500)\n","exp_35_neg = preprocess_partial_data(exp_35_neg, 500)\n","exp_28_neg = preprocess_partial_data(exp_28_neg, 500)\n","exp_14_neg = preprocess_partial_data(exp_14_neg, 500)\n","exp_40_neg = preprocess_partial_data(exp_40_neg, 500)\n","exp_88_neg = preprocess_partial_data(exp_88_neg, 500)\n","exp_27_neg = preprocess_partial_data(exp_27_neg, 500)\n","exp_134_neg = preprocess_partial_data(exp_134_neg, 500)\n","exp_97_neg = preprocess_partial_data(exp_97_neg, 500)\n","exp_2d1_neg = preprocess_partial_data(exp_2d1_neg, 500)\n","exp_64_neg = preprocess_partial_data(exp_64_neg, 500)"],"metadata":{"id":"sYsOnsAW9Rob","executionInfo":{"status":"ok","timestamp":1650964714460,"user_tz":-60,"elapsed":1702,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - Neural Network Ensemble"],"metadata":{"id":"cco-BOwij9af"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"j5qgb5mx3rOW"}},{"cell_type":"code","source":["def get_training_data(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"OIYXEisg2WX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_test_data(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"xH5J1l0cgIHI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"d6Qyl80Wzy-r"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,\n","             \"arv7_p3\":arv7_p3,\n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7,  \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3}"],"metadata":{"id":"d-bA8RfjcM35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Model Specs"],"metadata":{"id":"rxkmk6GHqC7g"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_classifiers = 50\n","\n","timestep = int(number_of_samples/number_of_classifiers)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]\n","\n","batch_size = 3\n","epochs = 10\n","loss_function = 'binary_crossentropy'\n","optimiser = 'adam'"],"metadata":{"id":"eztwFZUaloVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBcYHOw_BU4E","executionInfo":{"status":"ok","timestamp":1650888347765,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"62652afd-35c9-48f8-c037-b58efe79e12c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Creating Ensemble"],"metadata":{"id":"qG3eDbNkqG9A"}},{"cell_type":"code","source":["def create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples):\n","\n","  neural_nets = [0]*number_of_classifiers\n","\n","  for i in range(number_of_classifiers):\n","\n","    # print(f\"============================================== Neural Network {i} ============================================\")\n","\n","    ## make model \n","    neural_nets[i] = Sequential()\n","    neural_nets[i].add(Dense(16, activation='relu', input_dim = timestamps[i]))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(32, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(64, activation='relu'))\n","    neural_nets[i].add(Dense(1, activation='sigmoid'))\n","\n","    ## compile model \n","    neural_nets[i].compile(loss=loss_function, optimizer=optimiser, metrics=['accuracy'])\n","\n","    ## model summary\n","    # neural_nets[i].summary()\n","\n","    ## training data\n","    training_data, training_label = get_training_data(positive_samples=positives, negative_samples=negatives, timestamp=timestamps[i], test_samples=[test_samples])\n","\n","    ## train model\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n","    neural_nets[i].fit(training_data, training_label,  batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[callback], verbose=0)\n","\n","    # print(\"\\n\\n\")\n","\n","  return neural_nets"],"metadata":{"id":"GVVPVw4-ndtu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Evaluating Ensemble"],"metadata":{"id":"fGH97jNBfzdu"}},{"cell_type":"code","source":["def get_prediction(ensemble, timestamps, test_sample):\n","  predictions = []\n","\n","  for i in range(number_of_classifiers):\n","    test_data = get_test_data(test_sample, timestamps[i])\n","    prediction = ensemble[i].predict(test_data)\n","    predictions.append(prediction[0][0])\n","\n","  predictions = [int(i >= 0.5) for i in predictions]\n","  classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","\n","  return classification"],"metadata":{"id":"HslDzCxe1PaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with tule label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"TCTzCBpU0S8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  final_classifications = {}\n","\n","  ## use ensemble to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Testing sample: {test_sample_name}...\")\n","\n","    en = create_ensemble(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_sample_name)\n","    classification = get_prediction(en, timestamps, test_sample)\n","    \n","    \n","    final_classifications[key] = (classification, true_label_dict[key])\n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"HlIwk3By0Zqi","colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"status":"error","timestamp":1650888354674,"user_tz":-60,"elapsed":6919,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2e248431-2ec4-4c7b-e50c-96b007673ba4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample: exp_118_pos...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'sequential_1/dense_7/BiasAdd/ReadVariableOp/resource' has no attr named '_class'.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-5086e332c720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing sample: {test_sample_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0men\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-83e0a485fc39>\u001b[0m in \u001b[0;36mcreate_ensemble\u001b[0;34m(number_of_classifiers, batch_size, epochs, loss_function, optimiser, timestamps, test_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m## train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mneural_nets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# print(\"\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    530\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m    531\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_compute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    673\u001b[0m           \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m           \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m               var.op.name):\n\u001b[1;32m    716\u001b[0m             update_op = distribution.extended.update(\n\u001b[0;32m--> 717\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False)\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_cross_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m               \u001b[0;31m# In cross-replica context, extended.update returns a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n\u001b[0;32m-> 2633\u001b[0;31m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[0m\u001b[1;32m   2634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2509\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3101\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3102\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3108\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3109\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3110\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2509\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2628\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2629\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m       return self._replica_ctx_update(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3701\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3702\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3709\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3710\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    174\u001b[0m           \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m           \u001b[0;34m'Please pass these args as kwargs instead.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1447\u001b[0m                              \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m                              \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m                              use_nesterov=use_nesterov, name=name)\n\u001b[0m\u001b[1;32m   1450\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0mResourceApplyAdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_ops.ResourceApplyAdam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_apply_adam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[1;32m   1655\u001b[0m                            \"building a function.\")\n\u001b[0;32m-> 1656\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;31m# Large EagerTensors and resources are captured with Placeholder ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m       placeholder = _create_substitute_placeholder(\n\u001b[0;32m--> 765\u001b[0;31m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0m\u001b[1;32m    766\u001b[0m       \u001b[0;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0;31m# This attribute would be propogated into the arg_attr of the FunctionDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     placeholder = graph_placeholder(\n\u001b[0;32m-> 1306\u001b[0;31m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   1307\u001b[0m   \u001b[0mhandle_data_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       attrs=attrs, name=name)\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3785\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3872\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcolocation_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3874\u001b[0;31m           \u001b[0mall_colocation_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3876\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocation_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \u001b[0mdefault_colocation_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc:@%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m       \u001b[0mclass_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m       \u001b[0;31m# This op has no explicit colocation group, so it is itself its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["final_classifications"],"metadata":{"id":"4AuD_rrC2yYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"id":"mhkc8Lnr9-c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"WCjSN-dLz9Mq"}},{"cell_type":"code","source":["# ## checking the timestap where majority of classifiers agree\n","\n","# from collections import defaultdict\n","\n","# def get_timestamp(timestamps, predictions):\n","\n","#   ## create dict to hold count of predictions\n","#   label_counters = defaultdict(int)\n","\n","#   ## add entries to dict\n","#   for index, pred in enumerate(predictions):\n","#     label_counters[pred] += 1\n","\n","#     ## if label count == half of total possible predictions then majority is achieved\n","#     if(label_counters[pred] == int(len(predictions)/2)+1):\n","#       return timestamps[index], index\n","  \n","#   return -1, -1\n"],"metadata":{"id":"3r69Gbpd99So"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Timestamp where majority aggement is reached: {timestamp_final}\")\n","# print(f\"Index of final time stamp in array : {pred_index}\")"],"metadata":{"id":"ghvOJ4Ot_fRB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Save Ensemble"],"metadata":{"id":"PppLDxSdv5Uk"}},{"cell_type":"code","source":["# !pwd"],"metadata":{"id":"jAJAZJtKv816"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G1Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G2Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G3Test\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/G5Test"],"metadata":{"id":"UgtDxJjmxHQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## File paths to save models - uncomment as needed\n","\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/ARV7Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAPTest/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1Test/\n","# %cd /content/drive/MyDrive/Final-Year-Project/EnsembleModels50/YAP1N1Test/"],"metadata":{"id":"bwBDVrvMRsO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for i in range(number_of_classifiers):\n","#   filename = f\"ensemble-model-{i}.h5\"\n","#   neural_nets[i].save(filename)\n","\n","#   print(f\"Saved {filename}\")"],"metadata":{"id":"ZGXuLcuXx99S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Machine Learning - KNN Ensemble"],"metadata":{"id":"GvAKajynLNa9"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"H8ueQFk24bbg"}},{"cell_type":"code","source":["def get_training_data_knn(positive_samples, negative_samples, timestamp, test_samples=[]):\n","  \n","  training_data = []\n","  pos_count = 0\n","  neg_count = 0\n","\n","  ## iterate postive samples dict\n","  for key, sample in positive_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    pos_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(pos_subsample)\n","    pos_count += 1\n","\n","  ## iterate negative samples dict\n","  for key, sample in negative_samples.items():\n","\n","    ## if dataset is test data do not add to training set\n","    if(key in test_samples):\n","      continue\n","\n","    ## truncate sample to length t = timestamp\n","    neg_subsample = sample['Average Output'].to_numpy()[0:timestamp]\n","\n","    ## append subsample of length t to training data\n","    training_data.append(neg_subsample)\n","    neg_count += 1\n","\n","  ## create positive and negative (1 and 0) label based on sample \n","  pos_labels = np.ones(pos_count)\n","  neg_labels = np.zeros(neg_count)\n","\n","  ## concatenate labels for final training labels\n","  training_labels = np.concatenate((pos_labels, neg_labels), axis=0)\n","\n","  return np.asarray(training_data), training_labels ## np.asarry() converts list to 2D np array"],"metadata":{"id":"x4q6d44BLwpQ","executionInfo":{"status":"ok","timestamp":1650965362180,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["def get_test_data_knn(sample, timestamp):\n","  subsample = []\n","  subsample.append(sample['Average Output'].to_numpy()[0:timestamp])\n","\n","  return np.asarray(subsample)"],"metadata":{"id":"GZOfy-0GQuGA","executionInfo":{"status":"ok","timestamp":1650965364107,"user_tz":-60,"elapsed":12,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["def get_time_index(timestamps, predictions):\n","\n","  ## create dict to hold count of predictions\n","  label_counters = defaultdict(int)\n","\n","  ## add entries to dict\n","  for index, pred in enumerate(predictions):\n","    label_counters[pred] += 1\n","\n","    ## if label count == half of total possible predictions then majority is achieved\n","    if(label_counters[pred] == int(len(predictions)/2)+1):\n","      return timestamps[index]\n","  \n","  return -1"],"metadata":{"id":"2hib6StpHWbU","executionInfo":{"status":"ok","timestamp":1650965365934,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":["#### Training Data"],"metadata":{"id":"FOMhNuiKNGAw"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             #\"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"-prfZYD_VgMB","executionInfo":{"status":"ok","timestamp":1650966387195,"user_tz":-60,"elapsed":379,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":151,"outputs":[]},{"cell_type":"markdown","source":["#### Timestamps"],"metadata":{"id":"Ry9pqKjnNKiI"}},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"3cDeyMc3M_bN","executionInfo":{"status":"ok","timestamp":1650966389187,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIjHUplVOmH3","executionInfo":{"status":"ok","timestamp":1650966392173,"user_tz":-60,"elapsed":32,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"8dc6d012-ca91-4650-cd95-02b56bc71152"},"execution_count":153,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"markdown","source":["#### Model"],"metadata":{"id":"DJBWoo1SNMy3"}},{"cell_type":"code","source":["def KNN(k, test_sample, train_data, train_labels, distance_metric):\n","  test = np.tile(test_sample, (len(train_data),1)) # repeat test sample and stack vertically\n","  \n","  distances = None\n","\n","  if(distance_metric.lower() == 'manhattan' or distance_metric.lower() == 'cityblock'):\n","    distances = manhattan_distances(test, train_data).diagonal() # get pair wise manhattan distance for every row\n","  elif(distance_metric.lower() == 'euclidean'):\n","    distances = euclidean_distances(test, train_data).diagonal() # get pair wise euclidean distance for every row \n","  elif(distance_metric.lower() == 'cosine'):\n","    distances = cosine_distances(test, train_data).diagonal() # get pair wise cosine distance for every row \n","\n","  min_indexes = np.argsort(distances)[:k] # get k smallest indexes\n","\n","  knn_labels = list(train_labels[min_indexes]) # get k predictions\n","  final_pred = max(set(knn_labels), key=knn_labels.count)\n","\n","  return final_pred"],"metadata":{"id":"sGJZphgaLeL0","executionInfo":{"status":"ok","timestamp":1650966392564,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":154,"outputs":[]},{"cell_type":"markdown","source":["#### Model Predictions"],"metadata":{"id":"0C0XQKFHFtFV"}},{"cell_type":"markdown","source":["##### Held-out Test Set"],"metadata":{"id":"Vf8LAE4Qbxls"}},{"cell_type":"code","source":["# test_samples = {\"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \"exp_27_neg\":exp_27_neg,\"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg,\n","#                 \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \"g1\":g1, \"exp_86_pos\":exp_86_pos, \"rv1_ap1\":rv1_ap1,\"b5\":b5, \"exp_28_pos\":exp_28_pos}\n","# test_sample_keys = keys = list(test_samples.keys())\n","# test_labels = list(np.concatenate((np.ones(7),np.zeros(7))))\n","# test_label_dict = dict(zip(test_sample_keys, test_labels))"],"metadata":{"id":"AxaTjkExYX9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import time\n","# with tf.device(gpu):\n","\n","#   final_classifications = {}\n","\n","#   ## use KNN to evaluate the prediction for each of the samples individually\n","#   for key, value in test_samples.items():\n","#     test_sample_name = key\n","#     test_sample = value\n","\n","#     predictions = []\n","#     for t in timestamps:\n","#       train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=test_sample_keys)\n","#       test_data = get_test_data_knn(test_sample, t)\n","#       pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","#       predictions.append(pred)\n","    \n","#     print(f\"Testing sample {test_sample_name}\")\n","\n","#     time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","#     time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","#     classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","#     final_classifications[key] = (classification, true_label_dict[key])\n","  \n","#     print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","#     if(classification == 1.0):\n","#       print(f\"TTP: {time_to_result}s\")\n","\n","#     print(\"\")"],"metadata":{"id":"PVYWffD2Z5q6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(f\"Accuracy: {accuracy(final_classifications)}\")\n","# print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","# print(f\"Specificity: {specificity(final_classifications)}\")\n","# print(f\"Precision: {precision(final_classifications)}\")\n","# print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uV2qejqoblws","executionInfo":{"status":"ok","timestamp":1650617030081,"user_tz":-60,"elapsed":28,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2ec93859-5dee-4192-acbc-3cd201ad7bf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 78.57142857142857\n","Sensitivity/Recall: 71.42857142857143\n","Specificity: 85.71428571428571\n","Precision: 83.33333333333334\n","F1 Score: 76.92307692307693\n"]}]},{"cell_type":"markdown","source":["##### Cross Validation"],"metadata":{"id":"DuKAj66EbskM"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             #\"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"RGVdwT8rxS23","executionInfo":{"status":"ok","timestamp":1650966397897,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":155,"outputs":[]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels))"],"metadata":{"id":"SUDmHpF-GigC","executionInfo":{"status":"ok","timestamp":1650966399985,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":156,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    print(f\"Testing sample {test_sample_name}\")\n","\n","    time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","    time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","    classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","    final_classifications[key] = (classification, true_label_dict[key])\n","  \n","    print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")\n","\n","    if(classification == 1.0):\n","      print(f\"TTP: {time_to_result}s\")\n","\n","    print(\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rptrj0arSjSR","executionInfo":{"status":"ok","timestamp":1650966403522,"user_tz":-60,"elapsed":2845,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"bdaa62d4-aa6d-41af-a304-b393dd2d013b"},"execution_count":157,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing sample exp_118_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_86_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 628.0s\n","\n","Testing sample exp_129_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 690.0s\n","\n","Testing sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 1065.0s\n","\n","Testing sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 945.0s\n","\n","Testing sample exp_14_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_40_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 591.0s\n","\n","Testing sample exp_27_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 577s\n","\n","Testing sample exp_97_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_2d1_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample exp_64_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 572.0s\n","\n","Testing sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 582.0s\n","\n","Testing sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 599.0s\n","\n","Testing sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 575.0s\n","\n","Testing sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 614.0s\n","\n","Testing sample rv1_ap2\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 660.0s\n","\n","Testing sample rv1y_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 835.0s\n","\n","Testing sample rv1y_p4\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Testing sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 622.0s\n","\n","Testing sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 999.0s\n","\n","Testing sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 557.0s\n","\n","Testing sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 575.0s\n","\n","Testing sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","TTP: 570.0s\n","\n","Testing sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_86_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_129_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_165_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_35_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_14_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_40_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 975s\n","\n","Testing sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_97_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 567s\n","\n","Testing sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 576.0s\n","\n","Testing sample yap1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample yap1n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","TTP: 684.0s\n","\n","Testing sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample du145y_n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Testing sample arv7\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n"]}]},{"cell_type":"code","source":["print(f\"Accuracy: {accuracy(final_classifications)}\")\n","print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","print(f\"Specificity: {specificity(final_classifications)}\")\n","print(f\"Precision: {precision(final_classifications)}\")\n","print(f\"F1 Score: {f1(final_classifications)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SilNigCLya5","executionInfo":{"status":"ok","timestamp":1650966403523,"user_tz":-60,"elapsed":23,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"970ddc36-ff85-406f-f768-f6719ec45c95"},"execution_count":158,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7142857142857143\n","Sensitivity/Recall: 0.6428571428571429\n","Specificity: 0.8095238095238095\n","Precision: 0.8181818181818182\n","F1 Score: 0.7200000000000001\n"]}]},{"cell_type":"markdown","source":["#### Elbow Plot"],"metadata":{"id":"DgvFMAGtSbpy"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             #\"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"i1xQt-8FxVXG","executionInfo":{"status":"ok","timestamp":1650966425787,"user_tz":-60,"elapsed":642,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":159,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","  accuracies = []\n","  for k in range(1,30):\n","    final_classifications = {}\n","\n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      predictions = []\n","      for t in timestamps:\n","        train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","        test_data = get_test_data_knn(test_sample, t)\n","        pred = KNN(k, test_data, train_data, train_labels, 'cosine')\n","        predictions.append(pred)\n","      \n","      time_index = get_time_index(timestamps, predictions) # get the value of the sample at which the sample needs to be indexed\n","      \n","      classification = Counter(predictions).most_common(1)[0][0] # final prediction\n","      final_classifications[key] = (classification, true_label_dict[key])\n","\n","    acc = accuracy(final_classifications)\n","    accuracies.append(acc)\n","    print(f\"K: {k} \\t Accuracy: {acc}\")\n","    # print(f\"Predicted Label: {classification} \\t True Label: {true_label_dict[key]} \\t Correct?: {classification == true_label_dict[key]}\")"],"metadata":{"id":"WwBbkDraFWF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650966514202,"user_tz":-60,"elapsed":88053,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"f0062b80-f45a-46b6-d744-babae2744155"},"execution_count":160,"outputs":[{"output_type":"stream","name":"stdout","text":["K: 1 \t Accuracy: 0.6530612244897959\n","K: 2 \t Accuracy: 0.673469387755102\n","K: 3 \t Accuracy: 0.7142857142857143\n","K: 4 \t Accuracy: 0.6530612244897959\n","K: 5 \t Accuracy: 0.6326530612244898\n","K: 6 \t Accuracy: 0.6122448979591837\n","K: 7 \t Accuracy: 0.6122448979591837\n","K: 8 \t Accuracy: 0.5714285714285714\n","K: 9 \t Accuracy: 0.5714285714285714\n","K: 10 \t Accuracy: 0.5510204081632653\n","K: 11 \t Accuracy: 0.5306122448979592\n","K: 12 \t Accuracy: 0.5510204081632653\n","K: 13 \t Accuracy: 0.5102040816326531\n","K: 14 \t Accuracy: 0.5102040816326531\n","K: 15 \t Accuracy: 0.4489795918367347\n","K: 16 \t Accuracy: 0.4897959183673469\n","K: 17 \t Accuracy: 0.4897959183673469\n","K: 18 \t Accuracy: 0.5306122448979592\n","K: 19 \t Accuracy: 0.4489795918367347\n","K: 20 \t Accuracy: 0.5306122448979592\n","K: 21 \t Accuracy: 0.40816326530612246\n","K: 22 \t Accuracy: 0.46938775510204084\n","K: 23 \t Accuracy: 0.3877551020408163\n","K: 24 \t Accuracy: 0.46938775510204084\n","K: 25 \t Accuracy: 0.30612244897959184\n","K: 26 \t Accuracy: 0.3469387755102041\n","K: 27 \t Accuracy: 0.40816326530612246\n","K: 28 \t Accuracy: 0.46938775510204084\n","K: 29 \t Accuracy: 0.4489795918367347\n"]}]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = np.arange(1,30)\n","y = accuracies\n","axes.set_xlabel(\"K\")\n","axes.set_ylabel(\"Accuracy (%)\")\n","axes.plot(x,y)"],"metadata":{"id":"P8t0E1pS9YNL","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"ok","timestamp":1650966556872,"user_tz":-60,"elapsed":386,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"874fb5d2-17bc-472e-8d54-ac175e67c839"},"execution_count":162,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f4bee3e3ad0>]"]},"metadata":{},"execution_count":162},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Confidence "],"metadata":{"id":"qXrQKuQm8ery"}},{"cell_type":"markdown","source":["#### Helper Functions"],"metadata":{"id":"oZRyLyYo7k36"}},{"cell_type":"code","source":["def get_rH_00(true_vals, classifier_outputs):\n","  correct_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 0)):\n","      correct_pred_0 += 1\n","\n","  return correct_pred_0/total_pred_0\n","\n","\n","def get_rH_01(true_vals, classifier_outputs):\n","  wrong_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 0)):\n","      wrong_pred_1 += 1\n","    \n","  return wrong_pred_1/total_pred_1\n","\n","def get_rH_10(true_vals, classifier_outputs):\n","  wrong_pred_0 = 0\n","  total_pred_0 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 0):\n","      total_pred_0 += 1\n","    if(int(pred) == 0 and int(true_vals[idx] == 1)):\n","      wrong_pred_0 += 1\n","  \n","  return wrong_pred_0/total_pred_0\n","\n","def get_rH_11(true_vals, classifier_outputs):\n","  correct_pred_1 = 0\n","  total_pred_1 = 0\n","\n","  for idx, pred in enumerate(classifier_outputs):\n","    if(int(pred) == 1):\n","      total_pred_1 += 1\n","    if(int(pred) == 1 and int(true_vals[idx] == 1)):\n","      correct_pred_1 += 1\n","\n","  return correct_pred_1/total_pred_1"],"metadata":{"id":"6IQ6mN5uJ6z1","executionInfo":{"status":"ok","timestamp":1650964966455,"user_tz":-60,"elapsed":414,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["def get_confidence_multipliers(sample_predictions, true_labels):\n","\n","  sample_predictions = np.asarray(sample_predictions) # array of all predictions made by every classifer for all samples\n","\n","  #2d array of all possible multipliers for each classifier\n","  multipliers_final = []\n","\n","  # generate 4 multipliers for each classifier\n","  for classifier in range(len(sample_predictions[0])):\n","    classifier_output = sample_predictions[:, classifier]\n","    # print(len(classifier_output), len(true_labels))\n","    rH_00 = get_rH_00(true_labels, classifier_output)\n","    rH_01 = get_rH_01(true_labels, classifier_output)\n","    rH_10 = get_rH_10(true_labels, classifier_output)\n","    rH_11 = get_rH_11(true_labels, classifier_output)\n","    multipliers_classfier = [rH_00, rH_01, rH_10, rH_11] \n","\n","    # add multipliers to 2d array\n","    multipliers_final.append(multipliers_classfier)\n","\n","  return multipliers_final"],"metadata":{"id":"5r-wTh3nlga0","executionInfo":{"status":"ok","timestamp":1650964967170,"user_tz":-60,"elapsed":3,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["def get_confidence(preds, multipliers):\n","  \n","  # initialise variable\n","  confidence = 1\n","\n","  # the prediction for which the confidence is being calculated -- predication at time t by classifier Ht (most recent prediction)\n","  pred_t = preds[-1]\n","\n","  for idx , pred in enumerate(preds):\n","    # prediction at time k made by classifier Hk\n","    pred_k = pred\n","\n","    # array of multipliers for Hk \n","    multiplier_k = multipliers[idx]\n","\n","    if(pred_t == 0 and pred_k == 0):\n","        confidence*=(1-multiplier_k[0])\n","    elif(pred_t == 0 and pred_k == 1):\n","        confidence*=(1-multiplier_k[1])\n","    elif(pred_t == 1 and pred_k == 0):\n","        confidence*=(1-multiplier_k[2])  \n","    elif(pred_t == 1 and pred_k == 1):\n","        confidence*=(1-multiplier_k[3])\n","        \n","        \n","\n","  confidence = 1 - confidence\n","\n","  return confidence\n","  "],"metadata":{"id":"8SmPp5iDzHQJ","executionInfo":{"status":"ok","timestamp":1650964967589,"user_tz":-60,"elapsed":5,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["def generate_predictions_table(positives, negatives, timestamps):\n","\n","  sample_predictions = []\n","\n","  true_labels = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","\n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    predictions = []\n","    for t in timestamps:\n","      train_data, train_labels = get_training_data_knn(positive_samples=positives, negative_samples=negatives, timestamp=t, test_samples=[test_sample_name])\n","      test_data = get_test_data_knn(test_sample, t)\n","      pred = KNN(3, test_data, train_data, train_labels, 'cosine')\n","      predictions.append(pred)\n","    \n","    sample_predictions.append(predictions)\n","\n","  return sample_predictions, true_labels"],"metadata":{"id":"Qfe-e7-84_Zc","executionInfo":{"status":"ok","timestamp":1650964967920,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":["#### Random Threshold Testing"],"metadata":{"id":"bwcY82bSq0t6"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             #\"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"bZnftjyQxXcw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"asGaVch58nEo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650888392126,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2484fcc9-26b8-419b-c945-8d9345ac5569","id":"YF_lFeGo8nE2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"68OVHXKmw-Hg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","  \n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","      if(100*c > 99 ): # 99% confidence threshold\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","        if(pred == 1.0):\n","          print(f\"Earliness:  {time_index/timestamps[-1]}\")\n","          print(f\"TTP: {time_to_result}s\")\n","          ttps.append(time_to_result+30) # 30 second delay from reaction start when preprocessing\n","          earliness.append(time_index/timestamps[-1])\n","        break\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxnI-jcElWhV","executionInfo":{"status":"ok","timestamp":1650902042293,"user_tz":-60,"elapsed":5339,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"f574518f-297d-473b-9911-1ca2bf1ece96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 107.0s\n","\n","Sample exp_86_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 133.0s\n","\n","Sample exp_129_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 126.0s\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 131.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 135.0s\n","\n","Sample exp_28_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 112.0s\n","\n","Sample exp_14_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_40_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 111.0s\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 110.0s\n","\n","Sample exp_27_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 110.0s\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 131s\n","\n","Sample exp_97_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 127.0s\n","\n","Sample exp_2d1_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 106.0s\n","\n","Sample exp_64_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 107.0s\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 109.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 110.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 114.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 111.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 109.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 133.0s\n","\n","Sample du145a_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 110.0s\n","\n","Sample du145a_p2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 112.0s\n","\n","Sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 124.0s\n","\n","Sample rv1y_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample rv1y_p4\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 114.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.12\n","TTP: 194.0s\n","\n","Sample du145a_p3\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 105.0s\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 108.0s\n","\n","Sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.1\n","TTP: 108.0s\n","\n","Sample exp_118_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 110s\n","\n","Sample exp_86_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_129_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_165_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 113s\n","\n","Sample exp_35_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 116s\n","\n","Sample exp_28_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 120s\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 120s\n","\n","Sample exp_40_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_88_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_27_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.14\n","TTP: 158s\n","\n","Sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_97_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_2d1_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 108s\n","\n","Sample exp_64_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 110s\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 116.0s\n","\n","Sample yap1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample yap1n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 107.0s\n","\n","Sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv73\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.12\n","TTP: 130.0s\n","\n","Sample du145y_n1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 112.0s\n","\n","Sample arv7\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.1\n","TTP: 113.0s\n","\n","Accuracy: 67.3076923076923\n","Sensitivity/Recall: 87.09677419354838\n","Specificity: 38.095238095238095\n","Precision: 67.5\n","F1 Score: 76.05633802816901\n"]}]},{"cell_type":"markdown","source":["#### Learning best threshold"],"metadata":{"id":"KPuLuWoixCSR"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"executionInfo":{"status":"ok","timestamp":1650971233027,"user_tz":-60,"elapsed":1110,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"kwJtWthYxbQm"},"execution_count":294,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1650971233321,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"lqKHvOd_xMJX"},"execution_count":295,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650971233637,"user_tz":-60,"elapsed":13,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"4342954b-83b4-43e3-e406-0b823b6f704e","id":"6b0TimumxMJX"},"execution_count":296,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1650971235640,"user_tz":-60,"elapsed":443,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"id":"nXJwTuCQxMJX"},"execution_count":297,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"_m7lA1HIer-y","executionInfo":{"status":"ok","timestamp":1650971242238,"user_tz":-60,"elapsed":3403,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":298,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"yVEuBQRb1BpE","executionInfo":{"status":"ok","timestamp":1650971242240,"user_tz":-60,"elapsed":11,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":299,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are mad of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"rI2uBt6fxLlF","executionInfo":{"status":"ok","timestamp":1650971280747,"user_tz":-60,"elapsed":248,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":300,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTV9vJPW5zUg","executionInfo":{"status":"ok","timestamp":1650971282266,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"2f56556b-46d5-4cf6-cd6a-b64970165ebb"},"execution_count":301,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1184"]},"metadata":{},"execution_count":301}]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # array to hold cost function value for each candidate\n","  cost_function_values = []\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # evaluate every candidate\n","  for th in threshold_candidates:\n","\n","    # alpha\n","    alpha = 0.85\n","\n","    print(f\"Candidate: {th} \")\n","\n","    # array to hold earliness values for the samples \n","    earliness = []  \n","\n","    # dict to hold predictions vs true values for the samples  \n","    final_classifications = {}\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      # get KNN predicition for the sample\n","      predictions = sample_predictions[sample_idx]\n","\n","      for i in range(len(predictions)):\n","\n","        # get the confidence for that prediction \n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","        if(c > th): # check if confidence is above confidence threshold\n","\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          # predicted class for the sample is given by the prediction which led to the gien confidence value\n","          pred = predictions[i]\n","\n","          # update final outcomes dict\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","          # add to earliness array\n","          earliness.append(time_index/timestamps[-1])\n","      \n","      sample_idx += 1\n","\n","    # get avg accuracy and avg earliness for this threshold\n","    if(len(final_classifications) > 0):\n","      avg_accuracy = accuracy(final_classifications)\n","      avg_earliness = sum(earliness)/len(earliness)\n","\n","      # compute value of cost function and add to array \n","      cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","      cost_function_values.append(cf_score)\n","      print(f\"Score: {cf_score}\")\n","      print(\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKc1S0R6ebff","executionInfo":{"status":"ok","timestamp":1650971389997,"user_tz":-60,"elapsed":88904,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"790c53ee-60ea-416e-bd20-4f73231ec1dd"},"execution_count":302,"outputs":[{"output_type":"stream","name":"stdout","text":["Candidate: 0.4370314842578711 \n","Score: 0.38773291842034574\n","\n","Candidate: 0.5765242378810594 \n","Score: 0.38857692307692315\n","\n","Candidate: 0.7043978010994502 \n","Score: 0.38911784834382707\n","\n","Candidate: 0.7491789819376026 \n","Score: 0.38926155065220047\n","\n","Candidate: 0.7700227267318721 \n","Score: 0.3899593230769232\n","\n","Candidate: 0.7814009661835748 \n","Score: 0.39041267186919376\n","\n","Candidate: 0.8004658385093167 \n","Score: 0.39046975144114565\n","\n","Candidate: 0.8219967397253753 \n","Score: 0.3905890296144535\n","\n","Candidate: 0.846988276215195 \n","Score: 0.39067510489510504\n","\n","Candidate: 0.8691502463054188 \n","Score: 0.39137129272196614\n","\n","Candidate: 0.8829377225648636 \n","Score: 0.3914299243019131\n","\n","Candidate: 0.8964530892448512 \n","Score: 0.391797366426677\n","\n","Candidate: 0.8986979194128378 \n","Score: 0.3918542443587639\n","\n","Candidate: 0.9010093167701863 \n","Score: 0.39191368294534434\n","\n","Candidate: 0.9095354169265113 \n","Score: 0.3920030243531687\n","\n","Candidate: 0.9238328628554993 \n","Score: 0.3920316182993286\n","\n","Candidate: 0.9371863497175629 \n","Score: 0.3920602358086909\n","\n","Candidate: 0.944402605766109 \n","Score: 0.39269584199584223\n","\n","Candidate: 0.9447607478094568 \n","Score: 0.3927542014789208\n","\n","Candidate: 0.9502758660584989 \n","Score: 0.392812658187294\n","\n","Candidate: 0.956719308560122 \n","Score: 0.3928406730769233\n","\n","Candidate: 0.9580039525691699 \n","Score: 0.3928699618430759\n","\n","Candidate: 0.9609166236067026 \n","Score: 0.39295797482984485\n","\n","Candidate: 0.9637585812356979 \n","Score: 0.3932687469762944\n","\n","Candidate: 0.9652169529270453 \n","Score: 0.3932971411977287\n","\n","Candidate: 0.9682346082579434 \n","Score: 0.39335652005425326\n","\n","Candidate: 0.9705460621801051 \n","Score: 0.39338498691564655\n","\n","Candidate: 0.9728678423945922 \n","Score: 0.39341347769877205\n","\n","Candidate: 0.9751113407642529 \n","Score: 0.3935028801656907\n","\n","Candidate: 0.9760243739837136 \n","Score: 0.39353146853146875\n","\n","Candidate: 0.9785500636007047 \n","Score: 0.39358871751668745\n","\n","Candidate: 0.9807155062642703 \n","Score: 0.3936460630431965\n","\n","Candidate: 0.9809177442528736 \n","Score: 0.3942248822605968\n","\n","Candidate: 0.9815727018175971 \n","Score: 0.39428330605564677\n","\n","Candidate: 0.9822028747139588 \n","Score: 0.39431000098241503\n","\n","Candidate: 0.9838640473905662 \n","Score: 0.3943367186476218\n","\n","Candidate: 0.9854488078541375 \n","Score: 0.394363459080332\n","\n","Candidate: 0.9855638586956521 \n","Score: 0.39439277985441695\n","\n","Candidate: 0.9857958695917803 \n","Score: 0.39445149645576294\n","\n","Candidate: 0.9864438666114157 \n","Score: 0.3944796119373587\n","\n","Candidate: 0.9876332930141112 \n","Score: 0.39450390855941697\n","\n","Candidate: 0.9883778079038438 \n","Score: 0.39453078894620996\n","\n","Candidate: 0.9884589165430726 \n","Score: 0.39455769230769255\n","\n","Candidate: 0.988701107937193 \n","Score: 0.39461670066460514\n","\n","Candidate: 0.9889468916924318 \n","Score: 0.39464495902044067\n","\n","Candidate: 0.9890054912683368 \n","Score: 0.3947582346928685\n","\n","Candidate: 0.9891138341778358 \n","Score: 0.39478790077846715\n","\n","Candidate: 0.9900368278032037 \n","Score: 0.3948473093430178\n","\n","Candidate: 0.9909396453089245 \n","Score: 0.39513295755968203\n","\n","Candidate: 0.9911357027078567 \n","Score: 0.39516165787640595\n","\n","Candidate: 0.9918901165405811 \n","Score: 0.39522172238637526\n","\n","Candidate: 0.9926365155450263 \n","Score: 0.3952504982064571\n","\n","Candidate: 0.9932899606939951 \n","Score: 0.3952792988868586\n","\n","Candidate: 0.9938351755198831 \n","Score: 0.3953055315471049\n","\n","Candidate: 0.993869211671089 \n","Score: 0.39533308390701416\n","\n","Candidate: 0.9938848714376161 \n","Score: 0.3953593625232902\n","\n","Candidate: 0.9940060934959284 \n","Score: 0.39538826016043704\n","\n","Candidate: 0.9945357000012006 \n","Score: 0.39544613052603556\n","\n","Candidate: 0.9950368128978315 \n","Score: 0.39547250366617814\n","\n","Candidate: 0.995138628796807 \n","Score: 0.39550020006001835\n","\n","Candidate: 0.99516343432639 \n","Score: 0.39555826797930954\n","\n","Candidate: 0.9952396775580725 \n","Score: 0.3955821314102567\n","\n","Candidate: 0.9954645108520563 \n","Score: 0.3956099235111396\n","\n","Candidate: 0.995751002269148 \n","Score: 0.3956390429726662\n","\n","Candidate: 0.9959109451970444 \n","Score: 0.3961084191399155\n","\n","Candidate: 0.995946016407119 \n","Score: 0.39616755354977806\n","\n","Candidate: 0.996131753592256 \n","Score: 0.39619453148691025\n","\n","Candidate: 0.9963156305641439 \n","Score: 0.3962228477044431\n","\n","Candidate: 0.9966045219561355 \n","Score: 0.39633636118052307\n","\n","Candidate: 0.9969065411490683 \n","Score: 0.3963661193878588\n","\n","Candidate: 0.9969448474908345 \n","Score: 0.3963959037447617\n","\n","Candidate: 0.9969798817696416 \n","Score: 0.39668195396836203\n","\n","Candidate: 0.9971217105263158 \n","Score: 0.3967106979113605\n","\n","Candidate: 0.9973886925780531 \n","Score: 0.3967381421581955\n","\n","Candidate: 0.9975610159558379 \n","Score: 0.39679840848806397\n","\n","Candidate: 0.9976218502423063 \n","Score: 0.3968272547885554\n","\n","Candidate: 0.9976672501809648 \n","Score: 0.3968574540503747\n","\n","Candidate: 0.9977261257763975 \n","Score: 0.3969179328200589\n","\n","Candidate: 0.9977822043874318 \n","Score: 0.39694422480488084\n","\n","Candidate: 0.9977965557101325 \n","Score: 0.3969705400982\n","\n","Candidate: 0.9979087769625854 \n","Score: 0.39699554835408524\n","\n","Candidate: 0.9980227181543293 \n","Score: 0.3970219097672517\n","\n","Candidate: 0.998032591017541 \n","Score: 0.3970496261395066\n","\n","Candidate: 0.9980686339622273 \n","Score: 0.397107798243516\n","\n","Candidate: 0.9981152078847602 \n","Score: 0.3971289230769234\n","\n","Candidate: 0.9982400220067174 \n","Score: 0.39718991240076673\n","\n","Candidate: 0.9983626681959944 \n","Score: 0.39721777754955356\n","\n","Candidate: 0.9983817254118686 \n","Score: 0.39724566751147367\n","\n","Candidate: 0.9983878114421301 \n","Score: 0.39730419580419607\n","\n","Candidate: 0.9984664761499925 \n","Score: 0.3973281491134816\n","\n","Candidate: 0.9986144658398388 \n","Score: 0.39735479997255224\n","\n","Candidate: 0.9987037572080233 \n","Score: 0.397380135928329\n","\n","Candidate: 0.9987246413491268 \n","Score: 0.3974081730769234\n","\n","Candidate: 0.9987362271033815 \n","Score: 0.3975205724508053\n","\n","Candidate: 0.9988185127790112 \n","Score: 0.3975379969024267\n","\n","Candidate: 0.998919881306046 \n","Score: 0.3975567798360997\n","\n","Candidate: 0.9989484921542988 \n","Score: 0.3975863274656381\n","\n","Candidate: 0.998954574458722 \n","Score: 0.397841311566132\n","\n","Candidate: 0.9989863228490188 \n","Score: 0.39786977058029716\n","\n","Candidate: 0.9990186268472907 \n","Score: 0.3983201295986625\n","\n","Candidate: 0.9990598566875413 \n","Score: 0.3983503711965427\n","\n","Candidate: 0.9991305218271701 \n","Score: 0.3983697607922452\n","\n","Candidate: 0.9991701723151583 \n","Score: 0.39839869178440634\n","\n","Candidate: 0.9991785942175673 \n","Score: 0.39842492670668744\n","\n","Candidate: 0.9991836926369249 \n","Score: 0.3984511854464195\n","\n","Candidate: 0.9991869933180115 \n","Score: 0.39847883043387156\n","\n","Candidate: 0.9992255328844148 \n","Score: 0.3984969594240383\n","\n","Candidate: 0.9992618458915703 \n","Score: 0.3985260139860143\n","\n","Candidate: 0.9992642888768393 \n","Score: 0.3985564592297201\n","\n","Candidate: 0.9992778855554062 \n","Score: 0.3985814726674602\n","\n","Candidate: 0.9992926695692396 \n","Score: 0.39860923987255376\n","\n","Candidate: 0.9993084278380298 \n","Score: 0.39863020176544794\n","\n","Candidate: 0.9993372192859151 \n","Score: 0.3986885912628851\n","\n","Candidate: 0.9993803482578886 \n","Score: 0.39871372198253213\n","\n","Candidate: 0.9994115392473302 \n","Score: 0.39877500614401606\n","\n","Candidate: 0.9994285924677324 \n","Score: 0.3988029504741836\n","\n","Candidate: 0.9994425930350814 \n","Score: 0.39886165799465645\n","\n","Candidate: 0.9994445220085237 \n","Score: 0.39889242376279443\n","\n","Candidate: 0.9994529597615124 \n","Score: 0.3989191005700615\n","\n","Candidate: 0.9994856101501457 \n","Score: 0.3989458017954588\n","\n","Candidate: 0.9995229720473453 \n","Score: 0.3989739010989014\n","\n","Candidate: 0.999537685553187 \n","Score: 0.3989910321012019\n","\n","Candidate: 0.9995408708856857 \n","Score: 0.39901917788902236\n","\n","Candidate: 0.999546676221654 \n","Score: 0.39913201949565613\n","\n","Candidate: 0.9995566881002296 \n","Score: 0.39919411057692333\n","\n","Candidate: 0.9995643980052223 \n","Score: 0.399219681697613\n","\n","Candidate: 0.99957330695403 \n","Score: 0.3992328568395728\n","\n","Candidate: 0.9995887254857789 \n","Score: 0.39925156642713044\n","\n","Candidate: 0.9996097274069935 \n","Score: 0.3992799617509565\n","\n","Candidate: 0.9996236468051399 \n","Score: 0.39950806910280134\n","\n","Candidate: 0.9996411786724358 \n","Score: 0.399536701162915\n","\n","Candidate: 0.9996782475620801 \n","Score: 0.3995556464811787\n","\n","Candidate: 0.9996998826332635 \n","Score: 0.39958432705656244\n","\n","Candidate: 0.9997083603023238 \n","Score: 0.3996019230769233\n","\n","Candidate: 0.9997207522883296 \n","Score: 0.39963204118715956\n","\n","Candidate: 0.9997261980725225 \n","Score: 0.3996580166821133\n","\n","Candidate: 0.999730297574001 \n","Score: 0.3996840162619025\n","\n","Candidate: 0.9997334819452313 \n","Score: 0.3997044740973315\n","\n","Candidate: 0.9997354755265329 \n","Score: 0.40016076240434045\n","\n","Candidate: 0.9997371801449123 \n","Score: 0.400188605319914\n","\n","Candidate: 0.9997465369203933 \n","Score: 0.40021927931815754\n","\n","Candidate: 0.9997603874165881 \n","Score: 0.40027790576293176\n","\n","Candidate: 0.9997683902873717 \n","Score: 0.400303046672429\n","\n","Candidate: 0.9997746383524999 \n","Score: 0.4003310214375791\n","\n","Candidate: 0.9997794106550866 \n","Score: 0.40035621079951006\n","\n","Candidate: 0.9997823734327647 \n","Score: 0.4003856431894409\n","\n","Candidate: 0.9997912638486497 \n","Score: 0.4004136960600378\n","\n","Candidate: 0.9998001603985702 \n","Score: 0.40047269772481064\n","\n","Candidate: 0.9998105044080348 \n","Score: 0.400503649239441\n","\n","Candidate: 0.9998199067258482 \n","Score: 0.40051630277617145\n","\n","Candidate: 0.9998213364755795 \n","Score: 0.4005430725832703\n","\n","Candidate: 0.9998251858365632 \n","Score: 0.4005698675736308\n","\n","Candidate: 0.9998287724271062 \n","Score: 0.4005868054298645\n","\n","Candidate: 0.9998299521798835 \n","Score: 0.4006150586701437\n","\n","Candidate: 0.9998313111591157 \n","Score: 0.40072833817126297\n","\n","Candidate: 0.9998363946288995 \n","Score: 0.40075389334591816\n","\n","Candidate: 0.9998453376424136 \n","Score: 0.40081641292104236\n","\n","Candidate: 0.9998549997898556 \n","Score: 0.400847717027774\n","\n","Candidate: 0.999859799230975 \n","Score: 0.40087337697763253\n","\n","Candidate: 0.9998606099278295 \n","Score: 0.4011023146288929\n","\n","Candidate: 0.9998621730045256 \n","Score: 0.4011310541310543\n","\n","Candidate: 0.9998711255436912 \n","Score: 0.40115982093915603\n","\n","Candidate: 0.9998810778866666 \n","Score: 0.4012231427630859\n","\n","Candidate: 0.9998858545658877 \n","Score: 0.4012348678913857\n","\n","Candidate: 0.9998888454197272 \n","Score: 0.4012637388789223\n","\n","Candidate: 0.999893766318773 \n","Score: 0.401281208791209\n","\n","Candidate: 0.999904078112946 \n","Score: 0.40130155385348354\n","\n","Candidate: 0.9999106876329011 \n","Score: 0.40135946957191615\n","\n","Candidate: 0.9999120949101259 \n","Score: 0.40138560628303016\n","\n","Candidate: 0.9999125789798319 \n","Score: 0.40141319992656527\n","\n","Candidate: 0.9999144810186 \n","Score: 0.40143938726030437\n","\n","Candidate: 0.999917407058637 \n","Score: 0.401469899665552\n","\n","Candidate: 0.9999196727055972 \n","Score: 0.4014947051036919\n","\n","Candidate: 0.9999209173143355 \n","Score: 0.4015066217856751\n","\n","Candidate: 0.999921713822576 \n","Score: 0.4019685415740331\n","\n","Candidate: 0.9999228816186284 \n","Score: 0.4019995736793329\n","\n","Candidate: 0.9999240493295045 \n","Score: 0.40202051034789726\n","\n","Candidate: 0.9999250394266876 \n","Score: 0.4020371256818437\n","\n","Candidate: 0.9999257038919279 \n","Score: 0.40209647884708266\n","\n","Candidate: 0.999926876864723 \n","Score: 0.4021146042363436\n","\n","Candidate: 0.9999302406394617 \n","Score: 0.4021428969773583\n","\n","Candidate: 0.9999363784990747 \n","Score: 0.40216251301889616\n","\n","Candidate: 0.999940287930589 \n","Score: 0.4021879535558783\n","\n","Candidate: 0.9999407932811823 \n","Score: 0.40220470623278\n","\n","Candidate: 0.9999418119207559 \n","Score: 0.40223600298007095\n","\n","Candidate: 0.9999428276721853 \n","Score: 0.4022629695885512\n","\n","Candidate: 0.9999432003610988 \n","Score: 0.4022899623401322\n","\n","Candidate: 0.9999433173932946 \n","Score: 0.4023184361710067\n","\n","Candidate: 0.9999443021326279 \n","Score: 0.4024326082081186\n","\n","Candidate: 0.9999478135363614 \n","Score: 0.40246122059758443\n","\n","Candidate: 0.999950950096619 \n","Score: 0.40247235109248747\n","\n","Candidate: 0.9999520881022554 \n","Score: 0.40249809096013495\n","\n","Candidate: 0.999953000613953 \n","Score: 0.4025613361309905\n","\n","Candidate: 0.9999535366426099 \n","Score: 0.4027631400857209\n","\n","Candidate: 0.9999543290645376 \n","Score: 0.40279208200112865\n","\n","Candidate: 0.9999552458632233 \n","Score: 0.4028181168146924\n","\n","Candidate: 0.9999585763809526 \n","Score: 0.40285005083022724\n","\n","Candidate: 0.9999619999968481 \n","Score: 0.40286732464401437\n","\n","Candidate: 0.9999627101669518 \n","Score: 0.4028875551200394\n","\n","Candidate: 0.9999635893928879 \n","Score: 0.4029166289592762\n","\n","Candidate: 0.9999650403225935 \n","Score: 0.40294867393518713\n","\n","Candidate: 0.9999661333293455 \n","Score: 0.4029675020759419\n","\n","Candidate: 0.9999667652368291 \n","Score: 0.4029789849325934\n","\n","Candidate: 0.9999683077206989 \n","Score: 0.4030081607979449\n","\n","Candidate: 0.9999696644629767 \n","Score: 0.4030344169344171\n","\n","Candidate: 0.9999698320255672 \n","Score: 0.40309290930417363\n","\n","Candidate: 0.9999698674285147 \n","Score: 0.40311924591156895\n","\n","Candidate: 0.9999704392763644 \n","Score: 0.4031441313487106\n","\n","Candidate: 0.9999726633151287 \n","Score: 0.40316017430845036\n","\n","Candidate: 0.9999746926182802 \n","Score: 0.4031777116427192\n","\n","Candidate: 0.999975107940674 \n","Score: 0.40319674556213037\n","\n","Candidate: 0.9999758406646226 \n","Score: 0.40325560027336943\n","\n","Candidate: 0.9999767125190042 \n","Score: 0.4032865527065529\n","\n","Candidate: 0.9999770034424784 \n","Score: 0.40331457129826714\n","\n","Candidate: 0.9999775133903392 \n","Score: 0.4033307540210656\n","\n","Candidate: 0.9999780798703213 \n","Score: 0.40379953263867624\n","\n","Candidate: 0.9999784068532159 \n","Score: 0.40383103368977824\n","\n","Candidate: 0.9999786181819836 \n","Score: 0.40385209755349355\n","\n","Candidate: 0.9999788496851438 \n","Score: 0.40387767120659906\n","\n","Candidate: 0.9999791896823536 \n","Score: 0.40389578535237236\n","\n","Candidate: 0.999979450605192 \n","Score: 0.4039139175851609\n","\n","Candidate: 0.9999798309887113 \n","Score: 0.4039305694305696\n","\n","Candidate: 0.9999801314102842 \n","Score: 0.40395773267212565\n","\n","Candidate: 0.9999802562796114 \n","Score: 0.40396842307692327\n","\n","Candidate: 0.9999810811947044 \n","Score: 0.4039956324316006\n","\n","Candidate: 0.9999818615658542 \n","Score: 0.4040243705243707\n","\n","Candidate: 0.9999819577647824 \n","Score: 0.40413961114111585\n","\n","Candidate: 0.9999826306377975 \n","Score: 0.4041654830367828\n","\n","Candidate: 0.9999833824346565 \n","Score: 0.4041913809082486\n","\n","Candidate: 0.9999842867566477 \n","Score: 0.40422333191670223\n","\n","Candidate: 0.9999851259091388 \n","Score: 0.40442672146402\n","\n","Candidate: 0.999985208054301 \n","Score: 0.4044437914581638\n","\n","Candidate: 0.9999855008717964 \n","Score: 0.4044729876581543\n","\n","Candidate: 0.9999859447096207 \n","Score: 0.404502213334369\n","\n","Candidate: 0.999986334501379 \n","Score: 0.40452237762237775\n","\n","Candidate: 0.999986664708606 \n","Score: 0.4045334667858671\n","\n","Candidate: 0.9999871687525558 \n","Score: 0.40459816738648313\n","\n","Candidate: 0.9999877663041976 \n","Score: 0.4046305668016196\n","\n","Candidate: 0.9999880499174518 \n","Score: 0.4046371762414802\n","\n","Candidate: 0.9999883620294395 \n","Score: 0.40466658873041866\n","\n","Candidate: 0.9999886431641758 \n","Score: 0.4046914694530003\n","\n","Candidate: 0.9999887671004112 \n","Score: 0.4047178967077549\n","\n","Candidate: 0.9999892329644298 \n","Score: 0.4047443507785975\n","\n","Candidate: 0.9999898109519334 \n","Score: 0.4047601718078877\n","\n","Candidate: 0.9999900587602912 \n","Score: 0.4047927686838303\n","\n","Candidate: 0.9999902382432619 \n","Score: 0.4048101547842403\n","\n","Candidate: 0.9999903987863203 \n","Score: 0.40486939510133835\n","\n","Candidate: 0.9999906293533267 \n","Score: 0.40488532002348815\n","\n","Candidate: 0.999991082797052 \n","Score: 0.4049043161522797\n","\n","Candidate: 0.999991416898333 \n","Score: 0.40492333163525235\n","\n","Candidate: 0.9999915329488505 \n","Score: 0.40495306986591406\n","\n","Candidate: 0.9999917459440587 \n","Score: 0.40498283842623484\n","\n","Candidate: 0.9999919548487017 \n","Score: 0.40500804552590286\n","\n","Candidate: 0.99999203310972 \n","Score: 0.40503634114736736\n","\n","Candidate: 0.9999920635975157 \n","Score: 0.40509608505954975\n","\n","Candidate: 0.9999923476054544 \n","Score: 0.40510606418121775\n","\n","Candidate: 0.9999926650667984 \n","Score: 0.4051329333071023\n","\n","Candidate: 0.9999927113146974 \n","Score: 0.40514908274939\n","\n","Candidate: 0.9999929482954538 \n","Score: 0.4051760014179371\n","\n","Candidate: 0.9999933678215807 \n","Score: 0.4052014107818413\n","\n","Candidate: 0.9999935968253395 \n","Score: 0.4052191578283328\n","\n","Candidate: 0.9999936603780493 \n","Score: 0.40523692307692327\n","\n","Candidate: 0.9999936961459626 \n","Score: 0.4052408532975492\n","\n","Candidate: 0.9999937213112573 \n","Score: 0.40526942821039347\n","\n","Candidate: 0.999993783608148 \n","Score: 0.4053840218423554\n","\n","Candidate: 0.9999939200711047 \n","Score: 0.40540039193950694\n","\n","Candidate: 0.9999941837162607 \n","Score: 0.4054214132931952\n","\n","Candidate: 0.9999944942692944 \n","Score: 0.40545327547259563\n","\n","Candidate: 0.999994666105278 \n","Score: 0.4054635210150676\n","\n","Candidate: 0.999994739168877 \n","Score: 0.4059457542457544\n","\n","Candidate: 0.9999947989822511 \n","Score: 0.40597817047817064\n","\n","Candidate: 0.999994853289643 \n","Score: 0.4061841218249671\n","\n","Candidate: 0.9999949876716241 \n","Score: 0.40621366629195454\n","\n","Candidate: 0.9999951413077941 \n","Score: 0.4062197429202653\n","\n","Candidate: 0.9999952937527207 \n","Score: 0.40623993248131196\n","\n","Candidate: 0.9999954179781698 \n","Score: 0.40626484780248523\n","\n","Candidate: 0.9999955327590668 \n","Score: 0.40626782265851324\n","\n","Candidate: 0.9999956484174315 \n","Score: 0.40629434850863444\n","\n","Candidate: 0.9999956922346873 \n","Score: 0.4063193314538866\n","\n","Candidate: 0.9999957392449835 \n","Score: 0.4063459120763995\n","\n","Candidate: 0.9999957811561668 \n","Score: 0.4063725205612\n","\n","Candidate: 0.9999958440104972 \n","Score: 0.4063881448912914\n","\n","Candidate: 0.9999958920341036 \n","Score: 0.4064053595931877\n","\n","Candidate: 0.9999959706591788 \n","Score: 0.4064351907934587\n","\n","Candidate: 0.9999961037549442 \n","Score: 0.4064682045895283\n","\n","Candidate: 0.9999961677120356 \n","Score: 0.4064839120417157\n","\n","Candidate: 0.9999964156158418 \n","Score: 0.4065138315942734\n","\n","Candidate: 0.9999966673172949 \n","Score: 0.4065737651821864\n","\n","Candidate: 0.9999966867064051 \n","Score: 0.4065927208652329\n","\n","Candidate: 0.9999967596112298 \n","Score: 0.4066022128556377\n","\n","Candidate: 0.9999969205006134 \n","Score: 0.406668695228822\n","\n","Candidate: 0.9999970294854598 \n","Score: 0.40670198903998395\n","\n","Candidate: 0.999997053885501 \n","Score: 0.4067305661603446\n","\n","Candidate: 0.9999971188862069 \n","Score: 0.40673381689625765\n","\n","Candidate: 0.999997186517952 \n","Score: 0.40675292730525303\n","\n","Candidate: 0.9999972139705595 \n","Score: 0.40677999023715594\n","\n","Candidate: 0.999997231512866 \n","Score: 0.40680390720390736\n","\n","Candidate: 0.9999972437077724 \n","Score: 0.40683102577676444\n","\n","Candidate: 0.9999972686068397 \n","Score: 0.4068917084505322\n","\n","Candidate: 0.9999972928286716 \n","Score: 0.4069077820376868\n","\n","Candidate: 0.9999973558663249 \n","Score: 0.4069238726790453\n","\n","Candidate: 0.9999975047923952 \n","Score: 0.4069495345418914\n","\n","Candidate: 0.9999976333407155 \n","Score: 0.4069831896727809\n","\n","Candidate: 0.9999976745597249 \n","Score: 0.4070120984223005\n","\n","Candidate: 0.99999768863431 \n","Score: 0.4071280412877859\n","\n","Candidate: 0.9999977013926218 \n","Score: 0.4071459161509776\n","\n","Candidate: 0.9999977161464804 \n","Score: 0.407176603247499\n","\n","Candidate: 0.9999977321685911 \n","Score: 0.4071945230769233\n","\n","Candidate: 0.9999977488370677 \n","Score: 0.40722526886134164\n","\n","Candidate: 0.9999978292539469 \n","Score: 0.40723522526592487\n","\n","Candidate: 0.9999979347320864 \n","Score: 0.4072403846153848\n","\n","Candidate: 0.9999980277392728 \n","Score: 0.407242342638655\n","\n","Candidate: 0.9999980938109788 \n","Score: 0.40744763123142974\n","\n","Candidate: 0.9999981269782908 \n","Score: 0.4074770841075191\n","\n","Candidate: 0.9999981702757059 \n","Score: 0.4074969015946462\n","\n","Candidate: 0.9999982069070803 \n","Score: 0.40751351630636984\n","\n","Candidate: 0.9999982988997347 \n","Score: 0.4075285359801491\n","\n","Candidate: 0.9999983805600281 \n","Score: 0.4075548682087146\n","\n","Candidate: 0.9999983894890252 \n","Score: 0.4075763848637909\n","\n","Candidate: 0.9999984363114712 \n","Score: 0.40760277121908806\n","\n","Candidate: 0.9999985090118009 \n","Score: 0.40763241876657846\n","\n","Candidate: 0.9999985768116355 \n","Score: 0.4076653327804273\n","\n","Candidate: 0.9999986213617054 \n","Score: 0.40768371919342816\n","\n","Candidate: 0.99999863608082 \n","Score: 0.4081821433053083\n","\n","Candidate: 0.9999986581304203 \n","Score: 0.4082156608353563\n","\n","Candidate: 0.9999986838970918 \n","Score: 0.4082312507851432\n","\n","Candidate: 0.999998703998024 \n","Score: 0.4082337858220213\n","\n","Candidate: 0.9999987204742501 \n","Score: 0.40825921190526115\n","\n","Candidate: 0.9999987457151993 \n","Score: 0.4082683080278502\n","\n","Candidate: 0.9999988071445802 \n","Score: 0.40832910648303683\n","\n","Candidate: 0.9999988558607393 \n","Score: 0.40834480947779717\n","\n","Candidate: 0.99999886852837 \n","Score: 0.4083720050441364\n","\n","Candidate: 0.999998903092187 \n","Score: 0.4084008705892251\n","\n","Candidate: 0.999998933693784 \n","Score: 0.40843140885372853\n","\n","Candidate: 0.9999989454172893 \n","Score: 0.4084586964759381\n","\n","Candidate: 0.9999989634468772 \n","Score: 0.4084860139860142\n","\n","Candidate: 0.999998978177308 \n","Score: 0.4085199367755534\n","\n","Candidate: 0.9999989855592288 \n","Score: 0.4085813114477406\n","\n","Candidate: 0.9999990066582942 \n","Score: 0.40860052351600123\n","\n","Candidate: 0.999999032819248 \n","Score: 0.40860492966670914\n","\n","Candidate: 0.9999990534007279 \n","Score: 0.40863076923076946\n","\n","Candidate: 0.9999990905972591 \n","Score: 0.4086467416585615\n","\n","Candidate: 0.9999991179364474 \n","Score: 0.4086759329779134\n","\n","Candidate: 0.9999991292555517 \n","Score: 0.40879302010007657\n","\n","Candidate: 0.99999914324717 \n","Score: 0.40880251601680195\n","\n","Candidate: 0.9999991530192247 \n","Score: 0.408820300560367\n","\n","Candidate: 0.999999167391703 \n","Score: 0.40883810474451027\n","\n","Candidate: 0.9999991921034157 \n","Score: 0.4089069396606712\n","\n","Candidate: 0.9999992155580921 \n","Score: 0.40890490980258704\n","\n","Candidate: 0.9999992250659465 \n","Score: 0.4089294410625348\n","\n","Candidate: 0.9999992279643279 \n","Score: 0.40896396626629206\n","\n","Candidate: 0.9999992318165993 \n","Score: 0.4089835712763693\n","\n","Candidate: 0.9999992429424276 \n","Score: 0.4089998720791406\n","\n","Candidate: 0.9999992621128329 \n","Score: 0.4090111992832461\n","\n","Candidate: 0.999999276962785 \n","Score: 0.40921946205242443\n","\n","Candidate: 0.9999992850541171 \n","Score: 0.40924934647525196\n","\n","Candidate: 0.9999993231895915 \n","Score: 0.409264214046823\n","\n","Candidate: 0.9999993617146057 \n","Score: 0.4092958299369345\n","\n","Candidate: 0.9999993715268404 \n","Score: 0.4093274811126376\n","\n","Candidate: 0.9999993838236974 \n","Score: 0.40936251771678933\n","\n","Candidate: 0.9999993944569865 \n","Score: 0.40938083369144845\n","\n","Candidate: 0.9999994014264983 \n","Score: 0.4094075547147098\n","\n","Candidate: 0.9999994140610153 \n","Score: 0.40943430562725885\n","\n","Candidate: 0.9999994528614156 \n","Score: 0.40946444406181415\n","\n","Candidate: 0.9999994851055611 \n","Score: 0.40947277973985724\n","\n","Candidate: 0.9999994956610874 \n","Score: 0.40947440206852\n","\n","Candidate: 0.9999995169417859 \n","Score: 0.4094962055881341\n","\n","Candidate: 0.9999995356640634 \n","Score: 0.4095567210567213\n","\n","Candidate: 0.9999995490083948 \n","Score: 0.4095718697361036\n","\n","Candidate: 0.9999995616145925 \n","Score: 0.4095870354364739\n","\n","Candidate: 0.9999995701746394 \n","Score: 0.4095904138020498\n","\n","Candidate: 0.9999995903401707 \n","Score: 0.4096191053041449\n","\n","Candidate: 0.9999996066913874 \n","Score: 0.40965289381412084\n","\n","Candidate: 0.9999996094138108 \n","Score: 0.40967996361746384\n","\n","Candidate: 0.9999996127814239 \n","Score: 0.40970706392199374\n","\n","Candidate: 0.9999996197286576 \n","Score: 0.4097681244305612\n","\n","Candidate: 0.999999628097307 \n","Score: 0.409786855356833\n","\n","Candidate: 0.99999963279099 \n","Score: 0.41026634287214514\n","\n","Candidate: 0.9999996372015771 \n","Score: 0.4103008843745898\n","\n","Candidate: 0.9999996421971362 \n","Score: 0.4103269230769233\n","\n","Candidate: 0.9999996471743877 \n","Score: 0.4103529914529917\n","\n","Candidate: 0.9999996549800876 \n","Score: 0.41036198579072036\n","\n","Candidate: 0.9999996627832695 \n","Score: 0.4103812585019091\n","\n","Candidate: 0.9999996654241697 \n","Score: 0.4104108271865124\n","\n","Candidate: 0.9999996733517266 \n","Score: 0.41049973611294394\n","\n","Candidate: 0.9999996819109357 \n","Score: 0.4105277239922551\n","\n","Candidate: 0.9999996857302784 \n","Score: 0.4105248337809874\n","\n","Candidate: 0.9999996910743287 \n","Score: 0.4105408406026965\n","\n","Candidate: 0.9999996993868722 \n","Score: 0.41055686577033307\n","\n","Candidate: 0.9999997058060213 \n","Score: 0.41057462949894163\n","\n","Candidate: 0.9999997076975415 \n","Score: 0.4105906924400903\n","\n","Candidate: 0.9999997121830874 \n","Score: 0.4106084959816305\n","\n","Candidate: 0.9999997164043444 \n","Score: 0.4106228736800249\n","\n","Candidate: 0.9999997188295286 \n","Score: 0.410613129973475\n","\n","Candidate: 0.9999997222506727 \n","Score: 0.410644778166055\n","\n","Candidate: 0.9999997241099752 \n","Score: 0.41067991502168744\n","\n","Candidate: 0.9999997257445047 \n","Score: 0.4108906145847223\n","\n","Candidate: 0.9999997347594722 \n","Score: 0.41092085371276144\n","\n","Candidate: 0.9999997503325282 \n","Score: 0.41093898207056123\n","\n","Candidate: 0.9999997640117759 \n","Score: 0.41092935363247884\n","\n","Candidate: 0.9999997733494967 \n","Score: 0.4109405594405596\n","\n","Candidate: 0.9999997776122843 \n","Score: 0.4109674213388005\n","\n","Candidate: 0.9999997781889225 \n","Score: 0.4109751839464885\n","\n","Candidate: 0.9999997788827486 \n","Score: 0.41104645296665054\n","\n","Candidate: 0.9999997804081152 \n","Score: 0.4110734387563658\n","\n","Candidate: 0.9999997853824196 \n","Score: 0.4111039422518216\n","\n","Candidate: 0.9999997901717737 \n","Score: 0.4111161900926301\n","\n","Candidate: 0.9999997913639087 \n","Score: 0.41114153308856477\n","\n","Candidate: 0.9999997986694653 \n","Score: 0.4111773890058692\n","\n","Candidate: 0.9999998109155449 \n","Score: 0.4111958041958045\n","\n","Candidate: 0.9999998167274149 \n","Score: 0.4112107423189058\n","\n","Candidate: 0.9999998194945994 \n","Score: 0.41121169553900033\n","\n","Candidate: 0.9999998222747064 \n","Score: 0.4112731847591663\n","\n","Candidate: 0.9999998260996354 \n","Score: 0.41129521647259837\n","\n","Candidate: 0.9999998308849134 \n","Score: 0.41129797570850224\n","\n","Candidate: 0.9999998322750393 \n","Score: 0.41133409101138785\n","\n","Candidate: 0.9999998334907667 \n","Score: 0.4113667357232933\n","\n","Candidate: 0.9999998384873796 \n","Score: 0.4113994186832502\n","\n","Candidate: 0.9999998459848931 \n","Score: 0.41142862295969\n","\n","Candidate: 0.9999998510158601 \n","Score: 0.41143674712384415\n","\n","Candidate: 0.9999998529210943 \n","Score: 0.4114519230769233\n","\n","Candidate: 0.9999998539461334 \n","Score: 0.41151405586188217\n","\n","Candidate: 0.9999998553384485 \n","Score: 0.41154164970831664\n","\n","Candidate: 0.9999998563638433 \n","Score: 0.4115692760180998\n","\n","Candidate: 0.9999998618046391 \n","Score: 0.41158810612577557\n","\n","Candidate: 0.99999986879629 \n","Score: 0.41158399021473246\n","\n","Candidate: 0.9999998728361534 \n","Score: 0.41160285118534995\n","\n","Candidate: 0.9999998755329162 \n","Score: 0.41159166364296107\n","\n","Candidate: 0.9999998760830258 \n","Score: 0.411621170864534\n","\n","Candidate: 0.9999998767402314 \n","Score: 0.41170990180032757\n","\n","Candidate: 0.9999998773540448 \n","Score: 0.4117360005458766\n","\n","Candidate: 0.9999998795327476 \n","Score: 0.4117514792899411\n","\n","Candidate: 0.9999998856632402 \n","Score: 0.41176520016395707\n","\n","Candidate: 0.9999998907941476 \n","Score: 0.41180026430915084\n","\n","Candidate: 0.9999998926006423 \n","Score: 0.4118033605398753\n","\n","Candidate: 0.9999998947567941 \n","Score: 0.4117922255680265\n","\n","Candidate: 0.9999998963086894 \n","Score: 0.4118077836110479\n","\n","Candidate: 0.9999998967109092 \n","Score: 0.4123040325921837\n","\n","Candidate: 0.9999998969493917 \n","Score: 0.4123218332565641\n","\n","Candidate: 0.9999998974199598 \n","Score: 0.41232887035074\n","\n","Candidate: 0.9999998978537595 \n","Score: 0.412364692861096\n","\n","Candidate: 0.9999998984238906 \n","Score: 0.4125787292178023\n","\n","Candidate: 0.9999999003130133 \n","Score: 0.4126094531974053\n","\n","Candidate: 0.9999999019353404 \n","Score: 0.41262755598831574\n","\n","Candidate: 0.9999999025514369 \n","Score: 0.4126438712072008\n","\n","Candidate: 0.9999999028875455 \n","Score: 0.41267106912399637\n","\n","Candidate: 0.9999999067432456 \n","Score: 0.41268924191750306\n","\n","Candidate: 0.999999914789544 \n","Score: 0.41271831280502\n","\n","Candidate: 0.9999999205922989 \n","Score: 0.4127492326295231\n","\n","Candidate: 0.9999999224537164 \n","Score: 0.4127674856903535\n","\n","Candidate: 0.999999922776608 \n","Score: 0.41280392065561583\n","\n","Candidate: 0.9999999231587428 \n","Score: 0.41283131435493664\n","\n","Candidate: 0.9999999235827217 \n","Score: 0.4128460139860142\n","\n","Candidate: 0.9999999239482118 \n","Score: 0.4128734664365352\n","\n","Candidate: 0.9999999252451524 \n","Score: 0.41288475549950987\n","\n","Candidate: 0.9999999266837045 \n","Score: 0.41289587811945067\n","\n","Candidate: 0.9999999286436092 \n","Score: 0.4129288987608139\n","\n","Candidate: 0.9999999304105899 \n","Score: 0.41293641212801824\n","\n","Candidate: 0.9999999323285821 \n","Score: 0.4129366309284145\n","\n","Candidate: 0.9999999341758172 \n","Score: 0.4129992265504151\n","\n","Candidate: 0.9999999349843172 \n","Score: 0.41302143527204527\n","\n","Candidate: 0.999999936778069 \n","Score: 0.4130473318627684\n","\n","Candidate: 0.9999999385135889 \n","Score: 0.4131212114092385\n","\n","Candidate: 0.9999999403595807 \n","Score: 0.4131233778446495\n","\n","Candidate: 0.9999999416597645 \n","Score: 0.41315306986591416\n","\n","Candidate: 0.9999999421562312 \n","Score: 0.41319014217117056\n","\n","Candidate: 0.9999999434360439 \n","Score: 0.4132088887842105\n","\n","Candidate: 0.9999999450049273 \n","Score: 0.4132037613122175\n","\n","Candidate: 0.9999999458811044 \n","Score: 0.4132671071260031\n","\n","Candidate: 0.999999946546853 \n","Score: 0.4132748972942346\n","\n","Candidate: 0.9999999471684315 \n","Score: 0.413262426762427\n","\n","Candidate: 0.9999999481260793 \n","Score: 0.41327759916788825\n","\n","Candidate: 0.9999999492920235 \n","Score: 0.4132927902355949\n","\n","Candidate: 0.9999999499248475 \n","Score: 0.4133209230769233\n","\n","Candidate: 0.9999999514988087 \n","Score: 0.41334909056460806\n","\n","Candidate: 0.9999999528905554 \n","Score: 0.4133754443338549\n","\n","Candidate: 0.9999999535220196 \n","Score: 0.4134129280091058\n","\n","Candidate: 0.9999999541048243 \n","Score: 0.4134430550941966\n","\n","Candidate: 0.9999999542049735 \n","Score: 0.41353365978891343\n","\n","Candidate: 0.9999999543263924 \n","Score: 0.41353981732553186\n","\n","Candidate: 0.9999999546072917 \n","Score: 0.4135534082254382\n","\n","Candidate: 0.999999955519676 \n","Score: 0.4135410097642298\n","\n","Candidate: 0.9999999565387194 \n","Score: 0.41357506434086383\n","\n","Candidate: 0.9999999568440179 \n","Score: 0.4135942820353858\n","\n","Candidate: 0.9999999578147909 \n","Score: 0.4136284119106702\n","\n","Candidate: 0.9999999600569771 \n","Score: 0.4136458243804615\n","\n","Candidate: 0.9999999617619244 \n","Score: 0.41364835164835184\n","\n","Candidate: 0.9999999623792187 \n","Score: 0.4138319106080954\n","\n","Candidate: 0.9999999627398282 \n","Score: 0.4138626373626376\n","\n","Candidate: 0.9999999639873187 \n","Score: 0.4138784212042641\n","\n","Candidate: 0.9999999661478485 \n","Score: 0.4138942247633693\n","\n","Candidate: 0.9999999674238162 \n","Score: 0.41391192307692326\n","\n","Candidate: 0.9999999682550016 \n","Score: 0.41392964352720474\n","\n","Candidate: 0.9999999694370003 \n","Score: 0.41394738615577187\n","\n","Candidate: 0.9999999700563966 \n","Score: 0.4139783006598914\n","\n","Candidate: 0.9999999702181417 \n","Score: 0.41400549450549473\n","\n","Candidate: 0.9999999704456703 \n","Score: 0.41403272244996403\n","\n","Candidate: 0.9999999706087391 \n","Score: 0.4140468101534603\n","\n","Candidate: 0.9999999714485457 \n","Score: 0.41407409821816626\n","\n","Candidate: 0.9999999726271056 \n","Score: 0.4140731542327022\n","\n","Candidate: 0.9999999742153096 \n","Score: 0.41459213220239866\n","\n","Candidate: 0.999999975496919 \n","Score: 0.4146029218086925\n","\n","Candidate: 0.9999999757472772 \n","Score: 0.41466644688644716\n","\n","Candidate: 0.9999999759708247 \n","Score: 0.4146963639917899\n","\n","Candidate: 0.9999999764615997 \n","Score: 0.4147034329307059\n","\n","Candidate: 0.9999999769630887 \n","Score: 0.41470478567234315\n","\n","Candidate: 0.9999999770271297 \n","Score: 0.414730965088381\n","\n","Candidate: 0.9999999771501102 \n","Score: 0.41474953454189145\n","\n","Candidate: 0.99999997731417 \n","Score: 0.4147719517576116\n","\n","Candidate: 0.9999999774524513 \n","Score: 0.41476569858712736\n","\n","Candidate: 0.9999999777179491 \n","Score: 0.41475177949045233\n","\n","Candidate: 0.999999978839579 \n","Score: 0.4147622265913003\n","\n","Candidate: 0.999999979811562 \n","Score: 0.41479239622270336\n","\n","Candidate: 0.9999999798693555 \n","Score: 0.4148302820020673\n","\n","Candidate: 0.9999999801073665 \n","Score: 0.41489466811215714\n","\n","Candidate: 0.9999999803451995 \n","Score: 0.41492115384615413\n","\n","Candidate: 0.9999999804969322 \n","Score: 0.41493612769526844\n","\n","Candidate: 0.9999999807176723 \n","Score: 0.4149645995852673\n","\n","Candidate: 0.9999999808391927 \n","Score: 0.41495071883800233\n","\n","Candidate: 0.9999999811487039 \n","Score: 0.414979236701602\n","\n","Candidate: 0.9999999817252891 \n","Score: 0.4149923571605246\n","\n","Candidate: 0.999999982416149 \n","Score: 0.4149977724977728\n","\n","Candidate: 0.9999999833093809 \n","Score: 0.4150147852791127\n","\n","Candidate: 0.9999999839426194 \n","Score: 0.4150914298467493\n","\n","Candidate: 0.9999999841132085 \n","Score: 0.41512208436724596\n","\n","Candidate: 0.9999999844698342 \n","Score: 0.415214285714286\n","\n","Candidate: 0.9999999850688025 \n","Score: 0.4152528609811924\n","\n","Candidate: 0.9999999854736192 \n","Score: 0.41525459297983597\n","\n","Candidate: 0.9999999859470148 \n","Score: 0.4152738142686332\n","\n","Candidate: 0.9999999865964304 \n","Score: 0.41527556209182936\n","\n","Candidate: 0.9999999869685741 \n","Score: 0.4154306291887569\n","\n","Candidate: 0.9999999873328105 \n","Score: 0.4154481006956611\n","\n","Candidate: 0.9999999876897074 \n","Score: 0.41547536057692336\n","\n","Candidate: 0.9999999877487855 \n","Score: 0.415514382360311\n","\n","Candidate: 0.9999999877609702 \n","Score: 0.4155495436766626\n","\n","Candidate: 0.9999999878464538 \n","Score: 0.41557692307692334\n","\n","Candidate: 0.9999999879665081 \n","Score: 0.41561217111869886\n","\n","Candidate: 0.999999988061322 \n","Score: 0.41562591066673393\n","\n","Candidate: 0.999999988201643 \n","Score: 0.41566123680241357\n","\n","Candidate: 0.9999999883266371 \n","Score: 0.4156789505458573\n","\n","Candidate: 0.9999999884016973 \n","Score: 0.41567705396697574\n","\n","Candidate: 0.9999999885115218 \n","Score: 0.41569480126945774\n","\n","Candidate: 0.9999999887813471 \n","Score: 0.4157106059078539\n","\n","Candidate: 0.9999999891181873 \n","Score: 0.41574610340479223\n","\n","Candidate: 0.9999999892913667 \n","Score: 0.4157619624470021\n","\n","Candidate: 0.9999999894707021 \n","Score: 0.41578966109399496\n","\n","Candidate: 0.9999999898141865 \n","Score: 0.41582133832002455\n","\n","Candidate: 0.9999999900938378 \n","Score: 0.4158136094674559\n","\n","Candidate: 0.9999999903028771 \n","Score: 0.4157979757085023\n","\n","Candidate: 0.9999999905045521 \n","Score: 0.41581589608548164\n","\n","Candidate: 0.9999999906703005 \n","Score: 0.41582198236546086\n","\n","Candidate: 0.9999999907739854 \n","Score: 0.41582214390751\n","\n","Candidate: 0.999999991061729 \n","Score: 0.41583220012177824\n","\n","Candidate: 0.999999991413453 \n","Score: 0.4158581111957352\n","\n","Candidate: 0.9999999915154538 \n","Score: 0.4158840564983236\n","\n","Candidate: 0.9999999915749935 \n","Score: 0.41594795482295505\n","\n","Candidate: 0.9999999917658691 \n","Score: 0.41593231685587767\n","\n","Candidate: 0.9999999919645779 \n","Score: 0.4159603667855326\n","\n","Candidate: 0.9999999920152115 \n","Score: 0.4159745373910386\n","\n","Candidate: 0.9999999920347907 \n","Score: 0.4160026525198942\n","\n","Candidate: 0.9999999921341762 \n","Score: 0.4160148792813029\n","\n","Candidate: 0.9999999923229341 \n","Score: 0.41604505056696317\n","\n","Candidate: 0.9999999925070646 \n","Score: 0.4160672885254283\n","\n","Candidate: 0.9999999927752787 \n","Score: 0.416097534779051\n","\n","Candidate: 0.9999999929705423 \n","Score: 0.416599055873704\n","\n","Candidate: 0.9999999930127133 \n","Score: 0.4165997418688696\n","\n","Candidate: 0.9999999932166797 \n","Score: 0.41666563275434265\n","\n","Candidate: 0.9999999934840269 \n","Score: 0.4166825047850605\n","\n","Candidate: 0.9999999937275801 \n","Score: 0.4166872864685788\n","\n","Candidate: 0.9999999938896955 \n","Score: 0.41671833721833745\n","\n","Candidate: 0.9999999940186305 \n","Score: 0.4168117408906885\n","\n","Candidate: 0.9999999943050382 \n","Score: 0.41681257466368904\n","\n","Candidate: 0.9999999945163873 \n","Score: 0.41682235918239996\n","\n","Candidate: 0.9999999945888326 \n","Score: 0.41684958884146994\n","\n","Candidate: 0.9999999946797102 \n","Score: 0.4168768553721163\n","\n","Candidate: 0.9999999948001035 \n","Score: 0.4169163539712322\n","\n","Candidate: 0.9999999948604604 \n","Score: 0.4169355671447199\n","\n","Candidate: 0.9999999949125247 \n","Score: 0.41694870055317834\n","\n","Candidate: 0.999999994987913 \n","Score: 0.4171065350578627\n","\n","Candidate: 0.9999999950660092 \n","Score: 0.4171239258017189\n","\n","Candidate: 0.9999999953570549 \n","Score: 0.4171208903570869\n","\n","Candidate: 0.9999999956842864 \n","Score: 0.41711171161716887\n","\n","Candidate: 0.999999995826857 \n","Score: 0.41719167717528394\n","\n","Candidate: 0.9999999959631736 \n","Score: 0.4171743256743259\n","\n","Candidate: 0.999999996086731 \n","Score: 0.4172020940755553\n","\n","Candidate: 0.9999999961933629 \n","Score: 0.4172011530563894\n","\n","Candidate: 0.9999999962831261 \n","Score: 0.4172022655426767\n","\n","Candidate: 0.9999999963129828 \n","Score: 0.41721366056835574\n","\n","Candidate: 0.9999999963277674 \n","Score: 0.41723124406457757\n","\n","Candidate: 0.999999996340986 \n","Score: 0.4172570877989549\n","\n","Candidate: 0.9999999963717257 \n","Score: 0.417272664835165\n","\n","Candidate: 0.9999999964201995 \n","Score: 0.41729032513877895\n","\n","Candidate: 0.999999996445038 \n","Score: 0.41730800973441984\n","\n","Candidate: 0.9999999964636173 \n","Score: 0.4173360421409288\n","\n","Candidate: 0.9999999964858961 \n","Score: 0.4173186586141134\n","\n","Candidate: 0.9999999965266317 \n","Score: 0.4173467369983568\n","\n","Candidate: 0.9999999965676739 \n","Score: 0.4173624403183026\n","\n","Candidate: 0.9999999965959413 \n","Score: 0.4173760949195734\n","\n","Candidate: 0.9999999966266118 \n","Score: 0.4174125584360393\n","\n","Candidate: 0.9999999966531596 \n","Score: 0.4174179735261285\n","\n","Candidate: 0.9999999966770252 \n","Score: 0.41745451643791914\n","\n","Candidate: 0.9999999967148536 \n","Score: 0.41746412030875724\n","\n","Candidate: 0.9999999967537186 \n","Score: 0.41752910602910626\n","\n","Candidate: 0.9999999967816954 \n","Score: 0.4175595860450232\n","\n","Candidate: 0.9999999968588331 \n","Score: 0.41760051780280805\n","\n","Candidate: 0.9999999969860129 \n","Score: 0.41763733974358996\n","\n","Candidate: 0.9999999971825382 \n","Score: 0.41763668680173216\n","\n","Candidate: 0.9999999973157174 \n","Score: 0.41765272279875915\n","\n","Candidate: 0.9999999973392278 \n","Score: 0.4177182879794302\n","\n","Candidate: 0.9999999974019461 \n","Score: 0.41774904851246336\n","\n","Candidate: 0.9999999974540399 \n","Score: 0.41777985194721623\n","\n","Candidate: 0.9999999974662677 \n","Score: 0.4178415878813926\n","\n","Candidate: 0.9999999975073894 \n","Score: 0.41786413481696527\n","\n","Candidate: 0.9999999975523068 \n","Score: 0.4178636363636366\n","\n","Candidate: 0.9999999975889173 \n","Score: 0.41786733595306047\n","\n","Candidate: 0.9999999976561178 \n","Score: 0.4178794440853266\n","\n","Candidate: 0.99999999771066 \n","Score: 0.41790628537545166\n","\n","Candidate: 0.9999999978124132 \n","Score: 0.4179331643111449\n","\n","Candidate: 0.9999999979347223 \n","Score: 0.41808923834785927\n","\n","Candidate: 0.9999999979926797 \n","Score: 0.4181057963163599\n","\n","Candidate: 0.9999999980228025 \n","Score: 0.4181012359733292\n","\n","Candidate: 0.9999999980795378 \n","Score: 0.41862386475544394\n","\n","Candidate: 0.9999999981640739 \n","Score: 0.4186132220093076\n","\n","Candidate: 0.9999999982777454 \n","Score: 0.41859401709401733\n","\n","Candidate: 0.9999999983669441 \n","Score: 0.4186047206535448\n","\n","Candidate: 0.9999999983923653 \n","Score: 0.418602600680347\n","\n","Candidate: 0.9999999984137009 \n","Score: 0.4186154669741396\n","\n","Candidate: 0.9999999984392555 \n","Score: 0.41863478021978046\n","\n","Candidate: 0.9999999984784568 \n","Score: 0.4186155220762085\n","\n","Candidate: 0.9999999984987096 \n","Score: 0.41864344668207354\n","\n","Candidate: 0.9999999985081351 \n","Score: 0.4186606739716978\n","\n","Candidate: 0.99999999852148 \n","Score: 0.41868867092792617\n","\n","Candidate: 0.9999999985308219 \n","Score: 0.4187296112489663\n","\n","Candidate: 0.9999999985463213 \n","Score: 0.41875554574550294\n","\n","Candidate: 0.9999999985664458 \n","Score: 0.4187644230769233\n","\n","Candidate: 0.9999999986030648 \n","Score: 0.4187947519769952\n","\n","Candidate: 0.9999999986381511 \n","Score: 0.4188229662423909\n","\n","Candidate: 0.9999999986841014 \n","Score: 0.4188881622700069\n","\n","Candidate: 0.999999998744795 \n","Score: 0.4188927125506075\n","\n","Candidate: 0.9999999987740873 \n","Score: 0.41889077589077617\n","\n","Candidate: 0.9999999987994598 \n","Score: 0.41890616495417965\n","\n","Candidate: 0.9999999988314485 \n","Score: 0.41898907058234636\n","\n","Candidate: 0.9999999988500341 \n","Score: 0.4190045641767786\n","\n","Candidate: 0.9999999988579147 \n","Score: 0.419020080209436\n","\n","Candidate: 0.9999999988697776 \n","Score: 0.4190377926421407\n","\n","Candidate: 0.9999999988797775 \n","Score: 0.41906858370056366\n","\n","Candidate: 0.9999999988834029 \n","Score: 0.4191302999832414\n","\n","Candidate: 0.9999999989082181 \n","Score: 0.41919655944055967\n","\n","Candidate: 0.9999999989355699 \n","Score: 0.41919701041316787\n","\n","Candidate: 0.9999999989542314 \n","Score: 0.41920838702448343\n","\n","Candidate: 0.9999999989945099 \n","Score: 0.4192066606862528\n","\n","Candidate: 0.9999999990228281 \n","Score: 0.41923775458677015\n","\n","Candidate: 0.9999999990289192 \n","Score: 0.41924042672655837\n","\n","Candidate: 0.9999999990545312 \n","Score: 0.41924967691183934\n","\n","Candidate: 0.9999999990829956 \n","Score: 0.4194061019625538\n","\n","Candidate: 0.9999999990894543 \n","Score: 0.4194331226367179\n","\n","Candidate: 0.9999999990936812 \n","Score: 0.41947119620467666\n","\n","Candidate: 0.9999999991008287 \n","Score: 0.4194938958910306\n","\n","Candidate: 0.9999999991043833 \n","Score: 0.4195320701357469\n","\n","Candidate: 0.9999999991151123 \n","Score: 0.4195747155714046\n","\n","Candidate: 0.9999999991272247 \n","Score: 0.4195688229296479\n","\n","Candidate: 0.9999999991680807 \n","Score: 0.4195850291933566\n","\n","Candidate: 0.9999999992091722 \n","Score: 0.41957249829816223\n","\n","Candidate: 0.9999999992521114 \n","Score: 0.41955109281862074\n","\n","Candidate: 0.9999999993096327 \n","Score: 0.4195628905806161\n","\n","Candidate: 0.9999999993332206 \n","Score: 0.41954144635851975\n","\n","Candidate: 0.999999999347565 \n","Score: 0.41953772189349137\n","\n","Candidate: 0.9999999993562351 \n","Score: 0.41954731537892187\n","\n","Candidate: 0.999999999377174 \n","Score: 0.41956358974359\n","\n","Candidate: 0.9999999993977947 \n","Score: 0.4195932314534986\n","\n","Candidate: 0.9999999994011708 \n","Score: 0.4196206916229174\n","\n","Candidate: 0.9999999994049411 \n","Score: 0.4196846496742487\n","\n","Candidate: 0.9999999994099633 \n","Score: 0.4197122390620534\n","\n","Candidate: 0.999999999430794 \n","Score: 0.4197376373626376\n","\n","Candidate: 0.9999999994560729 \n","Score: 0.4202763971565626\n","\n","Candidate: 0.999999999476835 \n","Score: 0.42029120879120896\n","\n","Candidate: 0.9999999994916362 \n","Score: 0.4202947560340339\n","\n","Candidate: 0.9999999994962857 \n","Score: 0.420314121872104\n","\n","Candidate: 0.9999999995040451 \n","Score: 0.4203109095124922\n","\n","Candidate: 0.9999999995172799 \n","Score: 0.42037692307692326\n","\n","Candidate: 0.9999999995260598 \n","Score: 0.4204077387868931\n","\n","Candidate: 0.9999999995351159 \n","Score: 0.42046951006633326\n","\n","Candidate: 0.9999999995435851 \n","Score: 0.4204845687998604\n","\n","Candidate: 0.9999999995502415 \n","Score: 0.42051328671328686\n","\n","Candidate: 0.9999999995634234 \n","Score: 0.42054887152271553\n","\n","Candidate: 0.9999999995756594 \n","Score: 0.420564024746119\n","\n","Candidate: 0.999999999582257 \n","Score: 0.42056097774662715\n","\n","Candidate: 0.9999999995855531 \n","Score: 0.4205716039279871\n","\n","Candidate: 0.9999999995894928 \n","Score: 0.4206141854343377\n","\n","Candidate: 0.9999999995934871 \n","Score: 0.4206157358623114\n","\n","Candidate: 0.9999999995959898 \n","Score: 0.42063099771515633\n","\n","Candidate: 0.9999999996015776 \n","Score: 0.4206508560037525\n","\n","Candidate: 0.9999999996080969 \n","Score: 0.4206586024662362\n","\n","Candidate: 0.9999999996117397 \n","Score: 0.42081600353669335\n","\n","Candidate: 0.999999999617369 \n","Score: 0.42080851816894776\n","\n","Candidate: 0.9999999996281737 \n","Score: 0.4208263474821419\n","\n","Candidate: 0.9999999996444069 \n","Score: 0.42085342077277577\n","\n","Candidate: 0.9999999996569635 \n","Score: 0.4208390291491753\n","\n","Candidate: 0.9999999996647738 \n","Score: 0.4208707692307694\n","\n","Candidate: 0.9999999996689788 \n","Score: 0.420957508593102\n","\n","Candidate: 0.9999999996819812 \n","Score: 0.42093390071763254\n","\n","Candidate: 0.9999999996981903 \n","Score: 0.42093340455840467\n","\n","Candidate: 0.9999999997052702 \n","Score: 0.420949123849124\n","\n","Candidate: 0.9999999997131828 \n","Score: 0.420944001902271\n","\n","Candidate: 0.9999999997186843 \n","Score: 0.4209203105479209\n","\n","Candidate: 0.9999999997210471 \n","Score: 0.4209592760180997\n","\n","Candidate: 0.9999999997223075 \n","Score: 0.42097041649287986\n","\n","Candidate: 0.999999999723332 \n","Score: 0.42099320214669067\n","\n","Candidate: 0.9999999997359856 \n","Score: 0.42103231485349424\n","\n","Candidate: 0.9999999997485343 \n","Score: 0.42109673659673674\n","\n","Candidate: 0.9999999997525382 \n","Score: 0.4211406866850103\n","\n","Candidate: 0.9999999997569035 \n","Score: 0.42116602813528903\n","\n","Candidate: 0.99999999975843 \n","Score: 0.4211750539180447\n","\n","Candidate: 0.9999999997591179 \n","Score: 0.42120513819773386\n","\n","Candidate: 0.9999999997606833 \n","Score: 0.4212329293171728\n","\n","Candidate: 0.9999999997621914 \n","Score: 0.4212467123040895\n","\n","Candidate: 0.9999999997660713 \n","Score: 0.42127457932692325\n","\n","Candidate: 0.9999999997742477 \n","Score: 0.42128372526613356\n","\n","Candidate: 0.999999999782363 \n","Score: 0.4212788010111955\n","\n","Candidate: 0.999999999789156 \n","Score: 0.42128091681224034\n","\n","Candidate: 0.999999999801251 \n","Score: 0.4213463348416291\n","\n","Candidate: 0.9999999998104239 \n","Score: 0.4213767660910519\n","\n","Candidate: 0.9999999998129785 \n","Score: 0.42143777213352696\n","\n","Candidate: 0.9999999998177371 \n","Score: 0.42143294195969266\n","\n","Candidate: 0.9999999998214593 \n","Score: 0.42144700181708067\n","\n","Candidate: 0.9999999998248101 \n","Score: 0.4214705400981998\n","\n","Candidate: 0.9999999998278053 \n","Score: 0.42148938364474653\n","\n","Candidate: 0.9999999998299514 \n","Score: 0.4214893145528506\n","\n","Candidate: 0.9999999998334361 \n","Score: 0.4215082026977763\n","\n","Candidate: 0.9999999998356828 \n","Score: 0.42152237762237776\n","\n","Candidate: 0.9999999998360367 \n","Score: 0.42155793573515105\n","\n","Candidate: 0.9999999998400185 \n","Score: 0.4215484195139778\n","\n","Candidate: 0.9999999998445153 \n","Score: 0.4217033141739025\n","\n","Candidate: 0.9999999998466228 \n","Score: 0.42171773453277045\n","\n","Candidate: 0.9999999998480897 \n","Score: 0.4217465090641843\n","\n","Candidate: 0.9999999998497238 \n","Score: 0.4217729390131782\n","\n","Candidate: 0.9999999998512907 \n","Score: 0.4217826647037175\n","\n","Candidate: 0.9999999998529369 \n","Score: 0.42235049277877657\n","\n","Candidate: 0.9999999998561255 \n","Score: 0.42233418114143934\n","\n","Candidate: 0.9999999998595156 \n","Score: 0.42235174147886023\n","\n","Candidate: 0.9999999998643543 \n","Score: 0.4223257114452592\n","\n","Candidate: 0.9999999998694846 \n","Score: 0.4223408681052175\n","\n","Candidate: 0.9999999998765454 \n","Score: 0.4223342046303213\n","\n","Candidate: 0.999999999884239 \n","Score: 0.42230809716599205\n","\n","Candidate: 0.9999999998873073 \n","Score: 0.42234029422765257\n","\n","Candidate: 0.9999999998883276 \n","Score: 0.42234640359640374\n","\n","Candidate: 0.9999999998940341 \n","Score: 0.42239089545710196\n","\n","Candidate: 0.9999999998994307 \n","Score: 0.422455686299055\n","\n","Candidate: 0.9999999998998678 \n","Score: 0.42248327486845416\n","\n","Candidate: 0.999999999900374 \n","Score: 0.4225231333458719\n","\n","Candidate: 0.9999999999009157 \n","Score: 0.42253369306061\n","\n","Candidate: 0.9999999999012815 \n","Score: 0.42256141287284155\n","\n","Candidate: 0.9999999999019781 \n","Score: 0.4226014328808448\n","\n","Candidate: 0.9999999999029676 \n","Score: 0.42259491162966234\n","\n","Candidate: 0.9999999999038045 \n","Score: 0.4226252045826515\n","\n","Candidate: 0.999999999905073 \n","Score: 0.4226236061236063\n","\n","Candidate: 0.9999999999062497 \n","Score: 0.4226490542244642\n","\n","Candidate: 0.9999999999083333 \n","Score: 0.42266223890957294\n","\n","Candidate: 0.999999999910507 \n","Score: 0.42266312997347494\n","\n","Candidate: 0.9999999999109854 \n","Score: 0.4227537322874495\n","\n","Candidate: 0.9999999999118963 \n","Score: 0.4227769230769232\n","\n","Candidate: 0.9999999999147993 \n","Score: 0.42278532505385896\n","\n","Candidate: 0.9999999999177172 \n","Score: 0.42285167555217074\n","\n","Candidate: 0.9999999999190692 \n","Score: 0.4228452963221751\n","\n","Candidate: 0.9999999999216768 \n","Score: 0.42286369993642736\n","\n","Candidate: 0.9999999999238532 \n","Score: 0.42286228287841204\n","\n","Candidate: 0.9999999999241695 \n","Score: 0.42289314824248614\n","\n","Candidate: 0.9999999999260232 \n","Score: 0.4229550325296595\n","\n","Candidate: 0.9999999999285685 \n","Score: 0.4229785828279606\n","\n","Candidate: 0.999999999929888 \n","Score: 0.4229922054689498\n","\n","Candidate: 0.999999999930462 \n","Score: 0.422990888164205\n","\n","Candidate: 0.9999999999315354 \n","Score: 0.4229795853065405\n","\n","Candidate: 0.9999999999344371 \n","Score: 0.42302571574969594\n","\n","Candidate: 0.9999999999365423 \n","Score: 0.4230069230769232\n","\n","Candidate: 0.999999999937115 \n","Score: 0.4230256303329699\n","\n","Candidate: 0.9999999999395603 \n","Score: 0.4231824507151142\n","\n","Candidate: 0.9999999999417293 \n","Score: 0.42320894319427443\n","\n","Candidate: 0.9999999999424949 \n","Score: 0.4231801109963863\n","\n","Candidate: 0.9999999999433618 \n","Score: 0.4232167215655882\n","\n","Candidate: 0.9999999999445397 \n","Score: 0.42322566257272154\n","\n","Candidate: 0.9999999999456051 \n","Score: 0.4232169567186389\n","\n","Candidate: 0.9999999999468052 \n","Score: 0.4232461149961151\n","\n","Candidate: 0.9999999999483471 \n","Score: 0.4232601581232585\n","\n","Candidate: 0.9999999999495514 \n","Score: 0.4232767544428591\n","\n","Candidate: 0.9999999999521805 \n","Score: 0.4232478091528726\n","\n","Candidate: 0.9999999999541523 \n","Score: 0.4232593555093557\n","\n","Candidate: 0.9999999999545691 \n","Score: 0.4238442159889642\n","\n","Candidate: 0.9999999999562843 \n","Score: 0.4238589743589745\n","\n","Candidate: 0.9999999999581501 \n","Score: 0.42385579390669226\n","\n","Candidate: 0.9999999999591196 \n","Score: 0.4238474710221287\n","\n","Candidate: 0.9999999999597129 \n","Score: 0.4239131151867003\n","\n","Candidate: 0.9999999999606239 \n","Score: 0.42394344668207345\n","\n","Candidate: 0.9999999999615875 \n","Score: 0.4239712529738304\n","\n","Candidate: 0.9999999999618292 \n","Score: 0.42399652754811845\n","\n","Candidate: 0.9999999999621267 \n","Score: 0.42402442737984924\n","\n","Candidate: 0.9999999999623429 \n","Score: 0.424057543231962\n","\n","Candidate: 0.9999999999626581 \n","Score: 0.42406744031830257\n","\n","Candidate: 0.9999999999632342 \n","Score: 0.4241084157430147\n","\n","Candidate: 0.9999999999635251 \n","Score: 0.42410801115982477\n","\n","Candidate: 0.9999999999639142 \n","Score: 0.4241490924805533\n","\n","Candidate: 0.9999999999646756 \n","Score: 0.4241668884748471\n","\n","Candidate: 0.9999999999652295 \n","Score: 0.42417432567432584\n","\n","Candidate: 0.9999999999656255 \n","Score: 0.4241661778429544\n","\n","Candidate: 0.9999999999662172 \n","Score: 0.42421265594769514\n","\n","Candidate: 0.9999999999666904 \n","Score: 0.4242253605769232\n","\n","Candidate: 0.9999999999673468 \n","Score: 0.4242925752508363\n","\n","Candidate: 0.9999999999681252 \n","Score: 0.42429730635218454\n","\n","Candidate: 0.9999999999684039 \n","Score: 0.4243284487961909\n","\n","Candidate: 0.9999999999687462 \n","Score: 0.42439089687604986\n","\n","Candidate: 0.9999999999691566 \n","Score: 0.42441433566433584\n","\n","Candidate: 0.9999999999694491 \n","Score: 0.42441156874621455\n","\n","Candidate: 0.9999999999700018 \n","Score: 0.4243982891014416\n","\n","Candidate: 0.9999999999712713 \n","Score: 0.42442179599541574\n","\n","Candidate: 0.9999999999723548 \n","Score: 0.42440060728744955\n","\n","Candidate: 0.9999999999728715 \n","Score: 0.4244952007570638\n","\n","Candidate: 0.9999999999735724 \n","Score: 0.4245109600162372\n","\n","Candidate: 0.9999999999743716 \n","Score: 0.42463782334170697\n","\n","Candidate: 0.9999999999751972 \n","Score: 0.4246511280239197\n","\n","Candidate: 0.9999999999759126 \n","Score: 0.40827320954907176\n","\n","Candidate: 0.9999999999765501 \n","Score: 0.408299795779442\n","\n","Candidate: 0.9999999999770535 \n","Score: 0.40828922804387835\n","\n","Candidate: 0.9999999999773257 \n","Score: 0.40830789689034386\n","\n","Candidate: 0.9999999999781135 \n","Score: 0.4083159511296159\n","\n","Candidate: 0.9999999999789827 \n","Score: 0.40831336248121347\n","\n","Candidate: 0.9999999999801088 \n","Score: 0.39193528205128214\n","\n","Candidate: 0.9999999999811935 \n","Score: 0.39197269367643045\n","\n","Candidate: 0.9999999999818874 \n","Score: 0.39196742927597794\n","\n","Candidate: 0.9999999999825034 \n","Score: 0.3919568078979845\n","\n","Candidate: 0.9999999999828737 \n","Score: 0.39196757702600715\n","\n","Candidate: 0.9999999999832361 \n","Score: 0.3920320684677254\n","\n","Candidate: 0.9999999999834434 \n","Score: 0.3920617173524152\n","\n","Candidate: 0.99999999998363 \n","Score: 0.39208604779285183\n","\n","Candidate: 0.9999999999837861 \n","Score: 0.3926889632107025\n","\n","Candidate: 0.9999999999841015 \n","Score: 0.3926869725922311\n","\n","Candidate: 0.9999999999843946 \n","Score: 0.3927149239145611\n","\n","Candidate: 0.9999999999845146 \n","Score: 0.39274292601131855\n","\n","Candidate: 0.999999999984742 \n","Score: 0.39277370629370645\n","\n","Candidate: 0.9999999999850049 \n","Score: 0.39278270455659003\n","\n","Candidate: 0.9999999999851933 \n","Score: 0.39279991593106367\n","\n","Candidate: 0.9999999999853343 \n","Score: 0.39278981137367663\n","\n","Candidate: 0.9999999999854825 \n","Score: 0.3927961117349805\n","\n","Candidate: 0.9999999999857981 \n","Score: 0.39281886195995797\n","\n","Candidate: 0.9999999999860686 \n","Score: 0.3928361693151457\n","\n","Candidate: 0.9999999999863052 \n","Score: 0.3929038461538463\n","\n","Candidate: 0.9999999999864949 \n","Score: 0.3928992808291618\n","\n","Candidate: 0.9999999999868014 \n","Score: 0.3929332392378265\n","\n","Candidate: 0.9999999999871176 \n","Score: 0.39294797626615824\n","\n","Candidate: 0.9999999999872158 \n","Score: 0.3929903139140273\n","\n","Candidate: 0.999999999987293 \n","Score: 0.3929747717783598\n","\n","Candidate: 0.9999999999873515 \n","Score: 0.3929868253293669\n","\n","Candidate: 0.9999999999875879 \n","Score: 0.39302931584544504\n","\n","Candidate: 0.9999999999878131 \n","Score: 0.39307741981265987\n","\n","Candidate: 0.9999999999878477 \n","Score: 0.3931089921159175\n","\n","Candidate: 0.9999999999880964 \n","Score: 0.39317231196185887\n","\n","Candidate: 0.9999999999885207 \n","Score: 0.39314850427350445\n","\n","Candidate: 0.9999999999888073 \n","Score: 0.3931635773864691\n","\n","Candidate: 0.9999999999893515 \n","Score: 0.393187027258456\n","\n","Candidate: 0.9999999999898468 \n","Score: 0.393213306192415\n","\n","Candidate: 0.9999999999899349 \n","Score: 0.39320060051472705\n","\n","Candidate: 0.999999999990091 \n","Score: 0.3933286452353618\n","\n","Candidate: 0.9999999999903113 \n","Score: 0.3934266714593819\n","\n","Candidate: 0.9999999999904301 \n","Score: 0.39344214578686065\n","\n","Candidate: 0.9999999999904852 \n","Score: 0.3934548401037167\n","\n","Candidate: 0.9999999999908638 \n","Score: 0.3934619349722444\n","\n","Candidate: 0.9999999999915847 \n","Score: 0.3934690431519702\n","\n","Candidate: 0.9999999999920288 \n","Score: 0.39347202139965315\n","\n","Candidate: 0.9999999999921994 \n","Score: 0.39346504812215083\n","\n","Candidate: 0.9999999999923502 \n","Score: 0.39345241199478503\n","\n","Candidate: 0.9999999999926417 \n","Score: 0.3934765098238239\n","\n","Candidate: 0.9999999999929636 \n","Score: 0.3934723512336722\n","\n","Candidate: 0.9999999999931484 \n","Score: 0.3934823490956637\n","\n","Candidate: 0.999999999993312 \n","Score: 0.3935093790897195\n","\n","Candidate: 0.9999999999933555 \n","Score: 0.3935364602285134\n","\n","Candidate: 0.9999999999934438 \n","Score: 0.3935550699300701\n","\n","Candidate: 0.9999999999935552 \n","Score: 0.393620858268866\n","\n","Candidate: 0.9999999999935945 \n","Score: 0.3936082621082623\n","\n","Candidate: 0.9999999999936466 \n","Score: 0.39362986253290455\n","\n","Candidate: 0.9999999999936858 \n","Score: 0.3936686306082121\n","\n","Candidate: 0.9999999999936938 \n","Score: 0.3936760439560441\n","\n","Candidate: 0.9999999999937768 \n","Score: 0.3937063503703162\n","\n","Candidate: 0.999999999993902 \n","Score: 0.3937109512624781\n","\n","Candidate: 0.9999999999940306 \n","Score: 0.3942880902880904\n","\n","Candidate: 0.9999999999941809 \n","Score: 0.3942846153846155\n","\n","Candidate: 0.9999999999943381 \n","Score: 0.3942782324058921\n","\n","Candidate: 0.9999999999945395 \n","Score: 0.3942602204184974\n","\n","Candidate: 0.9999999999946656 \n","Score: 0.39429159212880155\n","\n","Candidate: 0.9999999999948044 \n","Score: 0.39436034353995536\n","\n","Candidate: 0.9999999999949611 \n","Score: 0.3943714958510878\n","\n","Candidate: 0.9999999999950155 \n","Score: 0.3943885064351992\n","\n","Candidate: 0.9999999999950491 \n","Score: 0.39442015579357365\n","\n","Candidate: 0.9999999999950806 \n","Score: 0.39448363977485945\n","\n","Candidate: 0.9999999999951854 \n","Score: 0.39445688100961557\n","\n","Candidate: 0.9999999999953748 \n","Score: 0.39448285585382376\n","\n","Candidate: 0.9999999999956032 \n","Score: 0.3945323648953788\n","\n","Candidate: 0.9999999999957416 \n","Score: 0.39457609432682905\n","\n","Candidate: 0.9999999999957753 \n","Score: 0.39456108597285083\n","\n","Candidate: 0.9999999999958253 \n","Score: 0.3946049294179816\n","\n","Candidate: 0.9999999999958891 \n","Score: 0.39464001813510674\n","\n","Candidate: 0.9999999999959608 \n","Score: 0.394769230769231\n","\n","Candidate: 0.9999999999960164 \n","Score: 0.39479280886931445\n","\n","Candidate: 0.9999999999961025 \n","Score: 0.3947986470051689\n","\n","Candidate: 0.9999999999962407 \n","Score: 0.3948104314083544\n","\n","Candidate: 0.9999999999963374 \n","Score: 0.3948162985529324\n","\n","Candidate: 0.9999999999963688 \n","Score: 0.39483109704963043\n","\n","Candidate: 0.9999999999964597 \n","Score: 0.394932281720266\n","\n","Candidate: 0.9999999999965822 \n","Score: 0.3949174185655301\n","\n","Candidate: 0.9999999999966197 \n","Score: 0.394941331802526\n","\n","Candidate: 0.9999999999966327 \n","Score: 0.3949563285320259\n","\n","Candidate: 0.9999999999967094 \n","Score: 0.39494742694991963\n","\n","Candidate: 0.9999999999968268 \n","Score: 0.3949325195762323\n","\n","Candidate: 0.9999999999968949 \n","Score: 0.3949595404595406\n","\n","Candidate: 0.9999999999969512 \n","Score: 0.39498661538461555\n","\n","Candidate: 0.9999999999970226 \n","Score: 0.3949807114807116\n","\n","Candidate: 0.9999999999970666 \n","Score: 0.3949958378295053\n","\n","Candidate: 0.9999999999971879 \n","Score: 0.39500497646786525\n","\n","Candidate: 0.9999999999973037 \n","Score: 0.3950352177942541\n","\n","Candidate: 0.9999999999973304 \n","Score: 0.3950202937765753\n","\n","Candidate: 0.9999999999973588 \n","Score: 0.3950264664912554\n","\n","Candidate: 0.999999999997427 \n","Score: 0.39509328473945426\n","\n","Candidate: 0.9999999999974962 \n","Score: 0.39511468602033706\n","\n","Candidate: 0.999999999997532 \n","Score: 0.39511794871794886\n","\n","Candidate: 0.9999999999975611 \n","Score: 0.3950880566801621\n","\n","Candidate: 0.9999999999976527 \n","Score: 0.3950880566801621\n","\n","Candidate: 0.9999999999977577 \n","Score: 0.39512777647884045\n","\n","Candidate: 0.9999999999978013 \n","Score: 0.3951282702069506\n","\n","Candidate: 0.9999999999978529 \n","Score: 0.395195907347993\n","\n","Candidate: 0.9999999999978744 \n","Score: 0.3952362973418021\n","\n","Candidate: 0.9999999999978783 \n","Score: 0.3952362973418021\n","\n","Candidate: 0.9999999999978895 \n","Score: 0.3952983028207749\n","\n","Candidate: 0.9999999999979012 \n","Score: 0.395323265691364\n","\n","Candidate: 0.9999999999979261 \n","Score: 0.395924988055423\n","\n","Candidate: 0.9999999999980232 \n","Score: 0.39589497807891605\n","\n","Candidate: 0.9999999999981223 \n","Score: 0.3959115863389724\n","\n","Candidate: 0.9999999999981812 \n","Score: 0.3958939611790081\n","\n","Candidate: 0.9999999999982345 \n","Score: 0.39592619542619556\n","\n","Candidate: 0.9999999999982951 \n","Score: 0.3960558053637387\n","\n","Candidate: 0.9999999999983633 \n","Score: 0.39607583795514845\n","\n","Candidate: 0.9999999999983915 \n","Score: 0.3960802220791762\n","\n","Candidate: 0.9999999999984159 \n","Score: 0.3960908981071286\n","\n","Candidate: 0.9999999999984431 \n","Score: 0.3961424770198356\n","\n","Candidate: 0.999999999998475 \n","Score: 0.3961375010089597\n","\n","Candidate: 0.9999999999985234 \n","Score: 0.396141968325792\n","\n","Candidate: 0.9999999999985609 \n","Score: 0.39615590876000983\n","\n","Candidate: 0.9999999999985827 \n","Score: 0.3962014574898787\n","\n","Candidate: 0.9999999999985938 \n","Score: 0.39618387776606967\n","\n","Candidate: 0.9999999999986042 \n","Score: 0.39622955209347627\n","\n","Candidate: 0.99999999999862 \n","Score: 0.3962563154902121\n","\n","Candidate: 0.9999999999986493 \n","Score: 0.39628313546918215\n","\n","Candidate: 0.9999999999986724 \n","Score: 0.39630683760683777\n","\n","Candidate: 0.9999999999986985 \n","Score: 0.39634330182529354\n","\n","Candidate: 0.9999999999987328 \n","Score: 0.39633530467411715\n","\n","Candidate: 0.9999999999987449 \n","Score: 0.39644040709556133\n","\n","Candidate: 0.9999999999987601 \n","Score: 0.39647078559738147\n","\n","Candidate: 0.9999999999987979 \n","Score: 0.3964788645858935\n","\n","Candidate: 0.999999999998828 \n","Score: 0.39646137444644924\n","\n","Candidate: 0.9999999999988523 \n","Score: 0.39648546917330285\n","\n","Candidate: 0.9999999999988844 \n","Score: 0.3965530645824765\n","\n","Candidate: 0.9999999999989115 \n","Score: 0.39655485093065407\n","\n","Candidate: 0.9999999999989289 \n","Score: 0.3965598565421718\n","\n","Candidate: 0.999999999998949 \n","Score: 0.3965487784747443\n","\n","Candidate: 0.9999999999989743 \n","Score: 0.3965312319259689\n","\n","Candidate: 0.9999999999989984 \n","Score: 0.3965491315136478\n","\n","Candidate: 0.9999999999990148 \n","Score: 0.3965799867516769\n","\n","Candidate: 0.9999999999990437 \n","Score: 0.39664189693801355\n","\n","Candidate: 0.9999999999990752 \n","Score: 0.3967105613305615\n","\n","Candidate: 0.9999999999990914 \n","Score: 0.3967255244755246\n","\n","Candidate: 0.999999999999106 \n","Score: 0.3967470205850489\n","\n","Candidate: 0.9999999999991201 \n","Score: 0.3967555481394962\n","\n","Candidate: 0.9999999999991352 \n","Score: 0.3967510648960162\n","\n","Candidate: 0.9999999999991562 \n","Score: 0.38037107023411393\n","\n","Candidate: 0.9999999999991809 \n","Score: 0.38039591529254224\n","\n","Candidate: 0.9999999999991881 \n","Score: 0.3805220680958388\n","\n","Candidate: 0.9999999999991929 \n","Score: 0.3805012624137353\n","\n","Candidate: 0.9999999999992187 \n","Score: 0.38051655573342336\n","\n","Candidate: 0.9999999999992644 \n","Score: 0.3805318825910933\n","\n","Candidate: 0.9999999999992952 \n","Score: 0.3805340707590984\n","\n","Candidate: 0.9999999999993039 \n","Score: 0.3811613758877387\n","\n","Candidate: 0.9999999999993165 \n","Score: 0.381204385814631\n","\n","Candidate: 0.9999999999993294 \n","Score: 0.3812140468227426\n","\n","Candidate: 0.9999999999993349 \n","Score: 0.38124716689560456\n","\n","Candidate: 0.9999999999993594 \n","Score: 0.38125019338203714\n","\n","Candidate: 0.999999999999382 \n","Score: 0.3812495477646656\n","\n","Candidate: 0.9999999999993869 \n","Score: 0.38122904449810296\n","\n","Candidate: 0.9999999999994158 \n","Score: 0.3812421652421654\n","\n","Candidate: 0.9999999999994419 \n","Score: 0.38123171996542804\n","\n","Candidate: 0.9999999999994487 \n","Score: 0.38126174612788805\n","\n","Candidate: 0.9999999999994578 \n","Score: 0.38128846153846174\n","\n","Candidate: 0.9999999999994684 \n","Score: 0.38131523718671423\n","\n","Candidate: 0.9999999999994771 \n","Score: 0.3813825293350719\n","\n","Candidate: 0.9999999999994816 \n","Score: 0.3814366515837106\n","\n","Candidate: 0.9999999999994877 \n","Score: 0.38141615123268596\n","\n","Candidate: 0.999999999999495 \n","Score: 0.38146363160648894\n","\n","Candidate: 0.9999999999995004 \n","Score: 0.3815112197677466\n","\n","Candidate: 0.999999999999508 \n","Score: 0.3815180069930072\n","\n","Candidate: 0.9999999999995195 \n","Score: 0.381517983722762\n","\n","Candidate: 0.9999999999995253 \n","Score: 0.38154187839495374\n","\n","Candidate: 0.999999999999539 \n","Score: 0.38154530304359285\n","\n","Candidate: 0.9999999999995554 \n","Score: 0.3815316122233932\n","\n","Candidate: 0.9999999999995598 \n","Score: 0.3815693186813188\n","\n","Candidate: 0.9999999999995621 \n","Score: 0.38160024643548685\n","\n","Candidate: 0.9999999999995649 \n","Score: 0.3816623147494709\n","\n","Candidate: 0.9999999999995739 \n","Score: 0.3816831228473021\n","\n","Candidate: 0.9999999999995867 \n","Score: 0.38179392759139613\n","\n","Candidate: 0.9999999999995928 \n","Score: 0.381787309464729\n","\n","Candidate: 0.9999999999996156 \n","Score: 0.3818048975246209\n","\n","Candidate: 0.9999999999996385 \n","Score: 0.381812133593889\n","\n","Candidate: 0.9999999999996494 \n","Score: 0.3819386935570232\n","\n","Candidate: 0.9999999999996598 \n","Score: 0.38191476815867076\n","\n","Candidate: 0.9999999999996706 \n","Score: 0.3819361359570663\n","\n","Candidate: 0.9999999999996837 \n","Score: 0.38195056863974225\n","\n","Candidate: 0.9999999999996878 \n","Score: 0.3819510489510491\n","\n","Candidate: 0.9999999999996971 \n","Score: 0.3819305268826857\n","\n","Candidate: 0.9999999999997065 \n","Score: 0.38195551761322805\n","\n","Candidate: 0.9999999999997082 \n","Score: 0.3819560053981108\n","\n","Candidate: 0.9999999999997176 \n","Score: 0.38198108448928136\n","\n","Candidate: 0.999999999999734 \n","Score: 0.38198863738840305\n","\n","Candidate: 0.999999999999743 \n","Score: 0.3819645178764899\n","\n","Candidate: 0.999999999999752 \n","Score: 0.38197559432342054\n","\n","Candidate: 0.9999999999997624 \n","Score: 0.38200787330316754\n","\n","Candidate: 0.9999999999997662 \n","Score: 0.3819942919271543\n","\n","Candidate: 0.9999999999997671 \n","Score: 0.3820591226954865\n","\n","Candidate: 0.999999999999769 \n","Score: 0.38271331183786284\n","\n","Candidate: 0.9999999999997711 \n","Score: 0.3827291090204761\n","\n","Candidate: 0.9999999999997746 \n","Score: 0.3827233354880415\n","\n","Candidate: 0.9999999999997791 \n","Score: 0.382768028846154\n","\n","Candidate: 0.9999999999997806 \n","Score: 0.38277311857817287\n","\n","Candidate: 0.9999999999997824 \n","Score: 0.38280352177942556\n","\n","Candidate: 0.9999999999997873 \n","Score: 0.382779716061984\n","\n","Candidate: 0.9999999999997923 \n","Score: 0.3827812151616501\n","\n","Candidate: 0.999999999999799 \n","Score: 0.38277909031717994\n","\n","Candidate: 0.9999999999998047 \n","Score: 0.38276243248277164\n","\n","Candidate: 0.9999999999998064 \n","Score: 0.3827893706293708\n","\n","Candidate: 0.9999999999998137 \n","Score: 0.38281637415982095\n","\n","Candidate: 0.999999999999823 \n","Score: 0.3828397981119732\n","\n","Candidate: 0.999999999999827 \n","Score: 0.38289612577203835\n","\n","Candidate: 0.999999999999828 \n","Score: 0.38292701208657376\n","\n","Candidate: 0.9999999999998289 \n","Score: 0.38298901098901117\n","\n","Candidate: 0.9999999999998332 \n","Score: 0.38300545420349835\n","\n","Candidate: 0.9999999999998386 \n","Score: 0.38300169683257934\n","\n","Candidate: 0.9999999999998418 \n","Score: 0.3830071731949034\n","\n","Candidate: 0.9999999999998446 \n","Score: 0.38305688905688917\n","\n","Candidate: 0.9999999999998516 \n","Score: 0.3831067272211185\n","\n","Candidate: 0.9999999999998577 \n","Score: 0.38307910193255035\n","\n","Candidate: 0.9999999999998592 \n","Score: 0.38320554074638247\n","\n","Candidate: 0.9999999999998621 \n","Score: 0.3833213399503723\n","\n","Candidate: 0.9999999999998652 \n","Score: 0.3833421882465362\n","\n","Candidate: 0.9999999999998666 \n","Score: 0.3833556257175661\n","\n","Candidate: 0.9999999999998714 \n","Score: 0.38335415269661854\n","\n","Candidate: 0.9999999999998769 \n","Score: 0.38335267600230205\n","\n","Candidate: 0.9999999999998785 \n","Score: 0.38334370498415454\n","\n","Candidate: 0.9999999999998807 \n","Score: 0.38334971153846165\n","\n","Candidate: 0.999999999999885 \n","Score: 0.38337075190141534\n","\n","Candidate: 0.9999999999998899 \n","Score: 0.3833956043956045\n","\n","Candidate: 0.9999999999998939 \n","Score: 0.38336782163883804\n","\n","Candidate: 0.9999999999998967 \n","Score: 0.38337765751836117\n","\n","Candidate: 0.9999999999999003 \n","Score: 0.3833611030478956\n","\n","Candidate: 0.9999999999999057 \n","Score: 0.3833633985661694\n","\n","Candidate: 0.999999999999909 \n","Score: 0.38342861305361314\n","\n","Candidate: 0.9999999999999103 \n","Score: 0.3834006612856171\n","\n","Candidate: 0.9999999999999112 \n","Score: 0.38339922103213253\n","\n","Candidate: 0.9999999999999118 \n","Score: 0.3833749634396023\n","\n","Candidate: 0.9999999999999134 \n","Score: 0.3833696798125733\n","\n","Candidate: 0.9999999999999156 \n","Score: 0.3833491349819178\n","\n","Candidate: 0.9999999999999194 \n","Score: 0.38402749379652623\n","\n","Candidate: 0.999999999999923 \n","Score: 0.3840578413834229\n","\n","Candidate: 0.999999999999925 \n","Score: 0.3840843865061202\n","\n","Candidate: 0.9999999999999261 \n","Score: 0.38415713858126327\n","\n","Candidate: 0.9999999999999265 \n","Score: 0.38415713858126327\n","\n","Candidate: 0.9999999999999275 \n","Score: 0.3841839160839163\n","\n","Candidate: 0.9999999999999283 \n","Score: 0.38420686205861776\n","\n","Candidate: 0.999999999999929 \n","Score: 0.3842220552884617\n","\n","Candidate: 0.9999999999999296 \n","Score: 0.3842255541069102\n","\n","Candidate: 0.9999999999999307 \n","Score: 0.3842603936533442\n","\n","Candidate: 0.9999999999999327 \n","Score: 0.38425218702865777\n","\n","Candidate: 0.9999999999999343 \n","Score: 0.38429107933950885\n","\n","Candidate: 0.9999999999999363 \n","Score: 0.38430648250831756\n","\n","Candidate: 0.9999999999999383 \n","Score: 0.384365233192005\n","\n","Candidate: 0.9999999999999386 \n","Score: 0.3843965430102094\n","\n","Candidate: 0.9999999999999394 \n","Score: 0.38445941015506246\n","\n","Candidate: 0.9999999999999416 \n","Score: 0.3844276435965092\n","\n","Candidate: 0.9999999999999432 \n","Score: 0.3844473122650139\n","\n","Candidate: 0.9999999999999446 \n","Score: 0.3844432234432236\n","\n","Candidate: 0.9999999999999463 \n","Score: 0.3844550178298525\n","\n","Candidate: 0.9999999999999472 \n","Score: 0.38445888594164473\n","\n","Candidate: 0.9999999999999485 \n","Score: 0.38445479619981626\n","\n","Candidate: 0.9999999999999496 \n","Score: 0.38458252028345496\n","\n","Candidate: 0.99999999999995 \n","Score: 0.38463471822295364\n","\n","Candidate: 0.9999999999999505 \n","Score: 0.38475561971540534\n","\n","Candidate: 0.9999999999999525 \n","Score: 0.3848082601961798\n","\n","Candidate: 0.9999999999999544 \n","Score: 0.3848166873449133\n","\n","Candidate: 0.9999999999999548 \n","Score: 0.38478476032715614\n","\n","Candidate: 0.9999999999999551 \n","Score: 0.3847648766328013\n","\n","Candidate: 0.9999999999999563 \n","Score: 0.3847894736842107\n","\n","Candidate: 0.999999999999958 \n","Score: 0.38478203393359023\n","\n","Candidate: 0.9999999999999603 \n","Score: 0.38478236397748605\n","\n","Candidate: 0.9999999999999618 \n","Score: 0.3847745538044047\n","\n","Candidate: 0.9999999999999623 \n","Score: 0.38474226588628774\n","\n","Candidate: 0.9999999999999631 \n","Score: 0.38473846153846164\n","\n","Candidate: 0.9999999999999645 \n","Score: 0.38471421085726276\n","\n","Candidate: 0.9999999999999656 \n","Score: 0.38470217231608783\n","\n","Candidate: 0.9999999999999667 \n","Score: 0.38472288776796987\n","\n","Candidate: 0.9999999999999685 \n","Score: 0.3847891464699685\n","\n","Candidate: 0.99999999999997 \n","Score: 0.3848100664767332\n","\n","Candidate: 0.9999999999999702 \n","Score: 0.38481043956043964\n","\n","Candidate: 0.9999999999999705 \n","Score: 0.3848649078194534\n","\n","Candidate: 0.9999999999999707 \n","Score: 0.3848649078194534\n","\n","Candidate: 0.9999999999999709 \n","Score: 0.3849031024224395\n","\n","Candidate: 0.9999999999999716 \n","Score: 0.3849031024224395\n","\n","Candidate: 0.9999999999999734 \n","Score: 0.3849492499202044\n","\n","Candidate: 0.9999999999999746 \n","Score: 0.3856044727744167\n","\n","Candidate: 0.9999999999999748 \n","Score: 0.3855764362220059\n","\n","Candidate: 0.9999999999999751 \n","Score: 0.39066807511737095\n","\n","Candidate: 0.9999999999999756 \n","Score: 0.3906610249177246\n","\n","Candidate: 0.999999999999976 \n","Score: 0.3906709039548023\n","\n","Candidate: 0.9999999999999765 \n","Score: 0.39068929750117876\n","\n","Candidate: 0.9999999999999767 \n","Score: 0.3907204910292729\n","\n","Candidate: 0.9999999999999769 \n","Score: 0.390783143939394\n","\n","Candidate: 0.9999999999999772 \n","Score: 0.3907761972498815\n","\n","Candidate: 0.9999999999999784 \n","Score: 0.39077777777777783\n","\n","Candidate: 0.9999999999999796 \n","Score: 0.3908050404184499\n","\n","Candidate: 0.9999999999999801 \n","Score: 0.3908109523809524\n","\n","Candidate: 0.9999999999999806 \n","Score: 0.39079971387696716\n","\n","Candidate: 0.9999999999999807 \n","Score: 0.3908400191021968\n","\n","Candidate: 0.9999999999999809 \n","Score: 0.3743265895953757\n","\n","Candidate: 0.9999999999999811 \n","Score: 0.3743265895953757\n","\n","Candidate: 0.9999999999999818 \n","Score: 0.3743260869565217\n","\n","Candidate: 0.9999999999999825 \n","Score: 0.3743628447024673\n","\n","Candidate: 0.9999999999999829 \n","Score: 0.374360465116279\n","\n","Candidate: 0.9999999999999835 \n","Score: 0.37441484716157203\n","\n","Candidate: 0.9999999999999838 \n","Score: 0.37447807017543855\n","\n","Candidate: 0.999999999999984 \n","Score: 0.39109628543499514\n","\n","Candidate: 0.9999999999999843 \n","Score: 0.39109628543499514\n","\n","Candidate: 0.9999999999999848 \n","Score: 0.39122401960784314\n","\n","Candidate: 0.999999999999986 \n","Score: 0.39119538537064313\n","\n","Candidate: 0.9999999999999871 \n","Score: 0.39118217626784835\n","\n","Candidate: 0.9999999999999873 \n","Score: 0.39121117705242336\n","\n","Candidate: 0.9999999999999875 \n","Score: 0.39121117705242336\n","\n","Candidate: 0.9999999999999877 \n","Score: 0.39126934523809526\n","\n","Candidate: 0.999999999999988 \n","Score: 0.391294088425236\n","\n","Candidate: 0.9999999999999888 \n","Score: 0.39132338308457715\n","\n","Candidate: 0.9999999999999896 \n","Score: 0.39131487025948103\n","\n","Candidate: 0.9999999999999898 \n","Score: 0.391303848075962\n","\n","Candidate: 0.9999999999999901 \n","Score: 0.3796846846846847\n","\n","Candidate: 0.9999999999999902 \n","Score: 0.37970075187969926\n","\n","Candidate: 0.9999999999999905 \n","Score: 0.3797084592145015\n","\n","Candidate: 0.9999999999999906 \n","Score: 0.3797084592145015\n","\n","Candidate: 0.9999999999999911 \n","Score: 0.37979817905918056\n","\n","Candidate: 0.9999999999999916 \n","Score: 0.3798009118541033\n","\n","Candidate: 0.999999999999992 \n","Score: 0.3804945904173106\n","\n","Candidate: 0.9999999999999922 \n","Score: 0.3804883720930232\n","\n","Candidate: 0.9999999999999926 \n","Score: 0.38061093749999997\n","\n","Candidate: 0.9999999999999929 \n","Score: 0.38057746478873233\n","\n","Candidate: 0.9999999999999931 \n","Score: 0.38055259026687593\n","\n","Candidate: 0.9999999999999933 \n","Score: 0.38055259026687593\n","\n","Candidate: 0.9999999999999938 \n","Score: 0.38063091482649836\n","\n","Candidate: 0.999999999999994 \n","Score: 0.38069668246445487\n","\n","Candidate: 0.9999999999999942 \n","Score: 0.3807246835443038\n","\n","Candidate: 0.9999999999999944 \n","Score: 0.38072857142857136\n","\n","Candidate: 0.9999999999999947 \n","Score: 0.38072857142857136\n","\n","Candidate: 0.9999999999999949 \n","Score: 0.3807942583732057\n","\n","Candidate: 0.9999999999999951 \n","Score: 0.3809903691813803\n","\n","Candidate: 0.9999999999999953 \n","Score: 0.3810337620578777\n","\n","Candidate: 0.9999999999999956 \n","Score: 0.38107269789983833\n","\n","Candidate: 0.9999999999999958 \n","Score: 0.3810681818181817\n","\n","Candidate: 0.999999999999996 \n","Score: 0.3810681818181817\n","\n","Candidate: 0.9999999999999962 \n","Score: 0.3811566068515496\n","\n","Candidate: 0.9999999999999964 \n","Score: 0.38113770491803267\n","\n","Candidate: 0.9999999999999967 \n","Score: 0.38110344827586196\n","\n","Candidate: 0.9999999999999969 \n","Score: 0.38119467554076525\n","\n","Candidate: 0.9999999999999971 \n","Score: 0.38117999999999985\n","\n","Candidate: 0.9999999999999973 \n","Score: 0.36966189667717664\n","\n","Candidate: 0.9999999999999974 \n","Score: 0.36966189667717664\n","\n","Candidate: 0.9999999999999976 \n","Score: 0.36969019226089056\n","\n","Candidate: 0.9999999999999978 \n","Score: 0.36981426121048744\n","\n","Candidate: 0.999999999999998 \n","Score: 0.3872769982993196\n","\n","Candidate: 0.9999999999999982 \n","Score: 0.38726167325568955\n","\n","Candidate: 0.9999999999999984 \n","Score: 0.3875132689118048\n","\n","Candidate: 0.9999999999999987 \n","Score: 0.39297149910233375\n","\n","Candidate: 0.9999999999999989 \n","Score: 0.3986813144379657\n","\n","Candidate: 0.9999999999999991 \n","Score: 0.39938333731771447\n","\n","Candidate: 0.9999999999999993 \n","Score: 0.39976694323502826\n","\n","Candidate: 0.9999999999999996 \n","Score: 0.3998319317130602\n","\n","Candidate: 0.9999999999999998 \n","Score: 0.4008403106474886\n","\n","Candidate: 1.0 \n"]}]},{"cell_type":"code","source":["# aim is to minimise cost function -- find index in array where this is the case\n","lowest_cf_score = np.min(np.array(cost_function_values))\n","index_best_th = np.argmin(np.array(cost_function_values))"],"metadata":{"id":"P2IsLZXQ77oZ","executionInfo":{"status":"ok","timestamp":1650971390376,"user_tz":-60,"elapsed":38,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}}},"execution_count":304,"outputs":[]},{"cell_type":"code","source":["lowest_cf_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iZ3ba0jhY0I","executionInfo":{"status":"ok","timestamp":1650971390378,"user_tz":-60,"elapsed":39,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"32c6511c-2507-4c10-c754-4e540806a624"},"execution_count":305,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.36966189667717664"]},"metadata":{},"execution_count":305}]},{"cell_type":"code","source":["index_best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBS0v3GAh77m","executionInfo":{"status":"ok","timestamp":1650971390382,"user_tz":-60,"elapsed":35,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"5d5fb493-b14d-437b-f05e-9d0782281115"},"execution_count":306,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1170"]},"metadata":{},"execution_count":306}]},{"cell_type":"code","source":["best_th = list(threshold_candidates)[index_best_th]\n","best_th"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmy0bv8N8YvW","executionInfo":{"status":"ok","timestamp":1650971390384,"user_tz":-60,"elapsed":29,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"96435d55-7465-4ec0-b08c-9ac3a089c5d1"},"execution_count":307,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9999999999999973"]},"metadata":{},"execution_count":307}]},{"cell_type":"markdown","source":["#### Testing with best threshold"],"metadata":{"id":"ypFTpLSAir09"}},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  final_classifications = {}\n","  ttps = []\n","  earliness = []\n","\n","  # create nN predictions excluding the current test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # count inconclusive results\n","  inconc_count = 0\n","  \n","  ## use KNN to evaluate the prediction for each of the samples individually\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    print(f\"Sample {test_sample_name}\")  \n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","      if(c > best_th): # best confidence threshold from cost function\n","        time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","        time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","        pred = predictions[i]\n","        final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","        print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","        if(pred == 1.0):\n","          print(f\"Earliness:  {time_index/timestamps[-1]}\")\n","          print(f\"TTP: {time_to_result + 30}s\")\n","          earliness.append(time_index/timestamps[-1])\n","        break\n","      if(i == len(predictions)-1):\n","        print(\"Inconclusive\")\n","        inconc_count += 1\n","    \n","    sample_idx += 1\n","    print(\"\")\n","\n","  print(f\"Accuracy: {accuracy(final_classifications)}\")\n","  print(f\"Sensitivity/Recall: {sensitivity(final_classifications)}\")\n","  print(f\"Specificity: {specificity(final_classifications)}\")\n","  print(f\"Precision: {precision(final_classifications)}\")\n","  print(f\"F1 Score: {f1(final_classifications)}\")\n","  print(f\"Average Earliness: {sum(earliness)/len(earliness)}\")\n","  print(f\"Total Inconclusive: {inconc_count}/{sample_idx}\")\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfPwqWWHiqnY","executionInfo":{"status":"ok","timestamp":1650971628552,"user_tz":-60,"elapsed":3379,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"97396a34-6b98-4679-9504-fab3fe84fd1b"},"execution_count":309,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample exp_118_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_86_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.58\n","TTP: 680.0s\n","\n","Sample exp_129_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_165_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.62\n","TTP: 720.0s\n","\n","Sample exp_35_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.8\n","TTP: 937.0s\n","\n","Sample exp_28_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_14_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_40_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_88_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.94\n","TTP: 1100.0s\n","\n","Sample exp_27_pos\n","Inconclusive\n","\n","Sample exp_134_pos\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.6\n","TTP: 692s\n","\n","Sample exp_97_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_2d1_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample exp_64_pos\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample g1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.6\n","TTP: 691.0s\n","\n","Sample g2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.6\n","TTP: 702.0s\n","\n","Sample g3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.6\n","TTP: 721.0s\n","\n","Sample g5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.6\n","TTP: 694.0s\n","\n","Sample rv1_ap1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.58\n","TTP: 666.0s\n","\n","Sample rv1_ap2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.68\n","TTP: 792.0s\n","\n","Sample arv7_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.6\n","TTP: 797.0s\n","\n","Sample rv1y_p3\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.7\n","TTP: 799.0s\n","\n","Sample rv1y_p4\n","Predicted Label: 0.0 \t True Label: 1.0 \t Correct?: False\n","\n","Sample arv7_p1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.58\n","TTP: 697.0s\n","\n","Sample arv7_p4\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.62\n","TTP: 1005.0s\n","\n","Sample b1\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.6\n","TTP: 672.0s\n","\n","Sample b2\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.6\n","TTP: 694.0s\n","\n","Sample b5\n","Predicted Label: 1.0 \t True Label: 1.0 \t Correct?: True\n","Earliness:  0.64\n","TTP: 733.0s\n","\n","Sample exp_118_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_86_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_129_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_165_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_35_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_28_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_14_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.9\n","TTP: 1051s\n","\n","Sample exp_40_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.76\n","TTP: 891s\n","\n","Sample exp_88_neg\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.94\n","TTP: 1103s\n","\n","Sample exp_27_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_134_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_97_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_2d1_neg\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample exp_64_neg\n","Inconclusive\n","\n","Sample yap\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.6\n","TTP: 693.0s\n","\n","Sample yap1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample yap1n1\n","Inconclusive\n","\n","Sample arv72\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv73\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145y_n1\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample arv7\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145a_p1\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.74\n","TTP: 859.0s\n","\n","Sample du145a_p2\n","Predicted Label: 0.0 \t True Label: 0.0 \t Correct?: True\n","\n","Sample du145a_p3\n","Predicted Label: 1.0 \t True Label: 0.0 \t Correct?: False\n","Earliness:  0.9\n","TTP: 1043.0s\n","\n","Accuracy: 0.6938775510204082\n","Sensitivity/Recall: 0.6666666666666666\n","Specificity: 0.7272727272727273\n","Precision: 0.75\n","F1 Score: 0.7058823529411765\n","Average Earliness: 0.6824999999999998\n","Total Inconclusive: 3/52\n"]}]},{"cell_type":"markdown","source":["#### Testing with different alpha values"],"metadata":{"id":"w43_TkUVitvi"}},{"cell_type":"code","source":["positives = {\"exp_118_pos\":exp_118_pos, \"exp_86_pos\":exp_86_pos,\"exp_129_pos\":exp_129_pos, \"exp_165_pos\":exp_165_pos, \n","             \"exp_35_pos\":exp_35_pos, \"exp_28_pos\":exp_28_pos, \"exp_14_pos\":exp_14_pos, \"exp_40_pos\":exp_40_pos, \n","             \"exp_88_pos\":exp_88_pos, \"exp_27_pos\":exp_27_pos, \n","             \"exp_134_pos\":exp_134_pos, \"exp_97_pos\":exp_97_pos, \"exp_2d1_pos\":exp_2d1_pos, \"exp_64_pos\":exp_64_pos, \n","             \"g1\":g1, \"g2\":g2, \"g3\":g3, \"g5\":g5, \"rv1_ap1\":rv1_ap1, \"rv1_ap2\":rv1_ap2,  \n","             \"arv7_p3\":arv7_p3,\"rv1y_p3\":rv1y_p3, \"rv1y_p4\":rv1y_p4, \n","             \"arv7_p1\":arv7_p1, \"arv7_p4\":arv7_p4, \"b1\":b1, \"b2\":b2, \"b5\":b5}\n","\n","negatives = {\"exp_118_neg\":exp_118_neg, \"exp_86_neg\":exp_86_neg, \"exp_129_neg\":exp_129_neg, \"exp_165_neg\":exp_165_neg, \n","             \"exp_35_neg\":exp_35_neg, \"exp_28_neg\":exp_28_neg, \"exp_14_neg\":exp_14_neg, \"exp_40_neg\":exp_40_neg, \n","             \"exp_88_neg\":exp_88_neg, \"exp_27_neg\":exp_27_neg, \"exp_134_neg\":exp_134_neg, \"exp_97_neg\":exp_97_neg, \n","             \"exp_2d1_neg\":exp_2d1_neg, \"exp_64_neg\":exp_64_neg, \"yap\":yap, \"yap1\":yap1, \"yap1n1\":yap1n1, \"arv72\":arv72, \n","             \"arv73\":arv73, \"du145y_n1\":du145y_n1, \"arv7\":arv7, \n","             \"du145a_p1\":du145a_p1, \"du145a_p2\":du145a_p2, \"du145a_p3\":du145a_p3\n","             }"],"metadata":{"id":"pJXWD05RjB-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["number_of_samples = len(g1['Average Output'])\n","number_of_timestamps = 50\n","\n","timestep = int(number_of_samples/number_of_timestamps)\n","timestamps = [*range(timestep, number_of_samples+timestep, timestep)]"],"metadata":{"id":"NSkTWcddjB-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(timestamps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650968988297,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"7210cbac-d92a-4dbe-c55b-32a102e5089c","id":"KWOXfxRKjB-i"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400]\n"]}]},{"cell_type":"code","source":["## combine positive and negative sample dicts\n","all_samples = {}\n","all_samples.update(positives)\n","all_samples.update(negatives)\n","\n","## create dict of samples with true label\n","keys = list(all_samples.keys())\n","true_labels_array = list(np.concatenate((np.ones(len(positives)),np.zeros(len(negatives)))))\n","true_label_dict = dict(zip(keys, true_labels_array))"],"metadata":{"id":"NXrd_74JjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  # create nN predictions using each dataset as the test sample\n","  sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","  # create multipliers for every classifier\n","  multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","  # sample index\n","  sample_idx = 0\n","\n","  # create set for all confidence values\n","  confidence_set = set()\n","  \n","\n","  for key, value in all_samples.items():\n","    test_sample_name = key\n","    test_sample = value\n","\n","    # get KNN predictions for the sample\n","    predictions = sample_predictions[sample_idx]\n","\n","    confidences = []\n","\n","    # for each prediction get the confidence and add to confidence array for the sample\n","    for i in range(len(predictions)):\n","      c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","      confidences.append(c)\n","    \n","    # update set with confidence values\n","    confidence_set = confidence_set.union(set(confidences))\n","    \n","    sample_idx += 1"],"metadata":{"id":"wcE9LintjB-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confidence_set = sorted(confidence_set)"],"metadata":{"id":"qb9FWSPgjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold_candidates = set()\n","\n","# threshold candidates are mad of the mean of every pair of values in confidence set after sorting\n","for i in range(1,len(confidence_set)):\n","  mean = 0.5*(confidence_set[i] + confidence_set[i-1])\n","  threshold_candidates.add(mean) \n","\n","# sort candidates (only for ordering purposes)\n","threshold_candidates = sorted(threshold_candidates)"],"metadata":{"id":"bM7ILJSwjB-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(threshold_candidates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650968996424,"user_tz":-60,"elapsed":9,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"ff02e445-3813-4771-ca60-b43eac52fd34","id":"36WDfG-TjB-l"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1184"]},"metadata":{},"execution_count":287}]},{"cell_type":"code","source":["with tf.device(gpu):\n","\n","  acc = []\n","  ear = []\n","\n","  for i in range(0,100,5):\n","\n","    \n","    # alpha\n","    alpha = i/100\n","\n","    print(f\"Alpha: {alpha}\")\n","\n","    # array to hold cost function value for each candidate\n","    cost_function_values = []\n","\n","    # create nN predictions using each dataset as the test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # evaluate every candidate\n","    for th in threshold_candidates:\n","\n","      # print(f\"Candidate: {th} \")\n","\n","      # array to hold earliness values for the samples \n","      earliness = []  \n","\n","      # dict to hold predictions vs true values for the samples  \n","      final_classifications = {}\n","\n","      # sample index\n","      sample_idx = 0\n","\n","      for key, value in all_samples.items():\n","        test_sample_name = key\n","        test_sample = value\n","  \n","        # get KNN predicition for the sample\n","        predictions = sample_predictions[sample_idx]\n","\n","        for i in range(len(predictions)):\n","\n","          # get the confidence for that prediction \n","          c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","\n","          if(c > th): # check if confidence is above confidence threshold\n","\n","            time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","            time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","            # predicted class for the sample is given by the prediction which led to the gien confidence value\n","            pred = predictions[i]\n","\n","            # update final outcomes dict\n","            final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","            # add to earliness array\n","            earliness.append(time_index/timestamps[-1])\n","        \n","        sample_idx += 1\n","\n","      # get avg accuracy and avg earliness for this threshold\n","      if(len(final_classifications) > 0):\n","        avg_accuracy = accuracy(final_classifications)\n","        avg_earliness = sum(earliness)/len(earliness)\n","\n","        # compute value of cost function and add to array \n","        cf_score = alpha*(1-avg_accuracy) + (1-alpha)*avg_earliness\n","        cost_function_values.append(cf_score)\n","        # print(f\"Score: {cf_score}\")\n","        # print(\"\")\n","\n","    index_best_th = np.argmin(np.array(cost_function_values))    \n","    best_th = list(threshold_candidates)[index_best_th]\n","\n","###########################################################################################################\n","\n","    ## teating with best th\n","    final_classifications = {}\n","    earliness = []\n","\n","    # create nN predictions excluding the current test sample\n","    sample_predictions, true_labels = generate_predictions_table(positives, negatives, timestamps)\n","\n","    # create multipliers for every classifier\n","    multipliers_2d = get_confidence_multipliers(sample_predictions, true_labels)\n","\n","    # sample index\n","    sample_idx = 0\n","\n","    # count inconclusive results\n","    inconc_count = 0\n","    \n","    ## use KNN to evaluate the prediction for each of the samples individually\n","    for key, value in all_samples.items():\n","      test_sample_name = key\n","      test_sample = value\n","\n","      # print(f\"Sample {test_sample_name}\")  \n","      predictions = sample_predictions[sample_idx]\n","\n","      confidences = []\n","      for i in range(len(predictions)):\n","        c = get_confidence(predictions[:i+1], multipliers_2d[:i+1]) # i+1 needed because slicing does not include last index \n","        confidences.append(c)\n","      \n","        if(c > best_th): # best confidence threshold from cost function\n","          time_index = timestamps[i] # get the value of the sample number at which the sample needs to be indexed\n","          time_to_result = test_sample.index[time_index-1] - test_sample.index[0] # get actual time acorrding the experiment at which result is obtained\n","\n","          pred = predictions[i]\n","          final_classifications[test_sample_name] = (pred, true_label_dict[test_sample_name])\n","\n","          # print(f\"Predicted Label: {pred} \\t True Label: {true_label_dict[test_sample_name]} \\t Correct?: {pred == true_label_dict[test_sample_name]}\")\n","          if(pred == 1.0):\n","            # print(f\"Earliness:  {time_index/timestamps[-1]}\")\n","            # print(f\"TTP: {time_to_result + 30}s\")\n","            earliness.append(time_index/timestamps[-1])\n","          break\n","        if(i == len(predictions)-1):\n","          # print(\"Inconclusive\")\n","          inconc_count += 1\n","      \n","      sample_idx += 1\n","      # print(\"\")\n","    print(f\"Avg Accuracy: {accuracy(final_classifications)}\")\n","    print(f\"Avg Earliness: {sum(earliness)/len(earliness)}\")\n","    acc.append(accuracy(final_classifications))\n","    ear.append(sum(earliness)/len(earliness))"],"metadata":{"id":"V6Fhz4hsiui6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axes = plt.subplots(1,1, figsize=(10,5))\n","x = acc\n","y = ear\n","axes.set_xlabel(\"Accuracy\")\n","axes.set_ylabel(\"Earliness\")\n","axes.plot(x,y, '-o')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"R0a7Bbrabp6R","executionInfo":{"status":"ok","timestamp":1650971390375,"user_tz":-60,"elapsed":413,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"515fdaf6-b702-4295-b9ea-d6d5335a1c65"},"execution_count":303,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f4beafecad0>]"]},"metadata":{},"execution_count":303},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"simepEdKIiL0"},"source":["### Github Commands"]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"YdlGDV3AzZ1L","executionInfo":{"status":"ok","timestamp":1650961414692,"user_tz":-60,"elapsed":357,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"}},"outputId":"4e4dd5b2-c85f-4c90-caa5-1c386577e332","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113155,"status":"ok","timestamp":1650961528088,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"itbAqo9qGukN","outputId":"29cbd0b5-27e2-4ce5-a491-7a13c89f317e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Final-Year-Project\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   Early Time Series Classification - Average Ouput.ipynb\u001b[m\n","\t\u001b[31mmodified:   Early Time Series Classification - Pixel Data NN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Visualisations.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}],"source":["username = \"adityag16\"\n","git_token = \"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\"\n","repository = \"/content/drive/MyDrive/Final-Year-Project\"\n","%cd {repository}\n","!git status"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1436,"status":"ok","timestamp":1650961529517,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"pNInxPqdG7nx","outputId":"71ee6316-d857-404e-9633-2f8b80e7d103"},"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git reset HEAD <file>...\" to unstage)\n","\n","\t\u001b[32mmodified:   Early Time Series Classification - Average Ouput.ipynb\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   Early Time Series Classification - Pixel Data NN.ipynb\u001b[m\n","\t\u001b[31mmodified:   Visualisations.ipynb\u001b[m\n","\n"]}],"source":["!git add 'Early Time Series Classification - Average Ouput.ipynb' 'Best Performances.docx'\n","!git status"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32447,"status":"ok","timestamp":1650961561959,"user":{"displayName":"Aditya Gupta","userId":"18047065785542078813"},"user_tz":-60},"id":"K1tS6nonHF9u","outputId":"9eac15d8-d647-47de-a286-da780442b593"},"outputs":[{"output_type":"stream","name":"stdout","text":["[main 4902339] Commented code and Cleanup notebook\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite Early Time Series Classification - Average Ouput.ipynb (93%)\n","Counting objects: 3, done.\n","Delta compression using up to 2 threads.\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 1.95 KiB | 332.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/adityag16/Final-Year-Project\n","   d220401..4902339  main -> main\n"]}],"source":["!git config --global user.email \"aditya.gupta18@imperial.ac.uk\"\n","!git config --global user.name \"adityag16\"\n","\n","!git commit -m \"Commented code and Cleanup notebook\"\n","!git push origin main"]},{"cell_type":"code","source":[""],"metadata":{"id":"8KO_iVTj0cIP"},"execution_count":null,"outputs":[]}]}